[
  "import base64\nimport contextlib\nimport io\nimport json\nimport os.path as osp\n\nimport PIL.Image\n\nfrom labelme import PY2\nfrom labelme import QT4\nfrom labelme import __version__\nfrom labelme import utils\nfrom labelme.logger import logger\n\nPIL.Image.MAX_IMAGE_PIXELS = None\n\n\n@contextlib.contextmanager\ndef open(name, mode):\n    assert mode in [\"r\", \"w\"]\n    if PY2:\n        mode += \"b\"\n        encoding = None\n    else:\n        encoding = \"utf-8\"\n    yield io.open(name, mode, encoding=encoding)\n    return\n\n\nclass LabelFileError(Exception):\n    pass\n\n\nclass LabelFile(object):\n    suffix = \".json\"\n\n    def __init__(self, filename=None):\n        self.shapes = []\n        self.imagePath = None\n        self.imageData = None\n",
  "    long_description=LONG_DESCRIPTION,\n    url='https://youtube-wrapper.readthedocs.io/en/latest/index.html',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Operating System :: OS Independent'\n    ],\n)\n",
  "                self.prevhVertex = self.hVertex\n                self.hVertex = None\n                self.prevhShape = self.hShape = shape\n                self.prevhEdge = self.hEdge\n                self.hEdge = None\n                self.setToolTip(\n                    self.tr(\"Click & drag to move shape '%s'\") % shape.label\n                )\n                self.setStatusTip(self.toolTip())\n                self.overrideCursor(CURSOR_GRAB)\n                self.update()\n                break\n        else:  # Nothing found, clear highlights, reset state.\n            self.unHighlight()\n        self.vertexSelected.emit(self.hVertex is not None)\n\n    def addPointToEdge(self):\n        shape = self.prevhShape\n        index = self.prevhEdge\n        point = self.prevMovePoint\n        if shape is None or index is None or point is None:\n            return\n        shape.insertPoint(index, point)\n        shape.highlightVertex(index, shape.MOVE_VERTEX)\n        self.hShape = shape\n        self.hVertex = index\n        self.hEdge = None\n        self.movingShape = True\n\n    def removeSelectedPoint(self):\n        shape = self.prevhShape\n        index = self.prevhVertex\n        if shape is None or index is None:\n            return\n        shape.removePoint(index)\n        shape.highlightClear()\n        self.hShape = shape\n        self.prevhVertex = None\n        self.movingShape = True  # Save changes\n\n",
  "    if out_file:\n        out_file = osp.abspath(out_file)\n        if osp.exists(out_file):\n            raise RuntimeError(\"File exists: %s\" % out_file)\n        else:\n            open(osp.abspath(out_file), \"w\")\n\n    cmd = (\n        \"docker run -it --rm\"\n        \" -e DISPLAY={0}:0\"\n        \" -e QT_X11_NO_MITSHM=1\"\n        \" -v /tmp/.X11-unix:/tmp/.X11-unix\"\n        \" -v {1}:{2}\"\n        \" -w /home/developer\"\n    )\n    in_file_a = osp.abspath(in_file)\n    in_file_b = osp.join(\"/home/developer\", osp.basename(in_file))\n    cmd = cmd.format(\n        ip,\n        in_file_a,\n        in_file_b,\n    )\n    if out_file:\n        out_file_a = osp.abspath(out_file)\n        out_file_b = osp.join(\"/home/developer\", osp.basename(out_file))\n        cmd += \" -v {0}:{1}\".format(out_file_a, out_file_b)\n    cmd += \" wkentaro/labelme labelme {0}\".format(in_file_b)\n    if out_file:\n        cmd += \" -O {0}\".format(out_file_b)\n    subprocess.call(shlex.split(cmd))\n\n    if out_file:\n        try:\n            json.load(open(out_file))\n            return out_file\n        except Exception:\n            if open(out_file).read() == \"\":\n                os.remove(out_file)\n            raise RuntimeError(\"Annotation is cancelled.\")\n\n",
  "import torch\nfrom tqdm import tqdm\nfrom torch.nn import CrossEntropyLoss\nfrom torch import optim\nfrom torchvision.transforms import Compose, Resize, RandomCrop, ToTensor, Normalize\nfrom torch.utils.tensorboard import SummaryWriter\nfrom utils import save_checkpoint, load_checkpoint, print_examples\nfrom create_dataset import get_loader\nfrom model import CNNToRNN\n\n\ndef train():\n    transforms = Compose(\n        [\n            Resize((356, 356)),\n            RandomCrop((299, 299)),\n            ToTensor(),\n            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ]\n    )\n\n    train_loader, dataset = get_loader(\n        images_dir=\"raw-data/Images\",\n        captions_file=\"raw-data/captions.txt\",\n        transforms=transforms,\n        num_workers=2,\n    )\n\n    torch.backends.cudnn.benchmark = True\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    load_model = False\n    save_model = False\n    train_CNN = False\n\n    # Hyperparameters\n    embed_size = 256\n    hidden_size = 256\n    vocab_size = len(dataset.vocabulary)\n    num_layers = 1\n    learning_rate = 3e-4\n",
  "            createLineMode=createLineMode,\n            createPointMode=createPointMode,\n            createLineStripMode=createLineStripMode,\n            createAiPolygonMode=createAiPolygonMode,\n            createAiMaskMode=createAiMaskMode,\n            zoom=zoom,\n            zoomIn=zoomIn,\n            zoomOut=zoomOut,\n            zoomOrg=zoomOrg,\n            keepPrevScale=keepPrevScale,\n            fitWindow=fitWindow,\n            fitWidth=fitWidth,\n            brightnessContrast=brightnessContrast,\n            zoomActions=zoomActions,\n            openNextImg=openNextImg,\n            openPrevImg=openPrevImg,\n            fileMenuActions=(open_, opendir, save, saveAs, close, quit),\n            tool=(),\n            # XXX: need to add some actions here to activate the shortcut\n            editMenu=(\n                edit,\n                duplicate,\n                copy,\n                paste,\n                delete,\n                None,\n                undo,\n                undoLastPoint,\n                None,\n                removePoint,\n                None,\n                toggle_keep_prev_mode,\n            ),\n            # menu shown at right click\n            menu=(\n                createMode,\n                createRectangleMode,\n                createCircleMode,\n                createLineMode,\n                createPointMode,\n",
  "            llm=self.chat_model,\n            prompt=self.mapping_prompt.chat_prompt,\n            output_parser=self.mapping_prompt.parser,\n            verbose=debug,\n            output_key=\"mapping_list\",\n        )\n\n        overall_chain = SequentialChain(\n            chains=[travel_agent, parser],\n            input_variables=[\"query\", \"format_instructions\"],\n            output_variables=[\"agent_suggestion\", \"mapping_list\"],\n            verbose=debug,\n        )\n\n        return overall_chain\n\n    def suggest_travel(self, query):\n        \"\"\"\n\n        Parameters\n        ----------\n        query\n\n        Returns\n        -------\n\n        \"\"\"\n        self.logger.info(\"Validating query\")\n        t1 = time.time()\n        self.logger.info(\n            \"Calling validation (model is {}) on user input\".format(\n                self.chat_model.model_name\n            )\n        )\n        validation_result = self.validation_chain(\n            {\n                \"query\": query,\n                \"format_instructions\": self.validation_prompt.parser.get_format_instructions(),\n            }\n        )\n",
  "# Scrapy settings for slidesmodel project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     https://docs.scrapy.org/en/latest/topics/settings.html\n#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = \"slidesmodel\"\n\nSPIDER_MODULES = [\"slidesmodel.spiders\"]\nNEWSPIDER_MODULE = \"slidesmodel.spiders\"\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = \"slidesmodel (+http://www.yourdomain.com)\"\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n",
  "from langchain.tools import tool\nfrom .helpers import advanced_video_search\nfrom youtube.models import Search\n\n\nclass FindProductVideoTools():\n    @tool\n    def find_product_video_id(product: str) -> str:\n        \"\"\"Useful when you need to find a product review video from youtube.\"\"\"\n        query: str = f'reviews of the latest {product}'\n        search_results: list[Search] = advanced_video_search(query)\n        return search_results[0].resource_id\n        \n        ",
  "# flake8: noqa\n\nfrom . import draw_json\nfrom . import draw_label_png\nfrom . import export_json\nfrom . import on_docker\n",
  "ef generate_bookmarks(users: list[User], posts: list[Post], bookmarks_count: int = 100) -> list[Bookmark]:\n    \"\"\"Generate bookmarks.\"\"\"\n    bookmarks: list[Bookmark] = []\n    ids = set()\n    for _ in range(bookmarks_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        bookmark: bookmark = Bookmark(author_id=author_id, post_id=post_id)\n        if (author_id, post_id) not in ids:\n            bookmarks.append(bookmark)\n        ids.add((author_id, post_id))\n    return bookmarks\n\ndef generate_comments(users: list[User], posts: list[Post], comments_count: int = 500) -> list[Like]:\n    \"\"\"Generate likes.\"\"\"\n    comments: list[Comment] = []\n    ids = set()\n    for _ in range(comments_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        comment: comment = Comment(\n            id='Comment_' + str(uuid4()),\n            author_id=author_id, \n            post_id=post_id, \n            comment_text=fake.text() )\n        if (author_id, post_id) not in ids:\n            comments.append(comment)\n        ids.add((author_id, post_id))\n    return comments",
  "from crewai import Agent\nfrom tools import FindProductVideoTools, FindProductReviewTools\nfrom langchain.llms.openai import OpenAI\nfrom langchain.chat_models import ChatOpenAI\n\n\nclass ProductReviewAgents():\n    def research_analyst(self):\n        return Agent(\n        role='Product Video Researcher',\n        goal=\"\"\"Find the best product review videos from youtube\"\"\",\n        backstory=\"\"\"Known for your indepth knowledge of various videos that \n        analyze different products on youtube. Now you have to find the best video that \n        reviews the given product.\"\"\",\n        llm=OpenAI(temperature=0.7),\n        verbose=True,\n        tools=[\n            FindProductVideoTools.find_product_video_id,\n            FindProductReviewTools.find_product_reviews\n        ]\n  )",
  "        return None\n\n    def addRecentFile(self, filename):\n        if filename in self.recentFiles:\n            self.recentFiles.remove(filename)\n        elif len(self.recentFiles) >= self.maxRecent:\n            self.recentFiles.pop()\n        self.recentFiles.insert(0, filename)\n\n    # Callbacks\n\n    def undoShapeEdit(self):\n        self.canvas.restoreShape()\n        self.labelList.clear()\n        self.loadShapes(self.canvas.shapes)\n        self.actions.undo.setEnabled(self.canvas.isShapeRestorable)\n\n    def tutorial(self):\n        url = \"https://github.com/wkentaro/labelme/tree/main/examples/tutorial\"  # NOQA\n        webbrowser.open(url)\n\n    def toggleDrawingSensitive(self, drawing=True):\n        \"\"\"Toggle drawing sensitive.\n\n        In the middle of drawing, toggling between modes should be disabled.\n        \"\"\"\n        self.actions.editMode.setEnabled(not drawing)\n        self.actions.undoLastPoint.setEnabled(drawing)\n        self.actions.undo.setEnabled(not drawing)\n        self.actions.delete.setEnabled(not drawing)\n\n    def toggleDrawMode(self, edit=True, createMode=\"polygon\"):\n        draw_actions = {\n            \"polygon\": self.actions.createMode,\n            \"rectangle\": self.actions.createRectangleMode,\n            \"circle\": self.actions.createCircleMode,\n            \"point\": self.actions.createPointMode,\n            \"line\": self.actions.createLineMode,\n            \"linestrip\": self.actions.createLineStripMode,\n            \"ai_polygon\": self.actions.createAiPolygonMode,\n",
  "\n    def __init__(self):\n        super().__init__(\n            encoder_path=gdown.cached_download(\n                url=\"https://github.com/wkentaro/labelme/releases/download/sam-20230416/sam_vit_h_4b8939.quantized.encoder.onnx\",  # NOQA\n                md5=\"958b5710d25b198d765fb6b94798f49e\",\n            ),\n            decoder_path=gdown.cached_download(\n                url=\"https://github.com/wkentaro/labelme/releases/download/sam-20230416/sam_vit_h_4b8939.quantized.decoder.onnx\",  # NOQA\n                md5=\"a997a408347aa081b17a3ffff9f42a80\",\n            ),\n        )\n\n\nclass EfficientSamVitT(EfficientSam):\n    name = \"EfficientSam (speed)\"\n\n    def __init__(self):\n        super().__init__(\n            encoder_path=gdown.cached_download(\n                url=\"https://github.com/labelmeai/efficient-sam/releases/download/onnx-models-20231225/efficient_sam_vitt_encoder.onnx\",  # NOQA\n                md5=\"2d4a1303ff0e19fe4a8b8ede69c2f5c7\",\n            ),\n            decoder_path=gdown.cached_download(\n                url=\"https://github.com/labelmeai/efficient-sam/releases/download/onnx-models-20231225/efficient_sam_vitt_decoder.onnx\",  # NOQA\n                md5=\"be3575ca4ed9b35821ac30991ab01843\",\n            ),\n        )\n\n\nclass EfficientSamVitS(EfficientSam):\n    name = \"EfficientSam (accuracy)\"\n\n    def __init__(self):\n        super().__init__(\n            encoder_path=gdown.cached_download(\n                url=\"https://github.com/labelmeai/efficient-sam/releases/download/onnx-models-20231225/efficient_sam_vits_encoder.onnx\",  # NOQA\n                md5=\"7d97d23e8e0847d4475ca7c9f80da96d\",\n            ),\n            decoder_path=gdown.cached_download(\n",
  "from sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, MappedAsDataclass\nfrom sqlalchemy.orm import sessionmaker\nfrom ...config.config import BaseConfig\nfrom contextlib import contextmanager\nfrom flask import current_app\n\n\nclass Base(MappedAsDataclass, DeclarativeBase):\n    pass\n\nSQLALCHEMY_DATABASE_URI = BaseConfig().db_conn_string\nengine = create_engine(SQLALCHEMY_DATABASE_URI)\nSession = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n\ndef create_all():\n    Base.metadata.create_all(bind=engine)\n    \ndef drop_all():\n    Base.metadata.drop_all(bind=engine)\n\n@contextmanager\ndef get_db():\n    try:\n        db = Session()\n        yield db\n    finally:\n        db.close()",
  "\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n    cleaned_comments: list[str] = list(map(clean_text, all_comments))\n    comments: list[str] = choices(population=cleaned_comments, k=10)\n    docs: list[Document] = [\n        Document(page_content=comment)\n        for comment in comments\n        if is_acceptable_len(comment)\n    ]\n    comments: list[dict[str, str | int]] = [\n        {\"doc_id\": i + 1, \"comment\": docs[i].page_content} for i in range(len(docs))\n    ]\n\ndata_dir = \"./agent_nelly/data_analysis/data\"\nfeatures_dir = \"features\"\nsave_features_dir = path.join(data_dir, features_dir, \"features.json\")\n\nwith open(save_features_dir, 'r') as f:\n    topics: list[str] = json.load(f)\n\n\nclass CustomerCommentData(BaseModel):\n    doc_id: int = Field(description=\"The doc_id from the input\")\n    topics: list[str] = Field(\n        description=\"List of the relevant topics for the customer review. Include only topics from the list provided.\",\n        default_factory=list,\n    )\n    sentiment: str = Field(\n        description=\"Sentiment of the topic\", enum=[\"positive\", \"neutral\", \"negative\"]\n    )\n    \n\nclass CommentsParser(BaseModel):\n    comment: list[CustomerCommentData] = Field(description=\"A list of the customer comment data\", default_factory=list)\n\n\noutput_parser = PydanticOutputParser(pydantic_object=CommentsParser)\nformat_instructions = output_parser.get_format_instructions()\n",
  "from .helpers import create_gslide_client, create_drive_client\nfrom typing import Any\nfrom .helpers import get_youtube_client\nfrom ..libraries.youtube import YouTube\n\n\ngslide_client: Any = create_gslide_client()\ndrive_client: Any = create_drive_client()\nyoutube_client: YouTube = get_youtube_client()\n\n\n\n",
  "import imgviz\nimport numpy as np\nimport skimage\n\nfrom labelme.logger import logger\n\n\ndef _get_contour_length(contour):\n    contour_start = contour\n    contour_end = np.r_[contour[1:], contour[0:1]]\n    return np.linalg.norm(contour_end - contour_start, axis=1).sum()\n\n\ndef compute_polygon_from_mask(mask):\n    contours = skimage.measure.find_contours(np.pad(mask, pad_width=1))\n    if len(contours) == 0:\n        logger.warning(\"No contour found, so returning empty polygon.\")\n        return np.empty((0, 2), dtype=np.float32)\n\n    contour = max(contours, key=_get_contour_length)\n    POLYGON_APPROX_TOLERANCE = 0.004\n    polygon = skimage.measure.approximate_polygon(\n        coords=contour,\n        tolerance=np.ptp(contour, axis=0).max() * POLYGON_APPROX_TOLERANCE,\n    )\n    polygon = np.clip(polygon, (0, 0), (mask.shape[0] - 1, mask.shape[1] - 1))\n    polygon = polygon[:-1]  # drop last point that is duplicate of first point\n\n    if 0:\n        import PIL.Image\n\n        image_pil = PIL.Image.fromarray(imgviz.gray2rgb(imgviz.bool2ubyte(mask)))\n        imgviz.draw.line_(image_pil, yx=polygon, fill=(0, 255, 0))\n        for point in polygon:\n            imgviz.draw.circle_(image_pil, center=point, diameter=10, fill=(0, 255, 0))\n        imgviz.io.imsave(\"contour.jpg\", np.asarray(image_pil))\n\n    return polygon[:, ::-1]  # yx -> xy\n",
  "    \"\"\"))\n  \n  product_crew = ProductReviewCrew(company)\n  result = product_crew.run()\n  print(\"\\n\\n########################\")\n  print(\"## Here is the Report\")\n  print(\"########################\\n\")\n  print(result)",
  "            yield Request(link, callback=self.parse_slide, meta={\"slide_item\": slide_item})\n        \n        # next_page = response.css('a.next.page-numbers::attr(href)').get()\n        # if next_page and int(next_page.split('/')[-2]) < 2:\n        #     self.logger.warning(f\"Crawling page number %d\", int(next_page.split('/')[-2]))\n        #     yield Request(next_page, callback=self.parse)\n        next_page = response.css('a.next.page-numbers::attr(href)').get()\n        if next_page:\n            self.logger.warning(f\"Crawling page number %d\", int(next_page.split('/')[-2]))\n            yield Request(next_page, callback=self.parse)\n            \n    def parse_slide(self, response: Response, **kwargs: Any) -> Any:\n        slide_item = response.meta[\"slide_item\"]\n        loader = ItemLoader(item=slide_item, response=response)\n        loader.add_css(field_name=\"tags\", css=\".Sm-tags a.mr-2::text\")\n        loader.add_css(field_name=\"description\", css=\".product-text p\")\n        loader.add_css(field_name=\"slides_count\", css='h4 small::text')\n        loader.add_css(field_name=\"colors\", css='li.color a::text')\n        loader.add_css(field_name=\"image_urls\", css='a.preview-link img::attr(src)')\n        # add slide link\n        yield loader.load_item()",
  "from collections import deque\nfrom collections.abc import Iterator\nfrom os import listdir, path\nfrom queue import Queue\n\nfrom .config import Config\nfrom .helpers import read_src\n\n\nclass DirectoryIterator(Iterator):\n    def __init__(self, config: Config) -> None:\n        super().__init__()\n        self._folders_ignore = set(config.directories_ignore)\n        self._files_ignore = set(config.files_ignore)\n        self._queue = deque(config.root_directory)  # adding the individual chars\n\n    def __iter__(self) -> Iterator:\n        return super().__iter__()\n\n    def __next__(self) -> list[str]:\n        if self._queue:\n            files: list[str] = list()\n            for _ in range(len(self._queue)):\n                directory: str = self._queue.popleft()\n                for entry in listdir(directory):\n                    entry_path: str = path.join(directory, entry)\n                    if (\n                        path.isfile(entry_path)\n                        and self._is_python_file(entry_path)\n                        and entry not in self._files_ignore\n                    ):\n                        files.append(entry_path)\n                    elif path.isdir(entry_path) and entry not in self._folders_ignore:\n                        self._queue.append(entry_path)\n            return files\n        else:\n            raise StopIteration()\n\n    def _is_python_file(self, file_path: str) -> bool:\n        return file_path.split(\".\")[-1] == \"py\"\n",
  "    return items\n\n\ndef get_channel_details(channel: Search) -> Channel:\n    \"\"\"Get channel details\"\"\"\n    response: YouTubeListResponse = youtube_client.find_channel_by_id(\n        channel_id=channel.resource_id\n    )\n    channel: Channel = response.items[0]\n    return channel\n\n\ndef parse_channel_details(channel: Channel) -> dict:\n    return {\n        \"title\": channel.snippet.title,\n        \"description\": channel.snippet.description,\n        \"date\": str(channel.snippet.published_at.date()),\n        \"subscribers\": channel.statistics.subscribers_count,\n        \"videos\": channel.statistics.videos_count,\n    }\n    \n    \ndef get_channels(product: str, max_results: int = 10) -> list[dict]:\n    channels: list[Search] = search_youtube_channels(product=product, max_results=max_results)\n    channels: list[Channel] = map(get_channel_details, channels)\n    channels: list[dict] = map(parse_channel_details, channels)\n    return channels\n\ndef save_data(file_path: str, data: list) -> None:\n    with open(file_path, 'w') as f:\n        json.dump(data, f, indent=4)\n        \ndef load_data(file_path: str) -> dict:\n    with open(file_path, 'r') as f:\n        data: list[dict] = json.load(f)\n    return data\n\n\ndef create_channels_table(table_data: list[dict]) -> Table:\n    table: Table = Table(row_styles=[\"dim\", \"\"],leading=1, box=box.MINIMAL_DOUBLE_HEAD,\n",
  "from langchain.tools import tool\nfrom .helpers import list_video_comments\nfrom youtube.models import Comment\n\n\nclass FindProductReviewTools():\n    @tool\n    def find_product_reviews(video_id: str) -> str:\n        \"\"\"Useful when you need to find a product reviews from youtube video comments.\"\"\"\n        comments: list[Comment] = list_video_comments(video_id)\n        comments: list[str] = [comment.snippet.text_display for comment in comments]\n        return ' '.join(comments)",
  "\n    def popUp(self, text=None, move=True, flags=None, group_id=None, description=None):\n        if self._fit_to_content[\"row\"]:\n            self.labelList.setMinimumHeight(\n                self.labelList.sizeHintForRow(0) * self.labelList.count() + 2\n            )\n        if self._fit_to_content[\"column\"]:\n            self.labelList.setMinimumWidth(self.labelList.sizeHintForColumn(0) + 2)\n        # if text is None, the previous label in self.edit is kept\n        if text is None:\n            text = self.edit.text()\n        # description is always initialized by empty text c.f., self.edit.text\n        if description is None:\n            description = \"\"\n        self.editDescription.setPlainText(description)\n        if flags:\n            self.setFlags(flags)\n        else:\n            self.resetFlags(text)\n        self.edit.setText(text)\n        self.edit.setSelection(0, len(text))\n        if group_id is None:\n            self.edit_group_id.clear()\n        else:\n            self.edit_group_id.setText(str(group_id))\n        items = self.labelList.findItems(text, QtCore.Qt.MatchFixedString)\n        if items:\n            if len(items) != 1:\n                logger.warning(\"Label list has duplicate '{}'\".format(text))\n            self.labelList.setCurrentItem(items[0])\n            row = self.labelList.row(items[0])\n            self.edit.completer().setCurrentRow(row)\n        self.edit.setFocus(QtCore.Qt.PopupFocusReason)\n        if move:\n            self.move(QtGui.QCursor.pos())\n        if self.exec_():\n            return (\n                self.edit.text(),\n                self.getFlags(),\n                self.getGroupId(),\n",
  "\ndef is_acceptable_len(text: str, l: int = 20) -> bool:\n    return len(text.split()) >= l\n\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n    cleaned_comments: list[str] = list(map(clean_text, all_comments))\n    comments: list[str] = choices(population=cleaned_comments, k=10)\n    docs: list[Document] = [\n        Document(page_content=comment)\n        for comment in comments\n        if is_acceptable_len(comment)\n    ]\n    comments: list[dict[str, str | int]] = [\n        {\"doc_id\": i + 1, \"comment\": docs[i].page_content} for i in range(len(docs))\n    ]\n\ndata_dir = \"./agent_nelly/data_analysis/data\"\nfeatures_dir = \"features\"\nsave_features_dir = path.join(data_dir, features_dir, \"features.json\")\n\nwith open(save_features_dir, 'r') as f:\n    topics: list[str] = json.load(f)\n\ncomment: dict = choice(comments)\n\n\nsentiment_msg: str = \"\"\"\nBelow is a customer comment in JSON format with the following keys:\n1. doc_id - identifier of the comment\n2. comment - the user comment\n\nPlease analyze the comment and identify the sentiment. The sentiment can be negative, neutral or \npositive. Only return a single string, the sentiment.\n\nComment:\n```\n{comment}\n```\n",
  "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "        shape.description = description\n\n        self._update_shape_color(shape)\n        if shape.group_id is None:\n            item.setText(\n                '{} <font color=\"#{:02x}{:02x}{:02x}\">●</font>'.format(\n                    html.escape(shape.label), *shape.fill_color.getRgb()[:3]\n                )\n            )\n        else:\n            item.setText(\"{} ({})\".format(shape.label, shape.group_id))\n        self.setDirty()\n        if self.uniqLabelList.findItemByLabel(shape.label) is None:\n            item = self.uniqLabelList.createItemFromLabel(shape.label)\n            self.uniqLabelList.addItem(item)\n            rgb = self._get_rgb_by_label(shape.label)\n            self.uniqLabelList.setItemLabel(item, shape.label, rgb)\n\n    def fileSearchChanged(self):\n        self.importDirImages(\n            self.lastOpenDir,\n            pattern=self.fileSearch.text(),\n            load=False,\n        )\n\n    def fileSelectionChanged(self):\n        items = self.fileListWidget.selectedItems()\n        if not items:\n            return\n        item = items[0]\n\n        if not self.mayContinue():\n            return\n\n        currIndex = self.imageList.index(str(item.text()))\n        if currIndex < len(self.imageList):\n            filename = self.imageList[currIndex]\n            if filename:\n                self.loadFile(filename)\n\n",
  "from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service as ChromeService\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.chrome.options import Options\ni\n\noptions = Options()\noptions.add_argument(\"--headless=new\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\ndriver.get(\"https://leetcode.com/problems/remove-linked-list-elements\")\nparagraphs = driver.find_elements(By.TAG_NAME, \"p\")\nprint(paragraphs)\ndriver.quit()",
  "            features, labels, test_size=0.2, random_state=42, stratify=labels\n        )\n        return (train_features, train_labels), (test_features, test_labels)\n\n    def save_features(self) -> DataFrame:\n        pass\n\n    def save_labels(self) -> DataFrame:\n        pass\n\n    def train_model(self, model: Model) -> float:\n        (train_features, train_labels), (test_features, test_labels) = self.get_train_test_data()\n        pipeline: Pipeline = Pipeline(steps=[\n            ('preprocessor', self.preprocessor),\n            ('classifier', model.model)\n        ])\n        logging.info('Queing the model \"%s\" for training.', model.name)\n        res: AsyncResult = train_model_task.delay(pipeline, train_features, train_labels, test_features, test_labels, model.name, model.save_path)\n        self.train_task_ids.append(res.id)\n        return res.id\n        \n\n    def run(self) -> None:  \n        self._train_results = chord((train_model_task.s(\n            self.create_train_config(model=model.model, name=model.classifier_name, save_path=model.save_path)\n            ) for model in self.models), send_training_report_task.s())()\n      \n    def get_results(self) -> list[Model]:\n        \"\"\"Get the training result.\"\"\"\n        logging.info('Getting the training results')\n        print(self._train_results.get())\n        \n    def get_best_models(self, start: int = 0, end: int = -1) -> Model:\n        best_models = redis.zrange(name=app_config.accuracy_channel, start=start, end=end, withscores=True)\n        return best_models\n        \n    def tune_best_models(self) -> None:\n        logging.info('Tuning the best models.')\n        best_models = self.get_best_models(start=-3, end=-1)\n        logging.info(best_models)\n",
  "from queue import Queue\nfrom threading import Thread\n\nfrom .config import Config\nfrom .file_processor import (\n    generate_function_docstrings,\n    queue_unprocessed_functions_methods,\n    generate_class_docstrings,\n)\nfrom .helpers import get_all_modules\n\n\ndef generate_docstrings(\n    config: Config,\n    module_path_queue: Queue,\n    functions_source_queue: Queue,\n    class_source_queue: Queue,\n    failed_modules_queue: Queue,\n) -> None:\n    \"\"\"Generate docstrings for classes and methods.\"\"\"\n    queue_modules: Thread = Thread(\n        target=get_all_modules,\n        name='get_all_modules',\n        args=(config, module_path_queue),\n    )\n    queue_modules.start()\n\n    for _ in range(1):\n        get_functions_source_thread: Thread = Thread(\n            target=queue_unprocessed_functions_methods,\n            args=(functions_source_queue, class_source_queue, module_path_queue),\n            daemon=True,\n        )\n        get_functions_source_thread.start()\n\n    for _ in range(1):\n        generate_functions_docstring_thread: Thread = Thread(\n            target=generate_function_docstrings,\n            args=(functions_source_queue, config),\n            daemon=True,\n",
  "from youtube import YouTube\n\nclient_secrets_file = \"/home/lyle/Downloads/search.json\"\nyoutube_client = YouTube(client_secret_file=client_secrets_file)\nyoutube_client_object = youtube_client.authenticate()\nyoutube_client.youtube_client = youtube_client_object\n",
  "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library that wraps around the Google calendar API. You can use it to schedule events using google calendar.'\n\nkey_words = [\n    'calendar', 'google-calendar', 'schedule events'\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings',\n    'pytz'\n]\n\nsetup(\n    name='oryks-google-calendar',\n    packages=find_packages(\n        include=[\n            'google_calendar',\n            'google_calendar.models',\n            'google_calendar.schemas',\n            'google_calendar.resources',\n        ]\n    ),\n",
  "from datetime import datetime\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom ..database import Base\nfrom sqlalchemy import ForeignKey\n\n\nclass View(Base):\n    __tablename__ = 'views'\n    \n    id: Mapped[str] = mapped_column(primary_key=True)\n    author_id: Mapped[str] = mapped_column(ForeignKey('users.id'))\n    post_id: Mapped[str] = mapped_column(ForeignKey('posts.id'))\n    view_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    \n    author = relationship('User', back_populates='views')\n    post = relationship('Post', back_populates='views')",
  "            src_tree: AST = parse_src(docstring)\n            func_node: FunctionDef = src_tree.body[0]\n            doc_str: str = ast.get_docstring(func_node)\n        except Exception:\n            return super().parse(docstring)\n        else:\n            return doc_str\n\n\nmodel_parser: Parser = DefaultParser()\n\n\ndef parse_function_docstr(func_dcstr: str) -> str:\n    return model_parser.parse(docstring=func_dcstr)\n",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy import Request\n# from slidesmodel.items import SlidesModelItem\nfrom scrapy.loader import ItemLoader\nfrom scrapy.utils.project import get_project_settings\nimport json\n\n\nclass SlidesModelspider(Spider):\n    name: str = \"problems\"\n    \n    def __init__(self, name: str | None = None, **kwargs: Any):\n        super().__init__(name, **kwargs)\n        # self.start_urls: list[str] = self.load_start_urls()\n        self.start_urls: list[str] = [\n            \"https://www.techiedelight.com/data-structures-and-algorithms-problems/\"\n        ]\n    \n    \n    def parse(self, response: Response, **kwargs: Any) -> Any:\n        self.logger.info(\"This is my first spider.\")\n        problem_links = response.css('.post-problems li')\n        # from random import choices\n        # problem_links = choices(population=problem_links, k=100)\n        # for problem_link in problem_links:\n        #     # title = problem_link.css('a::text')[0].get()\n        #     link = problem_link.css('a::attr(href)')[0].get()\n        #     # yield{\n        #     #     \"link\": link,\n        #     #     \"problem\": problem\n        #     # }\n            # yield Request(link, callback=self.parse_problem)\n        link = \"https://www.techiedelight.com/single-source-shortest-paths-bellman-ford-algorithm/\"\n        yield Request(link, callback=self.parse_problem)\n        # for slide in slides:\n        #     loader: ItemLoader = ItemLoader(item=SlidesModelItem(), selector=slide)\n        #     loader.add_css(\"title\", \".item a::text\")\n        #     loader.add_css(\"category\", \".category::text\")\n",
  "            \"ai_mask\": self.actions.createAiMaskMode,\n        }\n\n        self.canvas.setEditing(edit)\n        self.canvas.createMode = createMode\n        if edit:\n            for draw_action in draw_actions.values():\n                draw_action.setEnabled(True)\n        else:\n            for draw_mode, draw_action in draw_actions.items():\n                draw_action.setEnabled(createMode != draw_mode)\n        self.actions.editMode.setEnabled(not edit)\n\n    def setEditMode(self):\n        self.toggleDrawMode(True)\n\n    def updateFileMenu(self):\n        current = self.filename\n\n        def exists(filename):\n            return osp.exists(str(filename))\n\n        menu = self.menus.recentFiles\n        menu.clear()\n        files = [f for f in self.recentFiles if f != current and exists(f)]\n        for i, f in enumerate(files):\n            icon = utils.newIcon(\"labels\")\n            action = QtWidgets.QAction(\n                icon, \"&%d %s\" % (i + 1, QtCore.QFileInfo(f).fileName()), self\n            )\n            action.triggered.connect(functools.partial(self.loadRecent, f))\n            menu.addAction(action)\n\n    def popLabelListMenu(self, point):\n        self.menus.labelList.exec_(self.labelList.mapToGlobal(point))\n\n    def validateLabel(self, label):\n        # no validation\n        if self._config[\"validate_label\"] is None:\n            return True\n",
  "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library for working with Google Drive.'\n\nkey_words = [\n    'drive', 'google-drive', 'google-drive-api', 'upload files to Google Drive',\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-google-drive',\n    packages=find_packages(\n        include=[\n            'google_drive',\n            'google_drive.exceptions',\n            'google_drive.models',\n            'google_drive.schemas',\n            'google_drive.resources'\n        ]\n    ),\n",
  "import whisper\n\nmodel = whisper.load_model(\"medium.en\")\nresult = model.transcribe(\"code.wav\")\nprint(result[\"text\"])",
  "from scrapy import Item, Field\nfrom itemloaders.processors import TakeFirst, MapCompose, Join\nimport re\n\n\ndef remove_html_tags(description: str) -> str:\n    html_pattern = \"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\" \n    return re.sub(html_pattern, '', description)\n\ndef remove_unicode_chars(text: str) -> str:\n    return text.replace(u\"\\xa0\", \"\")\n\ndef num_of_slides(text: str) -> int:\n    vals = [val for val in list(text) if val.isdigit()]\n    return \"\".join(vals)\n\n\nclass SlidesModelItem(Item):\n    title = Field(output_processor=TakeFirst())\n    category = Field(output_processor=TakeFirst())\n    description = Field(\n        input_processor=MapCompose(remove_html_tags, remove_unicode_chars),\n        output_processor=Join()\n    )\n    tags = Field()\n    slides_count = Field(\n        input_processor=MapCompose(num_of_slides),\n        output_processor=TakeFirst()\n    )\n    colors = Field()\n    image_urls = Field()\n    images = Field()\n",
  "topic_assign_msg: str = \"\"\"\nBelow is a list of customer comments in JSON format with the following keys:\n1. doc_id - identifier of the comment\n2. comment - the user comment\n\nPlease analyze the provided comments and identify the main topics and sentiment. Include only the \ntopics mentioned in the following text:\nText: {topics}\n\n{format_instructions}\n\nuser comments: \n```{comments}```\n\"\"\"\n\ntopic_assign_tmpl = PromptTemplate(\n    template=topic_assign_msg,\n    input_variables=[\"topics\", \"comments\", \"format_instructions\"],\n)\n\nwith open('analysis.json', 'r') as f:\n    data = json.load(f)\n    \ni = data[-1][\"comment_id\"] + 1\n\nfrom time import sleep\nimport json\nfor _ in range(10):\n    d = comments[i: i+3]\n    x = {}\n    for s in d:\n        x[s['doc_id']] = s['comment']\n    i += 3\n    inputs = {\n        \"topics\": topics,\n        \"format_instructions\": format_instructions,\n        \"comments\": json.dumps(d),\n    }\n    # print(d)\n    # print(c)\n",
  "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n",
  "\nclass DirectoryIterator:\n    def __init__(self, config: Config):\n        self.config: Config = config\n        self.queue: deque[str] = deque(self.config.path)\n\n    def __iter__(self) -> Iterator:\n        return self\n\n    def __next__(self) -> list[str]:\n        files: list[str] = list()\n        if self.queue:\n            for _ in range(len(self.queue)):\n                root_dir: str = self.queue.popleft()\n                if root_dir.split('/')[-1] in self.config.directories_ignore:\n                    continue\n                entries: list[str] = listdir(root_dir)\n                for entry in entries:\n                    entry_path: str = path.join(root_dir, entry)\n                    if path.isfile(entry_path):\n                        if (\n                            entry_path not in self.config.files_ignore\n                            and entry.split('.')[-1] == 'py'\n                        ):\n                            files.append(entry_path)\n                    elif entry not in self.config.directories_ignore:\n                        self.queue.append(entry_path)\n            return files\n        else:\n            raise StopIteration()\n",
  "class GetPosts(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10\n    \nclass PostAuthor(BaseModel):\n    id: str\n    profile_picture: str\n    name: str\n    \nclass PostLike(BaseModel):\n    liked: bool\n    liked_by: Optional[list[PostAuthor]] = Field(default_factory=list)\n    key_like: Optional[PostAuthor] = None\n    likes_count: Optional[int] = Field(default=0)\n    \nclass KeyComment(BaseModel):\n    author: PostAuthor\n    text: str\n    comments_count: int\n    \nclass PostSchema(BaseModel):\n    id: str\n    text: str\n    image: str\n    author: PostAuthor\n    date_published: str\n    location: str\n    like: PostLike\n    bookmarked: bool\n    key_comment: Optional[KeyComment] = None",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "    optional: CommentThreadOptionalParameters = CommentThreadOptionalParameters(\n        maxResults=25\n    )\n    request: YouTubeRequest = YouTubeRequest(\n        part=part, filter=filter, optional_parameters=optional\n    )\n    comment_iterator: Iterator = youtube_client.get_comments_iterator(request)\n    done: bool = False\n    comment_count: int = 0\n    for comment_threads in comment_iterator:\n        comments: list[str] = []\n        if done:\n            break\n        for comment_thread in comment_threads:\n            comment: Comment = comment_thread.snippet.top_level_comment\n            comments.append(comment.snippet.text_display)\n            comment_count += 1\n            if comment_count > max_results:\n                done = True\n                break\n        with open(\"comments.json\", \"r\", encoding=\"utf-8\") as f:\n            existing_comments: list[str] = json.load(f)\n\n        with open(\"comments.json\", \"w\", encoding=\"utf-8\") as f:\n            existing_comments += comments\n            json.dump(existing_comments, fp=f, indent=2)\n    return comment_count\n\n\nclient_secrets_file = \"/home/lyle/Downloads/search.json\"\nyoutube_client = YouTube(client_secret_file=client_secrets_file)\nyoutube_client_object = youtube_client.authenticate()\nyoutube_client.youtube_client = youtube_client_object\n\n\n# print(get_video_id(video_title='iPhone 15 Pro Review: The Good, The Bad, & The Ugly!'))\nprint(list_video_comments(video_id=\"cBpGq-vDr2Y\"))\n",
  "\n    def setShape(self, shape):\n        self.setData(shape, Qt.UserRole)\n\n    def shape(self):\n        return self.data(Qt.UserRole)\n\n    def __hash__(self):\n        return id(self)\n\n    def __repr__(self):\n        return '{}(\"{}\")'.format(self.__class__.__name__, self.text())\n\n\nclass StandardItemModel(QtGui.QStandardItemModel):\n    itemDropped = QtCore.Signal()\n\n    def removeRows(self, *args, **kwargs):\n        ret = super().removeRows(*args, **kwargs)\n        self.itemDropped.emit()\n        return ret\n\n\nclass LabelListWidget(QtWidgets.QListView):\n    itemDoubleClicked = QtCore.Signal(LabelListWidgetItem)\n    itemSelectionChanged = QtCore.Signal(list, list)\n\n    def __init__(self):\n        super(LabelListWidget, self).__init__()\n        self._selectedItems = []\n\n        self.setWindowFlags(Qt.Window)\n        self.setModel(StandardItemModel())\n        self.model().setItemPrototype(LabelListWidgetItem())\n        self.setItemDelegate(HTMLDelegate())\n        self.setSelectionMode(QtWidgets.QAbstractItemView.ExtendedSelection)\n        self.setDragDropMode(QtWidgets.QAbstractItemView.InternalMove)\n        self.setDefaultDropAction(Qt.MoveAction)\n\n        self.doubleClicked.connect(self.itemDoubleClickedEvent)\n",
  "from qtpy import QtWidgets\n\n\nclass ColorDialog(QtWidgets.QColorDialog):\n    def __init__(self, parent=None):\n        super(ColorDialog, self).__init__(parent)\n        self.setOption(QtWidgets.QColorDialog.ShowAlphaChannel)\n        # The Mac native dialog does not support our restore button.\n        self.setOption(QtWidgets.QColorDialog.DontUseNativeDialog)\n        # Add a restore defaults button.\n        # The default is set at invocation time, so that it\n        # works across dialogs for different elements.\n        self.default = None\n        self.bb = self.layout().itemAt(1).widget()\n        self.bb.addButton(QtWidgets.QDialogButtonBox.RestoreDefaults)\n        self.bb.clicked.connect(self.checkRestore)\n\n    def getColor(self, value=None, title=None, default=None):\n        self.default = default\n        if title:\n            self.setWindowTitle(title)\n        if value:\n            self.setCurrentColor(value)\n        return self.currentColor() if self.exec_() else None\n\n    def checkRestore(self, button):\n        if (\n            self.bb.buttonRole(button) & QtWidgets.QDialogButtonBox.ResetRole\n            and self.default\n        ):\n            self.setCurrentColor(self.default)\n",
  "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "from .register_blueprints import register_blueprints",
  "    optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n        q=video_title, maxResults=1, type=[\"video\"]\n    )\n    search_request: YouTubeRequest = YouTubeRequest(\n        part=part, optional_parameters=optional_parameters\n    )\n    search_results: YouTubeResponse = youtube_client.search(search_request)\n    search_result: Search = search_results.items[0]\n    return search_result.resource_id\n\n\ndef get_video_details(video: Search) -> Video:\n    \"\"\"Get video details\"\"\"\n    response: YouTubeListResponse = youtube_client.find_video_by_id(video.resource_id)\n    video: Video = response.items[0]\n    return video\n\n\ndef parse_video_details(video: Video) -> dict:\n    return {\n        \"title\": video.snippet.title,\n        \"description\": video.snippet.description,\n        \"date\": str(video.snippet.published_at),\n        \"views\": video.statistics.views_count,\n        \"comments\": video.statistics.comments_count,\n        \"likes\": video.statistics.likes_count,\n    }\n    \ndef get_videos(product: str, channel: str) -> list[dict]:\n    videos: list[Search] = video_search(product=product, channel_title=channel)\n    videos: list[Video] = map(get_video_details, videos)\n    videos: list[dict] = map(parse_video_details, videos)\n    return videos\n\n\ndef create_videos_table(table_data: list[dict]) -> Table:\n    table: Table = Table(row_styles=[\"dim\", \"\"],leading=1, box=box.MINIMAL_DOUBLE_HEAD,\n         title=\"[bold italic gold1]Youtube videos reviewing Iphone 15 pro[/bold italic gold1]\")\n    table.add_column(header=\"[b]Video Title\", justify=\"left\", style=\"dark_orange\")\n    table.add_column(header=\"Views\", justify=\"left\", style=\"light_coral\")\n",
  "\n\ndef validate_config_item(key, value):\n    if key == \"validate_label\" and value not in [None, \"exact\"]:\n        raise ValueError(\n            \"Unexpected value for config key 'validate_label': {}\".format(value)\n        )\n    if key == \"shape_color\" and value not in [None, \"auto\", \"manual\"]:\n        raise ValueError(\n            \"Unexpected value for config key 'shape_color': {}\".format(value)\n        )\n    if key == \"labels\" and value is not None and len(value) != len(set(value)):\n        raise ValueError(\n            \"Duplicates are detected for config key 'labels': {}\".format(value)\n        )\n\n\ndef get_config(config_file_or_yaml=None, config_from_args=None):\n    # 1. default config\n    config = get_default_config()\n\n    # 2. specified as file or yaml\n    if config_file_or_yaml is not None:\n        config_from_yaml = yaml.safe_load(config_file_or_yaml)\n        if not isinstance(config_from_yaml, dict):\n            with open(config_from_yaml) as f:\n                logger.info(\"Loading config file from: {}\".format(config_from_yaml))\n                config_from_yaml = yaml.safe_load(f)\n        update_dict(config, config_from_yaml, validate_item=validate_config_item)\n\n    # 3. command line argument or specified config file\n    if config_from_args is not None:\n        update_dict(config, config_from_args, validate_item=validate_config_item)\n\n    return config\n",
  "channel_names: list[str] = get_channel_names()\nplaylist_name: str = 'Daily Videos'\nplaylist_items: list[str] = workflow(youtube, channel_names)\n\n# print(get_channel_id('Asianometry'))\n# print(redis.setex(name='PL_26vmg8W_AcEEl_Bo2AhziS-93r6b8bu:DqkZCzjdtbw', time=1, value=''))\n# print(redis.setex(name='PL_26vmg8W_AcEEl_Bo2AhziS-93r6b8bu:VzW_BtXSw6A', time=1, value=''))\n# print(redis.get(name='PL_26vmg8W_AcEEl_Bo2AhziS-93r6b8bu:DqkZCzjdtbw'))\n# print(find_latest_video('UC1LpsuAUaKoMzzJSEt5WImw', youtube))\n# channels: list[Channel] = get_all_channels(get_db)\n# latest_videos: list[Video] = [find_latest_video(channel.id, youtube) for channel in channels]\n# videos: list[Video] = Video.find().all()\n# for channel in channels:\n#     redis.setex(f'latest:{channel.id}', value='video_str', time=1)\n# for video in latest_videos:\n#     pl_id: str = 'PL_26vmg8W_AcEEl_Bo2AhziS-93r6b8bu'\n#     redis.setex(name=f'{pl_id}:{video.resource_id}', time=1, value='')\n# for video in videos:\n#     video.expire(num_seconds=1)",
  "from crewai import Task\nfrom textwrap import dedent\n\nclass ProductReviewTasks():\n    def research(self, agent, product):\n        return Task(description=dedent(f\"\"\"\n            Collect and summarize the most recent comments from the \n            products review from youtube.\n            Maje sure to capture the sentiment of each comment, \n            what the user liked, did not like as well as other \n            features that they wish were present.\n\n            Your final answer MUST be a report that includes a\n            comprehensive summary of the reviews, capturing \n            the most loved features.\n            \n            {self.__tip_section()}\n\n            Selected product by the customer: {product}\n            \"\"\"),\n            agent=agent\n        )\n    \n    def __tip_section(self):\n        return \"If you do your BEST WORK, I'll give you a $10,000 commision!\"",
  "    long_description=LONG_DESCRIPTION,\n    url='https://youtube-assistant.readthedocs.io/en/latest/',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Operating System :: OS Independent'\n    ],\n)\n",
  "                fitWidth,\n                None,\n                brightnessContrast,\n            ),\n        )\n\n        self.menus.file.aboutToShow.connect(self.updateFileMenu)\n\n        # Custom context menu for the canvas widget:\n        utils.addActions(self.canvas.menus[0], self.actions.menu)\n        utils.addActions(\n            self.canvas.menus[1],\n            (\n                action(\"&Copy here\", self.copyShape),\n                action(\"&Move here\", self.moveShape),\n            ),\n        )\n\n        selectAiModel = QtWidgets.QWidgetAction(self)\n        selectAiModel.setDefaultWidget(QtWidgets.QWidget())\n        selectAiModel.defaultWidget().setLayout(QtWidgets.QVBoxLayout())\n        #\n        selectAiModelLabel = QtWidgets.QLabel(self.tr(\"AI Model\"))\n        selectAiModelLabel.setAlignment(QtCore.Qt.AlignCenter)\n        selectAiModel.defaultWidget().layout().addWidget(selectAiModelLabel)\n        #\n        self._selectAiModelComboBox = QtWidgets.QComboBox()\n        selectAiModel.defaultWidget().layout().addWidget(self._selectAiModelComboBox)\n        model_names = [model.name for model in MODELS]\n        self._selectAiModelComboBox.addItems(model_names)\n        if self._config[\"ai\"][\"default\"] in model_names:\n            model_index = model_names.index(self._config[\"ai\"][\"default\"])\n        else:\n            logger.warning(\n                \"Default AI model is not found: %r\",\n                self._config[\"ai\"][\"default\"],\n            )\n            model_index = 0\n        self._selectAiModelComboBox.setCurrentIndex(model_index)\n        self._selectAiModelComboBox.currentIndexChanged.connect(\n",
  "    # popUp() + key_Up\n\n    def interact():\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Up)  # 'person' -> 'dog'  # NOQA\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Enter)  # NOQA\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Enter)  # NOQA\n\n    QtCore.QTimer.singleShot(500, interact)\n    label, flags, group_id, description = widget.popUp()\n    assert label == \"dog\"\n    assert flags == {}\n    assert group_id is None\n    assert description == \"\"\n",
  "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "                self.selectedShapes[i].selected = False\n                self.selectedShapes[i] = shape\n        else:\n            for i, shape in enumerate(self.selectedShapesCopy):\n                self.selectedShapes[i].points = shape.points\n        self.selectedShapesCopy = []\n        self.repaint()\n        self.storeShapes()\n        return True\n\n    def hideBackroundShapes(self, value):\n        self.hideBackround = value\n        if self.selectedShapes:\n            # Only hide other shapes if there is a current selection.\n            # Otherwise the user will not be able to select a shape.\n            self.setHiding(True)\n            self.update()\n\n    def setHiding(self, enable=True):\n        self._hideBackround = self.hideBackround if enable else False\n\n    def canCloseShape(self):\n        return self.drawing() and self.current and len(self.current) > 2\n\n    def mouseDoubleClickEvent(self, ev):\n        if self.double_click != \"close\":\n            return\n\n        if (\n            self.createMode == \"polygon\" and self.canCloseShape()\n        ) or self.createMode in [\"ai_polygon\", \"ai_mask\"]:\n            self.finalise()\n\n    def selectShapes(self, shapes):\n        self.setHiding()\n        self.selectionChanged.emit(shapes)\n        self.update()\n\n    def selectShapePoint(self, point, multiple_selection_mode):\n        \"\"\"Select the first shape created which contains this point.\"\"\"\n",
  "        self.labelList.itemSelectionChanged.connect(self.labelSelectionChanged)\n        self.labelList.itemDoubleClicked.connect(self.editLabel)\n        self.labelList.itemChanged.connect(self.labelItemChanged)\n        self.labelList.itemDropped.connect(self.labelOrderChanged)\n        self.shape_dock = QtWidgets.QDockWidget(self.tr(\"Polygon Labels\"), self)\n        self.shape_dock.setObjectName(\"Labels\")\n        self.shape_dock.setWidget(self.labelList)\n\n        self.uniqLabelList = UniqueLabelQListWidget()\n        self.uniqLabelList.setToolTip(\n            self.tr(\n                \"Select label to start annotating for it. \" \"Press 'Esc' to deselect.\"\n            )\n        )\n        if self._config[\"labels\"]:\n            for label in self._config[\"labels\"]:\n                item = self.uniqLabelList.createItemFromLabel(label)\n                self.uniqLabelList.addItem(item)\n                rgb = self._get_rgb_by_label(label)\n                self.uniqLabelList.setItemLabel(item, label, rgb)\n        self.label_dock = QtWidgets.QDockWidget(self.tr(\"Label List\"), self)\n        self.label_dock.setObjectName(\"Label List\")\n        self.label_dock.setWidget(self.uniqLabelList)\n\n        self.fileSearch = QtWidgets.QLineEdit()\n        self.fileSearch.setPlaceholderText(self.tr(\"Search Filename\"))\n        self.fileSearch.textChanged.connect(self.fileSearchChanged)\n        self.fileListWidget = QtWidgets.QListWidget()\n        self.fileListWidget.itemSelectionChanged.connect(self.fileSelectionChanged)\n        fileListLayout = QtWidgets.QVBoxLayout()\n        fileListLayout.setContentsMargins(0, 0, 0, 0)\n        fileListLayout.setSpacing(0)\n        fileListLayout.addWidget(self.fileSearch)\n        fileListLayout.addWidget(self.fileListWidget)\n        self.file_dock = QtWidgets.QDockWidget(self.tr(\"File List\"), self)\n        self.file_dock.setObjectName(\"Files\")\n        fileListWidget = QtWidgets.QWidget()\n        fileListWidget.setLayout(fileListLayout)\n        self.file_dock.setWidget(fileListWidget)\n\n",
  "# TODO(unknown):\n# - Zoom is too \"steppy\".\n\n\nLABEL_COLORMAP = imgviz.label_colormap()\n\n\nclass MainWindow(QtWidgets.QMainWindow):\n    FIT_WINDOW, FIT_WIDTH, MANUAL_ZOOM = 0, 1, 2\n\n    def __init__(\n        self,\n        config=None,\n        filename=None,\n        output=None,\n        output_file=None,\n        output_dir=None,\n    ):\n        if output is not None:\n            logger.warning(\"argument output is deprecated, use output_file instead\")\n            if output_file is None:\n                output_file = output\n\n        # see labelme/config/default_config.yaml for valid configuration\n        if config is None:\n            config = get_config()\n        self._config = config\n\n        # set default shape colors\n        Shape.line_color = QtGui.QColor(*self._config[\"shape\"][\"line_color\"])\n        Shape.fill_color = QtGui.QColor(*self._config[\"shape\"][\"fill_color\"])\n        Shape.select_line_color = QtGui.QColor(\n            *self._config[\"shape\"][\"select_line_color\"]\n        )\n        Shape.select_fill_color = QtGui.QColor(\n            *self._config[\"shape\"][\"select_fill_color\"]\n        )\n        Shape.vertex_fill_color = QtGui.QColor(\n            *self._config[\"shape\"][\"vertex_fill_color\"]\n        )\n",
  "full_chain = {\n    \"sentiment\": sentiment_chain,\n    \"comment\": lambda input: input['comment'],\n    \"topics\": lambda input: input['topics']\n} | branch\n\nres = full_chain.invoke({'comment': comment, \"topics\": topics})\nprint(comment)\nprint(res)\n",
  "        self.canvas.setEnabled(True)\n        # set zoom values\n        is_initial_load = not self.zoom_values\n        if self.filename in self.zoom_values:\n            self.zoomMode = self.zoom_values[self.filename][0]\n            self.setZoom(self.zoom_values[self.filename][1])\n        elif is_initial_load or not self._config[\"keep_prev_scale\"]:\n            self.adjustScale(initial=True)\n        # set scroll values\n        for orientation in self.scroll_values:\n            if self.filename in self.scroll_values[orientation]:\n                self.setScroll(\n                    orientation, self.scroll_values[orientation][self.filename]\n                )\n        # set brightness contrast values\n        dialog = BrightnessContrastDialog(\n            utils.img_data_to_pil(self.imageData),\n            self.onNewBrightnessContrast,\n            parent=self,\n        )\n        brightness, contrast = self.brightnessContrast_values.get(\n            self.filename, (None, None)\n        )\n        if self._config[\"keep_prev_brightness\"] and self.recentFiles:\n            brightness, _ = self.brightnessContrast_values.get(\n                self.recentFiles[0], (None, None)\n            )\n        if self._config[\"keep_prev_contrast\"] and self.recentFiles:\n            _, contrast = self.brightnessContrast_values.get(\n                self.recentFiles[0], (None, None)\n            )\n        if brightness is not None:\n            dialog.slider_brightness.setValue(brightness)\n        if contrast is not None:\n            dialog.slider_contrast.setValue(contrast)\n        self.brightnessContrast_values[self.filename] = (brightness, contrast)\n        if brightness is not None or contrast is not None:\n            dialog.onNewValue(None)\n        self.paintCanvas()\n        self.addRecentFile(self.filename)\n",
  "        # (from other spider middleware) raises an exception.\n\n        # Should return either None or an iterable of Request or item objects.\n        pass\n\n    def process_start_requests(self, start_requests, spider):\n        # Called with the start requests of the spider, and works\n        # similarly to the process_spider_output() method, except\n        # that it doesn’t have a response associated.\n\n        # Must return only requests (not items).\n        for r in start_requests:\n            yield r\n\n    def spider_opened(self, spider):\n        spider.logger.info(\"Spider opened: %s\" % spider.name)\n\n\nclass SlidesgoDownloaderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the downloader middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_request(self, request, spider):\n        # Called for each request that goes through the downloader\n        # middleware.\n\n        # Must either:\n        # - return None: continue processing this request\n        # - or return a Response object\n        # - or return a Request object\n        # - or raise IgnoreRequest: process_exception() methods of\n        #   installed downloader middleware will be called\n",
  "            self.client_secret_file = client_secret_file\n        if not self.client_secret_file:\n            raise ValueError('The client secret file must be provided.')\n        api_service_name: str = 'drive'\n        api_version: str = 'v3'\n        credentials_dir: str = '.drive_credentials'\n        scopes: list[str] = [\n            GoogleDriveScopes.metadata.value,\n            GoogleDriveScopes.drive.value,\n            GoogleDriveScopes.files.value,\n            GoogleDriveScopes.activity.value,\n        ]\n        oauth: GoogleOAuth = GoogleOAuth(\n            secrets_file=self.client_secret_file,\n            scopes=scopes,\n            api_service_name=api_service_name,\n            api_version=api_version,\n            credentials_dir=credentials_dir,\n        )\n        self.drive_client = oauth.authenticate_google_server()\n        return self.drive_client\n\n    def create_file(self) -> None:\n        \"\"\"Creates a new file on drive.\"\"\"\n        raise NotImplementedError()\n    \n    def upload_file(self) -> None:\n        \"\"\"Upload a file to drive.\"\"\"\n        raise NotImplementedError()\n    \n    def resumable_upload(self) -> None:\n        raise NotImplementedError()\n",
  "def send_email_local(user_email_address: str, message: str) -> None:\n    pass\n\ndef send_email_aws_ses(user_email_address: str, message: str) -> None:\n    pass\n\ndef send_account_activation_email(user_email_address: str, message: str) -> None:\n    pass\n\ndef send_password_reset_email(user_email_address: str, message: str) -> None:\n    pass\n\ndef generate_account_activation_email(message: str) -> None:\n    pass\n\ndef generate_password_reset_email(message: str) -> None:\n    pass",
  "import os.path as osp\n\nimport numpy as np\nimport PIL.Image\n\nfrom labelme.utils import image as image_module\n\nfrom .util import data_dir\nfrom .util import get_img_and_data\n\n\ndef test_img_b64_to_arr():\n    img, _ = get_img_and_data()\n    assert img.dtype == np.uint8\n    assert img.shape == (907, 1210, 3)\n\n\ndef test_img_arr_to_b64():\n    img_file = osp.join(data_dir, \"annotated_with_data/apc2016_obj3.jpg\")\n    img_arr = np.asarray(PIL.Image.open(img_file))\n    img_b64 = image_module.img_arr_to_b64(img_arr)\n    img_arr2 = image_module.img_b64_to_arr(img_b64)\n    np.testing.assert_allclose(img_arr, img_arr2)\n\n\ndef test_img_data_to_png_data():\n    img_file = osp.join(data_dir, \"annotated_with_data/apc2016_obj3.jpg\")\n    with open(img_file, \"rb\") as f:\n        img_data = f.read()\n    png_data = image_module.img_data_to_png_data(img_data)\n    assert isinstance(png_data, bytes)\n",
  "from redis import Redis\nfrom config.config import app_config\nfrom celery import Celery\nfrom utils import extract_dataset\nfrom schemas import Model, TrainedModel, TunedModel\nimport logging\nfrom schemas import Metrics\nfrom datetime import datetime\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\nfrom time import perf_counter\nfrom sklearn.pipeline import Pipeline\nfrom experiment_param_grids import hyperparameters\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.base import BaseEstimator\nfrom schemas.train_config import TrainConfig\nfrom os import path\nfrom utils import send_email\n\n\nredis: Redis = Redis(host=app_config.redis.redis_host, port=app_config.redis.redis_port, decode_responses=True)\ncelery = Celery(__name__)\ncelery.conf.broker_url = app_config.celery_broker_url\ncelery.conf.result_backend = app_config.celery_result_backend\ncelery.conf.event_serializer = 'pickle' # this event_serializer is optional. somehow i missed this when writing this solution and it still worked without.\ncelery.conf.task_serializer = 'pickle'\ncelery.conf.result_serializer = 'pickle'\ncelery.conf.accept_content = ['application/json', 'application/x-python-serialize']\n\n\n@celery.task(name='send_training_report_task')\ndef send_training_report_task(training_result):\n    try:\n        logging.info('Sending the email')\n        send_email()\n    except Exception as e:\n        logging.error(f'Unable to send email: {str(e)}')\n    else:\n        logging.info('Email sent')\n    return training_result\n\n",
  "import ast\nfrom ast import FunctionDef\nfrom queue import Queue\n\nfrom .helpers import read_src\n\n\nclass FunctionVisitor(ast.NodeVisitor):\n    def __init__(self, function_code_queue: Queue, file_path: str) -> None:\n        super().__init__()\n        self._function_code_queue = function_code_queue\n        self._file_path = file_path\n\n    def visit_FunctionDef(self, node: FunctionDef) -> None:\n        function_code: str = ast.unparse(ast_obj=node)\n        self._function_code_queue.put((self._file_path, function_code))\n",
  "from celery import Celery\nfrom config import CeleryConfig\n\n\ncelery_app: Celery = Celery(__name__)\ncelery_app.config_from_object(CeleryConfig)\ncelery_app.conf.beat_schedule = {\n        'clear-daily-playlist': {\n            'task': 'tasks.clear_daily_playlist',\n            'schedule': 10\n        }\n    }\ncelery_app.autodiscover_tasks(['tasks'])\n",
  "            self.tr(\"Zoom follows window width\"),\n            checkable=True,\n            enabled=False,\n        )\n        brightnessContrast = action(\n            \"&Brightness Contrast\",\n            self.brightnessContrast,\n            None,\n            \"color\",\n            \"Adjust brightness and contrast\",\n            enabled=False,\n        )\n        # Group zoom controls into a list for easier toggling.\n        zoomActions = (\n            self.zoomWidget,\n            zoomIn,\n            zoomOut,\n            zoomOrg,\n            fitWindow,\n            fitWidth,\n        )\n        self.zoomMode = self.FIT_WINDOW\n        fitWindow.setChecked(Qt.Checked)\n        self.scalers = {\n            self.FIT_WINDOW: self.scaleFitWindow,\n            self.FIT_WIDTH: self.scaleFitWidth,\n            # Set to one to scale to 100% when loading files.\n            self.MANUAL_ZOOM: lambda: 1,\n        }\n\n        edit = action(\n            self.tr(\"&Edit Label\"),\n            self.editLabel,\n            shortcuts[\"edit_label\"],\n            \"edit\",\n            self.tr(\"Modify the label of the selected polygon\"),\n            enabled=False,\n        )\n\n        fill_drawing = action(\n",
  "\n\ndef create_application_config(args: Namespace) -> Config:\n    config: Config = Config(\n        root_directory=set(args.path),\n        overwrite_function_docstring=args.overwrite_function_docstring,\n        documentation_style=args.documentation_style,\n    )\n    config.directories_ignore.update(set(args.directories_ignore))\n    config.files_ignore.update(set(args.files_ignore))\n    return config\n",
  "    n_classes = 4\n    maizenet = MaizeNet(n_classes)\n    maizenet.load_state_dict(torch.load(model_path, map_location=torch.device('cpu') ))\n    return maizenet\n\ndef preprocess_image(image):\n    mean = np.array([0.5, 0.5, 0.5])\n    std = np.array([0.25, 0.25, 0.25])\n    data_transform = transforms.Compose([\n            transforms.RandomResizedCrop(224), # resize and crop image to 224 x 224 pixels\n            transforms.RandomHorizontalFlip(), # flip the images horizontally\n            transforms.ToTensor(), # convert to pytorch tensor data type\n            transforms.Normalize(mean, std) # normalize the input image dataset.\n        ])\n    transformed_image = data_transform(image).to('cpu')\n    transformed_image = torch.unsqueeze(transformed_image, 0)\n    return transformed_image\n\ndef evaluate_image(image, model):\n    transformed_image = preprocess_image(image)\n    labels = ['Maize Leaf Rust', 'Northern Leaf Blight', 'Healthy', 'Gray Leaf Spot']\n    model.eval()\n    prediction = F.softmax(model(transformed_image), dim = 1)\n    data = {\n        'Maize Leaf Rust': round(float(prediction[0][0]), 4) * 100,\n        'Northern Leaf Blight': round(float(prediction[0][1]) * 100, 4),\n        'Healthy': round(float(prediction[0][2]), 4) * 100,\n        'Gray Leaf Spot': round(float(prediction[0][3]) * 100, 4)\n    }\n    prediction = prediction.argmax()\n    return labels[prediction], data\n",
  "        #     slide_item = loader.load_item()\n        #     link = slide.css(\".item a::attr(href)\").get()\n        #     self.logger.info(\"Parsing the slide\")\n        #     yield Request(link, callback=self.parse_slide, meta={\"slide_item\": slide_item})\n        \n            \n    def parse_problem(self, response: Response, **kwargs: Any) -> Any:\n        # slide_item = response.meta[\"slide_item\"]\n        # loader = ItemLoader(item=slide_item, response=response)\n        # loader.add_css(field_name=\"tags\", css=\".Sm-tags a.mr-2::text\")\n        # loader.add_css(field_name=\"description\", css=\".product-text p\")\n        # loader.add_css(field_name=\"slides_count\", css='h4 small::text')\n        # loader.add_css(field_name=\"colors\", css='li.color a::text')\n        # loader.add_css(field_name=\"image_urls\", css='a.preview-link img::attr(src)')\n        # add slide link\n        # yield loader.load_item()\n        categories: list[dict] = []\n        cats = response.css('span.cat-links a')\n        for cat in cats:\n            category = cat.css('::text').get()\n            category_link = cat.css('::attr(href)').get()\n            categories.append({\n                \"category\": category,\n                \"link\": category_link\n            })\n        \n        yield {\n            \"categories\": categories,\n            \"title\": response.css('h1::text').get(),\n            # \"problem\": response.css('.post-content p').getall(),\n            \"conditions\": response.css('.post-content ol').get(),\n            # \"io\": response.css('.io').get(),\n            # \"solutions\": response.css('h2::text').getall(), \n            # \"link\": response.url,\n            # \"code\": response.css('.c-line').getall(),\n            \"image\": response.css('.post-content p img::attr(src)').get()\n        }",
  "#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"\n\nIMAGES_URLS_FIELD = \"image_urls\"\nIMAGES_RESULT_FIELD = \"images\"\nIMAGES_STORE = \"/home/lyle/oryks/scrapy-tutorial/slidesmodel/images\"\nCONNECTION_STRING = \"sqlite:////home/lyle/oryks/scrapy-tutorial/data/slides.db\"\nSTART_URLS_PATH = \"/home/lyle/oryks/scrapy-tutorial/links.json\"\n",
  "# utils.py\n\nfrom playwright.sync_api import sync_playwright\nimport uuid\nfrom PIL import Image\nfrom PIL import Image\nimport io\nfrom os import path\nimport json\n\nindex: int = 1\n\ndef take_screenshot_from_url(url, session_data):\n    with sync_playwright() as playwright:\n        webkit = playwright.webkit\n        browser = webkit.launch()\n        browser_context = browser.new_context(device_scale_factor=2)\n        browser_context.add_cookies([session_data])\n        page = browser_context.new_page()\n        page.goto(url)\n        screenshot_bytes = page.locator(\".code\").screenshot()\n        browser.close()\n        return screenshot_bytes\n    \n    \ndef save_data(image_bytes: bytes, code: str) -> None:\n    file_name: str = str(uuid.uuid4())\n    image: Image = Image.open(io.BytesIO(image_bytes))\n    file_path: str = \"data\"\n    image_path: str = path.join(file_path, f\"{file_name}.png\")\n    image.save(image_path)\n    code_path: str = path.join(file_path, \"metadata.jsonl\")\n    metadata: dict = {\n        \"file_name\": f\"{file_name}.png\",\n        \"code\": code\n    }\n    with open(code_path, \"a+\", encoding=\"utf-8\") as f:\n        f.write(json.dumps(metadata) + \"\\n\")",
  "        api_version=api_version,\n        credentials_dir=credentials_dir,\n        credentials_file_name=credentials_file_name\n    )\n\n    gslides_client = auth.authenticate_google_server()\n    return gslides_client\n\n\ndef create_drive_client() -> Any:\n    secrets_file: str = \"/home/lyle/oryks/backend/api/libraries/drive.json\"\n    scopes: list[str] = [\n        GoogleDriveScopes.metadata.value,\n        GoogleDriveScopes.drive.value,\n        GoogleDriveScopes.files.value\n    ]\n    api_service_name: str = \"drive\"\n    api_version: str = \"v3\"\n    credentials_dir: str = GoogleDirectories.drive.value\n    credentials_file_name: Optional[str] = 'credentials.json'\n\n    auth: GoogleOAuth = GoogleOAuth(\n        secrets_file=secrets_file,\n        scopes=scopes,\n        api_service_name=api_service_name,\n        api_version=api_version,\n        credentials_dir=credentials_dir,\n        credentials_file_name=credentials_file_name\n    )\n\n    drive_client = auth.authenticate_google_server()\n    return drive_client\n\n\ndef get_youtube_client() -> YouTube:\n    client_secrets_file: str = \"/home/lyle/oryks/backend/api/libraries/youtube.json\"\n    youtube: YouTube = YouTube(client_secret_file=client_secrets_file)\n    return youtube\n\nyoutube_client: YouTube = get_youtube_client()\n",
  "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library for authenticating requests for various google services including ``gmail``, ``youtube``, ``drive`` and ``calendar``.'\n\nkey_words = [\n    'google-auth',\n]\n\ninstall_requires = [\n    'google-api-python-client',\n    'google-auth-oauthlib',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-google-oauth',\n    packages=find_packages(\n        include=[\n            'oryks_google_oauth',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n",
  "    # React to canvas signals.\n    def shapeSelectionChanged(self, selected_shapes):\n        self._noSelectionSlot = True\n        for shape in self.canvas.selectedShapes:\n            shape.selected = False\n        self.labelList.clearSelection()\n        self.canvas.selectedShapes = selected_shapes\n        for shape in self.canvas.selectedShapes:\n            shape.selected = True\n            item = self.labelList.findItemByShape(shape)\n            self.labelList.selectItem(item)\n            self.labelList.scrollToItem(item)\n        self._noSelectionSlot = False\n        n_selected = len(selected_shapes)\n        self.actions.delete.setEnabled(n_selected)\n        self.actions.duplicate.setEnabled(n_selected)\n        self.actions.copy.setEnabled(n_selected)\n        self.actions.edit.setEnabled(n_selected == 1)\n\n    def addLabel(self, shape):\n        if shape.group_id is None:\n            text = shape.label\n        else:\n            text = \"{} ({})\".format(shape.label, shape.group_id)\n        label_list_item = LabelListWidgetItem(text, shape)\n        self.labelList.addItem(label_list_item)\n        if self.uniqLabelList.findItemByLabel(shape.label) is None:\n            item = self.uniqLabelList.createItemFromLabel(shape.label)\n            self.uniqLabelList.addItem(item)\n            rgb = self._get_rgb_by_label(shape.label)\n            self.uniqLabelList.setItemLabel(item, shape.label, rgb)\n        self.labelDialog.addLabelHistory(shape.label)\n        for action in self.actions.onShapesPresent:\n            action.setEnabled(True)\n\n        self._update_shape_color(shape)\n        label_list_item.setText(\n            '{} <font color=\"#{:02x}{:02x}{:02x}\">●</font>'.format(\n                html.escape(text), *shape.fill_color.getRgb()[:3]\n            )\n",
  "#     part=part, \n#     optional_parameters=optional_parameters\n# )\n# search_results: YouTubeResponse = youtube.search(search_request)\n# print(search_results)\n# print(youtube.find_my_channel())\n# part: CommentThreadPart = CommentThreadPart()\n# filter: CommentThreadFilter = CommentThreadFilter(\n#     videoId='Tuc-rjJbsXU'\n# )\n# optional: CommentThreadOptionalParameters = CommentThreadOptionalParameters(\n#     maxResults=5\n# )\n# request:YouTubeRequest = YouTubeRequest(\n#     part=part,\n#     filter=filter,\n#     optional_parameters=optional\n# )\n# comment_iterator: Iterator = youtube.get_comments_iterator(request)\n# video_comments: list[Comment] = list()\n# for comment_threads in comment_iterator:\n#     for comment_thread in comment_threads:\n#         comment: Comment = comment_thread.snippet.top_level_comment\n#         video_comments.append(comment)\n# print(video_comments)\n# comment_id: str = 'UgzdXi_vWhXLkBA_Pwt4AaABAg'\n# response = youtube.get_comment(comment_id)\n# print(response)\n# import json\n\n# with open('comment.json', 'w') as f:\n#     json.dump(response, f, indent=4)\n# from youtube.resources.comment_thread.comment import CommentResource\n# import json\n# comment_res = CommentResource(youtube_client)\n# with open('comment.json', 'r') as f:\n#     comments = json.load(f)\n# print(comment_res.parse_youtube_list_response(comments))\n# replies = youtube.get_comment_replies('UgxwXLTWugMg7IEoKgR4AaABAg')\n# import json\n",
  "    for shape in sorted(data[\"shapes\"], key=lambda x: x[\"label\"]):\n        label_name = shape[\"label\"]\n        if label_name in label_name_to_value:\n            label_value = label_name_to_value[label_name]\n        else:\n            label_value = len(label_name_to_value)\n            label_name_to_value[label_name] = label_value\n    lbl, _ = utils.shapes_to_label(img.shape, data[\"shapes\"], label_name_to_value)\n\n    label_names = [None] * (max(label_name_to_value.values()) + 1)\n    for name, value in label_name_to_value.items():\n        label_names[value] = name\n\n    lbl_viz = imgviz.label2rgb(\n        lbl, imgviz.asgray(img), label_names=label_names, loc=\"rb\"\n    )\n\n    PIL.Image.fromarray(img).save(osp.join(out_dir, \"img.png\"))\n    utils.lblsave(osp.join(out_dir, \"label.png\"), lbl)\n    PIL.Image.fromarray(lbl_viz).save(osp.join(out_dir, \"label_viz.png\"))\n\n    with open(osp.join(out_dir, \"label_names.txt\"), \"w\") as f:\n        for lbl_name in label_names:\n            f.write(lbl_name + \"\\n\")\n\n    logger.info(\"Saved to: {}\".format(out_dir))\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "import os.path as osp\nfrom math import sqrt\n\nimport numpy as np\nfrom qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\n\nhere = osp.dirname(osp.abspath(__file__))\n\n\ndef newIcon(icon):\n    icons_dir = osp.join(here, \"../icons\")\n    return QtGui.QIcon(osp.join(\":/\", icons_dir, \"%s.png\" % icon))\n\n\ndef newButton(text, icon=None, slot=None):\n    b = QtWidgets.QPushButton(text)\n    if icon is not None:\n        b.setIcon(newIcon(icon))\n    if slot is not None:\n        b.clicked.connect(slot)\n    return b\n\n\ndef newAction(\n    parent,\n    text,\n    slot=None,\n    shortcut=None,\n    icon=None,\n    tip=None,\n    checkable=False,\n    enabled=True,\n    checked=False,\n):\n    \"\"\"Create a new action and assign callbacks, shortcuts, etc.\"\"\"\n    a = QtWidgets.QAction(text, parent)\n    if icon is not None:\n        a.setIconText(text.replace(\" \", \"\\n\"))\n",
  "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "#     sort_key=lambda x: len(x.src),\n#     device=device,\n# )\n\n# encoder_net = Encoder(\n#     input_size_encoder, encoder_embedding_size, hidden_size, num_layers, enc_dropout\n# ).to(device)\n\n# decoder_net = Decoder(\n#     input_size_decoder,\n#     decoder_embedding_size,\n#     hidden_size,\n#     output_size,\n#     num_layers,\n#     dec_dropout,\n# ).to(device)\n\n# model = Seq2Seq(encoder_net, decoder_net).to(device)\n# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# pad_idx = english.vocab.stoi[\"<pad>\"]\n# criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n\n# if load_model:\n#     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n\n\n# sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n\n# for epoch in range(num_epochs):\n#     print(f\"[Epoch {epoch} / {num_epochs}]\")\n\n#     checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n#     save_checkpoint(checkpoint)\n\n#     model.eval()\n\n#     translated_sentence = translate_sentence(\n#         model, sentence, german, english, device, max_length=50\n#     )\n",
  "            mask = labelme.utils.shape_to_mask(img.shape[:2], points, shape_type)\n\n            if group_id is None:\n                group_id = uuid.uuid1()\n\n            instance = (label, group_id)\n\n            if instance in masks:\n                masks[instance] = masks[instance] | mask\n            else:\n                masks[instance] = mask\n\n            if shape_type == \"rectangle\":\n                (x1, y1), (x2, y2) = points\n                x1, x2 = sorted([x1, x2])\n                y1, y2 = sorted([y1, y2])\n                points = [x1, y1, x2, y1, x2, y2, x1, y2]\n            if shape_type == \"circle\":\n                (x1, y1), (x2, y2) = points\n                r = np.linalg.norm([x2 - x1, y2 - y1])\n                # r(1-cos(a/2))<x, a=2*pi/N => N>pi/arccos(1-x/r)\n                # x: tolerance of the gap between the arc and the line segment\n                n_points_circle = max(int(np.pi / np.arccos(1 - 1 / r)), 12)\n                i = np.arange(n_points_circle)\n                x = x1 + r * np.sin(2 * np.pi / n_points_circle * i)\n                y = y1 + r * np.cos(2 * np.pi / n_points_circle * i)\n                points = np.stack((x, y), axis=1).flatten().tolist()\n            else:\n                points = np.asarray(points).flatten().tolist()\n\n            segmentations[instance].append(points)\n        segmentations = dict(segmentations)\n\n        for instance, mask in masks.items():\n            cls_name, group_id = instance\n            if cls_name not in class_name_to_id:\n                continue\n            cls_id = class_name_to_id[cls_name]\n\n            mask = np.asfortranarray(mask.astype(np.uint8))\n",
  "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool asynchronously.\"\"\"\n        raise NotImplementedError(\"Calculator does not support async\")\n\n\nclass YouTubeChannelVideoSearchTool(BaseTool):\n    name = \"youtube_channel_video_search\"\n    description = \"useful for when you need to answer questions about videos for a youtube channel\"\n    args_schema: Type[BaseModel] = YouTubeChannelSearch\n\n    def _run(\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool.\"\"\"\n        return ''\n\n    async def _arun(\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool asynchronously.\"\"\"\n        raise NotImplementedError(\"Calculator does not support async\")\n\nllm = ChatOpenAI(\n    temperature=0, \n    openai_api_key=config.open_ai_token,\n    )\n\ntools = [\n    YouTubeChannelTitleSearchTool(), \n    YouTubeChannelVideoSearchTool(),\n    YouTubeChannelSearchTool()\n    ]\nagent = initialize_agent(\n    tools, \n    llm, \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n    verbose=True,\n    handle_parsing_errors=True\n)\n",
  "from .set_config import set_configuration",
  "import ast\nimport os\nimport subprocess\nfrom argparse import ArgumentParser, Namespace\nfrom ast import AsyncFunctionDef, ClassDef, Constant, Expr, FunctionDef\nfrom collections import deque\nfrom os import listdir, path\nfrom queue import Queue\nfrom typing import Iterator\n\nfrom langchain.prompts import PromptTemplate\n\nfrom .config import Config\nfrom .extensions import llm\nfrom .templates import get_function_prompt_template, get_class_prompt_template\n\n\ndef generate_function_docstring(function_code: str, config: Config) -> str:\n    prompt_formatted_str: str = get_function_prompt_template(\n        function_code=function_code, config=config\n    )\n    function_and_docstring = llm.invoke(prompt_formatted_str)\n    return function_and_docstring\n\n\ndef generate_class_docstring(class_code: str, config: Config) -> str:\n    prompt_formatted_str: str = get_class_prompt_template(\n        class_code=class_code, config=config\n    )\n    class_and_docstring = llm.invoke(prompt_formatted_str)\n    return class_and_docstring\n\n\ndef get_class_docstring(class_and_docstring: str) -> str:\n    \"\"\"Get the class docstring.\"\"\"\n    class_tree = ast.parse(class_and_docstring)\n    for node in class_tree.body:\n        if isinstance(node, ClassDef):\n            cls_docstring: str = ast.get_docstring(node)\n            return cls_docstring\n",
  "def activate_user_account(session: Session, activation_data: ActivateUser):\n    with session() as db:\n        user: User = db.query(User).filter(User.id == activation_data.user_id).first()\n        if user.id == User.decode_auth_token(activation_data.activation_token):\n            user.activated = True\n            db.commit()\n            return True\n    raise InvalidTokenError('Invalid or Expired token.')\n\n\ndef loggin_user(session: Session, login_data: LoginUser):\n    with session() as db:\n        user: User = db.query(User).filter(User.email_address == login_data.email_address).first()\n        if user and user.check_password(login_data.password):\n            return True\n    raise ValueError('Invalid email address and or password.')\n",
  "            self.addLabel(shape)\n        self.labelList.clearSelection()\n        self._noSelectionSlot = False\n        self.canvas.loadShapes(shapes, replace=replace)\n\n    def loadLabels(self, shapes):\n        s = []\n        for shape in shapes:\n            label = shape[\"label\"]\n            points = shape[\"points\"]\n            shape_type = shape[\"shape_type\"]\n            flags = shape[\"flags\"]\n            description = shape.get(\"description\", \"\")\n            group_id = shape[\"group_id\"]\n            other_data = shape[\"other_data\"]\n\n            if not points:\n                # skip point-empty shape\n                continue\n\n            shape = Shape(\n                label=label,\n                shape_type=shape_type,\n                group_id=group_id,\n                description=description,\n                mask=shape[\"mask\"],\n            )\n            for x, y in points:\n                shape.addPoint(QtCore.QPointF(x, y))\n            shape.close()\n\n            default_flags = {}\n            if self._config[\"label_flags\"]:\n                for pattern, keys in self._config[\"label_flags\"].items():\n                    if re.match(pattern, label):\n                        for key in keys:\n                            default_flags[key] = False\n            shape.flags = default_flags\n            shape.flags.update(flags)\n            shape.other_data = other_data\n",
  "        dest=\"config\",\n        help=\"config file or yaml-format string (default: {})\".format(\n            default_config_file\n        ),\n        default=default_config_file,\n    )\n    # config for the gui\n    parser.add_argument(\n        \"--nodata\",\n        dest=\"store_data\",\n        action=\"store_false\",\n        help=\"stop storing image data to JSON file\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--autosave\",\n        dest=\"auto_save\",\n        action=\"store_true\",\n        help=\"auto save\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--nosortlabels\",\n        dest=\"sort_labels\",\n        action=\"store_false\",\n        help=\"stop sorting labels\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--flags\",\n        help=\"comma separated list of flags OR file containing flags\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--labelflags\",\n        dest=\"label_flags\",\n        help=r\"yaml string of label specific flags OR file containing json \"\n        r\"string of label specific flags (ex. {person-\\d+: [male, tall], \"\n        r\"dog-\\d+: [black, brown, white], .*: [occluded]})\",  # NOQA\n        default=argparse.SUPPRESS,\n",
  "from sqlalchemy.orm import Session\nfrom ..models.post import Post\nfrom ..schemas.post import (\n    CreatePost, GetPosts, GetPost, UpdatePost\n)\nfrom werkzeug.datastructures import FileStorage\nfrom flask import current_app\nfrom uuid import uuid4\nfrom werkzeug.utils import secure_filename\nimport os\nimport secrets\nfrom typing import Callable",
  "def create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like",
  "            session.add(slide)\n            session.commit()\n\n        except:\n            session.rollback()\n            raise\n\n        finally:\n            session.close()\n\n        return item\n\n\nclass DuplicatesPipeline(object):\n\n    def __init__(self):\n        \"\"\"\n        Initializes database connection and sessionmaker.\n        Creates tables.\n        \"\"\"\n        engine = db_connect()\n        create_table(engine)\n        self.Session = sessionmaker(bind=engine)\n        logging.info(\"****DuplicatesPipeline: database connected****\")\n\n    def process_item(self, item: Item, spider: Spider):\n        session = self.Session()\n        exist_slide = session.query(Slide).filter_by(title=item[\"title\"]).first()\n        session.close()\n        if exist_slide is not None:  # the current slide exists\n            raise DropItem(\"Duplicate item found: %s\" % item[\"title\"])\n        else:\n            return item",
  "@post.route(\"/views\", methods=[\"GET\"])\ndef get_post_views():\n    \"\"\"Get a posts comments.\"\"\"\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        views: list[View] = list_post_views(session=get_db, post_data=post_data)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    resp = [\n        RepeatableActivityCreated(\n            user_id=view.author_id,\n            post_id=view.post_id,\n            date_created=view.view_date,\n            id=view.id\n        ).model_dump()\n        for view in views\n    ]\n    return resp, HTTPStatus.OK",
  "def has_viewed(session: Session, activity: CreateActivity) -> View:\n    with session() as db:\n        view: View = db.query(View).filter(View.author_id==activity.user_id, View.post_id==activity.post_id).first()\n        if view:\n            return True\n    return False\n\ndef list_user_views(session: Session, user_data: GetUser) -> list[View]:\n    with session() as db:\n        user: User = db.query(User).filter(User.id == user_data.user_id).first()\n        views: list[View] = user.views\n    return views\n\ndef list_post_views(session: Session, post_data: GetPost):\n    with session() as db:\n        post: Post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        views: list[View] = post.views\n    return views",
  "                function_name=function_name,\n                function_code=function_code,\n                config=config,\n            )\n            new_tree = transformer.visit(module_tree)\n            ast.fix_missing_locations(new_tree)\n            new_module_code = ast.unparse(new_tree)\n        except Empty:\n            continue\n        except Exception as e:\n            print(e)\n            functions_source_queue.task_done()\n            continue\n        else:\n            save_processed_file(\n                file_path=module_path, processed_module_code=new_module_code\n            )\n            format_file(module_path)\n            functions_source_queue.task_done()\n\ndef generate_class_docstrings(class_source_queue: Queue, config: Config) -> None:\n    \"\"\"Generate docstrings for this file.\"\"\"\n    while True:\n        try:\n            module_path, class_name, class_code = class_source_queue.get()\n            module_tree = ast.parse(get_module_source_code(module_path))\n            transformer = ClassDocStringWriter(\n                module_path=module_path,\n                class_name=class_name,\n                class_code=class_code,\n                config=config,\n            )\n            new_tree = transformer.visit(module_tree)\n            ast.fix_missing_locations(new_tree)\n            new_module_code = ast.unparse(new_tree)\n        except Empty:\n            continue\n        except Exception as e:\n            print(e)\n            class_source_queue.task_done()\n",
  "from .register_blueprints import register_blueprints",
  "def get_exception(exc):\n    \"\"\"Log exceptions\"\"\"\n    if exc:\n        app_logger.warning(f\"{exc.__class__.__name__ }: {str(exc)}\")\n        \n        \ndef register_app_hooks(app: Flask):\n    @app.before_first_request\n    def application_startup():\n        \"\"\"Log the beginning of the application.\"\"\"\n        app_logger.info('Web app is up!')\n\n    @app.before_request\n    def log_request():\n        \"\"\"Log the data held in the request\"\"\"\n        if request.method in ['POST', 'PUT']:\n            log_post_request()\n        elif request.method in ['GET', 'DELETE']:\n            log_get_request()\n\n    @app.after_request\n    def log_response(response):\n        try:\n            get_response(response)\n        except Exception:\n            pass\n        finally:\n            return response\n\n    @app.teardown_request\n    def log_exception(exc):\n        get_exception(exc)",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom assistant.agents import default_agent\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set('agent', default_agent)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    agent = cl.user_session.get('agent')\n    msg = cl.Message(content='')\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({'input': message.content})['output']\n    await msg.update()\n",
  "@post.route(\"/create\", methods=[\"POST\", \"GET\"])\ndef create_new_post():\n    \"\"\"Create a new post.\"\"\"\n    if request.method == 'GET':\n        return {'success': 'post creation form'}, HTTPStatus.OK\n    elif request.method == 'POST':\n        try:\n            post_data = CreatePost(**request.form) \n        except ValidationError:\n            return {'Error': 'The data provided is invalid or incomplete!'}, HTTPStatus.BAD_REQUEST\n        try:\n            user_data = GetUser(user_id=post_data.author_id)\n            user = get_user(session=get_db, user_data=user_data)\n            if not user:\n                return {'Error': f'User with id {user_data.user_id} does not exists'}, HTTPStatus.NOT_FOUND \n            post: Post = create_post(post_data=post_data, post_image=request.files, session=get_db) \n        except (OperationalError, IntegrityError) as e:\n            print(e)\n            # Send email to\n            return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n        resp = CreatedPost(\n            id=post.id,\n            location=post.location,\n            text=post.text,\n            image_url=post.image_url,\n            author_id=post.author_id,\n            date_published=post.date_published\n        )\n        return resp.model_dump_json(indent=4), HTTPStatus.CREATED",
  "from ..schemas.activity import CreateActivity, GetRepeatableActivity\nfrom sqlalchemy.orm import Session\nfrom ..models.view import View\nfrom ..models.user import User\nfrom ..models.post import Post\nfrom ..schemas.user import GetUser\nfrom ..schemas.post import GetPost\nfrom uuid import uuid4\n\n\ndef create_view(session: Session, activity: CreateActivity) -> View:\n    with session() as db:\n        view: View = View(\n            author_id=activity.user_id,\n            post_id=activity.post_id,\n            id='View_' + str(uuid4())\n        )\n        db.add(view)\n        db.commit()\n        db.refresh(view)\n    return view",
  "import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n\ndef print_examples(model, device, dataset):\n    transform = transforms.Compose(\n        [\n            transforms.Resize((299, 299)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ]\n    )\n\n    model.eval()\n    test_img1 = transform(Image.open(\"test_examples/dog.jpg\").convert(\"RGB\")).unsqueeze(\n        0\n    )\n    print(\"Example 1 CORRECT: Dog on a beach by the ocean\")\n    print(\n        \"Example 1 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img1.to(device), dataset.vocabulary))\n    )\n    test_img2 = transform(\n        Image.open(\"test_examples/child.jpg\").convert(\"RGB\")\n    ).unsqueeze(0)\n    print(\"Example 2 CORRECT: Child holding red frisbee outdoors\")\n    print(\n        \"Example 2 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img2.to(device), dataset.vocabulary))\n    )\n    test_img3 = transform(Image.open(\"test_examples/bus.png\").convert(\"RGB\")).unsqueeze(\n        0\n    )\n    print(\"Example 3 CORRECT: Bus driving by parked cars\")\n    print(\n        \"Example 3 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img3.to(device), dataset.vocabulary))\n    )\n    test_img4 = transform(\n",
  "    imageData = data.get(\"imageData\")\n\n    if not imageData:\n        imagePath = os.path.join(os.path.dirname(json_file), data[\"imagePath\"])\n        with open(imagePath, \"rb\") as f:\n            imageData = f.read()\n            imageData = base64.b64encode(imageData).decode(\"utf-8\")\n    img = utils.img_b64_to_arr(imageData)\n\n    label_name_to_value = {\"_background_\": 0}\n    for shape in sorted(data[\"shapes\"], key=lambda x: x[\"label\"]):\n        label_name = shape[\"label\"]\n        if label_name in label_name_to_value:\n            label_value = label_name_to_value[label_name]\n        else:\n            label_value = len(label_name_to_value)\n            label_name_to_value[label_name] = label_value\n    lbl, _ = utils.shapes_to_label(img.shape, data[\"shapes\"], label_name_to_value)\n\n    label_names = [None] * (max(label_name_to_value.values()) + 1)\n    for name, value in label_name_to_value.items():\n        label_names[value] = name\n\n    lbl_viz = imgviz.label2rgb(\n        lbl, imgviz.asgray(img), label_names=label_names, loc=\"rb\"\n    )\n\n    PIL.Image.fromarray(img).save(osp.join(out_dir, \"img.png\"))\n    utils.lblsave(osp.join(out_dir, \"label.png\"), lbl)\n    PIL.Image.fromarray(lbl_viz).save(osp.join(out_dir, \"label_viz.png\"))\n\n    with open(osp.join(out_dir, \"label_names.txt\"), \"w\") as f:\n        for lbl_name in label_names:\n            f.write(lbl_name + \"\\n\")\n\n    logger.info(\"Saved to: {}\".format(out_dir))\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "    \nclass CNNToRNN(Module):\n    def __init__(self, embed_size, hidden_size, vocab_size, num_layers) -> None:\n        super().__init__()\n        self.encoder_cnn = EncoderCNN(embed_size=embed_size)\n        self.decoder_rnn = DecoderRNN(embed_size=embed_size, hidden_size=hidden_size, vocab_size=vocab_size, num_layers=num_layers)\n        \n    def forward(self, images, captions):\n        features = self.encoder_cnn(images)\n        outputs = self.decoder_rnn(features, captions)\n        return outputs\n    \n    def caption_image(self, image, vocabulary, max_length=50):\n        result_caption = []\n\n        with torch.no_grad():\n            x = self.encoder_cnn(image).unsqueeze(0)\n            # x = self.encoder_cnn(image)\n            states = None\n\n            for _ in range(max_length):\n                hiddens, states = self.decoder_rnn.lstm(x, states)\n                output = self.decoder_rnn.linear(hiddens.squeeze(0))\n                predicted = output.argmax(1)\n                result_caption.append(predicted.item())\n                x = self.decoder_rnn.embed(predicted).unsqueeze(0)\n\n                if vocabulary.itos[predicted.item()] == \"<EOS>\":\n                    break\n\n        return [vocabulary.itos[idx] for idx in result_caption]",
  "            slot=lambda x: self.actions.saveAuto.setChecked(x),\n            icon=\"save\",\n            tip=self.tr(\"Save automatically\"),\n            checkable=True,\n            enabled=True,\n        )\n        saveAuto.setChecked(self._config[\"auto_save\"])\n\n        saveWithImageData = action(\n            text=\"Save With Image Data\",\n            slot=self.enableSaveImageWithData,\n            tip=\"Save image data in label file\",\n            checkable=True,\n            checked=self._config[\"store_data\"],\n        )\n\n        close = action(\n            \"&Close\",\n            self.closeFile,\n            shortcuts[\"close\"],\n            \"close\",\n            \"Close current file\",\n        )\n\n        toggle_keep_prev_mode = action(\n            self.tr(\"Keep Previous Annotation\"),\n            self.toggleKeepPrevMode,\n            shortcuts[\"toggle_keep_prev_mode\"],\n            None,\n            self.tr('Toggle \"keep pevious annotation\" mode'),\n            checkable=True,\n        )\n        toggle_keep_prev_mode.setChecked(self._config[\"keep_prev\"])\n\n        createMode = action(\n            self.tr(\"Create Polygons\"),\n            lambda: self.toggleDrawMode(False, createMode=\"polygon\"),\n            shortcuts[\"create_polygon\"],\n            \"objects\",\n            self.tr(\"Start drawing polygons\"),\n",
  "import torch\nimport os\nfrom torch import nn\nfrom torchvision import transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport random\n\n\nclass MaizeNet(nn.Module):\n  def __init__(self, K) -> None:\n      super(MaizeNet, self).__init__()\n\n      self.conv_layers = nn.Sequential(\n          # convolution 1\n          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.MaxPool2d(2),\n          # Convolution 2\n          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.MaxPool2d(2),\n          # Convolution 3\n          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
  "\nfrom sqlalchemy import create_engine, Column, Table, ForeignKey, MetaData\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy import (\n    Integer, String, Date, DateTime, Float, Boolean, Text)\nfrom scrapy.utils.project import get_project_settings\nfrom sqlalchemy_utils import ScalarListType\n\n\nBase = declarative_base()\n\ndef db_connect():\n    \"\"\"\n    Performs database connection using database settings from settings.py.\n    Returns sqlalchemy engine instance\n    \"\"\"\n    settings: dict = get_project_settings()\n    connection_string: str = settings.get(\"CONNECTION_STRING\")\n    return create_engine(connection_string)\n\ndef create_table(engine):\n    Base.metadata.create_all(engine)\n    \n    \nslide_tag = Table('slide_tag', Base.metadata,\n    Column('slide_id', Integer, ForeignKey('slide.id')),\n    Column('tag_id', Integer, ForeignKey('tag.id'))\n)\n\nclass Slide(Base):\n    __tablename__ = \"slide\"\n\n    id = Column(String(), primary_key=True)\n    title = Column('title', String())\n    description = Column('description', Text())\n    category_id = Column(String(), ForeignKey('category.id'))\n    tags = relationship('Tag', secondary='slide_tag',\n        lazy='dynamic', backref=\"slide\")  # M-to-M for quote and tag\n    colors = Column(ScalarListType())\n",
  "import chainlit as cl\nfrom assistant.utils.assistant_utils import welcome_user\nfrom assistant.agent import get_agent_executor\n\n\n@cl.on_chat_start\nasync def start():\n    res = await cl.AskUserMessage(content=\"What is your name?\", timeout=30).send()\n    if res:\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        msg.content = welcome_user(user_name=res['content'])\n        await msg.update()\n        \n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    query: str = message.content\n    agent_executor = get_agent_executor(query)\n    msg.content = agent_executor.invoke({\"input\": query})['output']\n    await msg.update()",
  "    except ImportError:\n        # when this package is being installed\n        return long_description\n\n\ndef main():\n    version = get_version()\n\n    if sys.argv[1] == \"release\":\n        try:\n            import github2pypi  # NOQA\n        except ImportError:\n            print(\n                \"Please install github2pypi\\n\\n\\tpip install github2pypi\\n\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if not distutils.spawn.find_executable(\"twine\"):\n            print(\n                \"Please install twine:\\n\\n\\tpip install twine\\n\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        commands = [\n            \"git push origin main\",\n            \"git tag v{:s}\".format(version),\n            \"git push origin --tags\",\n            \"python setup.py sdist\",\n            \"twine upload dist/labelme-{:s}.tar.gz\".format(version),\n        ]\n        for cmd in commands:\n            print(\"+ {:s}\".format(cmd))\n            subprocess.check_call(shlex.split(cmd))\n        sys.exit(0)\n\n    setup(\n        name=\"labelme\",\n        version=version,\n",
  "        return None\n\n    def process_response(self, request, response, spider):\n        # Called with the response returned from the downloader.\n\n        # Must either;\n        # - return a Response object\n        # - return a Request object\n        # - or raise IgnoreRequest\n        return response\n\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        pass\n\n    def spider_opened(self, spider):\n        spider.logger.info(\"Spider opened: %s\" % spider.name)\n",
  "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library that wraps around the YouTube V3 API. You can use it find and manage YouTube resources including Videos, Playlists, Channels and Comments.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-youtube',\n    packages=find_packages(\n        include=[\n            'youtube',\n            'youtube.models',\n            'youtube.schemas',\n            'youtube.resources',\n            'youtube.resources.search',\n            'youtube.resources.video',\n",
  "from labelme.utils import shape as shape_module\n\nfrom .util import get_img_and_data\n\n\ndef test_shapes_to_label():\n    img, data = get_img_and_data()\n    label_name_to_value = {}\n    for shape in data[\"shapes\"]:\n        label_name = shape[\"label\"]\n        label_value = len(label_name_to_value)\n        label_name_to_value[label_name] = label_value\n    cls, _ = shape_module.shapes_to_label(\n        img.shape, data[\"shapes\"], label_name_to_value\n    )\n    assert cls.shape == img.shape[:2]\n\n\ndef test_shape_to_mask():\n    img, data = get_img_and_data()\n    for shape in data[\"shapes\"]:\n        points = shape[\"points\"]\n        mask = shape_module.shape_to_mask(img.shape[:2], points)\n        assert mask.shape == img.shape[:2]\n",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy.linkextractors import LinkExtractor \n\n\nclass SlidesLinkExtractor(Spider):\n    name: str = \"links-extractor\"\n    \n    start_urls: list[str] = [\n        \"https://slidemodel.com/templates/\"\n    ]\n    \n    def __init__(self, name=None, **kwargs): \n        super().__init__(name, **kwargs) \n  \n        self.link_extractor = LinkExtractor(unique=True) \n  \n    def parse(self, response: Response, **kwargs: Any) -> Any: \n        links = self.link_extractor.extract_links(response) \n  \n        for link in links: \n            if \"tag\" in link.url:\n                yield {\n                        \"url\": link.url, \n                        \"text\": link.text\n                    }",
  "            maker.filename(base + \".jpg\"),\n            maker.database(),  # e.g., The VOC2007 Database\n            maker.annotation(),  # e.g., Pascal VOC2007\n            maker.image(),  # e.g., flickr\n            maker.size(\n                maker.height(str(img.shape[0])),\n                maker.width(str(img.shape[1])),\n                maker.depth(str(img.shape[2])),\n            ),\n            maker.segmented(),\n        )\n\n        bboxes = []\n        labels = []\n        for shape in label_file.shapes:\n            if shape[\"shape_type\"] != \"rectangle\":\n                print(\n                    \"Skipping shape: label={label}, \" \"shape_type={shape_type}\".format(\n                        **shape\n                    )\n                )\n                continue\n\n            class_name = shape[\"label\"]\n            class_id = class_names.index(class_name)\n\n            (xmin, ymin), (xmax, ymax) = shape[\"points\"]\n            # swap if min is larger than max.\n            xmin, xmax = sorted([xmin, xmax])\n            ymin, ymax = sorted([ymin, ymax])\n\n            bboxes.append([ymin, xmin, ymax, xmax])\n            labels.append(class_id)\n\n            xml.append(\n                maker.object(\n                    maker.name(shape[\"label\"]),\n                    maker.pose(),\n                    maker.truncated(),\n                    maker.difficult(),\n",
  "    def __init__(self, *args, **kwargs):\n        self.epsilon = kwargs.pop(\"epsilon\", 10.0)\n        self.double_click = kwargs.pop(\"double_click\", \"close\")\n        if self.double_click not in [None, \"close\"]:\n            raise ValueError(\n                \"Unexpected value for double_click event: {}\".format(self.double_click)\n            )\n        self.num_backups = kwargs.pop(\"num_backups\", 10)\n        self._crosshair = kwargs.pop(\n            \"crosshair\",\n            {\n                \"polygon\": False,\n                \"rectangle\": True,\n                \"circle\": False,\n                \"line\": False,\n                \"point\": False,\n                \"linestrip\": False,\n                \"ai_polygon\": False,\n                \"ai_mask\": False,\n            },\n        )\n        super(Canvas, self).__init__(*args, **kwargs)\n        # Initialise local state.\n        self.mode = self.EDIT\n        self.shapes = []\n        self.shapesBackups = []\n        self.current = None\n        self.selectedShapes = []  # save the selected shapes here\n        self.selectedShapesCopy = []\n        # self.line represents:\n        #   - createMode == 'polygon': edge from last point to current\n        #   - createMode == 'rectangle': diagonal line of the rectangle\n        #   - createMode == 'line': the line\n        #   - createMode == 'point': the point\n        self.line = Shape()\n        self.prevPoint = QtCore.QPoint()\n        self.prevMovePoint = QtCore.QPoint()\n        self.offsets = QtCore.QPoint(), QtCore.QPoint()\n        self.scale = 1.0\n        self.pixmap = QtGui.QPixmap()\n",
  "def create_post(post_data: CreatePost, post_image: dict, session: Session):\n    post_image_url: str = save_post_photo(post_image)\n    post: Post = Post(\n        id='Post_' + str(uuid4()),\n        author_id=post_data.author_id,\n        location=post_data.location,\n        text=post_data.text,\n        image_url=post_image_url\n    )\n    with session() as db:\n        db.add(post)\n        db.commit()\n        db.refresh(post)\n    return post",
  "        memory=memory,\n    )\n    cl.user_session.set(\"agent\", agent)\n    \n\n@cl.on_message\nasync def main(message: cl.Message):\n    agent = cl.user_session.get(\"agent\")\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({\"input\": message.content})[\"output\"]\n    await msg.update()",
  "            \"line\",\n            \"point\",\n            \"linestrip\",\n            \"ai_polygon\",\n            \"ai_mask\",\n        ]:\n            raise ValueError(\"Unsupported createMode: %s\" % value)\n        self._createMode = value\n\n    def initializeAiModel(self, name):\n        if name not in [model.name for model in labelme.ai.MODELS]:\n            raise ValueError(\"Unsupported ai model: %s\" % name)\n        model = [model for model in labelme.ai.MODELS if model.name == name][0]\n\n        if self._ai_model is not None and self._ai_model.name == model.name:\n            logger.debug(\"AI model is already initialized: %r\" % model.name)\n        else:\n            logger.debug(\"Initializing AI model: %r\" % model.name)\n            self._ai_model = model()\n\n        if self.pixmap is None:\n            logger.warning(\"Pixmap is not set yet\")\n            return\n\n        self._ai_model.set_image(\n            image=labelme.utils.img_qt_to_arr(self.pixmap.toImage())\n        )\n\n    def storeShapes(self):\n        shapesBackup = []\n        for shape in self.shapes:\n            shapesBackup.append(shape.copy())\n        if len(self.shapesBackups) > self.num_backups:\n            self.shapesBackups = self.shapesBackups[-self.num_backups - 1 :]\n        self.shapesBackups.append(shapesBackup)\n\n    @property\n    def isShapeRestorable(self):\n        # We save the state AFTER each edit (not before) so for an\n        # edit to be undoable, we expect the CURRENT and the PREVIOUS state\n",
  "            enabled=False,\n        )\n        createAiPolygonMode = action(\n            self.tr(\"Create AI-Polygon\"),\n            lambda: self.toggleDrawMode(False, createMode=\"ai_polygon\"),\n            None,\n            \"objects\",\n            self.tr(\"Start drawing ai_polygon. Ctrl+LeftClick ends creation.\"),\n            enabled=False,\n        )\n        createAiPolygonMode.changed.connect(\n            lambda: self.canvas.initializeAiModel(\n                name=self._selectAiModelComboBox.currentText()\n            )\n            if self.canvas.createMode == \"ai_polygon\"\n            else None\n        )\n        createAiMaskMode = action(\n            self.tr(\"Create AI-Mask\"),\n            lambda: self.toggleDrawMode(False, createMode=\"ai_mask\"),\n            None,\n            \"objects\",\n            self.tr(\"Start drawing ai_mask. Ctrl+LeftClick ends creation.\"),\n            enabled=False,\n        )\n        createAiMaskMode.changed.connect(\n            lambda: self.canvas.initializeAiModel(\n                name=self._selectAiModelComboBox.currentText()\n            )\n            if self.canvas.createMode == \"ai_mask\"\n            else None\n        )\n        editMode = action(\n            self.tr(\"Edit Polygons\"),\n            self.setEditMode,\n            shortcuts[\"edit_polygon\"],\n            \"edit\",\n            self.tr(\"Move and edit the selected polygons\"),\n            enabled=False,\n        )\n",
  "from pydantic import BaseModel\nfrom typing import Optional\n\n\nclass UserBase(BaseModel):\n  first_name: str\n  last_name: str\n  email_address: str\n\n  \nclass UserCreate(UserBase):\n    password: str\n    role: str = 'user'\n    activated: bool = False\n    \nclass UserCreated(UserBase):\n    id: str\n    activation_token: str\n\nclass User(UserBase):\n    id: str\n    \n    class Config:\n        from_attributes = True\n        \nclass GetUser(BaseModel):\n    user_id: str\n    \nclass GetUsers(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10\n    \nclass ActivateUser(BaseModel):\n    user_id: str\n    activation_token: str\n    \nclass LoginUser(BaseModel):\n    email_address: str\n    password: str",
  "def get_exception(exc):\n    \"\"\"Log exceptions\"\"\"\n    if exc:\n        app_logger.warning(f\"{exc.__class__.__name__ }: {str(exc)}\")\n        \n        \ndef register_app_hooks(app: Flask):\n    @app.before_first_request\n    def application_startup():\n        \"\"\"Log the beginning of the application.\"\"\"\n        app_logger.info('Web app is up!')\n\n    @app.before_request\n    def log_request():\n        \"\"\"Log the data held in the request\"\"\"\n        if request.method in ['POST', 'PUT']:\n            log_post_request()\n        elif request.method in ['GET', 'DELETE']:\n            log_get_request()\n\n    @app.after_request\n    def log_response(response):\n        try:\n            get_response(response)\n        except Exception:\n            pass\n        finally:\n            return response\n\n    @app.teardown_request\n    def log_exception(exc):\n        get_exception(exc)",
  "            elif key == QtCore.Qt.Key_Left:\n                self.moveByKeyboard(QtCore.QPointF(-MOVE_SPEED, 0.0))\n            elif key == QtCore.Qt.Key_Right:\n                self.moveByKeyboard(QtCore.QPointF(MOVE_SPEED, 0.0))\n\n    def keyReleaseEvent(self, ev):\n        modifiers = ev.modifiers()\n        if self.drawing():\n            if int(modifiers) == 0:\n                self.snapping = True\n        elif self.editing():\n            if self.movingShape and self.selectedShapes:\n                index = self.shapes.index(self.selectedShapes[0])\n                if self.shapesBackups[-1][index].points != self.shapes[index].points:\n                    self.storeShapes()\n                    self.shapeMoved.emit()\n\n                self.movingShape = False\n\n    def setLastLabel(self, text, flags):\n        assert text\n        self.shapes[-1].label = text\n        self.shapes[-1].flags = flags\n        self.shapesBackups.pop()\n        self.storeShapes()\n        return self.shapes[-1]\n\n    def undoLastLine(self):\n        assert self.shapes\n        self.current = self.shapes.pop()\n        self.current.setOpen()\n        self.current.restoreShapeRaw()\n        if self.createMode in [\"polygon\", \"linestrip\"]:\n            self.line.points = [self.current[-1], self.current[0]]\n        elif self.createMode in [\"rectangle\", \"line\", \"circle\"]:\n            self.current.points = self.current.points[0:1]\n        elif self.createMode == \"point\":\n            self.current = None\n        self.drawingPolygon.emit(True)\n\n",
  "from pydantic import BaseModel\nfrom .post import PostAuthor\n    \nclass CommentSchema(BaseModel):\n    author: PostAuthor\n    text: str",
  "from scrapy import Item, Field\nfrom itemloaders.processors import TakeFirst, MapCompose, Join\nimport re\n\n\ndef remove_html_tags(description: str) -> str:\n    html_pattern = \"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\" \n    return re.sub(html_pattern, '', description)\n\ndef remove_unicode_chars(text: str) -> str:\n    return text.replace(u\"\\xa0\", \"\")\n\ndef num_of_slides(text: str) -> int:\n    vals = [val for val in list(text) if val.isdigit()]\n    return \"\".join(vals)\n\n\nclass SlidesModelItem(Item):\n    title = Field(output_processor=TakeFirst())\n    category = Field(output_processor=TakeFirst())\n    description = Field(\n        input_processor=MapCompose(remove_html_tags, remove_unicode_chars),\n        output_processor=Join()\n    )\n    tags = Field()\n    slides_count = Field(\n        input_processor=MapCompose(num_of_slides),\n        output_processor=TakeFirst()\n    )\n    colors = Field()\n    image_urls = Field()\n    images = Field()\n",
  "from datetime import datetime\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom ..database import Base\nfrom sqlalchemy import ForeignKey\n\n\nclass Like(Base):\n    __tablename__ = 'likes'\n    \n    author_id: Mapped[str] = mapped_column(ForeignKey('users.id'), primary_key=True)\n    post_id: Mapped[str] = mapped_column(ForeignKey('posts.id'), primary_key=True)\n    like_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    \n    author = relationship('User', back_populates='likes')\n    post = relationship('Post', back_populates='likes')",
  "# my_channel = youtube.find_my_channel()\n# part: CommentThreadPart = CommentThreadPart()\n# filter: CommentThreadFilter = CommentThreadFilter(\n#     videoId='-dJPoLm_gtE'\n# )\n# optional: CommentThreadOptionalParameters = CommentThreadOptionalParameters(\n#     maxResults=25\n# )\n# request:YouTubeRequest = YouTubeRequest(\n#     part=part,\n#     filter=filter,\n#     optional_parameters=optional\n# )\n# comments = youtube.find_video_comments(request)\n# part: CommentThreadPart = CommentThreadPart()\n# filter: CommentThreadFilter = CommentThreadFilter(\n#     allThreadsRelatedToChannelId='UCRijo3ddMTht_IHyNSNXpNQ'\n# )\n# optional: CommentThreadOptionalParameters = CommentThreadOptionalParameters(\n#     maxResults=25\n# )\n# request:YouTubeRequest = YouTubeRequest(\n#     part=part,\n#     filter=filter,\n#     optional_parameters=optional\n# )\n# channel_comments = youtube.find_all_channel_comments(request)\n# comment = youtube.get_comment('UgxAQ5xm0pH2NQcwokx4AaABAg')\n# replies = youtube.get_comment_replies('UgxwXLTWugMg7IEoKgR4AaABAg')\n# comment_text = 'Sample comment text'\n# video_id = 'jl3b4eLKiP8'\n# comment = youtube.insert_comment(video_id, comment_text)\n# comment_id = 'UgxnWN0P4ii1OiIEWft4AaABAg'\n# reply = 'Sample comment reply'\n# comment_reply = youtube.reply_to_comment(comment_id, reply)\n# channel_playlists = youtube.find_channel_playlists('UCRijo3ddMTht_IHyNSNXpNQ')\n# my_playlists = youtube.find_my_playlists()\n# print(my_playlists)\n# playlist_snippet = CreatePlaylistSnippet(\n#     title='sample title',\n",
  "        elif self.output_file:\n            self._saveFile(self.output_file)\n            self.close()\n        else:\n            self._saveFile(self.saveFileDialog())\n\n    def saveFileAs(self, _value=False):\n        assert not self.image.isNull(), \"cannot save empty image\"\n        self._saveFile(self.saveFileDialog())\n\n    def saveFileDialog(self):\n        caption = self.tr(\"%s - Choose File\") % __appname__\n        filters = self.tr(\"Label files (*%s)\") % LabelFile.suffix\n        if self.output_dir:\n            dlg = QtWidgets.QFileDialog(self, caption, self.output_dir, filters)\n        else:\n            dlg = QtWidgets.QFileDialog(self, caption, self.currentPath(), filters)\n        dlg.setDefaultSuffix(LabelFile.suffix[1:])\n        dlg.setAcceptMode(QtWidgets.QFileDialog.AcceptSave)\n        dlg.setOption(QtWidgets.QFileDialog.DontConfirmOverwrite, False)\n        dlg.setOption(QtWidgets.QFileDialog.DontUseNativeDialog, False)\n        basename = osp.basename(osp.splitext(self.filename)[0])\n        if self.output_dir:\n            default_labelfile_name = osp.join(\n                self.output_dir, basename + LabelFile.suffix\n            )\n        else:\n            default_labelfile_name = osp.join(\n                self.currentPath(), basename + LabelFile.suffix\n            )\n        filename = dlg.getSaveFileName(\n            self,\n            self.tr(\"Choose File\"),\n            default_labelfile_name,\n            self.tr(\"Label files (*%s)\") % LabelFile.suffix,\n        )\n        if isinstance(filename, tuple):\n            filename, _ = filename\n        return filename\n\n",
  "        relevanceLanguage=relevance_language,\n        type=['video'],\n        videoCaption=video_caption,\n        videoCategoryId=video_category_id,\n        videoDefinition=video_definition,\n        videoDimension=video_dimension,\n        videoDuration=video_duration,\n        videoPaidProductPlacement=video_paid_product_placement,\n        videoSyndicated=video_syndicated,\n        videoType=video_type\n    )\n    search_schema: YouTubeRequest = YouTubeRequest(\n        part=search_part, optional_parameters=optional_params\n    )\n    response: YouTubeResponse = youtube_client.search(search_schema)\n    items: list[Search] = response.items\n    return items\n\n\ndef list_video_comments(video_id: str) -> list[Comment]:\n    \"\"\"List a given videos comments\"\"\"\n    part: CommentThreadPart = CommentThreadPart()\n    filter: CommentThreadFilter = CommentThreadFilter(\n        videoId=video_id\n    )\n    optional: CommentThreadOptionalParameters = CommentThreadOptionalParameters(\n        maxResults=30\n    )\n    request:YouTubeRequest = YouTubeRequest(\n        part=part,\n        filter=filter,\n        optional_parameters=optional\n    )\n    comment_iterator: Iterator = youtube_client.get_comments_iterator(request)\n    video_comments: list[Comment] = list()\n    done: bool = False\n    comment_count: int = 0\n    for comment_threads in comment_iterator:\n        if done:\n            break\n",
  "        utils.addActions(self.canvas.menus[0], menu)\n        self.menus.edit.clear()\n        actions = (\n            self.actions.createMode,\n            self.actions.createRectangleMode,\n            self.actions.createCircleMode,\n            self.actions.createLineMode,\n            self.actions.createPointMode,\n            self.actions.createLineStripMode,\n            self.actions.createAiPolygonMode,\n            self.actions.createAiMaskMode,\n            self.actions.editMode,\n        )\n        utils.addActions(self.menus.edit, actions + self.actions.editMenu)\n\n    def setDirty(self):\n        # Even if we autosave the file, we keep the ability to undo\n        self.actions.undo.setEnabled(self.canvas.isShapeRestorable)\n\n        if self._config[\"auto_save\"] or self.actions.saveAuto.isChecked():\n            label_file = osp.splitext(self.imagePath)[0] + \".json\"\n            if self.output_dir:\n                label_file_without_path = osp.basename(label_file)\n                label_file = osp.join(self.output_dir, label_file_without_path)\n            self.saveLabels(label_file)\n            return\n        self.dirty = True\n        self.actions.save.setEnabled(True)\n        title = __appname__\n        if self.filename is not None:\n            title = \"{} - {}*\".format(title, self.filename)\n        self.setWindowTitle(title)\n\n    def setClean(self):\n        self.dirty = False\n        self.actions.save.setEnabled(False)\n        self.actions.createMode.setEnabled(True)\n        self.actions.createRectangleMode.setEnabled(True)\n        self.actions.createCircleMode.setEnabled(True)\n        self.actions.createLineMode.setEnabled(True)\n",
  "# for caption in captions[:5]:\n#     res = dataset.vocabulary.textualize(caption)\n#     print(res)",
  "import re\n\nfrom qtpy import QT_VERSION\nfrom qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\n\nimport labelme.utils\nfrom labelme.logger import logger\n\nQT5 = QT_VERSION[0] == \"5\"\n\n\n# TODO(unknown):\n# - Calculate optimal position so as not to go out of screen area.\n\n\nclass LabelQLineEdit(QtWidgets.QLineEdit):\n    def setListWidget(self, list_widget):\n        self.list_widget = list_widget\n\n    def keyPressEvent(self, e):\n        if e.key() in [QtCore.Qt.Key_Up, QtCore.Qt.Key_Down]:\n            self.list_widget.keyPressEvent(e)\n        else:\n            super(LabelQLineEdit, self).keyPressEvent(e)\n\n\nclass LabelDialog(QtWidgets.QDialog):\n    def __init__(\n        self,\n        text=\"Enter object label\",\n        parent=None,\n        labels=None,\n        sort_labels=True,\n        show_text_field=True,\n        completion=\"startswith\",\n        fit_to_content=None,\n        flags=None,\n    ):\n",
  "def get_exception(exc):\n    \"\"\"Log exceptions\"\"\"\n    if exc:\n        app_logger.warning(f\"{exc.__class__.__name__ }: {str(exc)}\")\n        \n        \ndef register_app_hooks(app: Flask):\n    @app.before_first_request\n    def application_startup():\n        \"\"\"Log the beginning of the application.\"\"\"\n        app_logger.info('Web app is up!')\n\n    @app.before_request\n    def log_request():\n        \"\"\"Log the data held in the request\"\"\"\n        if request.method in ['POST', 'PUT']:\n            log_post_request()\n        elif request.method in ['GET', 'DELETE']:\n            log_get_request()\n\n    @app.after_request\n    def log_response(response):\n        try:\n            get_response(response)\n        except Exception:\n            pass\n        finally:\n            return response\n\n    @app.teardown_request\n    def log_exception(exc):\n        get_exception(exc)",
  "from queue import Queue\n\nsource_code_queue: Queue = Queue()\nfunction_code_queue: Queue = Queue()\n",
  "```\n{comment}\n```\n\n{format_instructions}\n\"\"\"\n\npositive_tmpl = PromptTemplate(\n    template=topic_assg_msg,\n    input_variables=[\"comment\", \"topics\"],\n    partial_variables={\n        \"format_instructions\": positive_parser.get_format_instructions()\n    },\n)\n\nnegative_tmpl = PromptTemplate(\n    template=topic_assg_msg,\n    input_variables=[\"comment\", \"topics\"],\n    partial_variables={\n        \"format_instructions\": negative_parser.get_format_instructions()\n    },\n)\n\nsentiment_chain = sentiment_template | llm | StrOutputParser()\npos_chain = positive_tmpl | llm | positive_parser\nneg_chain = negative_tmpl | llm | negative_parser\n\n# res = sentiment_chain.invoke({\"comment\": comment})\n# print(res, comment)\n# if 'positive' in res.lower():\n#     res = pos_chain.invoke({\"comment\": comment, 'topics': topics})\n# elif 'negative' in res.lower():\n#     res = neg_chain.invoke({\"comment\": comment, 'topics': topics})\n# print(res)\n\nbranch = RunnableBranch(\n    (lambda input: 'positive' in input['sentiment'].lower(), pos_chain),\n    neg_chain\n)\n\n",
  "from oauth import OAuth\nfrom helpers import create_message, send_message\n\n    \ngmail_client = get_gmail_client('credentials.json')\nmessage = create_message()\nmessage = send_message(gmail_client, message)\nprint(message)",
  "        print(\"Generating dataset from:\", filename)\n\n        label_file = labelme.LabelFile(filename=filename)\n\n        base = osp.splitext(osp.basename(filename))[0]\n        out_img_file = osp.join(args.output_dir, \"JPEGImages\", base + \".jpg\")\n        out_clsp_file = osp.join(args.output_dir, \"SegmentationClass\", base + \".png\")\n        if not args.nonpy:\n            out_cls_file = osp.join(\n                args.output_dir, \"SegmentationClassNpy\", base + \".npy\"\n            )\n        if not args.noviz:\n            out_clsv_file = osp.join(\n                args.output_dir,\n                \"SegmentationClassVisualization\",\n                base + \".jpg\",\n            )\n        if not args.noobject:\n            out_insp_file = osp.join(\n                args.output_dir, \"SegmentationObject\", base + \".png\"\n            )\n            if not args.nonpy:\n                out_ins_file = osp.join(\n                    args.output_dir, \"SegmentationObjectNpy\", base + \".npy\"\n                )\n            if not args.noviz:\n                out_insv_file = osp.join(\n                    args.output_dir,\n                    \"SegmentationObjectVisualization\",\n                    base + \".jpg\",\n                )\n\n        img = labelme.utils.img_data_to_arr(label_file.imageData)\n        imgviz.io.imsave(out_img_file, img)\n\n        cls, ins = labelme.utils.shapes_to_label(\n            img_shape=img.shape,\n            shapes=label_file.shapes,\n            label_name_to_value=class_name_to_id,\n        )\n",
  "ef generate_bookmarks(users: list[User], posts: list[Post], bookmarks_count: int = 100) -> list[Bookmark]:\n    \"\"\"Generate bookmarks.\"\"\"\n    bookmarks: list[Bookmark] = []\n    ids = set()\n    for _ in range(bookmarks_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        bookmark: bookmark = Bookmark(author_id=author_id, post_id=post_id)\n        if (author_id, post_id) not in ids:\n            bookmarks.append(bookmark)\n        ids.add((author_id, post_id))\n    return bookmarks\n\ndef generate_comments(users: list[User], posts: list[Post], comments_count: int = 500) -> list[Like]:\n    \"\"\"Generate likes.\"\"\"\n    comments: list[Comment] = []\n    ids = set()\n    for _ in range(comments_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        comment: comment = Comment(\n            id='Comment_' + str(uuid4()),\n            author_id=author_id, \n            post_id=post_id, \n            comment_text=fake.text() )\n        if (author_id, post_id) not in ids:\n            comments.append(comment)\n        ids.add((author_id, post_id))\n    return comments",
  "    features_dir=app_config.features_dir,\n    dataset_metadata=dataset_metadata,\n    label_columns=label_cols,\n    feature_cols=feature_cols,\n    columns_to_drop=columns_to_drop,\n    numerical_features=numerical_features,\n    categorical_features=categorical_features\n)\n\nexperiment: Experiment = Experiment(\n    experiment_config=experiment_config,\n    preprocessor=create_experiment_pipeline(experiment_config),\n    models=models\n)\nexperiment.run()\n# experiment.get_results()\n# experiment.tune_best_models()\n# experiment.get_tuned_models()\n# print(experiment.get_best_models(start=-3, end=-1)) ",
  "from pydantic import BaseModel, Field\nfrom typing import Optional\nfrom datetime import datetime\n\n\nclass PostBase(BaseModel):\n    location: str\n    text: str\n    author_id: str\n\n\nclass CreatePost(PostBase):\n    pass\n\nclass UpdatePost(BaseModel):\n    post_id: str\n    author_id: str\n    location: Optional[str]\n    text: Optional[str]\n\nclass CreatedPost(PostBase):\n    date_published: datetime\n    id: str\n    image_url: str\n    likes: list\n    \nclass GetPost(BaseModel):\n    post_id: str",
  "        self._shape_raw = (self.shape_type, self.points, self.point_labels)\n        self.shape_type = shape_type\n        self.points = points\n        self.point_labels = point_labels\n        self.mask = mask\n\n    def restoreShapeRaw(self):\n        if self._shape_raw is None:\n            return\n        self.shape_type, self.points, self.point_labels = self._shape_raw\n        self._shape_raw = None\n\n    @property\n    def shape_type(self):\n        return self._shape_type\n\n    @shape_type.setter\n    def shape_type(self, value):\n        if value is None:\n            value = \"polygon\"\n        if value not in [\n            \"polygon\",\n            \"rectangle\",\n            \"point\",\n            \"line\",\n            \"circle\",\n            \"linestrip\",\n            \"points\",\n            \"mask\",\n        ]:\n            raise ValueError(\"Unexpected shape_type: {}\".format(value))\n        self._shape_type = value\n\n    def close(self):\n        self._closed = True\n\n    def addPoint(self, point, label=1):\n        if self.points and point == self.points[0]:\n            self.close()\n        else:\n",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy.linkextractors import LinkExtractor \n\n\nclass SlidesLinkExtractor(Spider):\n    name: str = \"leetcode\"\n    \n    start_urls: list[str] = [\n        \"https://www.techiedelight.com/data-structures-and-algorithms-problems/\"\n    ]\n    \n    def __init__(self, name=None, **kwargs): \n        super().__init__(name, **kwargs) \n  \n        self.link_extractor = LinkExtractor(unique=True) \n  \n    def parse(self, response: Response, **kwargs: Any) -> Any: \n        links = self.link_extractor.extract_links(response) \n  \n        for link in links: \n            yield {\n                    \"url\": link.url, \n                    \"text\": link.text\n                }",
  "from google_calendar import GoogleCalendar\nfrom google_calendar.schemas import (\n    ListCalendarEvents, CreateEvent, AttendeeSchema, ReminderSchema, RemindersSchema, \n    EventTimeSchema\n)\nfrom google_calendar.models import Event\nfrom datetime import datetime, timedelta, date as d\nimport pytz\n\nclient_secret: str = 'client_secret.json'\ngoogle_calendar: GoogleCalendar = GoogleCalendar(secret_file=client_secret)\ngoogle_calendar.authenticate()\n\n# req = ListCalendarEvents()\n# events = google_calendar.list_calendar_events(req)\n# items = events.items\n# print(len(items))\n# print(items[0])\n# print(items[-1])\n# import json\n# import random\n# from google_calendar.resources import EventResource\n# with open('events.json', 'r') as f:\n#     data = json.load(f)\n# event_resource: EventResource = EventResource(calendar_client=google_calendar.calendar_client)\n# events = event_resource.parse_items(data)\n# print(random.choice(events))\n# print(google_calendar.get_event(event_id='_6tlnaqrle5p6cpb4dhmj4phpegp68s9o6lnm6q3b75gj6sr3d5i6sqbb6go6gs3le9r34dj4ddlmmq3f6ks64sb5epq3apri75jj2tjmcss6e'))\n# print(google_calendar.quick_add('Meeting with emmanuel at 10.00 am tommorrow.'))\n# now = datetime.astimezone()\n# start = str(now.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n# end = str((now + timedelta(hours=2)).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n# create_event = CreateEvent(\n#     start=EventTimeSchema(dateTime=start),\n#     end=EventTimeSchema(dateTime=end),\n#     summary='Meeting Travis',\n#     description='Meet with Travis for launch of his new startup.',\n#     location='Weston Hotel, Nairobi',\n#     attendees=[\n#         AttendeeSchema(email='lpage@example.com'),\n",
  "def get_exception(exc):\n    \"\"\"Log exceptions\"\"\"\n    if exc:\n        app_logger.warning(f\"{exc.__class__.__name__ }: {str(exc)}\")\n        \n        \ndef register_app_hooks(app: Flask):\n    @app.before_first_request\n    def application_startup():\n        \"\"\"Log the beginning of the application.\"\"\"\n        app_logger.info('Web app is up!')\n\n    @app.before_request\n    def log_request():\n        \"\"\"Log the data held in the request\"\"\"\n        if request.method in ['POST', 'PUT']:\n            log_post_request()\n        elif request.method in ['GET', 'DELETE']:\n            log_get_request()\n\n    @app.after_request\n    def log_response(response):\n        try:\n            get_response(response)\n        except Exception:\n            pass\n        finally:\n            return response\n\n    @app.teardown_request\n    def log_exception(exc):\n        get_exception(exc)",
  "from itemadapter import ItemAdapter\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.exceptions import DropItem\nfrom os import path, mkdir\nfrom scrapy.http import Response\nfrom scrapy import Request, Spider\nfrom scrapy import Item\nfrom pathlib import PurePosixPath\nfrom urllib.parse import urlparse\nfrom slidesmodel.models import db_connect, Tag, Category, Slide, create_table, create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport uuid\nimport logging\n\n\nclass SlidesmodelPipeline:\n    def process_item(self, item: Item, spider: Spider):\n        return item\n    \nclass MyImagesPipeline(ImagesPipeline):\n    def file_path(self, request: Request, response: Response = None, info=None, *, item=None):\n        slide_name: str = request.meta['title']\n        return f\"{slide_name}/\" + PurePosixPath(urlparse(request.url).path).name\n    \n    def get_media_requests(self, item: Item, info):\n        for image_url in item[\"image_urls\"]:\n            yield Request(image_url, meta={\"title\": item[\"title\"]})\n            \n\nclass SaveSlidesPipeline(object):\n    def __init__(self):\n        \"\"\"\n        Initializes database connection and sessionmaker\n        Creates tables\n        \"\"\"\n        engine = db_connect()\n        create_table(engine)\n        self.Session = sessionmaker(bind=engine)\n\n\n",
  "#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}\n\n# Enable or disable spider middlewares\n# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    \"slidesgo.middlewares.SlidesgoSpiderMiddleware\": 543,\n#}\n\n# Enable or disable downloader middlewares\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#DOWNLOADER_MIDDLEWARES = {\n#    \"slidesgo.middlewares.SlidesgoDownloaderMiddleware\": 543,\n#}\n\n# Enable or disable extensions\n# See https://docs.scrapy.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    \"scrapy.extensions.telnet.TelnetConsole\": None,\n#}\n\n# Configure item pipelines\n# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n#ITEM_PIPELINES = {\n#    \"slidesgo.pipelines.SlidesgoPipeline\": 300,\n#}\n\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n",
  "def get_random_user(session: Session):\n    from random import choice\n    with session() as db:\n        user = choice(db.query(User).all())\n    return user\n\ndef get_user(session: Session, user_data: GetUser):\n    with session() as db:\n        user = db.query(User).filter(User.id == user_data.user_id).first()\n    return user\n\ndef get_users(session: Session, user_data: GetUsers):\n    with session() as db:\n        users = db.query(User).offset(user_data.offset).limit(user_data.limit).all()\n    return users",
  "ef generate_bookmarks(users: list[User], posts: list[Post], bookmarks_count: int = 100) -> list[Bookmark]:\n    \"\"\"Generate bookmarks.\"\"\"\n    bookmarks: list[Bookmark] = []\n    ids = set()\n    for _ in range(bookmarks_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        bookmark: bookmark = Bookmark(author_id=author_id, post_id=post_id)\n        if (author_id, post_id) not in ids:\n            bookmarks.append(bookmark)\n        ids.add((author_id, post_id))\n    return bookmarks\n\ndef generate_comments(users: list[User], posts: list[Post], comments_count: int = 500) -> list[Like]:\n    \"\"\"Generate likes.\"\"\"\n    comments: list[Comment] = []\n    ids = set()\n    for _ in range(comments_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        comment: comment = Comment(\n            id='Comment_' + str(uuid4()),\n            author_id=author_id, \n            post_id=post_id, \n            comment_text=fake.text() )\n        if (author_id, post_id) not in ids:\n            comments.append(comment)\n        ids.add((author_id, post_id))\n    return comments",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy import Request\nfrom slidesmodel.items import SlidesModelItem\nfrom scrapy.loader import ItemLoader\nfrom scrapy.utils.project import get_project_settings\nimport json\n\n\nclass SlidesModelspider(Spider):\n    name: str = \"slides\"\n    \n    def __init__(self, name: str | None = None, **kwargs: Any):\n        super().__init__(name, **kwargs)\n        self.start_urls: list[str] = self.load_start_urls()\n        # self.start_urls: list[str] = [\n        #     \"https://slidemodel.com/templates/tag/process-flow/\"\n        # ]\n    \n    @staticmethod\n    def load_start_urls() -> list:\n        settings: dict = get_project_settings()\n        links_path: str = settings.get(\"START_URLS_PATH\")\n        with open(links_path, \"r\") as f:\n            start_urls_dict: list[dict] = json.load(f)\n        return [\n            link.get(\"url\") for link in start_urls_dict\n        ]\n    \n    def parse(self, response: Response, **kwargs: Any) -> Any:\n        self.logger.info(\"This is my first spider.\")\n        slides = response.xpath(\"//div[@class='col-lg-3 col-sm-6 mt-4']\")\n        for slide in slides:\n            loader: ItemLoader = ItemLoader(item=SlidesModelItem(), selector=slide)\n            loader.add_css(\"title\", \".item a::text\")\n            loader.add_css(\"category\", \".category::text\")\n            slide_item = loader.load_item()\n            link = slide.css(\".item a::attr(href)\").get()\n            self.logger.info(\"Parsing the slide\")\n",
  "                self.line.close()\n            elif self.createMode == \"circle\":\n                self.line.points = [self.current[0], pos]\n                self.line.point_labels = [1, 1]\n                self.line.shape_type = \"circle\"\n            elif self.createMode == \"line\":\n                self.line.points = [self.current[0], pos]\n                self.line.point_labels = [1, 1]\n                self.line.close()\n            elif self.createMode == \"point\":\n                self.line.points = [self.current[0]]\n                self.line.point_labels = [1]\n                self.line.close()\n            assert len(self.line.points) == len(self.line.point_labels)\n            self.repaint()\n            self.current.highlightClear()\n            return\n\n        # Polygon copy moving.\n        if QtCore.Qt.RightButton & ev.buttons():\n            if self.selectedShapesCopy and self.prevPoint:\n                self.overrideCursor(CURSOR_MOVE)\n                self.boundedMoveShapes(self.selectedShapesCopy, pos)\n                self.repaint()\n            elif self.selectedShapes:\n                self.selectedShapesCopy = [s.copy() for s in self.selectedShapes]\n                self.repaint()\n            return\n\n        # Polygon/Vertex moving.\n        if QtCore.Qt.LeftButton & ev.buttons():\n            if self.selectedVertex():\n                self.boundedMoveVertex(pos)\n                self.repaint()\n                self.movingShape = True\n            elif self.selectedShapes and self.prevPoint:\n                self.overrideCursor(CURSOR_MOVE)\n                self.boundedMoveShapes(self.selectedShapes, pos)\n                self.repaint()\n                self.movingShape = True\n",
  "from langchain.prompts import PromptTemplate\nfrom os import path\nfrom langchain.llms.base import BaseLLM\nfrom langchain_openai import OpenAI\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n\ndata_dir = \"data\"\nvideo_data_dir = \"data\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"iphone_15_marques_review\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\napi_key: str = \"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\"\nchatgpt: BaseLLM = OpenAI(temperature=0, api_key=api_key)\n\nprompt: str = \"\"\"\nYou are given the transcript for a video that covers the review of the iphone 15 pro. Find out all the \nfeatures covered in the review. Only return the features of the iphine 15 pri. Return a JSON object with a single key called features.\nTranscript: {transcript}\n\"\"\"\n\nwith open(save_transcript_dir, \"r\") as f:\n    video_transcript = f.read()\n\ntemplate = PromptTemplate(template=prompt, input_variables=[\"transcript\"])\n\nchain = template | chatgpt\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=150)\nsplits = text_splitter.split_text(video_transcript)\ntopics = []\nfor doc in splits:\n    res = chain.invoke({\"transcript\": doc})\n    topics.append(res)\n    print(res)\nprint(topics)\n",
  "def create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like",
  "def log_get_request():\n    request_data = {\n        \"method\": request.method,\n        \"url root\": request.url_root,\n        \"user agent\": request.user_agent,\n        \"scheme\": request.scheme,\n        \"remote address\": request.remote_addr,\n        \"headers\": request.headers,\n        \"route\": request.endpoint,\n        \"base url\": request.base_url,\n        \"url\": request.url,\n    }\n    if request.args:\n        request_data[\"args\"] = request.args\n    if request.cookies:\n        request_data[\"cookies\"] = request.cookies\n    app_logger.info(str(request_data))\n\n\ndef get_response(response):\n    response_data = {\n        \"status\": response.status,\n        \"status code\": response.status_code,\n        \"response\": json.loads(response.data),\n    }\n    app_logger.info(str(response_data))",
  "        ins[cls == -1] = 0  # ignore it.\n\n        # class label\n        labelme.utils.lblsave(out_clsp_file, cls)\n        if not args.nonpy:\n            np.save(out_cls_file, cls)\n        if not args.noviz:\n            clsv = imgviz.label2rgb(\n                cls,\n                imgviz.rgb2gray(img),\n                label_names=class_names,\n                font_size=15,\n                loc=\"rb\",\n            )\n            imgviz.io.imsave(out_clsv_file, clsv)\n\n        if not args.noobject:\n            # instance label\n            labelme.utils.lblsave(out_insp_file, ins)\n            if not args.nonpy:\n                np.save(out_ins_file, ins)\n            if not args.noviz:\n                instance_ids = np.unique(ins)\n                instance_names = [str(i) for i in range(max(instance_ids) + 1)]\n                insv = imgviz.label2rgb(\n                    ins,\n                    imgviz.rgb2gray(img),\n                    label_names=instance_names,\n                    font_size=15,\n                    loc=\"rb\",\n                )\n                imgviz.io.imsave(out_insv_file, insv)\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "from config.config import app_config\nfrom os import path\nfrom zipfile import ZipFile\nimport logging\nimport pandas as pd\nfrom pandas import DataFrame\nfrom sklearn.pipeline import Pipeline\nfrom joblib import load\nfrom notification import get_gmail_client, create_message, send_message\n\n\ndef extract_dataset(archive_name: str = 'archive.zip', file_name: str = 'Titanic-Dataset.csv') -> None:\n    \"\"\"Extract the downloaded archive file into the data folder.\"\"\"\n    # Ubuntu OS\n    downloads_path: str = path.join(path.expanduser('~'), 'Downloads')\n    archive_path: str = path.join(downloads_path, archive_name)\n    try:\n        with ZipFile(archive_path, 'r') as zip_:\n            try:\n                zip_.extract(file_name, app_config.data_dir)\n                logging.info(f'The file {file_name} has been extracted to {path.join(app_config.data_dir, file_name)}.')\n            except KeyError:\n                print(f'There is no file \"{file_name}\" in the archive \"{archive_path}\".')\n                logging.error(f'There is no file \"{file_name}\" in the archive \"{archive_path}\".')\n    except FileNotFoundError:\n        print(f'There is no archive \"{archive_path}\".')\n        logging.error(f'There is no archive \"{archive_path}\".')\n    return path.join(app_config.data_dir, file_name)\n\n\ndef load_data(file_path: str = 'Titanic-Dataset.csv') -> DataFrame:\n    \"\"\"Load the Titanic dataset into a dataframe.\"\"\"\n    try:\n        data: DataFrame = pd.read_csv(file_path)\n    except FileNotFoundError:\n        print(f'There is no file such file \"{file_path}\".')\n        logging.error(f'There is no file such file \"{file_path}\".')\n    return data\n\n\n",
  "        for pattern, keys in self._flags.items():\n            if re.match(pattern, label_new):\n                for key in keys:\n                    flags_new[key] = flags_old.get(key, False)\n        self.setFlags(flags_new)\n\n    def deleteFlags(self):\n        for i in reversed(range(self.flagsLayout.count())):\n            item = self.flagsLayout.itemAt(i).widget()\n            self.flagsLayout.removeWidget(item)\n            item.setParent(None)\n\n    def resetFlags(self, label=\"\"):\n        flags = {}\n        for pattern, keys in self._flags.items():\n            if re.match(pattern, label):\n                for key in keys:\n                    flags[key] = False\n        self.setFlags(flags)\n\n    def setFlags(self, flags):\n        self.deleteFlags()\n        for key in flags:\n            item = QtWidgets.QCheckBox(key, self)\n            item.setChecked(flags[key])\n            self.flagsLayout.addWidget(item)\n            item.show()\n\n    def getFlags(self):\n        flags = {}\n        for i in range(self.flagsLayout.count()):\n            item = self.flagsLayout.itemAt(i).widget()\n            flags[item.text()] = item.isChecked()\n        return flags\n\n    def getGroupId(self):\n        group_id = self.edit_group_id.text()\n        if group_id:\n            return int(group_id)\n        return None\n",
  "from api import create_app\n\n\napp = create_app()",
  "def get_posts(session: Session, post_data: GetPosts):\n    with session() as db:\n        posts: list[Post] = db.query(Post).offset(post_data.offset).limit(post_data.limit).all()\n        for post in posts:\n            post.author\n        return posts\n\ndef delete_post(session: Session, post_data: GetPost):\n    with session() as db:\n        post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        db.delete(post)\n        db.commit()\n        \n    return post",
  "from youtube import YouTube\n\nclient_secret_file = '/home/downloads/client_secret.json'\nyoutube = YouTube(client_secret_file)\nyoutube.authenticate()\n\ndef get_channel_id():\n    videos = youtube.find_video_by_id('pIzyo4cCGxU')\n    channel_id = videos[0].channel_id\n    return channel_id\n\ndef get_channel_details(channel_id):\n    channel = youtube.find_channel_by_id(channel_id)\n    return channel\n\ndef get_channel_playlists(channel_id):\n        channel_playlists = youtube.find_channel_playlists(channel_id)\n        return channel_playlists\n\ndef get_playlist_items(playlist_id):\n    search_iterator = youtube.find_playlist_items(playlist_id, max_results=10)\n    playlists = list(next(search_iterator))\n    return playlists\n\ndef get_playlist_item_video_id(playlist_item):\n    video_id = playlist_item.video_id\n    return video_id\n\ndef get_videos(video_ids):\n    videos = youtube.find_video_by_id(video_ids)\n    return videos\n\ndef get_video_comments(video_id):\n    search_iterator = youtube.find_video_comments(video_id, max_results=20)\n    video_comments = list(next(search_iterator))\n    return video_comments\n\ndef main():\n    # channel_id = get_channel_id()\n    # channel = get_channel_details(channel_id)\n",
  "from flask import Flask, jsonify, redirect, url_for\nfrom http import HTTPStatus\nfrom .blueprints import register_blueprints\nfrom .config import set_configuration\nfrom oauthlib.oauth2.rfc6749.errors import InvalidGrantError, TokenExpiredError\nfrom flask_dance.contrib.google import google\n\n\ndef create_app() -> Flask:\n    \"\"\"Create the Flask App instance.\"\"\"\n    app = Flask(__name__)\n    set_configuration(app=app)\n    register_blueprints(app=app)\n    \n    \n    @app.route(\"/login\")\n    def login():\n        try:\n            if not google.authorized:\n                return redirect(url_for(\"google.login\"))\n            resp = google.get(\"/oauth2/v1/userinfo\")\n            if resp.ok:\n                return redirect(url_for(\"home.home_page\"))\n            return redirect(url_for(\"login\"))\n        except (TokenExpiredError, InvalidGrantError):\n            return redirect(url_for(\"google.login\"))\n    \n    @app.route(\"/health\")\n    def health():\n        return jsonify({\"Up\": True}), HTTPStatus.OK\n\n    app.shell_context_processor({\"app\": app})\n\n    return app",
  "# loader = TextLoader(file_path=save_transcript_dir)\n# docs = loader.load_and_split(text_splitter=text_splitter)\ndocs: list[Document] = [\n    Document(page_content=comment['comment']) for comment in analy\n]\nres = stuff_chain.run(docs)\n# chain = template | llm\n# res = chain.invoke({\"comments\": analy})\nprint(res)\n\n\n# def save_summary(summary: str) -> None:\n#     with open(save_transcript_dir, \"w\") as f:\n#         f.write(summary)\n\n\n# def summarize_video(video_transcript: str) -> str:\n#     with open(save_transcript_dir, \"r\") as f:\n#         summry: str = f.read()\n#     return summry\n",
  "from youtube import YouTube\nfrom youtube.schemas import (\n    SearchFilter, SearchOptionalParameters, SearchPart, YouTubeResponse, YouTubeRequest,\n    CommentThreadFilter, CommentThreadOptionalParameters, CommentThreadPart, CreatePlaylist, \n    CreatePlaylistSnippet, CreatePlaylistItem, VideoResourceId, CreatePlaylistItemSnippet\n)\nfrom typing import Iterator\nfrom datetime import datetime\nfrom youtube.models import Comment\n\n\nclient_secrets_file = '/home/lyle/Downloads/search.json'\nyoutube = YouTube(client_secret_file=client_secrets_file)\nyoutube_client = youtube.authenticate()\nyoutube.youtube_client = youtube_client\n\n# query: str = 'Python programming videos'\n# max_results: int = 10\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q=query,\n#     maxResults=max_results,\n#     type=['video', 'playlist', 'channel']\n# )\n# search_request: YouTubeRequest = YouTubeRequest(\n#     part=part, \n#     optional_parameters=optional_parameters\n# )\n# search_results: YouTubeResponse = youtube.search(search_request)\n# search_iterator: Iterator = youtube.get_search_iterator(search_request)\n# video = youtube.find_video_by_id('nDXsVhFG7TE')\n# videos = youtube.find_videos_by_ids(['nDXsVhFG7TE', 'aQXD-Wr6h64', 'AIqxfBhlwx0'])\n# ratings = youtube.get_video_ratings(['nDXsVhFG7TE', 'aQXD-Wr6h64', 'AIqxfBhlwx0'])\n# categories = youtube.get_video_categories()\n# video_abuse_reasons = youtube.list_video_abuse_report_reasons()\n# languages = youtube.list_languages()\n# regions = youtube.list_regions()\n# popular_video = youtube.find_most_popular_video_by_region()\n# channel = youtube.find_channel_by_id('UCRijo3ddMTht_IHyNSNXpNQ')\n# channels = youtube.find_channels_by_ids(['UCRijo3ddMTht_IHyNSNXpNQ'])\n",
  "\n        self.parser = PydanticOutputParser(pydantic_object=Trip)\n\n        self.system_message_prompt = SystemMessagePromptTemplate.from_template(\n            self.system_template,\n            partial_variables={\n                \"format_instructions\": self.parser.get_format_instructions()\n            },\n        )\n        self.human_message_prompt = HumanMessagePromptTemplate.from_template(\n            self.human_template, input_variables=[\"agent_suggestion\"]\n        )\n\n        self.chat_prompt = ChatPromptTemplate.from_messages(\n            [self.system_message_prompt, self.human_message_prompt]\n        )",
  "#         live.update(create_comments_table(table_data=queue))\n\n\ndef create_analyzed_comments_table(table_data: list[dict]) -> Table:\n    table: Table = Table(row_styles=[\"dim\", \"\"],leading=1, box=box.MINIMAL_DOUBLE_HEAD)\n    table.add_column(header=\"[b]Comment Id\", justify=\"left\", style=\"dark_orange\")\n    table.add_column(header=\"Comment\", justify=\"left\", style=\"light_coral\")\n    table.add_column(header=\"[b]Likes\", justify=\"left\", style=\"yellow2\")\n    table.add_column(header=\"Sentiment\", justify=\"left\", style=\"light_coral\")\n    table.add_column(header=\"[b]Topics\", justify=\"left\", style=\"yellow2\")\n    table.add_column(header=\"Date\", justify=\"center\", style=\"violet\")\n    table.columns[0].header_style = \"bold chartreuse1\"\n    table.columns[1].header_style = \"bold dark_goldenrod\"\n    table.columns[2].header_style = \"bold chartreuse1\"\n    table.columns[3].header_style = \"bold dark_goldenrod\"\n    table.columns[4].header_style = \"bold chartreuse1\"\n    table.columns[5].header_style = \"bold dark_goldenrod\"\n    table.border_style = \"bright_yellow\"\n    table.pad_edge = True\n    colors = {\n        'negative': 'red',\n        'positive': 'green',\n        'neutral': 'purple'\n    }\n    for row in table_data:\n        color = colors[row[\"sentiment\"]]\n        table.add_row(row[\"comment_id\"], row[\"comment\"], str(row[\"likes\"]), f\"[bold {color}]{row['sentiment']}[/bold {color}]\", \", \".join(row[\"features\"]), row[\"date_published\"])\n    return table\ndef analyze_comment(comment: dict) -> dict:\n    from random import choice, choices\n    sentiments: list[str] = ['negative', 'positive', 'neutral']\n    all_topics: list[str] = [\"Incremental changes in design\", \"Softer corners\", \"Slimmer bezels\", \"USB Type-C port\"]\n    sentiment: str = choice(sentiments)\n    topics: list[str] = choices(population=all_topics, k=3)\n    comment['topics'] = topics\n    comment['sentiment'] = sentiment\n    return comment\n# analyzed_comments: list[dict] = list(map(analyze_comment, comments)) \nwith open('analysis.json', 'r') as f:\n    analyzed_comments: list[dict] = json.load(f)\n",
  "# Define here the models for your spider middleware\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass SlidesmodelSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(self, response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(self, response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, or item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(self, response, exception, spider):\n        # Called when a spider or process_spider_input() method\n",
  "from data_utils import extract_archive\nfrom dotenv import load_dotenv\nimport os\n\n\nload_dotenv()\n\nDOWNLOAD_PATH: str = os.environ[\"DOWNLOAD_PATH\"]\nEXTRACT_PATH: str = os.environ[\"EXTRACT_PATH\"]\nARCHIVE_NAME: str = \"archive (2).zip\"\n\nextract_archive(\n    archive_path=DOWNLOAD_PATH, \n    archive_name=ARCHIVE_NAME, \n    extract_path=EXTRACT_PATH\n)\n\n",
  "from flask import Flask\nfrom .home import code\n\n\ndef register_blueprints(app: Flask) -> bool:\n    \"\"\"Register the application blueprints.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether all the blueprints were registered.\n    \"\"\"\n    app.register_blueprint(code)\n    return True",
  "                new_docstring_node = make_docstring_node(class_docstring)\n            node.body.insert(0, new_docstring_node)\n            methods_docstrings: dict[str, str] = get_class_methods_docstrings(\n                class_and_docstring\n            )\n            for class_node in node.body:\n                if isinstance(class_node, FunctionDef):\n                    function_doc: str = ast.get_docstring(node=class_node)\n                    if (\n                        not function_doc\n                        or self.config.overwrite_class_methods_docstring\n                    ):\n                        function_name: str = class_node.name\n                        new_docstring_node = make_docstring_node(\n                            methods_docstrings[function_name]\n                        )\n                        class_node.body.insert(0, new_docstring_node)\n        return node\n\n\nclass DocstringWriter(NodeTransformer, BaseModel):\n    module_code: str = Field(description='The source code for this module')\n    config: Config = Field(description='The application configurations.')\n\n    def visit_classDef(self, node: FunctionDef) -> Any:\n        docstring: str = ast.get_docstring(node=node)\n        if self.config.overwrite_function_docstring or not docstring:\n            function_code: str = ast.get_source_segment(\n                source=self.module_code, node=node, padded=True\n            )\n            function_and_docstring: str = generate_function_docstring(\n                function_code, self.config\n            )\n            function_docstring: str = get_function_docstring(function_and_docstring)\n            new_docstring_node = make_docstring_node(function_docstring)\n            node.body.insert(0, new_docstring_node)\n\n        return node\n\n    def visit_ClassDef(self, node: ClassDef) -> Any:\n",
  "import logging.config\nimport logstash\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef create_dev_logger():\n    \"\"\"Create the application logger.\"\"\"\n    config = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"standard\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n            },\n            \"json\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n                \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n            },\n        },\n        \"handlers\": {\n            \"standard\": {\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"json\",\n            },\n        },\n        \"loggers\": {\"\": {\"handlers\": [\"standard\"], \"level\": logging.INFO}},\n    }\n\n    logging.config.dictConfig(config)\n\n    logger = logging.getLogger(__name__)\n\n    return logger",
  "    res: TimeStamps = chain.invoke(inputs)\n    # res.time_stamps.sort(key=lambda x: x.start_time)\n    return res\n\n\nids: dict[str, str] = {\n    \"set_mismatch\": \"d-ulaeRBA64\",\n    \"leaf_similar_tree\": \"Nr8dbnL0_cM\",\n    \"mk_vld_par\": \"mgQ4O9iUEbg\",\n    \"pams\": \"kWhy4ZUBdOY\",\n    \"sapltk\": \"Cg6_nF7YIks\",\n    \"smallest_str_leaf\": \"UvdWfxQ_ZDs\",\n    \"sub_arr_k_diff_ints\": \"etI6HqWVa8U\",\n    \"remv_nodes_lnkd_lst\": \"y783sRTezDg\",\n    \"rvl_card_inc_order\": \"i2QrUdwWlak\",\n    \"rmv_dup_srt_arr_2\": \"ycAq8iqh0TI\",\n    \"town_jdg\": \"QiGaxdUINJ8\",\n    \"rang_sm_bst\": \"uLVG45n4Sbg\",\n    \"artmtc_slcs_2\": \"YIMwwT9JdIE\",\n    \"lst_unq_ints_k_rmvl\": \"Nsp_ta7SlEk\",\n    \"all_ppl_scrt\": \"1XujGRSU1bQ\",\n    \"stdnts_mss_lnch\": \"d_cvtFwnOZg\",\n}\nvideo_id: str = ids[\"stdnts_mss_lnch\"]\n\nclass Segment(BaseModel):\n    time_stamp: str = Field(description=\"The time stamp\")\n    title: str = Field(description=\"The time stamp title\")\n    \ngemma_parser = PydanticOutputParser(pydantic_object=Segment)\n\nsegment_str_gemma: str = (\"\"\"Extract all the time stamps and their titles from the following text. Only\"\"\" \n                    \"\"\" include valid time stamps.Return a json string only with the keys \"\"\"\n                    \"\"\"```time_stamp``` and ```title```.\\ntext: ```{text}```\"\"\"\n)\n\nsegment_str_gemma_v1: str = (\"\"\"Extract all the start time stamps, end time stamps and their titles from the following text. Only\"\"\" \n                    \"\"\" include valid time stamps.Return a json string only with the keys \"\"\"\n                    \"\"\"```start_time```, ```end_time``` and ```title```.\\ntext: ```{text}```\"\"\"\n)\n",
  "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\"✅ Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\"❌ Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file\n",
  "    llm_with_tools = llm.bind(functions=functions)\n\n    agent = (\n        {\n            \"input\": lambda x: x[\"input\"],\n            \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n                x[\"intermediate_steps\"]\n            ),\n        }\n        | prompt\n        | llm_with_tools\n        | OpenAIFunctionsAgentOutputParser()\n    )\n\n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n    return agent_executor\n",
  "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\"✅ Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\"❌ Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file\n",
  "        filename = None\n        if self.filename is None:\n            filename = self.imageList[0]\n        else:\n            currIndex = self.imageList.index(self.filename)\n            if currIndex + 1 < len(self.imageList):\n                filename = self.imageList[currIndex + 1]\n            else:\n                filename = self.imageList[-1]\n        self.filename = filename\n\n        if self.filename and load:\n            self.loadFile(self.filename)\n\n        self._config[\"keep_prev\"] = keep_prev\n\n    def openFile(self, _value=False):\n        if not self.mayContinue():\n            return\n        path = osp.dirname(str(self.filename)) if self.filename else \".\"\n        formats = [\n            \"*.{}\".format(fmt.data().decode())\n            for fmt in QtGui.QImageReader.supportedImageFormats()\n        ]\n        filters = self.tr(\"Image & Label files (%s)\") % \" \".join(\n            formats + [\"*%s\" % LabelFile.suffix]\n        )\n        fileDialog = FileDialogPreview(self)\n        fileDialog.setFileMode(FileDialogPreview.ExistingFile)\n        fileDialog.setNameFilter(filters)\n        fileDialog.setWindowTitle(\n            self.tr(\"%s - Choose Image or Label file\") % __appname__,\n        )\n        fileDialog.setWindowFilePath(path)\n        fileDialog.setViewMode(FileDialogPreview.Detail)\n        if fileDialog.exec_():\n            fileName = fileDialog.selectedFiles()[0]\n            if fileName:\n                self.loadFile(fileName)\n\n",
  "from json import load\nfrom typing import Any\nimport streamlit as st\nfrom youtube import YouTube\nfrom youtube.models import Search, Video\nfrom youtube.resources.schemas import (\n    CreatePlaylistSchema, CreatePlaylistSnippet, CreateStatus, CreatePlaylistItem, CreatePlaylistItemSnippet,\n    VideoResourceId, YouTubeRequest, SearchPart, SearchOptionalParameters, SearchFilter\n)\nfrom typing import Any\n\n\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()\n\n\ndef load_data(file_name: str = 'live-news.json') -> dict[str, Any]:\n    \"\"\"Load a json file.\"\"\"\n    with open(file_name, 'r', encoding='utf-8') as f:\n        data: dict[str, Any] = load(f)\n    return data\n\ndef search_news(text: str) -> list[dict[str, Any]]:\n    part: SearchPart = SearchPart()\n    optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n        q=text,\n        maxResults=5,\n        eventType='live',\n        type=['video']\n    )\n    search = YouTubeRequest(part=part, optional_parameters=optional_parameters)\n    results: list[Search] = youtube.search(search).items\n    results: dict[str, Any] = [result.model_dump() for result in results]\n    return results\n\ndef search_video(video_id: str) -> dict[str, Any]:\n    return youtube.find_video_by_id(video_id).model_dump()\n\ndef get_thumbnail_url(data: dict[str, Any]) -> str:\n",
  "            self.points.append(point)\n            self.point_labels.append(label)\n\n    def canAddPoint(self):\n        return self.shape_type in [\"polygon\", \"linestrip\"]\n\n    def popPoint(self):\n        if self.points:\n            if self.point_labels:\n                self.point_labels.pop()\n            return self.points.pop()\n        return None\n\n    def insertPoint(self, i, point, label=1):\n        self.points.insert(i, point)\n        self.point_labels.insert(i, label)\n\n    def removePoint(self, i):\n        if not self.canAddPoint():\n            logger.warning(\n                \"Cannot remove point from: shape_type=%r\",\n                self.shape_type,\n            )\n            return\n\n        if self.shape_type == \"polygon\" and len(self.points) <= 3:\n            logger.warning(\n                \"Cannot remove point from: shape_type=%r, len(points)=%d\",\n                self.shape_type,\n                len(self.points),\n            )\n            return\n\n        if self.shape_type == \"linestrip\" and len(self.points) <= 2:\n            logger.warning(\n                \"Cannot remove point from: shape_type=%r, len(points)=%d\",\n                self.shape_type,\n                len(self.points),\n            )\n            return\n",
  "import collections\nimport threading\n\nimport imgviz\nimport numpy as np\nimport onnxruntime\nimport skimage\n\nfrom ..logger import logger\nfrom . import _utils\n\n\nclass SegmentAnythingModel:\n    def __init__(self, encoder_path, decoder_path):\n        self._image_size = 1024\n\n        self._encoder_session = onnxruntime.InferenceSession(encoder_path)\n        self._decoder_session = onnxruntime.InferenceSession(decoder_path)\n\n        self._lock = threading.Lock()\n        self._image_embedding_cache = collections.OrderedDict()\n\n        self._thread = None\n\n    def set_image(self, image: np.ndarray):\n        with self._lock:\n            self._image = image\n            self._image_embedding = self._image_embedding_cache.get(\n                self._image.tobytes()\n            )\n\n        if self._image_embedding is None:\n            self._thread = threading.Thread(\n                target=self._compute_and_cache_image_embedding\n            )\n            self._thread.start()\n\n    def _compute_and_cache_image_embedding(self):\n        with self._lock:\n            logger.debug(\"Computing image embedding...\")\n",
  "from langchain_community.document_loaders.generic import GenericLoader\nfrom langchain_community.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain_community.document_loaders.blob_loaders.youtube_audio import (\n    YoutubeAudioLoader,\n)\nfrom langchain_core.documents import Document\nfrom os import path\n\n# Two Karpathy lecture videos\nurls = [\"https://www.youtube.com/watch?v=altvPR7x9IA\"]\n\n# Directory to save audio files\ndata_dir = \"data\"\nvideo_data_dir = \"video\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"sample\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\n\nloader = GenericLoader(\n    YoutubeAudioLoader(urls, save_video_dir), OpenAIWhisperParser(api_key=api_key)\n)\ndocs = loader.load()\n\nfull_transcript = \"\"\nfor doc in docs:\n    full_transcript += doc.page_content\n\nwith open(save_transcript_dir, \"w\", encoding=\"utf-8\") as f:\n    f.write(full_transcript)\n\nprint(full_transcript)\n\n\ndef transcribe_video(video_id: str, save_video_dir: str, api_key: str) -> str:\n    url: str = f\"https://www.youtube.com/watch?v={video_id}\"\n    loader: GenericLoader = GenericLoader(\n        YoutubeAudioLoader([url], save_video_dir), OpenAIWhisperParser(api_key=api_key)\n",
  "         title=\"[bold italic gold1]Youtube channels reviewing Iphone 15 pro[/bold italic gold1]\")\n    table.add_column(header=\"[b]Channel Title\", justify=\"left\", style=\"dark_orange\")\n    table.add_column(header=\"Subscribers\", justify=\"left\", style=\"light_coral\")\n    table.add_column(header=\"[b]Videos\", justify=\"left\", style=\"yellow2\")\n    table.add_column(header=\"Date\", justify=\"center\", style=\"violet\")\n    table.columns[0].header_style = \"bold chartreuse1\"\n    table.columns[1].header_style = \"bold dark_goldenrod\"\n    table.columns[2].header_style = \"bold chartreuse1\"\n    table.columns[3].header_style = \"bold dark_goldenrod\"\n    table.border_style = \"bright_yellow\"\n    table.pad_edge = True\n    for row in table_data:\n        table.add_row(row[\"title\"], str(row[\"subscribers\"]), str(row[\"videos\"]), row[\"date\"])\n    return table\n\n\ndef video_search(\n    product: str, channel_title: str, max_results: int = 5\n) -> list[Search]:\n    \"\"\"Search the given channel for the given videos.\"\"\"\n    query: str = f\"latest {product} review\"\n    channel_id: str = get_channel_id(channel_name=channel_title)\n    search_part: SearchPart = SearchPart()\n    optional_params: SearchOptionalParameters = SearchOptionalParameters(\n        channelId=channel_id,\n        q=query,\n        maxResults=max_results,\n        type=[\"video\"],\n    )\n    search_schema: YouTubeRequest = YouTubeRequest(\n        part=search_part, optional_parameters=optional_params\n    )\n    response: YouTubeResponse = youtube_client.search(search_schema)\n    items: list[Search] = response.items\n    return items\n\n\ndef get_video_id(video_title: str) -> str:\n    \"\"\"Get video id given the title.\"\"\"\n    part: SearchPart = SearchPart()\n",
  "from argparse import Namespace\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\nfrom .config import Config\nfrom .docstring_generator import generate_docstrings\nfrom .extensions import (\n    failed_modules_queue,\n    functions_source_code_queue,\n    modules_path_queue,\n    class_source_code_queue,\n)\nfrom .helpers import create_application_config, parse_arguments\n\n\ndef run():\n    \"\"\"Runs the application by parsing arguments, creating a configuration, and generating docstrings.\n\n    Returns:\n        function: The run function.\n        docstring: The docstring for the run function.\n        exceptions: Any exceptions that may be thrown during execution.\"\"\"\n    args: Namespace = parse_arguments()\n    config: Config = create_application_config(args)\n    generate_docstrings(\n        config=config,\n        module_path_queue=modules_path_queue,\n        functions_source_queue=functions_source_code_queue,\n        failed_modules_queue=failed_modules_queue,\n        class_source_queue=class_source_code_queue,\n    )\n\n\nif __name__ == '__main__':\n    run()\n",
  "from .set_config import set_configuration",
  "```\n{comment}\n```\n\n{format_instructions}\n\"\"\"\n\npositive_tmpl = PromptTemplate(\n    template=topic_assg_msg,\n    input_variables=[\"comment\", \"topics\"],\n    partial_variables={\n        \"format_instructions\": positive_parser.get_format_instructions()\n    },\n)\n\nnegative_tmpl = PromptTemplate(\n    template=topic_assg_msg,\n    input_variables=[\"comment\", \"topics\"],\n    partial_variables={\n        \"format_instructions\": negative_parser.get_format_instructions()\n    },\n)\n\nsentiment_chain = sentiment_template | llm | StrOutputParser()\npos_chain = positive_tmpl | llm | positive_parser\nneg_chain = negative_tmpl | llm | negative_parser\n\n# res = sentiment_chain.invoke({\"comment\": comment})\n# print(res, comment)\n# if 'positive' in res.lower():\n#     res = pos_chain.invoke({\"comment\": comment, 'topics': topics})\n# elif 'negative' in res.lower():\n#     res = neg_chain.invoke({\"comment\": comment, 'topics': topics})\n# print(res)\n\nbranch = RunnableBranch(\n    (lambda input: 'positive' in input['sentiment'].lower(), pos_chain),\n    neg_chain\n)\n\n",
  "from itemadapter import ItemAdapter\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.exceptions import DropItem\nfrom os import path, mkdir\nfrom scrapy.http import Response\nfrom scrapy import Request, Spider\nfrom scrapy import Item\nfrom pathlib import PurePosixPath\nfrom urllib.parse import urlparse\nfrom slidesmodel.models import db_connect, Tag, Category, Slide, create_table, create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport uuid\nimport logging\n\n\nclass SlidesmodelPipeline:\n    def process_item(self, item: Item, spider: Spider):\n        return item\n    \nclass MyImagesPipeline(ImagesPipeline):\n    def file_path(self, request: Request, response: Response = None, info=None, *, item=None):\n        slide_name: str = request.meta['title']\n        return f\"{slide_name}/\" + PurePosixPath(urlparse(request.url).path).name\n    \n    def get_media_requests(self, item: Item, info):\n        for image_url in item[\"image_urls\"]:\n            yield Request(image_url, meta={\"title\": item[\"title\"]})\n            \n\nclass SaveSlidesPipeline(object):\n    def __init__(self):\n        \"\"\"\n        Initializes database connection and sessionmaker\n        Creates tables\n        \"\"\"\n        engine = db_connect()\n        create_table(engine)\n        self.Session = sessionmaker(bind=engine)\n\n\n",
  "def generate_password_reset_token(session: Session, reset_password_request: RequestPasswordReset):\n    with session() as db:\n        user: User = db.query(User).filter(User.email_address == reset_password_request.email_address).first()\n    resp = {\n        'user_id': user.id,\n        'email_address': user.email_address,\n        'password_reset_token': user.generate_password_reset_token()\n    }\n    return resp\n\n\ndef password_repeated(session: Session, password_reset: PasswordReset):\n    with session() as db:\n        user: User = db.query(User).filter(User.email_address == password_reset.email_address).first()\n    return user.check_password(password_reset.password)",
  "@post.route(\"/likes\", methods=[\"GET\"])\ndef get_post_likes():\n    \"\"\"Get a posts likes.\"\"\"\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        likes: list[Bookmark] = list_post_likes(session=get_db, post_data=post_data)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    resp = [\n        ActivityCreated(\n            user_id=like.author_id,\n            post_id=like.post_id,\n            date_created=like.like_date\n        ).model_dump()\n        for like in likes\n    ]\n    return resp, HTTPStatus.OK",
  "from dotenv import load_dotenv\nload_dotenv()\n# from assistant.utils.channel_utils import get_channel_latest_video, get_favorite_channels_latest_videos\n# from assistant.utils.playlist_utils import add_video_to_youtube_playlist\nfrom assistant.agent import get_agent_executor\n# from assistant.tools.playlist.helpers import list_playlist_videos\n# from assistant.tools.comment.helpers import list_video_comments\nfrom assistant.agent import get_tools\nfrom assistant.tools.comment.helpers import (\n    list_video_comments, find_my_comments, find_author_comments, list_comment_replies\n)\nfrom assistant.tools.channel.helpers import find_my_youtube_username\n\ntitle: str = 'Real Engineering'\n# print(get_favorite_channels_latest_videos())\n# title: str = 'How Nebula Works from Real Engineering'\n# playlist: str = 'Daily Videos'\n# add_video_to_youtube_playlist(title, playlist)\n# query = 'When was the youtube channel Ark Invest created?'\n# print(agent_executor.invoke({\"input\": query})['output'])\n# print(list_playlist_videos(title, title))\n#PLx7ERghZ6LoOKkmL4oeLoqWousfkKpdM_\n# print(list_video_comments('How Nebula Works', max_results=10))\n# query = 'When was my youtube channel created?'\n# agent_executor = get_agent_executor()\n# print(agent_executor.invoke({\"input\": query})['output'])\n# tools = get_tools(query)\n# print(len(tools))\n# t = [tool.description for tool in tools]\n# print(t)\n# print(find_author_comments('Trapping Rain Water - Google Interview Question - Leetcode 42', '@NeetCode'))\n\nquery = \"List all the replies to the comments by neetcode on the video titled 'Trapping Rain Water - Google Interview Question - Leetcode 42'\"\nagent_executor = get_agent_executor()\nprint(agent_executor.invoke({\"input\": query})['output'])\n# print(list_comment_replies('neetcode', 'Trapping Rain Water - Google Interview Question - Leetcode 42'))",
  "# Define here the models for your spider middleware\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass SlidesgoSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(self, response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(self, response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, or item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(self, response, exception, spider):\n        # Called when a spider or process_spider_input() method\n",
  "@post.route(\"/get\", methods=[\"GET\"])\ndef get_one_post():\n    \"\"\"Get a single post.\"\"\"\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post = get_post(session=get_db, post_data=post_data)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    if post:\n        resp = CreatedPost(\n            id=post.id,\n            location=post.location,\n            text=post.text,\n            image_url=post.image_url,\n            author_id=post.author_id,\n            date_published=post.date_published\n        )\n        return resp.model_dump_json(indent=4), HTTPStatus.OK\n    \n    return {'Error':f'No post with id {post_data.post_id}'}, HTTPStatus.NOT_FOUND",
  "\n        if text and not self.validateLabel(text):\n            self.errorMessage(\n                self.tr(\"Invalid label\"),\n                self.tr(\"Invalid label '{}' with validation type '{}'\").format(\n                    text, self._config[\"validate_label\"]\n                ),\n            )\n            text = \"\"\n        if text:\n            self.labelList.clearSelection()\n            shape = self.canvas.setLastLabel(text, flags)\n            shape.group_id = group_id\n            shape.description = description\n            self.addLabel(shape)\n            self.actions.editMode.setEnabled(True)\n            self.actions.undoLastPoint.setEnabled(False)\n            self.actions.undo.setEnabled(True)\n            self.setDirty()\n        else:\n            self.canvas.undoLastLine()\n            self.canvas.shapesBackups.pop()\n\n    def scrollRequest(self, delta, orientation):\n        units = -delta * 0.1  # natural scroll\n        bar = self.scrollBars[orientation]\n        value = bar.value() + bar.singleStep() * units\n        self.setScroll(orientation, value)\n\n    def setScroll(self, orientation, value):\n        self.scrollBars[orientation].setValue(int(value))\n        self.scroll_values[orientation][self.filename] = value\n\n    def setZoom(self, value):\n        self.actions.fitWidth.setChecked(False)\n        self.actions.fitWindow.setChecked(False)\n        self.zoomMode = self.MANUAL_ZOOM\n        self.zoomWidget.setValue(value)\n        self.zoom_values[self.filename] = (self.zoomMode, value)\n\n",
  "from flask_bcrypt import Bcrypt\nfrom flask_cors import CORS\n\n\nbcrypt = Bcrypt()\ncors = CORS()",
  "#         self.dropout = nn.Dropout(p)\n#         self.hidden_size = hidden_size\n#         self.num_layers = num_layers\n\n#         self.embedding = nn.Embedding(input_size, embedding_size)\n#         self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n\n#     def forward(self, x):\n#         # x shape: (seq_length, N) where N is batch size\n\n#         embedding = self.dropout(self.embedding(x))\n#         # embedding shape: (seq_length, N, embedding_size)\n\n#         outputs, (hidden, cell) = self.rnn(embedding)\n#         # outputs shape: (seq_length, N, hidden_size)\n\n#         return hidden, cell\n\n\n# class Decoder(nn.Module):\n#     def __init__(\n#         self, input_size, embedding_size, hidden_size, output_size, num_layers, p\n#     ):\n#         super(Decoder, self).__init__()\n#         self.dropout = nn.Dropout(p)\n#         self.hidden_size = hidden_size\n#         self.num_layers = num_layers\n\n#         self.embedding = nn.Embedding(input_size, embedding_size)\n#         self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n#         self.fc = nn.Linear(hidden_size, output_size)\n\n#     def forward(self, x, hidden, cell):\n#         # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n#         # is 1 here because we are sending in a single word and not a sentence\n#         x = x.unsqueeze(0)\n\n#         embedding = self.dropout(self.embedding(x))\n#         # embedding shape: (1, N, embedding_size)\n\n",
  "# Scrapy settings for leetcode project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     https://docs.scrapy.org/en/latest/topics/settings.html\n#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = \"leetcode\"\n\nSPIDER_MODULES = [\"leetcode.spiders\"]\nNEWSPIDER_MODULE = \"leetcode.spiders\"\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\nUSER_AGENT = 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n",
  "def handle_method_not_allowed(exeption: Exception) -> Response:\n    \"\"\"Handle all method not allowed errors.\n\n    Called when a route tries to handle a request with a methods that is not\n    allowed for the given route.\n\n    Parameters\n    ----------\n    exception: Exception\n        The exception that was raised. This is a subclass of Exception.\n\n    Returns\n    -------\n    Response:\n        A string consiting of json data and response code.\n    \"\"\"\n    return make_response(jsonify({\"error\": str(exeption)}), HTTPStatus.METHOD_NOT_ALLOWED)\n\n\ndef handle_internal_server_error(exeption: Exception) -> Response:\n    \"\"\"Handle all internal server errors.\n\n    This method is called when an error occurs within the application server.\n\n    Parameters\n    ----------\n    exception: Exception\n        The exception that was raised. This is a subclass of Exception.\n\n    Returns\n    -------\n    Response:\n        A string consiting of json data and response code.\n    \"\"\"\n    return make_response(jsonify({\"error\": str(exeption)}), HTTPStatus.INTERNAL_SERVER_ERROR)",
  "      request is reasonable and achievable within the constraints they set.\n\n      A valid request should contain the following:\n      - A start and end location\n      - A trip duration that is reasonable given the start and end location\n      - Some other details, like the user's interests and/or preferred mode of transport\n\n      Any request that contains potentially harmful activities is not valid, regardless of what\n      other details are provided.\n\n      If the request is not valid, set\n      plan_is_valid = 0 and use your travel expertise to update the request to make it valid,\n      keeping your revised request shorter than 100 words.\n\n      If the request seems reasonable, then set plan_is_valid = 1 and\n      don't revise the request.\n\n      {format_instructions}\n    \"\"\"\n\n        self.human_template = \"\"\"\n      ####{query}####\n    \"\"\"\n\n        self.parser = PydanticOutputParser(pydantic_object=Validation)\n\n        self.system_message_prompt = SystemMessagePromptTemplate.from_template(\n            self.system_template,\n            partial_variables={\n                \"format_instructions\": self.parser.get_format_instructions()\n            },\n        )\n        self.human_message_prompt = HumanMessagePromptTemplate.from_template(\n            self.human_template, input_variables=[\"query\"]\n        )\n\n        self.chat_prompt = ChatPromptTemplate.from_messages(\n            [self.system_message_prompt, self.human_message_prompt]\n        )\n\n",
  "        self.zoomWidget = ZoomWidget()\n        self.setAcceptDrops(True)\n\n        self.canvas = self.labelList.canvas = Canvas(\n            epsilon=self._config[\"epsilon\"],\n            double_click=self._config[\"canvas\"][\"double_click\"],\n            num_backups=self._config[\"canvas\"][\"num_backups\"],\n            crosshair=self._config[\"canvas\"][\"crosshair\"],\n        )\n        self.canvas.zoomRequest.connect(self.zoomRequest)\n\n        scrollArea = QtWidgets.QScrollArea()\n        scrollArea.setWidget(self.canvas)\n        scrollArea.setWidgetResizable(True)\n        self.scrollBars = {\n            Qt.Vertical: scrollArea.verticalScrollBar(),\n            Qt.Horizontal: scrollArea.horizontalScrollBar(),\n        }\n        self.canvas.scrollRequest.connect(self.scrollRequest)\n\n        self.canvas.newShape.connect(self.newShape)\n        self.canvas.shapeMoved.connect(self.setDirty)\n        self.canvas.selectionChanged.connect(self.shapeSelectionChanged)\n        self.canvas.drawingPolygon.connect(self.toggleDrawingSensitive)\n\n        self.setCentralWidget(scrollArea)\n\n        features = QtWidgets.QDockWidget.DockWidgetFeatures()\n        for dock in [\"flag_dock\", \"label_dock\", \"shape_dock\", \"file_dock\"]:\n            if self._config[dock][\"closable\"]:\n                features = features | QtWidgets.QDockWidget.DockWidgetClosable\n            if self._config[dock][\"floatable\"]:\n                features = features | QtWidgets.QDockWidget.DockWidgetFloatable\n            if self._config[dock][\"movable\"]:\n                features = features | QtWidgets.QDockWidget.DockWidgetMovable\n            getattr(self, dock).setFeatures(features)\n            if self._config[dock][\"show\"] is False:\n                getattr(self, dock).setVisible(False)\n\n        self.addDockWidget(Qt.RightDockWidgetArea, self.flag_dock)\n",
  "from experiment_config import ExperimentConfig\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator\nfrom schemas import DataSet, Model\nfrom pandas import DataFrame, Series\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom extensions import train_model_task, send_training_report_task, redis, tune_model, train_tuned_model\nfrom celery.result import AsyncResult\nimport logging\nfrom celery import chord\nfrom experiment_models import models\nfrom time import sleep\nfrom config.config import app_config\nfrom schemas.train_config import TrainConfig\n\n\nclass Experiment:\n    def __init__(self, experiment_config: ExperimentConfig, preprocessor: ColumnTransformer, models: dict[str, BaseEstimator]):\n        self.experiment_config = experiment_config\n        self.preprocessor = preprocessor\n        self.models = models\n        self.dataset: DataSet = DataSet(metadata=experiment_config.dataset_metadata)\n        self.trained_models: list[Model] = []\n        self.train_task_ids: list[str] = []\n    \n    def get_features(self) -> DataFrame:\n        data: DataFrame = self.dataset.get_dataset()\n        features: DataFrame = data[self.experiment_config.feature_cols]\n        return features\n\n    def get_labels(self) -> Series:\n        data: DataFrame = self.dataset.get_dataset()\n        labels: Series = data[self.experiment_config.label_columns]\n        return labels\n\n    def get_train_test_data(self) -> ((DataFrame, Series), (DataFrame, Series)):\n        features = self.get_features()\n        labels = self.get_labels()\n        train_features, test_features, train_labels, test_labels = train_test_split(\n",
  "import gdown\n\nfrom .efficient_sam import EfficientSam\nfrom .segment_anything_model import SegmentAnythingModel\n\n\nclass SegmentAnythingModelVitB(SegmentAnythingModel):\n    name = \"SegmentAnything (speed)\"\n\n    def __init__(self):\n        super().__init__(\n            encoder_path=gdown.cached_download(\n                url=\"https://github.com/wkentaro/labelme/releases/download/sam-20230416/sam_vit_b_01ec64.quantized.encoder.onnx\",  # NOQA\n                md5=\"80fd8d0ab6c6ae8cb7b3bd5f368a752c\",\n            ),\n            decoder_path=gdown.cached_download(\n                url=\"https://github.com/wkentaro/labelme/releases/download/sam-20230416/sam_vit_b_01ec64.quantized.decoder.onnx\",  # NOQA\n                md5=\"4253558be238c15fc265a7a876aaec82\",\n            ),\n        )\n\n\nclass SegmentAnythingModelVitL(SegmentAnythingModel):\n    name = \"SegmentAnything (balanced)\"\n\n    def __init__(self):\n        super().__init__(\n            encoder_path=gdown.cached_download(\n                url=\"https://github.com/wkentaro/labelme/releases/download/sam-20230416/sam_vit_l_0b3195.quantized.encoder.onnx\",  # NOQA\n                md5=\"080004dc9992724d360a49399d1ee24b\",\n            ),\n            decoder_path=gdown.cached_download(\n                url=\"https://github.com/wkentaro/labelme/releases/download/sam-20230416/sam_vit_l_0b3195.quantized.decoder.onnx\",  # NOQA\n                md5=\"851b7faac91e8e23940ee1294231d5c7\",\n            ),\n        )\n\n\nclass SegmentAnythingModelVitH(SegmentAnythingModel):\n    name = \"SegmentAnything (accuracy)\"\n",
  "import os\n\nfrom youtube import YouTube\n\nclient_secrets_file = os.environ['CLIENT_SECRET_FILE']\nyoutube_client = YouTube(client_secret_file=client_secrets_file)\nyoutube_client.authenticate()\n",
  "\nclass Config(BaseModel):\n    path: set[str] = Field(description='The path to the source code directory')\n    overwrite_function_docstring: Optional[bool] = Field(\n        description='Whether or not to overwrite the existing function docstring',\n        default=False,\n    )\n    overwrite_class_docstring: Optional[bool] = Field(\n        description='Whether or not to overwrite the existing class docstring',\n        default=False,\n    )\n    overwrite_class_methods_docstring: Optional[bool] = Field(\n        description='Whether or not to overwrite the existing class methods docstring',\n        default=False,\n    )\n    documentation_style: Optional[str] = Field(\n        description='The format of documentation to use',\n        default='Numpy-Style',\n        enum=['Numpy-Style', 'Google-Style', 'Sphinx-Style'],\n    )\n    directories_ignore: set[str] = Field(\n        description='Directories to ignore',\n        default={'venv', '.venv', '__pycache__', '.git', 'build', 'dist', 'docs'},\n    )\n    files_ignore: set[str] = Field(\n        description='Files to ignore',\n        default_factory=set,\n    )\n",
  "        else:\n            if ev.orientation() == QtCore.Qt.Vertical:\n                mods = ev.modifiers()\n                if QtCore.Qt.ControlModifier == int(mods):\n                    # with Ctrl/Command key\n                    self.zoomRequest.emit(ev.delta(), ev.pos())\n                else:\n                    self.scrollRequest.emit(\n                        ev.delta(),\n                        QtCore.Qt.Horizontal\n                        if (QtCore.Qt.ShiftModifier == int(mods))\n                        else QtCore.Qt.Vertical,\n                    )\n            else:\n                self.scrollRequest.emit(ev.delta(), QtCore.Qt.Horizontal)\n        ev.accept()\n\n    def moveByKeyboard(self, offset):\n        if self.selectedShapes:\n            self.boundedMoveShapes(self.selectedShapes, self.prevPoint + offset)\n            self.repaint()\n            self.movingShape = True\n\n    def keyPressEvent(self, ev):\n        modifiers = ev.modifiers()\n        key = ev.key()\n        if self.drawing():\n            if key == QtCore.Qt.Key_Escape and self.current:\n                self.current = None\n                self.drawingPolygon.emit(False)\n                self.update()\n            elif key == QtCore.Qt.Key_Return and self.canCloseShape():\n                self.finalise()\n            elif modifiers == QtCore.Qt.AltModifier:\n                self.snapping = False\n        elif self.editing():\n            if key == QtCore.Qt.Key_Up:\n                self.moveByKeyboard(QtCore.QPointF(0.0, -MOVE_SPEED))\n            elif key == QtCore.Qt.Key_Down:\n                self.moveByKeyboard(QtCore.QPointF(0.0, MOVE_SPEED))\n",
  "\n    decoder_inputs = {\n        \"image_embeddings\": image_embedding,\n        \"batched_point_coords\": batched_point_coords,\n        \"batched_point_labels\": batched_point_labels,\n        \"orig_im_size\": np.array(image.shape[:2], dtype=np.int64),\n    }\n\n    masks, _, _ = decoder_session.run(None, decoder_inputs)\n    mask = masks[0, 0, 0, :, :]  # (1, 1, 3, H, W) -> (H, W)\n    mask = mask > 0.0\n\n    MIN_SIZE_RATIO = 0.05\n    skimage.morphology.remove_small_objects(\n        mask, min_size=mask.sum() * MIN_SIZE_RATIO, out=mask\n    )\n\n    if 0:\n        imgviz.io.imsave(\"mask.jpg\", imgviz.label2rgb(mask, imgviz.rgb2gray(image)))\n    return mask\n",
  "        flags=None,\n    ):\n        if imageData is not None:\n            imageData = base64.b64encode(imageData).decode(\"utf-8\")\n            imageHeight, imageWidth = self._check_image_height_and_width(\n                imageData, imageHeight, imageWidth\n            )\n        if otherData is None:\n            otherData = {}\n        if flags is None:\n            flags = {}\n        data = dict(\n            version=__version__,\n            flags=flags,\n            shapes=shapes,\n            imagePath=imagePath,\n            imageData=imageData,\n            imageHeight=imageHeight,\n            imageWidth=imageWidth,\n        )\n        for key, value in otherData.items():\n            assert key not in data\n            data[key] = value\n        try:\n            with open(filename, \"w\") as f:\n                json.dump(data, f, ensure_ascii=False, indent=2)\n            self.filename = filename\n        except Exception as e:\n            raise LabelFileError(e)\n\n    @staticmethod\n    def is_label_file(filename):\n        return osp.splitext(filename)[1].lower() == LabelFile.suffix\n",
  "        utils.addActions(\n            self.menus.file,\n            (\n                open_,\n                openNextImg,\n                openPrevImg,\n                opendir,\n                self.menus.recentFiles,\n                save,\n                saveAs,\n                saveAuto,\n                changeOutputDir,\n                saveWithImageData,\n                close,\n                deleteFile,\n                None,\n                quit,\n            ),\n        )\n        utils.addActions(self.menus.help, (help,))\n        utils.addActions(\n            self.menus.view,\n            (\n                self.flag_dock.toggleViewAction(),\n                self.label_dock.toggleViewAction(),\n                self.shape_dock.toggleViewAction(),\n                self.file_dock.toggleViewAction(),\n                None,\n                fill_drawing,\n                None,\n                hideAll,\n                showAll,\n                toggleAll,\n                None,\n                zoomIn,\n                zoomOut,\n                zoomOrg,\n                keepPrevScale,\n                None,\n                fitWindow,\n",
  "\ndef get_exception(exc):\n    \"\"\"Log exceptions\"\"\"\n    if exc:\n        app_logger.warning(f\"{exc.__class__.__name__ }: {str(exc)}\")\n",
  "You are given the comments by various users on the review of {product}. Use the comments to answer \nthe questions that follow. When answering questions, try to list out your answer, with each answer \non its own separate line. If you do not know the answer, just say that you do not know. DO NOT MAKE \nSTUFF UP.\n---------\n{context}\nQuestion: {question}\nHelpful answer: \n\"\"\"\n\nproduct: str = \"iphone 15 pro max\"\ntemplate = PromptTemplate.from_template(template_str)\ntemplate = template.partial(product=product)\n\nvectordb = Chroma(\n    persist_directory=persist_directory,\n    embedding_function=embeddings\n)\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, api_key=api_key),\n    chain_type=\"stuff\",\n    return_source_documents=True,\n    retriever=vectordb.as_retriever(search_kwargs={\"k\": 10}),\n    chain_type_kwargs={\"prompt\": template}\n)\n\nwhile True:\n    query = input(\"User: \")\n    res = qa_chain.invoke(query)\n    print(res[\"result\"])",
  "import os\n\nfrom langchain.agents import AgentExecutor, Tool\nfrom langchain.agents.format_scratchpad import format_to_openai_function_messages\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain.schema.document import Document\nfrom langchain.tools.render import format_tool_to_openai_function\nfrom langchain.vectorstores.faiss import FAISS\n\nfrom .tools import YouTubeSearchVideoTool\nfrom .tools.channel import MyYouTubeChannelDetailsTool, YouTubeChannelDetailsTool\nfrom .tools.comment import (\n    FindMyCommentsTool,\n    FindUserCommentsTool,\n    ListVideoCommentRepliesTool,\n    ListVideoCommentsTool,\n    ReplyCommentTool,\n)\nfrom .tools.playlist import (\n    CreatePlaylistTool,\n    DeleteYoutubePlaylistsTool,\n    InsertVideoIntoPlaylistTool,\n    ListChannelPlaylistsTool,\n    ListPlaylistVideosTool,\n    ListUserPlaylistsTool,\n)\nfrom .tools.video import YouTubeVideoDetailsTool\n\nOPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\nOPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\")  # \"gpt-3.5-turbo-0613\"\nllm = ChatOpenAI(temperature=0, model=OPENAI_MODEL, api_key=OPENAI_API_KEY)\ntools = [\n    YouTubeSearchVideoTool(),\n    ListUserPlaylistsTool(),\n    ListPlaylistVideosTool(),\n    ListVideoCommentsTool(),\n    YouTubeVideoDetailsTool(),\n",
  "        gmail_client = build(self.api_service_name, self.api_version, credentials=credentials)\n        return gmail_client\n    \n    def authenticate(self) -> Any:\n        credentials: Credentials = self.get_credentials()\n        if not credentials or self.credentials_expired(credentials=credentials):\n            credentials = self.generate_credentials()\n            self.save_credentials(credentials=credentials)\n        gmail_client = self.get_gmail_client(credentials=credentials)\n        return gmail_client",
  "\nclass ItineraryTemplate(object):\n    def __init__(self):\n        self.system_template = \"\"\"\n      You are a travel agent who helps users make exciting travel plans.\n\n      The user's request will be denoted by four hashtags. Convert the\n      user's request into a detailed itinerary describing the places\n      they should visit and the things they should do.\n\n      Try to include the specific address of each location.\n\n      Remember to take the user's preferences and timeframe into account,\n      and give them an itinerary that would be fun and doable given their constraints.\n\n      Return the itinerary as a bulleted list with clear start and end locations.\n      Be sure to mention the type of transit for the trip.\n      If specific start and end locations are not given, choose ones that you think are suitable and give specific addresses.\n      Your output must be the list and nothing else.\n    \"\"\"\n\n        self.human_template = \"\"\"\n      ####{query}####\n    \"\"\"\n\n        self.system_message_prompt = SystemMessagePromptTemplate.from_template(\n            self.system_template,\n        )\n        self.human_message_prompt = HumanMessagePromptTemplate.from_template(\n            self.human_template, input_variables=[\"query\"]\n        )\n\n        self.chat_prompt = ChatPromptTemplate.from_messages(\n            [self.system_message_prompt, self.human_message_prompt]\n        )\n\n\nclass MappingTemplate(object):\n    def __init__(self):\n        self.system_template = \"\"\"\n",
  "        if self.mayContinue():\n            self.loadFile(filename)\n\n    def openPrevImg(self, _value=False):\n        keep_prev = self._config[\"keep_prev\"]\n        if QtWidgets.QApplication.keyboardModifiers() == (\n            Qt.ControlModifier | Qt.ShiftModifier\n        ):\n            self._config[\"keep_prev\"] = True\n\n        if not self.mayContinue():\n            return\n\n        if len(self.imageList) <= 0:\n            return\n\n        if self.filename is None:\n            return\n\n        currIndex = self.imageList.index(self.filename)\n        if currIndex - 1 >= 0:\n            filename = self.imageList[currIndex - 1]\n            if filename:\n                self.loadFile(filename)\n\n        self._config[\"keep_prev\"] = keep_prev\n\n    def openNextImg(self, _value=False, load=True):\n        keep_prev = self._config[\"keep_prev\"]\n        if QtWidgets.QApplication.keyboardModifiers() == (\n            Qt.ControlModifier | Qt.ShiftModifier\n        ):\n            self._config[\"keep_prev\"] = True\n\n        if not self.mayContinue():\n            return\n\n        if len(self.imageList) <= 0:\n            return\n\n",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy import Request\nfrom slidesmodel.items import SlidesModelItem\nfrom scrapy.loader import ItemLoader\nfrom scrapy.utils.project import get_project_settings\nimport json\n\n\nclass SlidesModelspider(Spider):\n    name: str = \"slides\"\n    \n    def __init__(self, name: str | None = None, **kwargs: Any):\n        super().__init__(name, **kwargs)\n        self.start_urls: list[str] = self.load_start_urls()\n        # self.start_urls: list[str] = [\n        #     \"https://slidemodel.com/templates/tag/process-flow/\"\n        # ]\n    \n    @staticmethod\n    def load_start_urls() -> list:\n        settings: dict = get_project_settings()\n        links_path: str = settings.get(\"START_URLS_PATH\")\n        with open(links_path, \"r\") as f:\n            start_urls_dict: list[dict] = json.load(f)\n        return [\n            link.get(\"url\") for link in start_urls_dict\n        ]\n    \n    def parse(self, response: Response, **kwargs: Any) -> Any:\n        self.logger.info(\"This is my first spider.\")\n        slides = response.xpath(\"//div[@class='col-lg-3 col-sm-6 mt-4']\")\n        for slide in slides:\n            loader: ItemLoader = ItemLoader(item=SlidesModelItem(), selector=slide)\n            loader.add_css(\"title\", \".item a::text\")\n            loader.add_css(\"category\", \".category::text\")\n            slide_item = loader.load_item()\n            link = slide.css(\".item a::attr(href)\").get()\n            self.logger.info(\"Parsing the slide\")\n",
  "\ndef create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like\n",
  "def list_user_likes(session: Session, user_data: GetUser) -> list[Like]:\n    with session() as db:\n        user: User = db.query(User).filter(User.id == user_data.user_id).first()\n        likes: list[Like] = user.likes\n    return likes\n\ndef list_post_likes(session: Session, post_data: GetPost):\n    with session() as db:\n        post: Post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        likes: list[Like] = post.likes\n        for like in likes:\n            like.author\n    return likes\n\ndef get_key_like(session: Session, post_data: GetPost):\n    from random import choice\n    with session() as db:\n        post: Post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        likes: list[Like] = post.likes\n        for like in likes:\n            like.author\n    return choice(likes).author if likes else None",
  "from typing import Any, Optional\n\nfrom oryks_google_oauth import GoogleDriveScopes, GoogleOAuth\nfrom pydantic import BaseModel\n\n\nclass GoogleDrive(BaseModel):\n    \"\"\"Provides methods for interacting with the Drive API.\n\n    This class acts as an interface to the Drive API, providing methods for interacting with\n    the Drive API.\n\n    Attributes\n    ----------\n    client_secret_file: str\n        The path to the json file containing your authentication information.\n    \"\"\"\n\n    client_secret_file: Optional[str] = None\n    authenticated: Optional[bool] = False\n    drive_client: Optional[Any] = None\n\n    def authenticate(self, client_secret_file: Optional[str] = None) -> None:\n        \"\"\"Authenticate the requests made to drive.\n\n        Used to generate the credentials that are used when authenticating requests to drive.\n\n        Parameters\n        ----------\n        client_secret_file: str\n            The path to clients secret json file from Google\n\n        Raises\n        ------\n        ValueError:\n            When the client secrets file is not provided\n        FileNotFoundError:\n            When the secrets file path is not found\n        \"\"\"\n        if client_secret_file:\n",
  "import argparse\nimport os\n\nimport imgviz\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom labelme.logger import logger\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"label_png\", help=\"label PNG file\")\n    parser.add_argument(\n        \"--labels\",\n        help=\"labels list (comma separated text or file)\",\n        default=None,\n    )\n    parser.add_argument(\"--image\", help=\"image file\", default=None)\n    args = parser.parse_args()\n\n    if args.labels is not None:\n        if os.path.exists(args.labels):\n            with open(args.labels) as f:\n                label_names = [label.strip() for label in f]\n        else:\n            label_names = args.labels.split(\",\")\n    else:\n        label_names = None\n\n    if args.image is not None:\n        image = imgviz.io.imread(args.image)\n    else:\n        image = None\n\n    label = imgviz.io.imread(args.label_png)\n    label = label.astype(np.int32)\n    label[label == 255] = -1\n",
  "import datetime\nimport logging\nimport os\nimport sys\n\nimport termcolor\n\nif os.name == \"nt\":  # Windows\n    import colorama\n\n    colorama.init()\n\nfrom . import __appname__\n\nCOLORS = {\n    \"WARNING\": \"yellow\",\n    \"INFO\": \"white\",\n    \"DEBUG\": \"blue\",\n    \"CRITICAL\": \"red\",\n    \"ERROR\": \"red\",\n}\n\n\nclass ColoredFormatter(logging.Formatter):\n    def __init__(self, fmt, use_color=True):\n        logging.Formatter.__init__(self, fmt)\n        self.use_color = use_color\n\n    def format(self, record):\n        levelname = record.levelname\n        if self.use_color and levelname in COLORS:\n\n            def colored(text):\n                return termcolor.colored(\n                    text,\n                    color=COLORS[levelname],\n                    attrs={\"bold\": True},\n                )\n\n            record.levelname2 = colored(\"{:<7}\".format(record.levelname))\n",
  "    logging.info('Getting the playlist id for %s', playlist_name)\n    playlist_id: str = get_playlist_id(playlist_name)\n    logging.info('The playlist %s id is %s', playlist_name, playlist_id)\n    playlist_items: list[str] = []\n    for channel_name in channel_names:\n        logging.info('Getting the channel id for \"%s\".', channel_name)\n        channel_id: str = get_channel_id(channel_name)\n        logging.info('The channel \"%s\" has id \"%s\".', channel_name, channel_id)\n        logging.info('Getting the latest video for channel \"%s\".', channel_name)\n        latest_video: Video = find_latest_video(channel_id, youtube)\n        logging.info('Fetched the latest video for %s.', channel_name)\n        logging.info('The latest video for channel: \"%s\" is :\"%s\"', channel_name, latest_video.title)\n        logging.info('Creating a playlist item for video: \"%s\"', latest_video.title)\n        playlist_item: PlaylistItem = add_video_to_playlist(latest_video, playlist_id, youtube, position=0)\n        if playlist_item:\n            logging.info('Added \"%s\" to \"%s\".', latest_video.title, playlist_name)\n            playlist_items.append({\n                'id': playlist_item.id,\n                'title': playlist_item.snippet.title\n            })\n        else:\n            logging.info('The video \"%s\" already exists in playlist \"%s\".', latest_video.title, playlist_name)\n        logging.info('Video id: %s.', latest_video.resource_id)\n    if playlist_items:\n        logging.info('Added all the latest videos to the playlist.')\n    else:\n        logging.info('Did not add any videos to playlist.')\n    return playlist_items\n\n\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = get_youtube_client(client_secret_file)\n# playlist_id: str = get_playlist_id('Daily Videos')\n# channel_id: str = get_channel_id('CNBC')\n# latest_video: Video = find_latest_video(channel_id, youtube)\n# playlist_item: PlaylistItem = add_video_to_playlist(latest_video.resource_id, playlist_id, youtube, position=0)\n# delete_video_playlist('UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS41NkI0NEY2RDEwNTU3Q0M2', youtube)\n# ids = ['UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS41NkI0NEY2RDEwNTU3Q0M2', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS4yODlGNEE0NkRGMEEzMEQy', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS4wMTcyMDhGQUE4NTIzM0Y5', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS41MjE1MkI0OTQ2QzJGNzNG', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS4wOTA3OTZBNzVEMTUzOTMy', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS4xMkVGQjNCMUM1N0RFNEUx', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS41MzJCQjBCNDIyRkJDN0VD', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS5DQUNERDQ2NkIzRUQxNTY1', 'UExfMjZ2bWc4V19BY0VFbF9CbzJBaHppUy05M3I2YjhidS45NDk1REZENzhEMzU5MDQz']\n# for id in ids:\n#     delete_video_playlist(id, youtube)\n",
  "        new_height = image_size\n        new_width = int(round(width * scale))\n    return scale, new_height, new_width\n\n\ndef _resize_image(image_size, image):\n    scale, new_height, new_width = _compute_scale_to_resize_image(\n        image_size=image_size, image=image\n    )\n    scaled_image = imgviz.resize(\n        image,\n        height=new_height,\n        width=new_width,\n        backend=\"pillow\",\n    ).astype(np.float32)\n    return scale, scaled_image\n\n\ndef _compute_image_embedding(image_size, encoder_session, image):\n    image = imgviz.asrgb(image)\n\n    scale, x = _resize_image(image_size, image)\n    x = (x - np.array([123.675, 116.28, 103.53], dtype=np.float32)) / np.array(\n        [58.395, 57.12, 57.375], dtype=np.float32\n    )\n    x = np.pad(\n        x,\n        (\n            (0, image_size - x.shape[0]),\n            (0, image_size - x.shape[1]),\n            (0, 0),\n        ),\n    )\n    x = x.transpose(2, 0, 1)[None, :, :, :]\n\n    output = encoder_session.run(output_names=None, input_feed={\"x\": x})\n    image_embedding = output[0]\n\n    return image_embedding\n\n",
  "# -*- coding: utf-8 -*-\n\nimport functools\nimport html\nimport math\nimport os\nimport os.path as osp\nimport re\nimport webbrowser\n\nimport imgviz\nimport natsort\nfrom qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\nfrom qtpy.QtCore import Qt\n\nfrom labelme import PY2\nfrom labelme import __appname__\nfrom labelme.ai import MODELS\nfrom labelme.config import get_config\nfrom labelme.label_file import LabelFile\nfrom labelme.label_file import LabelFileError\nfrom labelme.logger import logger\nfrom labelme.shape import Shape\nfrom labelme.widgets import BrightnessContrastDialog\nfrom labelme.widgets import Canvas\nfrom labelme.widgets import FileDialogPreview\nfrom labelme.widgets import LabelDialog\nfrom labelme.widgets import LabelListWidget\nfrom labelme.widgets import LabelListWidgetItem\nfrom labelme.widgets import ToolBar\nfrom labelme.widgets import UniqueLabelQListWidget\nfrom labelme.widgets import ZoomWidget\n\nfrom . import utils\n\n# FIXME\n# - [medium] Set max zoom value to something big enough for FitWidth/Window\n\n",
  "# flake8: noqa\n\nfrom ._io import lblsave\n\nfrom .image import apply_exif_orientation\nfrom .image import img_arr_to_b64\nfrom .image import img_arr_to_data\nfrom .image import img_b64_to_arr\nfrom .image import img_data_to_arr\nfrom .image import img_data_to_pil\nfrom .image import img_data_to_png_data\nfrom .image import img_pil_to_data\nfrom .image import img_qt_to_arr\n\nfrom .shape import labelme_shapes_to_label\nfrom .shape import masks_to_bboxes\nfrom .shape import polygons_to_mask\nfrom .shape import shape_to_mask\nfrom .shape import shapes_to_label\n\nfrom .qt import newIcon\nfrom .qt import newButton\nfrom .qt import newAction\nfrom .qt import addActions\nfrom .qt import labelValidator\nfrom .qt import struct\nfrom .qt import distance\nfrom .qt import distancetoline\nfrom .qt import fmtShortcut\n",
  "    args_schema: Type[BaseModel] = YouTubeChannelTitleSearch\n\n    def _run(\n        self, title: str, \n        run_manager: Optional[CallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool.\"\"\"\n        youtube_response: YouTubeResponse = youtube.find_channel_by_name(title)\n        search_results: list[Search] = youtube_response.items\n        return search_results[0]\n\n    async def _arun(\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool asynchronously.\"\"\"\n        raise NotImplementedError(\"Calculator does not support async\")\n    \n\nclass YouTubeChannelSearch(BaseModel):\n    id: str\n\n\nclass YouTubeChannelSearchTool(BaseTool):\n    name = \"youtube_channel_search\"\n    description = \"\"\"\n    useful when you ned to find information about a channel when provided with the channel id. \n    To use this tool you must provide the channel id.\n    \"\"\"\n    args_schema: Type[BaseModel] = YouTubeChannelSearch\n\n    def _run(\n        self, \n        id: str, \n        run_manager: Optional[CallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool.\"\"\"\n        youtube_channel: YouTubeResponse = youtube.find_channel_by_id(id)\n        return youtube_channel\n\n    async def _arun(\n",
  "from redis import Redis\n\nredis = Redis()\n\npage = '1'\nres = redis.zrevrange(f'quote_authors', 0, 10, withscores=True)\nprint(res)",
  "from datetime import datetime\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom ..database import Base\nfrom sqlalchemy import ForeignKey\n\n\nclass Bookmark(Base):\n    __tablename__ = 'bookmarks'\n    \n    author_id: Mapped[str] = mapped_column(ForeignKey('users.id'), primary_key=True)\n    post_id: Mapped[str] = mapped_column(ForeignKey('posts.id'), primary_key=True)\n    bookmark_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    \n    author = relationship('User', back_populates='bookmarks')\n    post = relationship('Post', back_populates='bookmarks')",
  "        if filename is not None:\n            self.load(filename)\n        self.filename = filename\n\n    @staticmethod\n    def load_image_file(filename):\n        try:\n            image_pil = PIL.Image.open(filename)\n        except IOError:\n            logger.error(\"Failed opening image file: {}\".format(filename))\n            return\n\n        # apply orientation to image according to exif\n        image_pil = utils.apply_exif_orientation(image_pil)\n\n        with io.BytesIO() as f:\n            ext = osp.splitext(filename)[1].lower()\n            if PY2 and QT4:\n                format = \"PNG\"\n            elif ext in [\".jpg\", \".jpeg\"]:\n                format = \"JPEG\"\n            else:\n                format = \"PNG\"\n            image_pil.save(f, format=format)\n            f.seek(0)\n            return f.read()\n\n    def load(self, filename):\n        keys = [\n            \"version\",\n            \"imageData\",\n            \"imagePath\",\n            \"shapes\",  # polygonal annotations\n            \"flags\",  # image level flags\n            \"imageHeight\",\n            \"imageWidth\",\n        ]\n        shape_keys = [\n            \"label\",\n            \"points\",\n",
  "from langchain.agents import AgentType, Tool, initialize_agent, tool\nfrom langchain.llms import OpenAI\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.utilities import SerpAPIWrapper\nimport googlemaps\nimport os\nimport chainlit as cl\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\n@tool\ndef get_agrovets(query: str) -> str:\n    \"\"\"Useful when you need to get agrovets in a given location. Give it a query, such as agrovets in Nairobi, Kenya.\n    \"\"\"\n    gmaps = googlemaps.Client(key=os.environ['GOOGLE_MAPS_API_KEY'])\n    results = gmaps.places(query=f'Get me aggrovets in {query}')\n    aggrovet_locations: list[dict] = list()\n    for result in results['results']:\n        bussiness: dict = dict()\n        bussiness['business_status'] = result['business_status']\n        bussiness['formatted_address'] = result['formatted_address']\n        bussiness['name'] = result['name']\n        bussiness['opening_hours'] = result.get('opening_hours', 'NaN')\n        aggrovet_locations.append(bussiness)\n    return aggrovet_locations\n\n\n@cl.on_chat_start\nasync def start():\n    tools: list[Tool] = [\n        get_agrovets\n    ]\n    llm = OpenAI(temperature=0)\n    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n    agent = initialize_agent(\n        tools,\n        llm,\n        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n        verbose=True,\n",
  "from dotenv import load_dotenv\n\nload_dotenv()\nfrom langchain.agents import tool\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain_core.utils.function_calling import convert_to_openai_function\nfrom langchain_community.utilities.google_search import GoogleSearchAPIWrapper\nimport os\nfrom langchain_openai import ChatOpenAI, OpenAI\nfrom langchain.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain.llms.base import BaseLLM\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom os import path\n\n\nOPENAI_API_KEY: str = \"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\"\n\nGOOGLE_API_KEY: str = os.environ.get(\n    \"GOOGLE_API_KEY\", \"AIzaSyDDuuMXlQ-7iiT7QvQg6c8nbyV0mFxSAYo\"\n)\nGOOGLE_CSE_ID: str = os.environ.get(\"GOOGLE_CSE_ID\", \"a347832f863fd4f5d\")\n\nchat_model: BaseLLM = ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY)\nllm: BaseLLM = OpenAI(temperature=0, api_key=OPENAI_API_KEY)\n\ngoogle_search = GoogleSearchAPIWrapper(\n    google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID, k=3\n)\n\ndata_dir = \"data\"\nvideo_data_dir = \"data\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"iphone_15_marques_review\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\n\nclass UserQuery(BaseModel):\n    query: str = Field(description=\"What the user wants to search for on the web\")\n    result_count: int = Field(description=\"The number of results to return\", default=5)\n",
  "        image_file = files[0]\n        image_data = image_file.content # byte values of the image\n        image = Image.open(io.BytesIO(image_data))\n        model = load_model()\n        predicted_label, predictions = evaluate_image(image, model)\n        analysis_text: str = f\"\"\"\n            After analyzing the image you uploaded, here is what I found:\n            Maize Leaf Rust probability: {predictions['Maize Leaf Rust']}%\n            Northern Leaf Blight probability: {predictions['Northern Leaf Blight']}%\n            Healthy probability: {predictions['Healthy']}%\n            Gray Leaf Spot probability: {predictions['Gray Leaf Spot']}%\n            Your plant is most likely infected with {predicted_label}.\n            \"\"\"\n        elements = [\n            cl.Image(\n                name=\"image2\", display=\"inline\", content=image_data\n                ), \n            cl.Text(name=\"simple_text\", content=analysis_text, display=\"inline\", size='large')\n        ]\n        await cl.Message(content=f\"Maize image with {predicted_label}!\", elements=elements).send()\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run('Tell me some facts about the maize disease leaf rust especially in relation to kenya.')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Tell me some facts about the maize disease {predicted_label} especially in relation to kenya.')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Get me aggrovets in {user_location}, Kenya')\n        await msg.update()\n        await cl.Message(content='Feel free to ask me more questions about maize plant diseases and how to deal with them.').send()\n    else:\n        await cl.Message(content='Currently cannot detect pests. Still working on that model.').send()\n    \n\n@cl.on_message\nasync def main(message: cl.Message):\n",
  "# Define here the models for your spider middleware\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass LeetcodeSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(self, response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(self, response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, or item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(self, response, exception, spider):\n        # Called when a spider or process_spider_input() method\n",
  "from youtube import YouTube\nimport json\nimport os\nfrom typing import Optional\nfrom youtube.models.video_model import Video\n\ndef to_json(channels):\n    with open('channels.json', 'w', encoding='utf-8') as f:\n        f.write(json.dumps(channels, indent=4))\n        \ndef save_to_channels(video: Video, file_name: Optional[str] = \"kenyan_channels.json\") -> None:\n    kenyan_channels = []\n    if video:\n        if os.path.exists(file_name):\n            with open(file_name, 'r', encoding='utf-8') as f:\n                try:\n                    kenyan_channels = json.loads(f.read())\n                except json.decoder.JSONDecodeError:\n                    pass\n        with open(file_name, 'w', encoding='utf-8') as f:\n            data = {\n                video.channel_title: video.channel_id\n            }\n            if not data in kenyan_channels:\n                kenyan_channels.append(data)\n            f.write(json.dumps(kenyan_channels, indent=2))\n            print(kenyan_channels)\n    \n\ndef print_videos(videos):\n    vids = []\n    for video in videos:\n        vid = {\n            'title': video.video_title,\n            'channel': video.channel_title\n        }\n        vids.append(vid)\n    print(vids)\n\n# client_secrets_file = '/home/lyle/Downloads/python_learning_site.json'\n",
  "# flake8: noqa\n\nfrom .brightness_contrast_dialog import BrightnessContrastDialog\n\nfrom .canvas import Canvas\n\nfrom .color_dialog import ColorDialog\n\nfrom .file_dialog_preview import FileDialogPreview\n\nfrom .label_dialog import LabelDialog\nfrom .label_dialog import LabelQLineEdit\n\nfrom .label_list_widget import LabelListWidget\nfrom .label_list_widget import LabelListWidgetItem\n\nfrom .tool_bar import ToolBar\n\nfrom .unique_label_qlist_widget import UniqueLabelQListWidget\n\nfrom .zoom_widget import ZoomWidget\n",
  "            \"group_id\",\n            \"shape_type\",\n            \"flags\",\n            \"description\",\n            \"mask\",\n        ]\n        try:\n            with open(filename, \"r\") as f:\n                data = json.load(f)\n\n            if data[\"imageData\"] is not None:\n                imageData = base64.b64decode(data[\"imageData\"])\n                if PY2 and QT4:\n                    imageData = utils.img_data_to_png_data(imageData)\n            else:\n                # relative path from label file to relative path from cwd\n                imagePath = osp.join(osp.dirname(filename), data[\"imagePath\"])\n                imageData = self.load_image_file(imagePath)\n            flags = data.get(\"flags\") or {}\n            imagePath = data[\"imagePath\"]\n            self._check_image_height_and_width(\n                base64.b64encode(imageData).decode(\"utf-8\"),\n                data.get(\"imageHeight\"),\n                data.get(\"imageWidth\"),\n            )\n            shapes = [\n                dict(\n                    label=s[\"label\"],\n                    points=s[\"points\"],\n                    shape_type=s.get(\"shape_type\", \"polygon\"),\n                    flags=s.get(\"flags\", {}),\n                    description=s.get(\"description\"),\n                    group_id=s.get(\"group_id\"),\n                    mask=utils.img_b64_to_arr(s[\"mask\"]) if s.get(\"mask\") else None,\n                    other_data={k: v for k, v in s.items() if k not in shape_keys},\n                )\n                for s in data[\"shapes\"]\n            ]\n        except Exception as e:\n            raise LabelFileError(e)\n",
  "\ndef distancetoline(point, line):\n    p1, p2 = line\n    p1 = np.array([p1.x(), p1.y()])\n    p2 = np.array([p2.x(), p2.y()])\n    p3 = np.array([point.x(), point.y()])\n    if np.dot((p3 - p1), (p2 - p1)) < 0:\n        return np.linalg.norm(p3 - p1)\n    if np.dot((p3 - p2), (p1 - p2)) < 0:\n        return np.linalg.norm(p3 - p2)\n    if np.linalg.norm(p2 - p1) == 0:\n        return np.linalg.norm(p3 - p1)\n    return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n\n\ndef fmtShortcut(text):\n    mod, key = text.split(\"+\", 1)\n    return \"<b>%s</b>+<b>%s</b>\" % (mod, key)\n",
  "        self.selectionModel().selectionChanged.connect(self.itemSelectionChangedEvent)\n\n    def __len__(self):\n        return self.model().rowCount()\n\n    def __getitem__(self, i):\n        return self.model().item(i)\n\n    def __iter__(self):\n        for i in range(len(self)):\n            yield self[i]\n\n    @property\n    def itemDropped(self):\n        return self.model().itemDropped\n\n    @property\n    def itemChanged(self):\n        return self.model().itemChanged\n\n    def itemSelectionChangedEvent(self, selected, deselected):\n        selected = [self.model().itemFromIndex(i) for i in selected.indexes()]\n        deselected = [self.model().itemFromIndex(i) for i in deselected.indexes()]\n        self.itemSelectionChanged.emit(selected, deselected)\n\n    def itemDoubleClickedEvent(self, index):\n        self.itemDoubleClicked.emit(self.model().itemFromIndex(index))\n\n    def selectedItems(self):\n        return [self.model().itemFromIndex(i) for i in self.selectedIndexes()]\n\n    def scrollToItem(self, item):\n        self.scrollTo(self.model().indexFromItem(item))\n\n    def addItem(self, item):\n        if not isinstance(item, LabelListWidgetItem):\n            raise TypeError(\"item must be LabelListWidgetItem\")\n        self.model().setItem(self.model().rowCount(), 0, item)\n        item.setSizeHint(self.itemDelegate().sizeHint(None, None))\n\n",
  "from celery import Celery\nfrom config import CeleryConfig\n\n\ncelery_app: Celery = Celery(__name__)\ncelery_app.config_from_object(CeleryConfig)\ncelery_app.conf.beat_schedule = {\n        'create-daily-playlist': {\n            'task': 'tasks.create_daily_playlist',\n            'schedule': 10\n        }\n    }\ncelery_app.autodiscover_tasks(['tasks'])\n",
  "            lambda: self.canvas.initializeAiModel(\n                name=self._selectAiModelComboBox.currentText()\n            )\n            if self.canvas.createMode in [\"ai_polygon\", \"ai_mask\"]\n            else None\n        )\n\n        self.tools = self.toolbar(\"Tools\")\n        self.actions.tool = (\n            open_,\n            opendir,\n            openPrevImg,\n            openNextImg,\n            save,\n            deleteFile,\n            None,\n            createMode,\n            editMode,\n            duplicate,\n            delete,\n            undo,\n            brightnessContrast,\n            None,\n            fitWindow,\n            zoom,\n            None,\n            selectAiModel,\n        )\n\n        self.statusBar().showMessage(str(self.tr(\"%s started.\")) % __appname__)\n        self.statusBar().show()\n\n        if output_file is not None and self._config[\"auto_save\"]:\n            logger.warn(\n                \"If `auto_save` argument is True, `output_file` argument \"\n                \"is ignored and output filename is automatically \"\n                \"set as IMAGE_BASENAME.json.\"\n            )\n        self.output_file = output_file\n        self.output_dir = output_dir\n",
  "from pydantic import Field, BaseModel\n\n\nclass Trip(BaseModel):\n    start: str = Field(description=\"start location of trip\")\n    end: str = Field(description=\"end location of trip\")\n    waypoints: list[str] = Field(description=\"list of waypoints\")\n    transit: str = Field(description=\"mode of transportation\")",
  "import os\n\nfrom langchain.llms.base import BaseLLM\nfrom langchain_openai import OpenAI\n\napi_key: str = os.environ[\"OPENAI_API_KEY\"]\n\nchatgpt: BaseLLM = OpenAI(temperature=0, api_key=api_key)\n",
  "    def addZoom(self, increment=1.1):\n        zoom_value = self.zoomWidget.value() * increment\n        if increment > 1:\n            zoom_value = math.ceil(zoom_value)\n        else:\n            zoom_value = math.floor(zoom_value)\n        self.setZoom(zoom_value)\n\n    def zoomRequest(self, delta, pos):\n        canvas_width_old = self.canvas.width()\n        units = 1.1\n        if delta < 0:\n            units = 0.9\n        self.addZoom(units)\n\n        canvas_width_new = self.canvas.width()\n        if canvas_width_old != canvas_width_new:\n            canvas_scale_factor = canvas_width_new / canvas_width_old\n\n            x_shift = round(pos.x() * canvas_scale_factor) - pos.x()\n            y_shift = round(pos.y() * canvas_scale_factor) - pos.y()\n\n            self.setScroll(\n                Qt.Horizontal,\n                self.scrollBars[Qt.Horizontal].value() + x_shift,\n            )\n            self.setScroll(\n                Qt.Vertical,\n                self.scrollBars[Qt.Vertical].value() + y_shift,\n            )\n\n    def setFitWindow(self, value=True):\n        if value:\n            self.actions.fitWidth.setChecked(False)\n        self.zoomMode = self.FIT_WINDOW if value else self.MANUAL_ZOOM\n        self.adjustScale()\n\n    def setFitWidth(self, value=True):\n        if value:\n            self.actions.fitWindow.setChecked(False)\n",
  "        # to be in the undo stack.\n        if len(self.shapesBackups) < 2:\n            return False\n        return True\n\n    def restoreShape(self):\n        # This does _part_ of the job of restoring shapes.\n        # The complete process is also done in app.py::undoShapeEdit\n        # and app.py::loadShapes and our own Canvas::loadShapes function.\n        if not self.isShapeRestorable:\n            return\n        self.shapesBackups.pop()  # latest\n\n        # The application will eventually call Canvas.loadShapes which will\n        # push this right back onto the stack.\n        shapesBackup = self.shapesBackups.pop()\n        self.shapes = shapesBackup\n        self.selectedShapes = []\n        for shape in self.shapes:\n            shape.selected = False\n        self.update()\n\n    def enterEvent(self, ev):\n        self.overrideCursor(self._cursor)\n\n    def leaveEvent(self, ev):\n        self.unHighlight()\n        self.restoreCursor()\n\n    def focusOutEvent(self, ev):\n        self.restoreCursor()\n\n    def isVisible(self, shape):\n        return self.visible.get(shape, True)\n\n    def drawing(self):\n        return self.mode == self.CREATE\n\n    def editing(self):\n        return self.mode == self.EDIT\n",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "def activate_user_account(session: Session, activation_data: ActivateUser):\n    with session() as db:\n        user: User = db.query(User).filter(User.id == activation_data.user_id).first()\n        if user.id == User.decode_auth_token(activation_data.activation_token):\n            user.activated = True\n            db.commit()\n            return True\n    raise InvalidTokenError('Invalid or Expired token.')\n\n\ndef loggin_user(session: Session, login_data: LoginUser):\n    with session() as db:\n        user: User = db.query(User).filter(User.email_address == login_data.email_address).first()\n        if user and user.check_password(login_data.password):\n            return True\n    raise ValueError('Invalid email address and or password.')\n",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy import Request\n# from slidesmodel.items import SlidesModelItem\nfrom scrapy.loader import ItemLoader\nfrom scrapy.utils.project import get_project_settings\nimport json\n\n\nclass SlidesGospider(Spider):\n    name: str = \"slides\"\n    \n    def __init__(self, name: str | None = None, **kwargs: Any):\n        super().__init__(name, **kwargs)\n        # self.start_urls: list[str] = self.load_start_urls()\n        self.start_urls: list[str] = [\n            \"https://slidesgo.com/food#rs=home\"\n        ]\n    \n    \n    def parse(self, response: Response, **kwargs: Any) -> Any:\n        self.logger.info(\"This is my first spider.\")\n        slide_links = response.css('div.theme_post a::attr(href)')\n        for slide_link in slide_links:\n            # title = problem_link.css('a::text')[0].get()\n            link = slide_link.get()\n            yield{\n                \"link\": link,\n            }\n            # yield Request(link, callback=self.parse_problem)\n        # for slide in slides:\n        #     loader: ItemLoader = ItemLoader(item=SlidesModelItem(), selector=slide)\n        #     loader.add_css(\"title\", \".item a::text\")\n        #     loader.add_css(\"category\", \".category::text\")\n        #     slide_item = loader.load_item()\n        #     link = slide.css(\".item a::attr(href)\").get()\n        #     self.logger.info(\"Parsing the slide\")\n        #     yield Request(link, callback=self.parse_slide, meta={\"slide_item\": slide_item})\n        \n",
  "def generate_users(count: int = 10) -> list[UserCreate]:\n    \"\"\"Generate ten random users.\"\"\"\n    first_names = (fake.name() for _ in range(count))\n    last_names = (fake.name() for _ in range(count))\n    emails = (fake.email() for i in range(count))\n    profile_pictures = [f'profile-{i}.jpg' for i in range(21)]\n    return [\n        User(\n            id='User_' + str(uuid4()),\n            first_name=first_name,\n            last_name=last_name,\n            email_address=email,\n            password=User.hash_password('password'),\n            profile_picture_url=image\n        ) \n        for first_name, last_name, email, image in zip(first_names, last_names, emails, profile_pictures)\n    ]",
  "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n",
  "        Shape.hvertex_fill_color = QtGui.QColor(\n            *self._config[\"shape\"][\"hvertex_fill_color\"]\n        )\n\n        # Set point size from config file\n        Shape.point_size = self._config[\"shape\"][\"point_size\"]\n\n        super(MainWindow, self).__init__()\n        self.setWindowTitle(__appname__)\n\n        # Whether we need to save or not.\n        self.dirty = False\n\n        self._noSelectionSlot = False\n\n        self._copied_shapes = None\n\n        # Main widgets and related state.\n        self.labelDialog = LabelDialog(\n            parent=self,\n            labels=self._config[\"labels\"],\n            sort_labels=self._config[\"sort_labels\"],\n            show_text_field=self._config[\"show_label_text_field\"],\n            completion=self._config[\"label_completion\"],\n            fit_to_content=self._config[\"fit_to_content\"],\n            flags=self._config[\"label_flags\"],\n        )\n\n        self.labelList = LabelListWidget()\n        self.lastOpenDir = None\n\n        self.flag_dock = self.flag_widget = None\n        self.flag_dock = QtWidgets.QDockWidget(self.tr(\"Flags\"), self)\n        self.flag_dock.setObjectName(\"Flags\")\n        self.flag_widget = QtWidgets.QListWidget()\n        if config[\"flags\"]:\n            self.loadFlags({k: False for k in config[\"flags\"]})\n        self.flag_dock.setWidget(self.flag_widget)\n        self.flag_widget.itemChanged.connect(self.setDirty)\n\n",
  "        image_file = files[0]\n        image_data = image_file.content # byte values of the image\n        image = Image.open(io.BytesIO(image_data))\n        model = load_model()\n        predicted_label, predictions = evaluate_image(image, model)\n        analysis_text: str = f\"\"\"\n            After analyzing the image you uploaded, here is what I found:\n            Maize Leaf Rust probability: {predictions['Maize Leaf Rust']}%\n            Northern Leaf Blight probability: {predictions['Northern Leaf Blight']}%\n            Healthy probability: {predictions['Healthy']}%\n            Gray Leaf Spot probability: {predictions['Gray Leaf Spot']}%\n            Your plant is most likely infected with {predicted_label}.\n            \"\"\"\n        elements = [\n            cl.Image(\n                name=\"image2\", display=\"inline\", content=image_data\n                ), \n            cl.Text(name=\"simple_text\", content=analysis_text, display=\"inline\", size='large')\n        ]\n        await cl.Message(content=f\"Maize image with {predicted_label}!\", elements=elements).send()\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Tell me some facts about the maize disease {predicted_label} especially in relation to kenya.')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'What fungicides or pesticides can be used to deal with the maize disease {predicted_label}?')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Get me aggrovets in {user_location}, Kenya')\n        await msg.update()\n        await cl.Message(content='Feel free to ask me more questions about maize plant diseases and how to deal with them.').send()\n    else:\n        await cl.Message(content='Currently cannot detect pests. Still working on that model.').send()\n    \n\n@cl.on_message\nasync def main(message: cl.Message):\n",
  "@post.route(\"/load_more_comments\", methods=[\"GET\"])\ndef load_more_comments():\n    \"\"\"Get a single post.\"\"\"\n    offset: str = request.args.get('offset', 0)\n    limit: str = request.args.get('limit', 10)\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        comments: list[Comment] = list_post_comments(session=get_db, post_data=post_data, offset=offset, limit=limit)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    post_comments = []\n    for comment in comments:\n        comment_author: PostAuthor = PostAuthor(\n            id=comment.author.id,\n            profile_picture=url_for('static', filename=f'img/{comment.author.profile_picture_url}'),\n            name=comment.author.first_name\n        )\n        comment_schema: CommentSchema = CommentSchema(\n            author=comment_author,\n            text=comment.comment_text\n        )\n        post_comments.append(comment_schema.model_dump())\n    return post_comments",
  "# Define here the models for your scraped items\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass LeetcodeItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass\n",
  "from pydantic_settings import BaseSettings\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass PostgresSettings(BaseSettings):\n    postgres_host: str\n    postgres_port: int\n    postgres_user: str\n    postgres_password: str\n    postgres_db: str\n    \n    @property\n    def sqlalchemy_db_url(self) -> str:\n        return f\"postgresql://{self.postgres_user}:{self.postgres_password}@{self.postgres_host}:{self.postgres_port}/{self.postgres_db}\"\n\n\nclass RedisSettings(BaseSettings):\n    redis_host: str\n    redis_port: int\n\n    \nclass CeleryConfig(BaseSettings):\n    celery_broker_url: str\n    celery_result_backend: str\n\n\nclass Config(BaseSettings):\n    expiration_time: int\n",
  "def add_user(user: User) -> User:\n    with get_db() as session:\n        session.add(user)\n        session.commit()\n        session.refresh(user)\n    return user\n\ndef add_post(post: Post) -> Post:\n    with get_db() as session:\n        session.add(post)\n        session.commit()\n        session.refresh(post)\n    return post\n\ndef add_likes(likes: list[Like]) -> None:\n    with get_db() as session:\n        for like in likes:\n            session.add(like)\n        session.commit()\n        \ndef add_bookmarks(bookmarks: list[Bookmark]) -> None:\n    with get_db() as session:\n        for bookmark in bookmarks:\n            session.add(bookmark)\n        session.commit()\n    \ndef add_comments(comments: list[Comment]) -> None:\n    with get_db() as session:\n        for comment in comments:\n            session.add(comment)\n        session.commit()",
  "# MIT License\n# Copyright (c) Kentaro Wada\n\nimport math\nimport uuid\n\nimport numpy as np\nimport PIL.Image\nimport PIL.ImageDraw\n\nfrom labelme.logger import logger\n\n\ndef polygons_to_mask(img_shape, polygons, shape_type=None):\n    logger.warning(\n        \"The 'polygons_to_mask' function is deprecated, \" \"use 'shape_to_mask' instead.\"\n    )\n    return shape_to_mask(img_shape, points=polygons, shape_type=shape_type)\n\n\ndef shape_to_mask(img_shape, points, shape_type=None, line_width=10, point_size=5):\n    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n    mask = PIL.Image.fromarray(mask)\n    draw = PIL.ImageDraw.Draw(mask)\n    xy = [tuple(point) for point in points]\n    if shape_type == \"circle\":\n        assert len(xy) == 2, \"Shape of shape_type=circle must have 2 points\"\n        (cx, cy), (px, py) = xy\n        d = math.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n        draw.ellipse([cx - d, cy - d, cx + d, cy + d], outline=1, fill=1)\n    elif shape_type == \"rectangle\":\n        assert len(xy) == 2, \"Shape of shape_type=rectangle must have 2 points\"\n        draw.rectangle(xy, outline=1, fill=1)\n    elif shape_type == \"line\":\n        assert len(xy) == 2, \"Shape of shape_type=line must have 2 points\"\n        draw.line(xy=xy, fill=1, width=line_width)\n    elif shape_type == \"linestrip\":\n        draw.line(xy=xy, fill=1, width=line_width)\n    elif shape_type == \"point\":\n        assert len(xy) == 1, \"Shape of shape_type=point must have 1 points\"\n",
  "def generate_email(user_email_address: str, email_type: str) -> str:\n    email_types: dict[str, Callable] = {\n        'password_reset': send_password_reset_email,\n        'account_activation': send_account_activation_email\n    }\n    return email_types[email_type]\n\ndef send_email(user_email_address: str, email_sender: str) -> None:\n    email_senders: dict[str, Callable] = {\n        'local': send_email_local,\n        'aws_ses': send_email_aws_ses\n    }\n    return email_sender[email_sender]",
  "from pydantic import BaseModel, Field\nfrom schemas import DatasetMetadata\nfrom datetime import datetime\nfrom json import dump\n\n\nclass ExperimentConfig(BaseModel):\n    data_dir: str\n    models_directory: str\n    features_dir: str\n    dataset_metadata: DatasetMetadata\n    label_columns: list[str] = Field(default_factory=list)\n    feature_cols: list[str] = Field(default_factory=list)\n    columns_to_drop: list[str] = Field(default_factory=list)\n    numerical_features: list[str] = Field(default_factory=list)\n    categorical_features: list[str] = Field(default_factory=list)\n    \n    def save_experiment_config(self, path: str,\n            title: str = '', \n            description: str = '', \n            date: datetime=datetime.now()\n        ) -> None:\n        with open(path, 'w', encoding='utf-8') as f:\n            dump(self.model_dump(), f, indent=4)\n        \n        \n",
  "        # (from other spider middleware) raises an exception.\n\n        # Should return either None or an iterable of Request or item objects.\n        pass\n\n    def process_start_requests(self, start_requests, spider):\n        # Called with the start requests of the spider, and works\n        # similarly to the process_spider_output() method, except\n        # that it doesn’t have a response associated.\n\n        # Must return only requests (not items).\n        for r in start_requests:\n            yield r\n\n    def spider_opened(self, spider):\n        spider.logger.info(\"Spider opened: %s\" % spider.name)\n\n\nclass SlidesmodelDownloaderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the downloader middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_request(self, request, spider):\n        # Called for each request that goes through the downloader\n        # middleware.\n\n        # Must either:\n        # - return None: continue processing this request\n        # - or return a Response object\n        # - or return a Request object\n        # - or raise IgnoreRequest: process_exception() methods of\n        #   installed downloader middleware will be called\n",
  "#!/usr/bin/env python\n\nimport argparse\nimport collections\nimport datetime\nimport glob\nimport json\nimport os\nimport os.path as osp\nimport sys\nimport uuid\n\nimport imgviz\nimport numpy as np\n\nimport labelme\n\ntry:\n    import pycocotools.mask\nexcept ImportError:\n    print(\"Please install pycocotools:\\n\\n    pip install pycocotools\\n\")\n    sys.exit(1)\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"input_dir\", help=\"input annotated directory\")\n    parser.add_argument(\"output_dir\", help=\"output dataset directory\")\n    parser.add_argument(\"--labels\", help=\"labels file\", required=True)\n    parser.add_argument(\"--noviz\", help=\"no visualization\", action=\"store_true\")\n    args = parser.parse_args()\n\n    if osp.exists(args.output_dir):\n        print(\"Output directory already exists:\", args.output_dir)\n        sys.exit(1)\n    os.makedirs(args.output_dir)\n    os.makedirs(osp.join(args.output_dir, \"JPEGImages\"))\n    if not args.noviz:\n",
  "from .youtube import YouTube\nfrom .youtube.schemas import YouTubeListResponse, YouTubeResponse\nfrom .youtube.models import Video, Search, Playlist\nfrom os import path\nfrom langchain_core.language_models.base import BaseLanguageModel\nfrom langchain_openai import OpenAI\nfrom langchain_community.llms import Ollama\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel, Field\n# from pydantic import BaseModel, Field\nfrom langchain.output_parsers import PydanticOutputParser\n\nfrom .oryks_google_oauth import (\n    GoogleSlidesScope, GoogleOAuth, GoogleDirectories, GoogleDriveScopes\n)\nfrom typing import Optional, Any\nimport json\n\n\napi_key: str = \"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\"\nopen_ai: BaseLanguageModel = OpenAI(temperature=0, api_key=api_key)\n\ngemma_2b: BaseLanguageModel = Ollama(model=\"gemma:2b\")\nllama_2b: BaseLanguageModel = Ollama(model=\"llama2\")\n\ndef create_gslide_client() -> Any:\n    secrets_file: str = \"/home/lyle/oryks/backend/api/libraries/slide.json\"\n    scopes: list[str] = [\n        GoogleSlidesScope.slides.value,\n        GoogleSlidesScope.drive.value\n    ]\n    api_service_name: str = \"slides\"\n    api_version: str = \"v1\"\n    credentials_dir: str = GoogleDirectories.slides.value\n    credentials_file_name: Optional[str] = 'credentials.json'\n\n    auth: GoogleOAuth = GoogleOAuth(\n        secrets_file=secrets_file,\n        scopes=scopes,\n        api_service_name=api_service_name,\n",
  "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n    cleaned_comments: list[str] = list(map(clean_text, all_comments))\n    # comments: list[str] = choices(population=cleaned_comments, k=3)\n    comments = cleaned_comments\n    docs: list[Document] = [\n        Document(page_content=comment)\n        for comment in comments\n        if is_acceptable_len(comment)\n    ]\n    comments: list[dict[str, str | int]] = [\n        {\"doc_id\": i + 1, \"comment\": docs[i].page_content} for i in range(len(docs))\n    ]\n\ndata_dir = \"./agent_nelly/data_analysis/data\"\nfeatures_dir = \"features\"\nsave_features_dir = path.join(data_dir, features_dir, \"features.json\")\n\nwith open(save_features_dir, 'r') as f:\n    topics: list[str] = json.load(f)\n\n\nclass CustomerCommentData(BaseModel):\n    doc_id: int = Field(description=\"The doc_id from the input\")\n    topics: list[str] = Field(\n        description=\"List of the relevant topics for the customer review. Include only topics from the list provided.\",\n        default_factory=list,\n    )\n    sentiment: str = Field(\n        description=\"Sentiment of the topic\", enum=[\"positive\", \"neutral\", \"negative\"]\n    )\n    \n\nclass CommentsParser(BaseModel):\n    comment: list[CustomerCommentData] = Field(description=\"A list of the customer comment data\", default_factory=list)\n\n\noutput_parser = PydanticOutputParser(pydantic_object=CommentsParser)\nformat_instructions = output_parser.get_format_instructions()\n\n",
  "            mask = pycocotools.mask.encode(mask)\n            area = float(pycocotools.mask.area(mask))\n            bbox = pycocotools.mask.toBbox(mask).flatten().tolist()\n\n            data[\"annotations\"].append(\n                dict(\n                    id=len(data[\"annotations\"]),\n                    image_id=image_id,\n                    category_id=cls_id,\n                    segmentation=segmentations[instance],\n                    area=area,\n                    bbox=bbox,\n                    iscrowd=0,\n                )\n            )\n\n        if not args.noviz:\n            viz = img\n            if masks:\n                labels, captions, masks = zip(\n                    *[\n                        (class_name_to_id[cnm], cnm, msk)\n                        for (cnm, gid), msk in masks.items()\n                        if cnm in class_name_to_id\n                    ]\n                )\n                viz = imgviz.instances2rgb(\n                    image=img,\n                    labels=labels,\n                    masks=masks,\n                    captions=captions,\n                    font_size=15,\n                    line_width=2,\n                )\n            out_viz_file = osp.join(args.output_dir, \"Visualization\", base + \".jpg\")\n            imgviz.io.imsave(out_viz_file, viz)\n\n    with open(out_ann_file, \"w\") as f:\n        json.dump(data, f)\n\n",
  "from langchain.chains import RetrievalQA\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain.vectorstores.chroma import Chroma\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.docstore.document import Document\nfrom langchain.prompts import PromptTemplate\nfrom os import path\nimport json\nfrom random import choices\n\ndata_dir = \"data\"\nvideo_data_dir = \"data\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"iphone_15_marques_review\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\npersist_directory = path.join(data_dir, \"vectore_store\")\n\napi_key: str = \"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\"\nfile_path: str = \"comments.json\"\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n    comments: list[str] = choices(population=all_comments, k=50)\n    comments: list[Document] = [Document(page_content=comment) for comment in all_comments]\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30)\nsplit_docs = text_splitter.split_documents(comments)\n\nembeddings = OpenAIEmbeddings(api_key=api_key)\n# vectordb = FAISS.from_texts(splits, embeddings)\n# vectordb = FAISS.from_documents(documents=comments, embedding=embeddings)\n# vectordb = Chroma.from_documents(\n#     documents=split_docs,\n#     embedding=embeddings,\n#     persist_directory=persist_directory\n# )\n\ntemplate_str: str = \"\"\"\n",
  "        if self.selectedVertex():  # A vertex is marked for selection.\n            index, shape = self.hVertex, self.hShape\n            shape.highlightVertex(index, shape.MOVE_VERTEX)\n        else:\n            for shape in reversed(self.shapes):\n                if self.isVisible(shape) and shape.containsPoint(point):\n                    self.setHiding()\n                    if shape not in self.selectedShapes:\n                        if multiple_selection_mode:\n                            self.selectionChanged.emit(self.selectedShapes + [shape])\n                        else:\n                            self.selectionChanged.emit([shape])\n                        self.hShapeIsSelected = False\n                    else:\n                        self.hShapeIsSelected = True\n                    self.calculateOffsets(point)\n                    return\n        self.deSelectShape()\n\n    def calculateOffsets(self, point):\n        left = self.pixmap.width() - 1\n        right = 0\n        top = self.pixmap.height() - 1\n        bottom = 0\n        for s in self.selectedShapes:\n            rect = s.boundingRect()\n            if rect.left() < left:\n                left = rect.left()\n            if rect.right() > right:\n                right = rect.right()\n            if rect.top() < top:\n                top = rect.top()\n            if rect.bottom() > bottom:\n                bottom = rect.bottom()\n\n        x1 = left - point.x()\n        y1 = top - point.y()\n        x2 = right - point.x()\n        y2 = bottom - point.y()\n        self.offsets = QtCore.QPointF(x1, y1), QtCore.QPointF(x2, y2)\n",
  "\nfrom random import randint    \ndef like(comment: dict) -> dict:\n    comment['likes'] = randint(0,2)\n    return comment\n\nanalyzed_comments: list[dict] = list(map(like, analyzed_comments))\n            \n            \nfrom collections import deque\nqueue = deque(maxlen=10, iterable=analyzed_comments[:batch])\nwith Live(create_analyzed_comments_table(table_data=queue)) as live:\n    for data in analyzed_comments[batch:]:\n        queue.append(data)\n        live.update(create_analyzed_comments_table(table_data=queue))\n        sleep(0.5)",
  "from langchain.output_parsers import PydanticOutputParser\nfrom langchain.pydantic_v1 import Field, BaseModel\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import OpenAI\nimport re\nimport json\nfrom langchain.docstore.document import Document\nfrom random import choices\nfrom langchain.base_language import BaseLanguageModel\n\nfile_path: str = \"comments.json\"\napi_key: str = \"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\"\n\n\ndef lower(text: str) -> str:\n    return text.lower().strip()\n\n\ndef remove_urls(text: str) -> str:\n    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n    text = re.sub(url_pattern, \"\", text)\n    return text\n\n\ndef remove_punctuations(text: str) -> str:\n    punctuation_pattern = r\"[^\\w\\s]\"\n    cleaned = re.sub(punctuation_pattern, \"\", text)\n    return cleaned\n\n\ndef clean_text(text: str) -> str:\n    text = lower(text)\n    text = remove_urls(text)\n    text = remove_punctuations(text)\n    return text\n\n\ndef is_acceptable_len(text: str, l=15) -> bool:\n    return len(text.split()) >= l\n\n",
  "import logging\nfrom logging import Handler\nfrom typing import Optional\n\n\ndef create_logger(handlers: Optional[Handler] = []) -> None:\n    logging_format: str = \"%(asctime)s - %(levelname)s - %(message)s\"\n    date_format: str = \"[%X]\"\n    logging.basicConfig(\n        format=logging_format,\n        datefmt=date_format,\n        handlers=handlers,\n        level=logging.INFO,\n    )\n",
  "        w = self.centralWidget().width() - 2.0\n        return w / self.canvas.pixmap.width()\n\n    def enableSaveImageWithData(self, enabled):\n        self._config[\"store_data\"] = enabled\n        self.actions.saveWithImageData.setChecked(enabled)\n\n    def closeEvent(self, event):\n        if not self.mayContinue():\n            event.ignore()\n        self.settings.setValue(\"filename\", self.filename if self.filename else \"\")\n        self.settings.setValue(\"window/size\", self.size())\n        self.settings.setValue(\"window/position\", self.pos())\n        self.settings.setValue(\"window/state\", self.saveState())\n        self.settings.setValue(\"recentFiles\", self.recentFiles)\n        # ask the use for where to save the labels\n        # self.settings.setValue('window/geometry', self.saveGeometry())\n\n    def dragEnterEvent(self, event):\n        extensions = [\n            \".%s\" % fmt.data().decode().lower()\n            for fmt in QtGui.QImageReader.supportedImageFormats()\n        ]\n        if event.mimeData().hasUrls():\n            items = [i.toLocalFile() for i in event.mimeData().urls()]\n            if any([i.lower().endswith(tuple(extensions)) for i in items]):\n                event.accept()\n        else:\n            event.ignore()\n\n    def dropEvent(self, event):\n        if not self.mayContinue():\n            event.ignore()\n            return\n        items = [i.toLocalFile() for i in event.mimeData().urls()]\n        self.importDroppedImageFiles(items)\n\n    # User Dialogs #\n\n    def loadRecent(self, filename):\n",
  "from ..schemas.activity import CreateActivity, GetRepeatableActivity\nfrom sqlalchemy.orm import Session\nfrom ..models.view import View\nfrom ..models.user import User\nfrom ..models.post import Post\nfrom ..schemas.user import GetUser\nfrom ..schemas.post import GetPost\nfrom uuid import uuid4\n\n\ndef create_view(session: Session, activity: CreateActivity) -> View:\n    with session() as db:\n        view: View = View(\n            author_id=activity.user_id,\n            post_id=activity.post_id,\n            id='View_' + str(uuid4())\n        )\n        db.add(view)\n        db.commit()\n        db.refresh(view)\n    return view",
  "        self.filename = None\n        for file in imageFiles:\n            if file in self.imageList or not file.lower().endswith(tuple(extensions)):\n                continue\n            label_file = osp.splitext(file)[0] + \".json\"\n            if self.output_dir:\n                label_file_without_path = osp.basename(label_file)\n                label_file = osp.join(self.output_dir, label_file_without_path)\n            item = QtWidgets.QListWidgetItem(file)\n            item.setFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable)\n            if QtCore.QFile.exists(label_file) and LabelFile.is_label_file(label_file):\n                item.setCheckState(Qt.Checked)\n            else:\n                item.setCheckState(Qt.Unchecked)\n            self.fileListWidget.addItem(item)\n\n        if len(self.imageList) > 1:\n            self.actions.openNextImg.setEnabled(True)\n            self.actions.openPrevImg.setEnabled(True)\n\n        self.openNextImg()\n\n    def importDirImages(self, dirpath, pattern=None, load=True):\n        self.actions.openNextImg.setEnabled(True)\n        self.actions.openPrevImg.setEnabled(True)\n\n        if not self.mayContinue() or not dirpath:\n            return\n\n        self.lastOpenDir = dirpath\n        self.filename = None\n        self.fileListWidget.clear()\n\n        filenames = self.scanAllImages(dirpath)\n        if pattern:\n            try:\n                filenames = [f for f in filenames if re.search(pattern, f)]\n            except re.error:\n                pass\n        for filename in filenames:\n",
  "from .extensions import drive_client, gslide_client, youtube_client",
  "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport os.path as osp\n\nimport numpy as np\nimport PIL.Image\n\nhere = osp.dirname(osp.abspath(__file__))\n\n\ndef main():\n    label_png = osp.join(here, \"apc2016_obj3_json/label.png\")\n    print(\"Loading:\", label_png)\n    print()\n\n    lbl = np.asarray(PIL.Image.open(label_png))\n    labels = np.unique(lbl)\n\n    label_names_txt = osp.join(here, \"apc2016_obj3_json/label_names.txt\")\n    label_names = [name.strip() for name in open(label_names_txt)]\n    print(\"# of labels:\", len(labels))\n    print(\"# of label_names:\", len(label_names))\n    if len(labels) != len(label_names):\n        print(\"Number of unique labels and label_names must be same.\")\n        quit(1)\n    print()\n\n    print(\"label: label_name\")\n    for label, label_name in zip(labels, label_names):\n        print(\"%d: %s\" % (label, label_name))\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "def delete_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = db.query(Like).filter(Like.author_id==activity.user_id, Like.post_id==activity.post_id).first()\n        db.delete(like)\n        db.commit()\n    return like\n\ndef has_liked(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = db.query(Like).filter(Like.author_id==activity.user_id, Like.post_id==activity.post_id).first()\n        if like:\n            return True\n    return False",
  "            record.message2 = colored(record.msg)\n\n            asctime2 = datetime.datetime.fromtimestamp(record.created)\n            record.asctime2 = termcolor.colored(asctime2, color=\"green\")\n\n            record.module2 = termcolor.colored(record.module, color=\"cyan\")\n            record.funcName2 = termcolor.colored(record.funcName, color=\"cyan\")\n            record.lineno2 = termcolor.colored(record.lineno, color=\"cyan\")\n        return logging.Formatter.format(self, record)\n\n\nlogger = logging.getLogger(__appname__)\nlogger.setLevel(logging.INFO)\n\nstream_handler = logging.StreamHandler(sys.stderr)\nhandler_format = ColoredFormatter(\n    \"%(asctime)s [%(levelname2)s] %(module2)s:%(funcName2)s:%(lineno2)s\"\n    \"- %(message2)s\"\n)\nstream_handler.setFormatter(handler_format)\n\nlogger.addHandler(stream_handler)\n",
  "from ..libraries.oryks_google_oauth import (\n    GoogleSlidesScope, GoogleOAuth, GoogleDirectories, GoogleDriveScopes\n)\nfrom ..libraries.youtube import YouTube\nfrom typing import Optional, Any\n\n\ndef create_gslide_client() -> Any:\n    secrets_file: str = \"/home/lyle/oryks/backend/api/libraries/slide.json\"\n    scopes: list[str] = [\n        GoogleSlidesScope.slides.value,\n        GoogleSlidesScope.drive.value\n    ]\n    api_service_name: str = \"slides\"\n    api_version: str = \"v1\"\n    credentials_dir: str = GoogleDirectories.slides.value\n    credentials_file_name: Optional[str] = 'credentials.json'\n\n    auth: GoogleOAuth = GoogleOAuth(\n        secrets_file=secrets_file,\n        scopes=scopes,\n        api_service_name=api_service_name,\n        api_version=api_version,\n        credentials_dir=credentials_dir,\n        credentials_file_name=credentials_file_name\n    )\n\n    gslides_client = auth.authenticate_google_server()\n    return gslides_client\n\n\ndef create_drive_client() -> Any:\n    secrets_file: str = \"/home/lyle/oryks/backend/api/libraries/drive.json\"\n    scopes: list[str] = [\n        GoogleDriveScopes.metadata.value,\n        GoogleDriveScopes.drive.value,\n        GoogleDriveScopes.files.value\n    ]\n    api_service_name: str = \"drive\"\n    api_version: str = \"v3\"\n",
  "# MIT License\n# Copyright (c) Kentaro Wada\n\nimport os.path as osp\n\nimport numpy as np\nimport PIL.Image\n\n\ndef lblsave(filename, lbl):\n    import imgviz\n\n    if osp.splitext(filename)[1] != \".png\":\n        filename += \".png\"\n    # Assume label ranses [-1, 254] for int32,\n    # and [0, 255] for uint8 as VOC.\n    if lbl.min() >= -1 and lbl.max() < 255:\n        lbl_pil = PIL.Image.fromarray(lbl.astype(np.uint8), mode=\"P\")\n        colormap = imgviz.label_colormap()\n        lbl_pil.putpalette(colormap.flatten())\n        lbl_pil.save(filename)\n    else:\n        raise ValueError(\n            \"[%s] Cannot save the pixel-wise class label as PNG. \"\n            \"Please consider using the .npy format.\" % filename\n        )\n",
  "from google_drive import GoogleDrive\n\n\nclient_secrets_file = 'drive.json'\ndrive = GoogleDrive(client_secret_file=client_secrets_file)\ndrive.authenticate()\n",
  "            self.line.paint(p)\n        if self.selectedShapesCopy:\n            for s in self.selectedShapesCopy:\n                s.paint(p)\n\n        if (\n            self.fillDrawing()\n            and self.createMode == \"polygon\"\n            and self.current is not None\n            and len(self.current.points) >= 2\n        ):\n            drawing_shape = self.current.copy()\n            if drawing_shape.fill_color.getRgb()[3] == 0:\n                logger.warning(\n                    \"fill_drawing=true, but fill_color is transparent,\"\n                    \" so forcing to be opaque.\"\n                )\n                drawing_shape.fill_color.setAlpha(64)\n            drawing_shape.addPoint(self.line[1])\n            drawing_shape.fill = True\n            drawing_shape.paint(p)\n        elif self.createMode == \"ai_polygon\" and self.current is not None:\n            drawing_shape = self.current.copy()\n            drawing_shape.addPoint(\n                point=self.line.points[1],\n                label=self.line.point_labels[1],\n            )\n            points = self._ai_model.predict_polygon_from_points(\n                points=[[point.x(), point.y()] for point in drawing_shape.points],\n                point_labels=drawing_shape.point_labels,\n            )\n            if len(points) > 2:\n                drawing_shape.setShapeRefined(\n                    shape_type=\"polygon\",\n                    points=[QtCore.QPointF(point[0], point[1]) for point in points],\n                    point_labels=[1] * len(points),\n                )\n                drawing_shape.fill = self.fillDrawing()\n                drawing_shape.selected = True\n                drawing_shape.paint(p)\n",
  "from ..blueprints.database.schemas.user import UserCreate\nfrom ..blueprints.database.schemas.post import CreatePost\nfrom ..blueprints.database.models import User, Post, Like, Comment, Bookmark\nfrom ..blueprints.database.database import get_db\nfrom ..blueprints.database.crud.user import create_user\nfrom ..blueprints.database.crud.post import create_post\nfrom faker import Faker\nfrom datetime import datetime, timedelta\nimport random\nfrom uuid import uuid4\n\n\nfake = Faker()",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy.linkextractors import LinkExtractor \n\n\nclass SlidesLinkExtractor(Spider):\n    name: str = \"links-extractor\"\n    \n    start_urls: list[str] = [\n        \"https://slidemodel.com/templates/\"\n    ]\n    \n    def __init__(self, name=None, **kwargs): \n        super().__init__(name, **kwargs) \n  \n        self.link_extractor = LinkExtractor(unique=True) \n  \n    def parse(self, response: Response, **kwargs: Any) -> Any: \n        links = self.link_extractor.extract_links(response) \n  \n        for link in links: \n            if \"tag\" in link.url:\n                yield {\n                        \"url\": link.url, \n                        \"text\": link.text\n                    }",
  "# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n\n\n# useful for handling different item types with a single interface\nfrom itemadapter import ItemAdapter\n\n\nclass SlidesgoPipeline:\n    def process_item(self, item, spider):\n        return item\n",
  "from langchain.prompts import PromptTemplate\n\nfrom .config import Config\n\n\ndef get_function_prompt_template(function_code: str, config: Config) -> str:\n    function_prompt_template: str = \"\"\"\n    Generate python docstring for the given python function using the provided documentation style:\n    Function code: {function_code}\n    Documentation style: {documentation_style}\n    \"\"\"\n    prompt = PromptTemplate.from_template(template=function_prompt_template)\n    prompt_formatted_str: str = prompt.format(\n        function_code=function_code, documentation_style=config.documentation_style\n    )\n    return prompt_formatted_str\n\n\ndef get_class_prompt_template(class_code: str, config: Config) -> str:\n    function_prompt_template: str = \"\"\"\n    Generate python docstring for the given python class using the provided documentation style:\n    Class code: {class_code}\n    Documentation style: {documentation_style}\n    \"\"\"\n    prompt = PromptTemplate.from_template(template=function_prompt_template)\n    prompt_formatted_str: str = prompt.format(\n        class_code=class_code, documentation_style=config.documentation_style\n    )\n    return prompt_formatted_str\n",
  "def create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like",
  "        # divide by scale to allow more precision when zoomed in\n        return labelme.utils.distance(p1 - p2) < (self.epsilon / self.scale)\n\n    def intersectionPoint(self, p1, p2):\n        # Cycle through each image edge in clockwise fashion,\n        # and find the one intersecting the current line segment.\n        # http://paulbourke.net/geometry/lineline2d/\n        size = self.pixmap.size()\n        points = [\n            (0, 0),\n            (size.width() - 1, 0),\n            (size.width() - 1, size.height() - 1),\n            (0, size.height() - 1),\n        ]\n        # x1, y1 should be in the pixmap, x2, y2 should be out of the pixmap\n        x1 = min(max(p1.x(), 0), size.width() - 1)\n        y1 = min(max(p1.y(), 0), size.height() - 1)\n        x2, y2 = p2.x(), p2.y()\n        d, i, (x, y) = min(self.intersectingEdges((x1, y1), (x2, y2), points))\n        x3, y3 = points[i]\n        x4, y4 = points[(i + 1) % 4]\n        if (x, y) == (x1, y1):\n            # Handle cases where previous point is on one of the edges.\n            if x3 == x4:\n                return QtCore.QPointF(x3, min(max(0, y2), max(y3, y4)))\n            else:  # y3 == y4\n                return QtCore.QPointF(min(max(0, x2), max(x3, x4)), y3)\n        return QtCore.QPointF(x, y)\n\n    def intersectingEdges(self, point1, point2, points):\n        \"\"\"Find intersecting edges.\n\n        For each edge formed by `points', yield the intersection\n        with the line segment `(x1,y1) - (x2,y2)`, if it exists.\n        Also return the distance of `(x2,y2)' to the middle of the\n        edge along with its index, so that the one closest can be chosen.\n        \"\"\"\n        (x1, y1) = point1\n        (x2, y2) = point2\n        for i in range(4):\n",
  "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport argparse\nimport distutils.spawn\nimport json\nimport os\nimport os.path as osp\nimport platform\nimport shlex\nimport subprocess\nimport sys\n\n\ndef get_ip():\n    dist = platform.platform().split(\"-\")[0]\n    if dist == \"Linux\":\n        return \"\"\n    elif dist == \"Darwin\":\n        cmd = \"ifconfig en0\"\n        output = subprocess.check_output(shlex.split(cmd))\n        if str != bytes:  # Python3\n            output = output.decode(\"utf-8\")\n        for row in output.splitlines():\n            cols = row.strip().split(\" \")\n            if cols[0] == \"inet\":\n                ip = cols[1]\n                return ip\n        else:\n            raise RuntimeError(\"No ip is found.\")\n    else:\n        raise RuntimeError(\"Unsupported platform.\")\n\n\ndef labelme_on_docker(in_file, out_file):\n    ip = get_ip()\n    cmd = \"xhost + %s\" % ip\n    subprocess.check_output(shlex.split(cmd))\n\n",
  "def create_prod_logger():\n    \"\"\"Create the application logger.\"\"\"\n    config = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"standard\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n            },\n            \"json\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n                \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n            },\n        },\n        \"handlers\": {\n            \"standard\": {\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"json\",\n            },\n        },\n        \"loggers\": {\"\": {\"handlers\": [\"standard\"], \"level\": logging.INFO}},\n    }\n\n    logging.config.dictConfig(config)\n\n    logger = logging.getLogger(__name__)\n\n    return logger",
  "\n        self.points.pop(i)\n        self.point_labels.pop(i)\n\n    def isClosed(self):\n        return self._closed\n\n    def setOpen(self):\n        self._closed = False\n\n    def getRectFromLine(self, pt1, pt2):\n        x1, y1 = pt1.x(), pt1.y()\n        x2, y2 = pt2.x(), pt2.y()\n        return QtCore.QRectF(x1, y1, x2 - x1, y2 - y1)\n\n    def paint(self, painter):\n        if self.mask is None and not self.points:\n            return\n\n        color = self.select_line_color if self.selected else self.line_color\n        pen = QtGui.QPen(color)\n        # Try using integer sizes for smoother drawing(?)\n        pen.setWidth(max(1, int(round(2.0 / self.scale))))\n        painter.setPen(pen)\n\n        if self.mask is not None:\n            image_to_draw = np.zeros(self.mask.shape + (4,), dtype=np.uint8)\n            fill_color = (\n                self.select_fill_color.getRgb()\n                if self.selected\n                else self.fill_color.getRgb()\n            )\n            image_to_draw[self.mask] = fill_color\n            qimage = QtGui.QImage.fromData(labelme.utils.img_arr_to_data(image_to_draw))\n            painter.drawImage(\n                int(round(self.points[0].x())),\n                int(round(self.points[0].y())),\n                qimage,\n            )\n\n",
  "def create_user(user_data: UserCreate, session: Session):\n    hashed_password = User.hash_password(user_data.password)\n    user = User(\n        id='User_' + str(uuid4()),\n        first_name=user_data.first_name,\n        last_name=user_data.last_name,\n        email_address=user_data.email_address,\n        password=hashed_password\n    )\n    with session() as db:\n        db.add(user)\n        db.commit()\n        db.refresh(user)\n    return user\n\ndef get_user_by_email(session: Session, email: str):\n    with session() as db:\n        user = db.query(User).filter(User.email_address == email).first()\n    return user",
  "from os import path\nimport json\nfrom random import choices, choice\nfrom langchain.docstore.document import Document\nimport re\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import OpenAI\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.output_parsers import PydanticOutputParser\nfrom langchain_core.runnables import RunnableBranch\nfrom langchain_core.output_parsers import StrOutputParser\n\n\napi_key: str = \"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\"\nllm = OpenAI(temperature=0, api_key=api_key)\nfile_path: str = \"comments.json\"\n\n\ndef lower(text: str) -> str:\n    return text.lower().strip()\n\n\ndef remove_urls(text: str) -> str:\n    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n    text = re.sub(url_pattern, \"\", text)\n    return text\n\n\ndef remove_punctuations(text: str) -> str:\n    punctuation_pattern = r\"[^\\w\\s]\"\n    cleaned = re.sub(punctuation_pattern, \"\", text)\n    return cleaned\n\n\ndef clean_text(text: str) -> str:\n    text = lower(text)\n    text = remove_urls(text)\n    text = remove_punctuations(text)\n    return text\n\n",
  "    def _saveFile(self, filename):\n        if filename and self.saveLabels(filename):\n            self.addRecentFile(filename)\n            self.setClean()\n\n    def closeFile(self, _value=False):\n        if not self.mayContinue():\n            return\n        self.resetState()\n        self.setClean()\n        self.toggleActions(False)\n        self.canvas.setEnabled(False)\n        self.actions.saveAs.setEnabled(False)\n\n    def getLabelFile(self):\n        if self.filename.lower().endswith(\".json\"):\n            label_file = self.filename\n        else:\n            label_file = osp.splitext(self.filename)[0] + \".json\"\n\n        return label_file\n\n    def deleteFile(self):\n        mb = QtWidgets.QMessageBox\n        msg = self.tr(\n            \"You are about to permanently delete this label file, \" \"proceed anyway?\"\n        )\n        answer = mb.warning(self, self.tr(\"Attention\"), msg, mb.Yes | mb.No)\n        if answer != mb.Yes:\n            return\n\n        label_file = self.getLabelFile()\n        if osp.exists(label_file):\n            os.remove(label_file)\n            logger.info(\"Label file is removed: {}\".format(label_file))\n\n            item = self.fileListWidget.currentItem()\n            item.setCheckState(Qt.Unchecked)\n\n            self.resetState()\n",
  "    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n]\nmodels: list[Model] = [\n    UntrainedModel(\n        save_path=path.join(app_config.models_dir, 'trained', model_name),\n        model=model,\n        classifier_name=model_name,\n        train_date=datetime.now(),\n        owner='Lyle Okoth'\n    ) \n    for model_name, model in zip(names, classifiers)\n]",
  "\ndef create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like\n",
  "class DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    \n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = 'secret-key'\n    SQLALCHEMY_DATABASE_URI = 'sqlite:///'\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}",
  "# Get the data\nfrom utils import extract_dataset, load_data\nfrom experiment import Experiment\nfrom pandas import DataFrame\nfrom schemas import DatasetMetadata\nfrom uuid import uuid4\nfrom os import path\nfrom config.config import app_config\nfrom experiment_config import ExperimentConfig\nfrom experiment_models import models\nfrom experiment_pipelines import create_experiment_pipeline\nimport logging\n\n\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n# Unzip and store the downloaded dataset with its metadata\narchive_name: str = 'archive.zip'\nfile_name: str = 'Titanic-Dataset.csv'\ndata_path: str = extract_dataset(archive_name, file_name)\ndata_path: str = extract_dataset()\ndata: DataFrame = load_data(data_path)\ndataset_metadata: DatasetMetadata = DatasetMetadata(\n    source='https://www.kaggle.com/datasets/yasserh/titanic-dataset',\n    cols=data.columns.values.tolist(),\n    description='A dataset that shows the survivors of the titanic tragedy.',\n    path=data_path,\n    id=f'Dataset_{str(uuid4())}'\n)\ndataset_metadata_path: str = path.join(app_config.data_dir, 'titanic_metadata.json')\ndataset_metadata.save(dataset_metadata_path)\n\n# Create an experiment for training various models\nlabel_cols: list[str] = ['Survived']\nfeature_cols: list[str] = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', \"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\ncolumns_to_drop: list[str] = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\nnumerical_features: list[str] = [\"Age\", \"Fare\"]\ncategorical_features: list[str] = [\"Pclass\", \"Sex\", \"Embarked\"]\nexperiment_config: ExperimentConfig = ExperimentConfig(\n    data_dir=app_config.data_dir,\n    models_directory=app_config.models_dir,\n",
  "class GetPosts(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10\n    \nclass PostAuthor(BaseModel):\n    id: str\n    profile_picture: str\n    name: str\n    \nclass PostLike(BaseModel):\n    liked: bool\n    liked_by: Optional[list[PostAuthor]] = Field(default_factory=list)\n    key_like: Optional[PostAuthor] = None\n    likes_count: Optional[int] = Field(default=0)\n    \nclass KeyComment(BaseModel):\n    author: PostAuthor\n    text: str\n    comments_count: int\n    \nclass PostSchema(BaseModel):\n    id: str\n    text: str\n    image: str\n    author: PostAuthor\n    date_published: str\n    location: str\n    like: PostLike\n    bookmarked: bool\n    key_comment: Optional[KeyComment] = None",
  "def list_user_likes(session: Session, user_data: GetUser) -> list[Like]:\n    with session() as db:\n        user: User = db.query(User).filter(User.id == user_data.user_id).first()\n        likes: list[Like] = user.likes\n    return likes\n\ndef list_post_likes(session: Session, post_data: GetPost):\n    with session() as db:\n        post: Post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        likes: list[Like] = post.likes\n        for like in likes:\n            like.author\n    return likes\n\ndef get_key_like(session: Session, post_data: GetPost):\n    from random import choice\n    with session() as db:\n        post: Post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        likes: list[Like] = post.likes\n        for like in likes:\n            like.author\n    return choice(likes).author if likes else None",
  "# Define here the models for your scraped items\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass SlidesgoItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass\n",
  "from argparse import Namespace\n\nfrom .config import Config\nfrom .docstring_generator import generate_project_docstrings\nfrom .extensions import function_code_queue, source_code_queue\nfrom .ui import create_application_config, parse_arguments\n\n\ndef main():\n    args: Namespace = parse_arguments()\n    config: Config = create_application_config(args)\n    generate_project_docstrings(\n        config=config,\n        source_code_queue=source_code_queue,\n        function_code_queue=function_code_queue,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "\"\"\"This script contains helper methods for use with the application.\"\"\"\nfrom flask import Flask\n\nfrom .config import Config\n\n\ndef set_configuration(app: Flask, flask_env: str = \"development\") -> None:\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance.\n    \"\"\"\n    app.config.from_object(Config[flask_env])",
  "def delete_user(session: Session, user_data: GetUser):\n    with session() as db:\n        user = db.query(User).filter(User.id == user_data.user_id).first()\n        db.delete(user)\n        db.commit()\n        \n    return user\n\n\ndef user_account_active(session: Session, user_data: GetUser):\n    with session() as db:\n        user: User = db.query(User).filter(User.id == user_data.user_id).first()\n    return user.activated",
  "import argparse\nimport base64\nimport json\nimport os\nimport os.path as osp\n\nimport imgviz\nimport PIL.Image\n\nfrom labelme import utils\nfrom labelme.logger import logger\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"json_file\")\n    parser.add_argument(\"-o\", \"--out\", default=None)\n    args = parser.parse_args()\n\n    json_file = args.json_file\n\n    if args.out is None:\n        out_dir = osp.splitext(osp.basename(json_file))[0]\n        out_dir = osp.join(osp.dirname(json_file), out_dir)\n    else:\n        out_dir = args.out\n    if not osp.exists(out_dir):\n        os.mkdir(out_dir)\n\n    data = json.load(open(json_file))\n    imageData = data.get(\"imageData\")\n\n    if not imageData:\n        imagePath = os.path.join(os.path.dirname(json_file), data[\"imagePath\"])\n        with open(imagePath, \"rb\") as f:\n            imageData = f.read()\n            imageData = base64.b64encode(imageData).decode(\"utf-8\")\n    img = utils.img_b64_to_arr(imageData)\n\n    label_name_to_value = {\"_background_\": 0}\n",
  "                self.editDescription.toPlainText(),\n            )\n        else:\n            return None, None, None, None\n",
  "# utils.py\n\nfrom playwright.sync_api import sync_playwright\nimport uuid\nfrom PIL import Image\nfrom PIL import Image\nimport io\nfrom os import path\nimport json\n\nindex: int = 1\n\ndef take_screenshot_from_url(url, session_data):\n    with sync_playwright() as playwright:\n        webkit = playwright.webkit\n        browser = webkit.launch()\n        browser_context = browser.new_context(device_scale_factor=2)\n        browser_context.add_cookies([session_data])\n        page = browser_context.new_page()\n        page.goto(url)\n        screenshot_bytes = page.locator(\".code\").screenshot()\n        browser.close()\n        return screenshot_bytes\n    \n    \ndef save_data(image_bytes: bytes, code: str) -> None:\n    file_name: str = str(uuid.uuid4())\n    image: Image = Image.open(io.BytesIO(image_bytes))\n    file_path: str = \"data\"\n    image_path: str = path.join(file_path, f\"{file_name}.png\")\n    image.save(image_path)\n    code_path: str = path.join(file_path, \"metadata.jsonl\")\n    metadata: dict = {\n        \"file_name\": f\"{file_name}.png\",\n        \"code\": code\n    }\n    with open(code_path, \"a+\", encoding=\"utf-8\") as f:\n        f.write(json.dumps(metadata) + \"\\n\")",
  "        if labels:\n            self.labelList.addItems(labels)\n        if self._sort_labels:\n            self.labelList.sortItems()\n        else:\n            self.labelList.setDragDropMode(QtWidgets.QAbstractItemView.InternalMove)\n        self.labelList.currentItemChanged.connect(self.labelSelected)\n        self.labelList.itemDoubleClicked.connect(self.labelDoubleClicked)\n        self.labelList.setFixedHeight(150)\n        self.edit.setListWidget(self.labelList)\n        layout.addWidget(self.labelList)\n        # label_flags\n        if flags is None:\n            flags = {}\n        self._flags = flags\n        self.flagsLayout = QtWidgets.QVBoxLayout()\n        self.resetFlags()\n        layout.addItem(self.flagsLayout)\n        self.edit.textChanged.connect(self.updateFlags)\n        # text edit\n        self.editDescription = QtWidgets.QTextEdit()\n        self.editDescription.setPlaceholderText(\"Label description\")\n        self.editDescription.setFixedHeight(50)\n        layout.addWidget(self.editDescription)\n        self.setLayout(layout)\n        # completion\n        completer = QtWidgets.QCompleter()\n        if not QT5 and completion != \"startswith\":\n            logger.warn(\n                \"completion other than 'startswith' is only \"\n                \"supported with Qt5. Using 'startswith'\"\n            )\n            completion = \"startswith\"\n        if completion == \"startswith\":\n            completer.setCompletionMode(QtWidgets.QCompleter.InlineCompletion)\n            # Default settings.\n            # completer.setFilterMode(QtCore.Qt.MatchStartsWith)\n        elif completion == \"contains\":\n            completer.setCompletionMode(QtWidgets.QCompleter.PopupCompletion)\n            completer.setFilterMode(QtCore.Qt.MatchContains)\n",
  "        docstring: str = ast.get_docstring(node=node)\n        if not docstring or self.config.overwrite_class_docstring:\n            class_code: str = ast.get_source_segment(\n                source=self.module_code, node=node, padded=True\n            )\n            class_and_docstring: str = generate_class_docstring(class_code, self.config)\n            class_docstring: str = get_class_docstring(class_and_docstring)\n            new_docstring_node = make_docstring_node(class_docstring)\n            node.body.insert(0, new_docstring_node)\n            methods_docstrings: dict[str, str] = get_class_methods_docstrings(\n                class_and_docstring\n            )\n            for class_node in node.body:\n                if isinstance(class_node, FunctionDef):\n                    function_doc: str = ast.get_docstring(node=class_node)\n                    if (\n                        not function_doc\n                        or self.config.overwrite_class_methods_docstring\n                    ):\n                        function_name: str = class_node.name\n                        new_docstring_node = make_docstring_node(\n                            methods_docstrings[function_name]\n                        )\n                        class_node.body.insert(0, new_docstring_node)\n        return node\n",
  "import json\nimport os.path as osp\n\nimport imgviz\n\nimport labelme.utils\n\n\ndef assert_labelfile_sanity(filename):\n    assert osp.exists(filename)\n\n    data = json.load(open(filename))\n\n    assert \"imagePath\" in data\n    imageData = data.get(\"imageData\", None)\n    if imageData is None:\n        parent_dir = osp.dirname(filename)\n        img_file = osp.join(parent_dir, data[\"imagePath\"])\n        assert osp.exists(img_file)\n        img = imgviz.io.imread(img_file)\n    else:\n        img = labelme.utils.img_b64_to_arr(imageData)\n\n    H, W = img.shape[:2]\n    assert H == data[\"imageHeight\"]\n    assert W == data[\"imageWidth\"]\n\n    assert \"shapes\" in data\n    for shape in data[\"shapes\"]:\n        assert \"label\" in shape\n        assert \"points\" in shape\n        for x, y in shape[\"points\"]:\n            assert 0 <= x <= W\n            assert 0 <= y <= H\n",
  "from flask import Flask\nfrom .home import code\n\n\ndef register_blueprints(app: Flask) -> bool:\n    \"\"\"Register the application blueprints.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether all the blueprints were registered.\n    \"\"\"\n    app.register_blueprint(code)\n    return True",
  "\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\nfrom googleapiclient.discovery import build\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.exceptions import RefreshError\nfrom typing import Any\nfrom os import path, mkdir\nfrom json import dump, load\nfrom models import Scopes\n\n\nclass OAuth(BaseModel):\n    secrets_file: str\n    scopes: list[str] = [\n        Scopes.drafts.value, Scopes.labels.value\n    ]\n    api_service_name: Optional[str] = 'gmail'\n    api_version: Optional[str] = 'v1'\n    credentials_file_name: Optional[str] = 'credentials.json' \n    credentials_dir: Optional[str] = '.gmail_credentials'\n    \n    def credentials_to_dict(self, credentials: Credentials) -> dict:\n        \"\"\"Convert credentials to a dict.\"\"\"\n        return {\n            'token': credentials.token,\n            'refresh_token': credentials.refresh_token,\n            'token_uri': credentials.token_uri,\n            'client_id': credentials.client_id,\n            'client_secret': credentials.client_secret,\n            'scopes': credentials.scopes,\n        }\n        \n    def create_default_credentials_path(self) -> str:\n        \"\"\"Create the default credentials directory.\"\"\"\n        current_user_home_dir = path.expanduser('~')\n        if not path.exists(path.join(current_user_home_dir, self.credentials_dir)):\n            mkdir(path.join(current_user_home_dir, self.credentials_dir))\n        return path.join(current_user_home_dir, self.credentials_dir)\n",
  "            tip=self.tr(\"Toggle all polygons\"),\n            enabled=False,\n        )\n\n        help = action(\n            self.tr(\"&Tutorial\"),\n            self.tutorial,\n            icon=\"help\",\n            tip=self.tr(\"Show tutorial page\"),\n        )\n\n        zoom = QtWidgets.QWidgetAction(self)\n        zoomBoxLayout = QtWidgets.QVBoxLayout()\n        zoomLabel = QtWidgets.QLabel(\"Zoom\")\n        zoomLabel.setAlignment(Qt.AlignCenter)\n        zoomBoxLayout.addWidget(zoomLabel)\n        zoomBoxLayout.addWidget(self.zoomWidget)\n        zoom.setDefaultWidget(QtWidgets.QWidget())\n        zoom.defaultWidget().setLayout(zoomBoxLayout)\n        self.zoomWidget.setWhatsThis(\n            str(\n                self.tr(\n                    \"Zoom in or out of the image. Also accessible with \"\n                    \"{} and {} from the canvas.\"\n                )\n            ).format(\n                utils.fmtShortcut(\n                    \"{},{}\".format(shortcuts[\"zoom_in\"], shortcuts[\"zoom_out\"])\n                ),\n                utils.fmtShortcut(self.tr(\"Ctrl+Wheel\")),\n            )\n        )\n        self.zoomWidget.setEnabled(False)\n\n        zoomIn = action(\n            self.tr(\"Zoom &In\"),\n            functools.partial(self.addZoom, 1.1),\n            shortcuts[\"zoom_in\"],\n            \"zoom-in\",\n            self.tr(\"Increase zoom level\"),\n",
  "import pytest\nfrom qtpy import QtCore\nfrom qtpy import QtWidgets\n\nfrom labelme.widgets import LabelDialog\nfrom labelme.widgets import LabelQLineEdit\n\n\n@pytest.mark.gui\ndef test_LabelQLineEdit(qtbot):\n    list_widget = QtWidgets.QListWidget()\n    list_widget.addItems([\"cat\", \"dog\", \"person\"])\n    widget = LabelQLineEdit()\n    widget.setListWidget(list_widget)\n    qtbot.addWidget(widget)\n\n    # key press to navigate in label list\n    item = widget.list_widget.findItems(\"cat\", QtCore.Qt.MatchExactly)[0]\n    widget.list_widget.setCurrentItem(item)\n    assert widget.list_widget.currentItem().text() == \"cat\"\n    qtbot.keyPress(widget, QtCore.Qt.Key_Down)\n    assert widget.list_widget.currentItem().text() == \"dog\"\n\n    # key press to enter label\n    qtbot.keyPress(widget, QtCore.Qt.Key_P)\n    qtbot.keyPress(widget, QtCore.Qt.Key_E)\n    qtbot.keyPress(widget, QtCore.Qt.Key_R)\n    qtbot.keyPress(widget, QtCore.Qt.Key_S)\n    qtbot.keyPress(widget, QtCore.Qt.Key_O)\n    qtbot.keyPress(widget, QtCore.Qt.Key_N)\n    assert widget.text() == \"person\"\n\n\n@pytest.mark.gui\ndef test_LabelDialog_addLabelHistory(qtbot):\n    labels = [\"cat\", \"dog\", \"person\"]\n    widget = LabelDialog(labels=labels, sort_labels=True)\n    qtbot.addWidget(widget)\n\n    widget.addLabelHistory(\"bicycle\")\n",
  "\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"in_file\", help=\"Input file or directory.\")\n    parser.add_argument(\"-O\", \"--output\")\n    args = parser.parse_args()\n\n    if not distutils.spawn.find_executable(\"docker\"):\n        print(\"Please install docker\", file=sys.stderr)\n        sys.exit(1)\n\n    try:\n        out_file = labelme_on_docker(args.in_file, args.output)\n        if out_file:\n            print(\"Saved to: %s\" % out_file)\n    except RuntimeError as e:\n        sys.stderr.write(e.__str__() + \"\\n\")\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "    agent = cl.user_session.get(\"agent\")\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({\"input\": message.content})[\"output\"]\n    await msg.update()",
  "        self.visible = {}\n        self._hideBackround = False\n        self.hideBackround = False\n        self.hShape = None\n        self.prevhShape = None\n        self.hVertex = None\n        self.prevhVertex = None\n        self.hEdge = None\n        self.prevhEdge = None\n        self.movingShape = False\n        self.snapping = True\n        self.hShapeIsSelected = False\n        self._painter = QtGui.QPainter()\n        self._cursor = CURSOR_DEFAULT\n        # Menus:\n        # 0: right-click without selection and dragging of shapes\n        # 1: right-click with selection and dragging of shapes\n        self.menus = (QtWidgets.QMenu(), QtWidgets.QMenu())\n        # Set widget options.\n        self.setMouseTracking(True)\n        self.setFocusPolicy(QtCore.Qt.WheelFocus)\n\n        self._ai_model = None\n\n    def fillDrawing(self):\n        return self._fill_drawing\n\n    def setFillDrawing(self, value):\n        self._fill_drawing = value\n\n    @property\n    def createMode(self):\n        return self._createMode\n\n    @createMode.setter\n    def createMode(self, value):\n        if value not in [\n            \"polygon\",\n            \"rectangle\",\n            \"circle\",\n",
  "        qlabel.setAlignment(Qt.AlignBottom)\n\n        item.setSizeHint(qlabel.sizeHint())\n\n        self.setItemWidget(item, qlabel)\n",
  "def reset_password(session: Session, password_reset: PasswordReset):\n    with session() as db:\n        user: User = db.query(User).filter(User.email_address == password_reset.email_address).first()\n        email_address = user.decode_password_token(password_reset.password_reset_token)\n        if email_address == user.email_address:\n            user.password = user.hash_password(password_reset.password)\n            db.commit()\n            return True",
  "    ],\n)\n",
  "#     description='sample description',\n#     defaultLanguage='en'\n# )\n# playlist = youtube.insert_playlist(playlist_schema=CreatePlaylist(snippet=playlist_snippet))\n# playlist_snippet = CreatePlaylistSnippet(\n#     title='sample title updated',\n#     description='sample description',\n#     defaultLanguage='en'\n# )\n# playlist = youtube.update_playlist(playlist_id='PL_26vmg8W_AejZY4OPSqdHrdIaRjoSvTW', \n#                                    playlist_schema=CreatePlaylist(snippet=playlist_snippet))\n# youtube.delete_playlist(playlist_id='PL_26vmg8W_AejZY4OPSqdHrdIaRjoSvTW')\n# my_playlists_iterator = youtube.get_my_playlists_iterator()\n# print(next(my_playlists_iterator))\n# print(next(my_playlists_iterator))\n# playlist_items = youtube.find_playlist_items(playlist_id='PL_26vmg8W_AfD5tzNAbIGbtTLU6ivjorS')\n# item_ids = [\n#     'UExfMjZ2bWc4V19BZkQ1dHpOQWJJR2J0VExVNml2am9yUy5DMkM0MjQ3OTgwQzBCMEZB',\n#     'UExfMjZ2bWc4V19BZkQ1dHpOQWJJR2J0VExVNml2am9yUy5BRjY4NjdBRjA5RTdCMUMx'\n# ]\n# playlist_items = youtube.find_playlist_items_by_ids(item_ids)\n# resource_id = VideoResourceId(videoId='jbcjK0W6U0E')\n# item_snippet = CreatePlaylistItemSnippet(playlistId='PL_26vmg8W_AfD5tzNAbIGbtTLU6ivjorS', resourceId=resource_id)\n# item = youtube.insert_playlist_item(CreatePlaylistItem(snippet=item_snippet))\n# youtube.delete_playlist_item(playlist_item_id='UExfMjZ2bWc4V19BZkQ1dHpOQWJJR2J0VExVNml2am9yUy5CNzAzQzRDMkI3QThEQzZB')\n# print(item)\n# channel = youtube.find_channel_by_name('Ark Invest')\n# print(channel)\n# query: str = 'Python programming videos'\n# max_results: int = 10\n# january_2023 = datetime(year=2023, month=1, day=1)\n# january_2023 = str(january_2023.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q=query,\n#     maxResults=max_results,\n#     type=['video'],\n#     publishedAfter=january_2023\n# )\n# search_request: YouTubeRequest = YouTubeRequest(\n",
  "from google_calendar import GoogleCalendar\nimport os\n\nclient_secret: str = os.environ['CLIENT_SECRET_FILE']\ngoogle_calendar: GoogleCalendar = GoogleCalendar(secret_file=client_secret)\ngoogle_calendar.authenticate()",
  "from zipfile import ZipFile\nfrom os import path, mkdir\nimport os\n\n\ndef download_data():\n    pass\n\n\ndef extract_archive(archive_path: str, archive_name: str, extract_path: str = None) -> None:\n    if not extract_path:\n        extract_path: str = \"raw-data\"\n        if not path.exists(extract_path):\n            mkdir(extract_path)\n    archive_path: str = path.join(archive_path, archive_name)\n    with ZipFile(file=archive_path, mode=\"r\") as z_object:\n        z_object.extractall(path=extract_path)\n        \n ",
  "from dotenv import load_dotenv\n\nload_dotenv()\nfrom langchain.agents import AgentExecutor, Tool\nfrom langchain.agents.format_scratchpad import format_to_openai_function_messages\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain.tools.render import format_tool_to_openai_function\nfrom typing import Optional\nfrom langchain.llms.base import BaseLLM\nfrom langchain_openai import OpenAI, ChatOpenAI\nfrom langchain.callbacks.manager import (\n    AsyncCallbackManagerForToolRun,\n    CallbackManagerForToolRun,\n)\nfrom langchain.tools import BaseTool, Tool\nfrom langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n\n\nclass GoogleSearchTool(BaseTool):\n    name = \"google_search\"\n    description = \"\"\"\n    useful when you need to to search for the latest information from the web\n    \"\"\"\n\n    def _run(\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool.\"\"\"\n        search = GoogleSearchAPIWrapper()\n        return search.run(query=query)\n\n    async def _arun(\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n    ) -> str:\n        \"\"\"Use the tool asynchronously.\"\"\"\n        raise NotImplementedError()\n\n\napi_key: str = \"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\"\n",
  "from data_utils import extract_archive\nfrom dotenv import load_dotenv\nimport os\n\n\nload_dotenv()\n\nDOWNLOAD_PATH: str = os.environ[\"DOWNLOAD_PATH\"]\nEXTRACT_PATH: str = os.environ[\"EXTRACT_PATH\"]\nARCHIVE_NAME: str = \"archive (2).zip\"\n\nextract_archive(\n    archive_path=DOWNLOAD_PATH, \n    archive_name=ARCHIVE_NAME, \n    extract_path=EXTRACT_PATH\n)\n\n",
  "# print(video)",
  "# with open('replies.json', 'w') as f:\n#     json.dump(replies, f, indent=4)\n# from youtube.resources.comment_thread.comment import CommentResource\n# import json\n# comment_res = CommentResource(youtube_client)\n# with open('replies.json', 'r') as f:\n#     comments = json.load(f)\n# print(comment_res.parse_youtube_response(comments))\n# print(len(comment_res.parse_youtube_response(comments).items))\n\n# comment_text = 'Sample comment text'\n# video_id = 'jl3b4eLKiP8'\n# comment = youtube.insert_comment(video_id, comment_text)\n# print(comment)\n\n# comment_id = 'UgyblK9NGskUXp91WIt4AaABAg'\n# reply = 'Sample comment reply'\n# comment_reply = youtube.reply_to_comment(comment_id, reply)\n# channel = youtube.find_my_channel()\n# print(channel.items[0].snippet.custom_url)\n# import json\n# my_activities = youtube.list_my_activities()\n# with open('my_activities.json', 'w') as f:\n#     json.dump(my_activities, f, indent=4)\n# print(my_activities)\n# print(youtube.find_channel_by_id(channel_id=\"UCj3FYGvdAVNdD3M0dvKr3cA\"))\nit = youtube.get_comments_iterator(video_id='cBpGq-vDr2Y')\nprint(next(it))",
  "        return None\n\n    def process_response(self, request, response, spider):\n        # Called with the response returned from the downloader.\n\n        # Must either;\n        # - return a Response object\n        # - return a Request object\n        # - or raise IgnoreRequest\n        return response\n\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        pass\n\n    def spider_opened(self, spider):\n        spider.logger.info(\"Spider opened: %s\" % spider.name)\n",
  "            line_path = QtGui.QPainterPath()\n            contours = skimage.measure.find_contours(np.pad(self.mask, pad_width=1))\n            for contour in contours:\n                contour += [self.points[0].y(), self.points[0].x()]\n                line_path.moveTo(contour[0, 1], contour[0, 0])\n                for point in contour[1:]:\n                    line_path.lineTo(point[1], point[0])\n            painter.drawPath(line_path)\n\n        if self.points:\n            line_path = QtGui.QPainterPath()\n            vrtx_path = QtGui.QPainterPath()\n            negative_vrtx_path = QtGui.QPainterPath()\n\n            if self.shape_type in [\"rectangle\", \"mask\"]:\n                assert len(self.points) in [1, 2]\n                if len(self.points) == 2:\n                    rectangle = self.getRectFromLine(*self.points)\n                    line_path.addRect(rectangle)\n                if self.shape_type == \"rectangle\":\n                    for i in range(len(self.points)):\n                        self.drawVertex(vrtx_path, i)\n            elif self.shape_type == \"circle\":\n                assert len(self.points) in [1, 2]\n                if len(self.points) == 2:\n                    rectangle = self.getCircleRectFromLine(self.points)\n                    line_path.addEllipse(rectangle)\n                for i in range(len(self.points)):\n                    self.drawVertex(vrtx_path, i)\n            elif self.shape_type == \"linestrip\":\n                line_path.moveTo(self.points[0])\n                for i, p in enumerate(self.points):\n                    line_path.lineTo(p)\n                    self.drawVertex(vrtx_path, i)\n            elif self.shape_type == \"points\":\n                assert len(self.points) == len(self.point_labels)\n                for i, point_label in enumerate(self.point_labels):\n                    if point_label == 1:\n                        self.drawVertex(vrtx_path, i)\n                    else:\n",
  "client_secrets_file = '/home/lyle/Downloads/client_secret.json'\ncredentials_path = '.'\nyoutube = YouTube(client_secrets_file)\nyoutube.authenticate(credentials_directory=credentials_path)\nsearch_iterator = youtube.search_video('Python for beginners' ,max_results=2)\nprint(list(next(search_iterator)))\n# print(list(next(search_iterator)))\n# print(len(search_iterator.items))\n# print_videos(next(search_iterator))\n# print_videos(next(search_iterator))\n# print_videos(next(search_iterator))\n# print(next(search_iterator))\n# print_videos(list(next(search_iterator)))\n# print_videos(next(search_iterator))\n# print_videos(next(search_iterator))\n# videos = youtube.find_video_by_id('RFDK1rdJ_gg')\n# print(videos)\n# save_to_channels(video)\n# ids = ['rfscVS0vtbw', 'TFa38ONq5PY']\n# youtube.find_videos(ids)\n# youtube.find_most_popular_video_by_region('us')\n# search_iterator = youtube.search_channel('Python for beginners',max_results=2)\n# channel = youtube.find_channel_by_id('UCu8luTDe_Xxd2ahAXsCWX5g')\n# print(channel)\n# print(channel.to_json())\n# to_json([channel.to_dict()])\n# search_iterator = youtube.search_channel('Python for beginners',max_results=2)\n# print(next(search_iterator))\n# channel = youtube.find_channel_by_name('GoogleDevelopers')\n# channel = youtube.find_channel_by_name('@PROROBOTS')\n# print(channel)\n# search_iterator = youtube.find_video_comments('VSB2vjWa1LA', max_results=20)\n# print(next(search_iterator))\n# print(next(search_iterator))\n# search_iterator = youtube.find_all_channel_comments('UCu8luTDe_Xxd2ahAXsCWX5g', max_results=20)\n# print(next(search_iterator))\n# print(next(search_iterator))\n# search_iterator = youtube.search_playlist('Python for beginners',max_results=20)\n# print(next(search_iterator))\n# print(next(search_iterator))\n",
  "        loc=\"rb\",\n    )\n\n    plt.subplot(121)\n    plt.imshow(img)\n    plt.subplot(122)\n    plt.imshow(lbl_viz)\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "\n\ndef get_channels() -> list[Channel]:\n    logging.info('Getting the channel details from the database.')\n    channels: list[Channel] = get_all_channels(get_db)\n    logging.info('Fetched the channel details from the database.')\n    return channels\n\ndef get_channel_names() -> list[str]:\n    logging.info('Fetching the channel names.')\n    channels: list[Channel] = get_all_channels(get_db)\n    logging.info('Fetched the channel names.')\n    return [channel.title for channel in channels]\n\n\ndef get_channel_id(name: str) -> str:\n    channel: Channel = get_channel_by_title(name, get_db)\n    return channel.id\n\n\ndef find_latest_video(channel_id: str, youtube_client: YouTube) -> Video:\n    if redis.get(name=f'latest:{channel_id}'):\n        logging.info('Found video in cache, retrieving it.')\n        video_str: str = redis.get(name=f'latest:{channel_id}')\n        video: Video = Video(**loads(video_str))\n        logging.info('Successfully retrieved video from cache.')\n    else:\n        logging.info('Video missing from cache, retrieving from youtube.')\n        part: SearchPart = SearchPart()\n        optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n            q='',\n            maxResults=1,\n            type=['video'],\n            channelId=channel_id,\n            order='date'\n        )\n        search: YouTubeRequest = YouTubeRequest(part=part, optional_parameters=optional_parameters)\n        response: YouTubeResponse = youtube_client.search(search)\n        logging.info('Retrieved the latest video from youtube.')\n        search_responses: list[Search] = response.items\n",
  "\ntopic_assign_msg: str = \"\"\"\nBelow is a list of customer comments in JSON format with the following keys:\n1. doc_id - identifier of the comment\n2. comment - the user comment\n\nPlease analyze the provided comments and identify the main topics and sentiment. Include only the \ntopics mentioned in the following text:\nText: {topics}\n\n{format_instructions}\n\nuser comments: \n```{comments}```\n\"\"\"\n\ntopic_assign_tmpl = PromptTemplate(\n    template=topic_assign_msg,\n    input_variables=[\"topics\", \"comments\", \"format_instructions\"],\n)\n# topic_assign_tmpl = ChatPromptTemplate.from_messages(\n#     [\n#         (\"system\", \"You are a helpful assistant. Your task is to analyze user comments.\"),\n#         (\"user\", topic_assign_msg)\n#     ]\n# )\n\n# messages = topic_assign_tmpl.format(\n#     topics=topics,\n#     format_instructions=format_instructions,\n#     comments=json.dumps(comments)\n# )\n\ninputs = {\n    \"topics\": topics,\n    \"format_instructions\": format_instructions,\n    \"comments\": json.dumps(comments),\n}\n\nchat = OpenAI(temperature=0, api_key=api_key)\n",
  "            if osp.dirname(filename) and not osp.exists(osp.dirname(filename)):\n                os.makedirs(osp.dirname(filename))\n            lf.save(\n                filename=filename,\n                shapes=shapes,\n                imagePath=imagePath,\n                imageData=imageData,\n                imageHeight=self.image.height(),\n                imageWidth=self.image.width(),\n                otherData=self.otherData,\n                flags=flags,\n            )\n            self.labelFile = lf\n            items = self.fileListWidget.findItems(self.imagePath, Qt.MatchExactly)\n            if len(items) > 0:\n                if len(items) != 1:\n                    raise RuntimeError(\"There are duplicate files.\")\n                items[0].setCheckState(Qt.Checked)\n            # disable allows next and previous image to proceed\n            # self.filename = filename\n            return True\n        except LabelFileError as e:\n            self.errorMessage(\n                self.tr(\"Error saving label data\"), self.tr(\"<b>%s</b>\") % e\n            )\n            return False\n\n    def duplicateSelectedShape(self):\n        added_shapes = self.canvas.duplicateSelectedShapes()\n        for shape in added_shapes:\n            self.addLabel(shape)\n        self.setDirty()\n\n    def pasteSelectedShape(self):\n        self.loadShapes(self._copied_shapes, replace=False)\n        self.setDirty()\n\n    def copySelectedShape(self):\n        self._copied_shapes = [s.copy() for s in self.canvas.selectedShapes]\n        self.actions.paste.setEnabled(len(self._copied_shapes) > 0)\n",
  "        elif self.createMode == \"ai_mask\" and self.current is not None:\n            drawing_shape = self.current.copy()\n            drawing_shape.addPoint(\n                point=self.line.points[1],\n                label=self.line.point_labels[1],\n            )\n            mask = self._ai_model.predict_mask_from_points(\n                points=[[point.x(), point.y()] for point in drawing_shape.points],\n                point_labels=drawing_shape.point_labels,\n            )\n            y1, x1, y2, x2 = imgviz.instances.masks_to_bboxes([mask])[0].astype(int)\n            drawing_shape.setShapeRefined(\n                shape_type=\"mask\",\n                points=[QtCore.QPointF(x1, y1), QtCore.QPointF(x2, y2)],\n                point_labels=[1, 1],\n                mask=mask[y1 : y2 + 1, x1 : x2 + 1],\n            )\n            drawing_shape.selected = True\n            drawing_shape.paint(p)\n\n        p.end()\n\n    def transformPos(self, point):\n        \"\"\"Convert from widget-logical coordinates to painter-logical ones.\"\"\"\n        return point / self.scale - self.offsetToCenter()\n\n    def offsetToCenter(self):\n        s = self.scale\n        area = super(Canvas, self).size()\n        w, h = self.pixmap.width() * s, self.pixmap.height() * s\n        aw, ah = area.width(), area.height()\n        x = (aw - w) / (2 * s) if aw > w else 0\n        y = (ah - h) / (2 * s) if ah > h else 0\n        return QtCore.QPointF(x, y)\n\n    def outOfPixmap(self, p):\n        w, h = self.pixmap.width(), self.pixmap.height()\n        return not (0 <= p.x() <= w - 1 and 0 <= p.y() <= h - 1)\n\n    def finalise(self):\n",
  "\n        # Polygon drawing.\n        if self.drawing():\n            if self.createMode in [\"ai_polygon\", \"ai_mask\"]:\n                self.line.shape_type = \"points\"\n            else:\n                self.line.shape_type = self.createMode\n\n            self.overrideCursor(CURSOR_DRAW)\n            if not self.current:\n                self.repaint()  # draw crosshair\n                return\n\n            if self.outOfPixmap(pos):\n                # Don't allow the user to draw outside the pixmap.\n                # Project the point to the pixmap's edges.\n                pos = self.intersectionPoint(self.current[-1], pos)\n            elif (\n                self.snapping\n                and len(self.current) > 1\n                and self.createMode == \"polygon\"\n                and self.closeEnough(pos, self.current[0])\n            ):\n                # Attract line to starting point and\n                # colorise to alert the user.\n                pos = self.current[0]\n                self.overrideCursor(CURSOR_POINT)\n                self.current.highlightVertex(0, Shape.NEAR_VERTEX)\n            if self.createMode in [\"polygon\", \"linestrip\"]:\n                self.line.points = [self.current[-1], pos]\n                self.line.point_labels = [1, 1]\n            elif self.createMode in [\"ai_polygon\", \"ai_mask\"]:\n                self.line.points = [self.current.points[-1], pos]\n                self.line.point_labels = [\n                    self.current.point_labels[-1],\n                    0 if is_shift_pressed else 1,\n                ]\n            elif self.createMode == \"rectangle\":\n                self.line.points = [self.current[0], pos]\n                self.line.point_labels = [1, 1]\n",
  "        slider = QtWidgets.QSlider(Qt.Horizontal)\n        slider.setRange(0, 150)\n        slider.setValue(50)\n        slider.valueChanged.connect(self.onNewValue)\n        return slider\n",
  "        \"requests\": create_slides_request\n    }\n    response = (\n        slide_client.presentations()\n        .batchUpdate(presentationId=presentation_id, body=request_body)\n        .execute()\n    )\n    create_slide_response = response.get(\"replies\")[0].get(\"createSlide\")\n    print(f\"Created slide with ID:{(create_slide_response.get('objectId'))}\")\n    slide_name: str = f\"{page_id.casefold().strip().replace(' ', '_')}.json\"\n    with open(slide_name, \"w\") as f:\n        json.dump(response, f)\n    return response\n\n\ndef create_textbox_with_text(presentation_id: str, page_id: str, slide_client: Any) -> dict:\n  try:\n    # Create a new square textbox, using the supplied element ID.\n    element_id = \"MyTextBox_10\"\n    pt350 = {\"magnitude\": 350, \"unit\": \"PT\"}\n    requests = [\n        {\n            \"createShape\": {\n                \"objectId\": element_id,\n                \"shapeType\": \"TEXT_BOX\",\n                \"elementProperties\": {\n                    \"pageObjectId\": page_id,\n                    \"size\": {\"height\": pt350, \"width\": pt350},\n                    \"transform\": {\n                        \"scaleX\": 1,\n                        \"scaleY\": 1,\n                        \"translateX\": 350,\n                        \"translateY\": 100,\n                        \"unit\": \"PT\",\n                    },\n                },\n            }\n        },\n        # Insert text into the box, using the supplied element ID.\n        {\n",
  "import ast\nfrom ast import AST, NodeTransformer\nfrom queue import Empty, Queue\nfrom openai import RateLimitError\n\nfrom .config import Config\nfrom .helpers import format_file, parse_src, read_src, save_src\nfrom .transformers import FunctionTransformer\nfrom .walkers import FunctionVisitor\n\n\ndef process_file(source_code_queue: Queue, function_code_queue: Queue):\n    while True:\n        try:\n            file_path: str = source_code_queue.get(timeout=1)\n            print(f\"processing the file: {file_path}\")\n            file_src: str = read_src(file_path=file_path)\n            src_tree: AST = parse_src(file_src)\n            visitor: FunctionVisitor = FunctionVisitor(\n                function_code_queue=function_code_queue,\n                file_path=file_path,\n            )\n            visitor.visit(src_tree)\n            source_code_queue.task_done()\n        except Empty:\n            print(\"Terminating the file processing..\")\n            break\n\n\ndef process_function(config: Config, function_code_queue: Queue) -> None:\n    while True:\n        try:\n            file_path, function_code = function_code_queue.get(timeout=1)\n            # print(function_code)\n            file_src: str = read_src(file_path=file_path)\n            src_tree: AST = parse_src(file_src)\n            # print_src(src_tree)\n            transformer: NodeTransformer = FunctionTransformer(\n                config=config, function_src=function_code\n            )\n",
  "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\n\nfrom calendar_assistant.usecases.agent import agent_executor\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent_executor.invoke({\"input\": message.content})['output']\n    await msg.update()",
  "        image_file = files[0]\n        image_data = image_file.content # byte values of the image\n        image = Image.open(io.BytesIO(image_data))\n        model = load_model()\n        predicted_label, predictions = evaluate_image(image, model)\n        analysis_text: str = f\"\"\"\n            After analyzing the image you uploaded, here is what I found:\n            Maize Leaf Rust probability: {predictions['Maize Leaf Rust']}%\n            Northern Leaf Blight probability: {predictions['Northern Leaf Blight']}%\n            Healthy probability: {predictions['Healthy']}%\n            Gray Leaf Spot probability: {predictions['Gray Leaf Spot']}%\n            Your plant is most likely infected with {predicted_label}.\n            \"\"\"\n        elements = [\n            cl.Image(\n                name=\"image2\", display=\"inline\", content=image_data\n                ), \n            cl.Text(name=\"simple_text\", content=analysis_text, display=\"inline\", size='large')\n        ]\n        await cl.Message(content=f\"Maize image with {predicted_label}!\", elements=elements).send()\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Tell me some facts about the maize disease {predicted_label} especially in relation to kenya.')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'What fungicides or pesticides can be used to deal with the maize disease {predicted_label}?')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Get me aggrovets in {user_location}, Kenya')\n        await msg.update()\n        await cl.Message(content='Feel free to ask me more questions about maize plant diseases and how to deal with them.').send()\n    else:\n        await cl.Message(content='Currently cannot detect pests. Still working on that model.').send()\n    \n\n@cl.on_message\nasync def main(message: cl.Message):\n",
  "import os.path as osp\nimport shutil\n\nimport yaml\n\nfrom labelme.logger import logger\n\nhere = osp.dirname(osp.abspath(__file__))\n\n\ndef update_dict(target_dict, new_dict, validate_item=None):\n    for key, value in new_dict.items():\n        if validate_item:\n            validate_item(key, value)\n        if key not in target_dict:\n            logger.warn(\"Skipping unexpected key in config: {}\".format(key))\n            continue\n        if isinstance(target_dict[key], dict) and isinstance(value, dict):\n            update_dict(target_dict[key], value, validate_item=validate_item)\n        else:\n            target_dict[key] = value\n\n\n# -----------------------------------------------------------------------------\n\n\ndef get_default_config():\n    config_file = osp.join(here, \"default_config.yaml\")\n    with open(config_file) as f:\n        config = yaml.safe_load(f)\n\n    # save default config to ~/.labelmerc\n    user_config_file = osp.join(osp.expanduser(\"~\"), \".labelmerc\")\n    if not osp.exists(user_config_file):\n        try:\n            shutil.copy(config_file, user_config_file)\n        except Exception:\n            logger.warn(\"Failed to save config: {}\".format(user_config_file))\n\n    return config\n",
  "import os\nimport pandas as pd\nfrom spacy.lang.en import English\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom collections import defaultdict\nfrom torchvision.transforms import Compose, ToTensor, Resize\n\n\nnlp = English()\n# Create a Tokenizer with the default settings for English\n# including punctuation rules and exceptions\ntokenizer = nlp.tokenizer\n\ntransforms = Compose([\n    ToTensor()\n])\n\nclass Vocabulary:\n    def __init__(self, freq_threshold: int) -> None:\n        self.freq_threshold: int = freq_threshold\n        self.itos: dict[int, str] = {\n            0: \"<PAD>\",\n            1: \"<SOS>\",\n            2: \"<EOS>\",\n            3: \"<UNK>\"\n        }\n        self.stoi: dict[str, int] = self.invert_dict(self.itos)\n        \n    def __len__(self) -> int:\n        return len(self.itos)\n    \n    @staticmethod\n    def tokenize(text: str) -> list[str]:\n        return [token.text.lower() for token in tokenizer(text)]\n        \n    @staticmethod\n    def invert_dict(dct: dict) -> dict:\n",
  "\n    def getCircleRectFromLine(self, line):\n        \"\"\"Computes parameters to draw with `QPainterPath::addEllipse`\"\"\"\n        if len(line) != 2:\n            return None\n        (c, point) = line\n        r = line[0] - line[1]\n        d = math.sqrt(math.pow(r.x(), 2) + math.pow(r.y(), 2))\n        rectangle = QtCore.QRectF(c.x() - d, c.y() - d, 2 * d, 2 * d)\n        return rectangle\n\n    def makePath(self):\n        if self.shape_type in [\"rectangle\", \"mask\"]:\n            path = QtGui.QPainterPath()\n            if len(self.points) == 2:\n                rectangle = self.getRectFromLine(*self.points)\n                path.addRect(rectangle)\n        elif self.shape_type == \"circle\":\n            path = QtGui.QPainterPath()\n            if len(self.points) == 2:\n                rectangle = self.getCircleRectFromLine(self.points)\n                path.addEllipse(rectangle)\n        else:\n            path = QtGui.QPainterPath(self.points[0])\n            for p in self.points[1:]:\n                path.lineTo(p)\n        return path\n\n    def boundingRect(self):\n        return self.makePath().boundingRect()\n\n    def moveBy(self, offset):\n        self.points = [p + offset for p in self.points]\n\n    def moveVertexBy(self, i, offset):\n        self.points[i] = self.points[i] + offset\n\n    def highlightVertex(self, i, action):\n        \"\"\"Highlight a vertex appropriately based on the current action\n\n",
  "            ('classifier', untrained_model)\n        ])\n    if model_params:\n        untrained_model.set_params(**model_params)\n    train_start_time: float = perf_counter()\n    pipeline.fit(train_config.train_features, train_config.train_labels.values.ravel())\n    train_stop_time: float = perf_counter()\n    predictions: list[int] = pipeline.predict(train_config.test_features).tolist()\n    accuracy: float = accuracy_score(train_config.test_labels, predictions)\n    precision: float = precision_score(train_config.test_labels, predictions)\n    recall: float = recall_score(train_config.test_labels, predictions)\n    f1: float = f1_score(train_config.test_labels, predictions)\n    metrics: Metrics = Metrics(\n        accuracy=round(accuracy,2),\n        precision=round(precision,2),\n        recall=round(recall,2),\n        f1=round(f1,2)\n    )\n    model_train_time = train_stop_time - train_start_time\n    if train:\n        save_path: str = path.join(app_config.models_dir, 'trained', train_config.classifier_name)\n    else:\n        save_path: str = path.join(app_config.models_dir, 'tuned', train_config.classifier_name)\n    Model.save_model(pipeline, save_path)\n    return {\n        'model_name': train_config.classifier_name,\n        'metrics': metrics,\n        'train_time': model_train_time\n    }\n    \n    \n@celery.task(name='train_tuned_model')\ndef train_tuned_model(tuned_model_data: dict, train_config: TrainConfig):\n    train_results: dict = fit_pipeline(train_config=train_config, model_params=tuned_model_data['params'])\n    tuned_model: TunedModel = TunedModel(\n        classifier_name=train_results['model_name'],\n        train_date=datetime.now(),\n        save_path=path.join(app_config.models_dir, 'trained', train_results['model_name']),\n        owner='Lyle Okoth',\n        metrics=train_results['metrics'],\n",
  "from langchain.prompts import PromptTemplate\n\nfunction_prompt_template: str = \"\"\"\nGenerate python docstring for the given python function using the provided documentation style.\nMake sure to provide atleast two examples of the function usage only in the docstring as well\nas the exceptions that may be raised when using the function. Make sure to return the\nfunction and its docstring.\nFunction code: {function_code}\nDocumentation style: {documentation_style}\n\"\"\"\nfunction_prompt = PromptTemplate.from_template(template=function_prompt_template)\n",
  "from flask import Flask\nfrom .home import home\nfrom .oauth import auth, google_blueprint\n\n\ndef register_blueprints(app: Flask) -> bool:\n    \"\"\"Register the application blueprints.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether all the blueprints were registered.\n    \"\"\"\n    app.register_blueprint(home)\n    app.register_blueprint(auth, url_prefix=\"/auth\")\n    app.register_blueprint(google_blueprint, url_prefix=\"/login\")\n    return True",
  "        # (from other spider middleware) raises an exception.\n\n        # Should return either None or an iterable of Request or item objects.\n        pass\n\n    def process_start_requests(self, start_requests, spider):\n        # Called with the start requests of the spider, and works\n        # similarly to the process_spider_output() method, except\n        # that it doesn’t have a response associated.\n\n        # Must return only requests (not items).\n        for r in start_requests:\n            yield r\n\n    def spider_opened(self, spider):\n        spider.logger.info(\"Spider opened: %s\" % spider.name)\n\n\nclass LeetcodeDownloaderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the downloader middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_request(self, request, spider):\n        # Called for each request that goes through the downloader\n        # middleware.\n\n        # Must either:\n        # - return None: continue processing this request\n        # - or return a Response object\n        # - or return a Request object\n        # - or raise IgnoreRequest: process_exception() methods of\n        #   installed downloader middleware will be called\n",
  "import ast\nfrom ast import AST, FunctionDef, NodeTransformer\n\nfrom .config import Config\nfrom .helpers import generate_doc_string, make_docstring_node\nfrom .model_parsers import parse_function_docstr\n\n\nclass FunctionTransformer(NodeTransformer):\n    def __init__(self, config: Config, function_src: str) -> None:\n        super().__init__()\n        self._config: Config = config\n        self._function_src = function_src\n\n    def visit_FunctionDef(self, node: FunctionDef) -> None:\n        ast_tree: AST = ast.parse(self._function_src)\n        function_node: AST = ast_tree.body[0]\n        docstring: str = ast.get_docstring(node=node)\n        if function_node.name == node.name:\n            if not docstring:\n                src_code: str = ast.unparse(node)\n                func_docstr: str = generate_doc_string(\n                    src_code=src_code, config=self._config\n                )\n                doc_str: str = parse_function_docstr(func_docstr.strip())\n                if doc_str:\n                    dcstr_node: AST = make_docstring_node(doc_str)\n                    node.body.insert(0, dcstr_node)\n            elif self._config.overwrite_function_docstring:\n                src_code: str = ast.unparse(node)\n                func_docstr: str = generate_doc_string(\n                    src_code=src_code, config=self._config\n                )\n                doc_str: str = parse_function_docstr(func_docstr.strip())\n                if doc_str:\n                    dcstr_node: AST = make_docstring_node(doc_str)\n                    node.body[0] = dcstr_node\n        return node\n",
  "        p = self._painter\n        p.begin(self)\n        p.setRenderHint(QtGui.QPainter.Antialiasing)\n        p.setRenderHint(QtGui.QPainter.HighQualityAntialiasing)\n        p.setRenderHint(QtGui.QPainter.SmoothPixmapTransform)\n\n        p.scale(self.scale, self.scale)\n        p.translate(self.offsetToCenter())\n\n        p.drawPixmap(0, 0, self.pixmap)\n\n        # draw crosshair\n        if (\n            self._crosshair[self._createMode]\n            and self.drawing()\n            and self.prevMovePoint\n            and not self.outOfPixmap(self.prevMovePoint)\n        ):\n            p.setPen(QtGui.QColor(0, 0, 0))\n            p.drawLine(\n                0,\n                int(self.prevMovePoint.y()),\n                self.width() - 1,\n                int(self.prevMovePoint.y()),\n            )\n            p.drawLine(\n                int(self.prevMovePoint.x()),\n                0,\n                int(self.prevMovePoint.x()),\n                self.height() - 1,\n            )\n\n        Shape.scale = self.scale\n        for shape in self.shapes:\n            if (shape.selected or not self._hideBackround) and self.isVisible(shape):\n                shape.fill = shape.selected or shape == self.hShape\n                shape.paint(p)\n        if self.current:\n            self.current.paint(p)\n            assert len(self.line.points) == len(self.line.point_labels)\n",
  "            x3, y3 = points[i]\n            x4, y4 = points[(i + 1) % 4]\n            denom = (y4 - y3) * (x2 - x1) - (x4 - x3) * (y2 - y1)\n            nua = (x4 - x3) * (y1 - y3) - (y4 - y3) * (x1 - x3)\n            nub = (x2 - x1) * (y1 - y3) - (y2 - y1) * (x1 - x3)\n            if denom == 0:\n                # This covers two cases:\n                #   nua == nub == 0: Coincident\n                #   otherwise: Parallel\n                continue\n            ua, ub = nua / denom, nub / denom\n            if 0 <= ua <= 1 and 0 <= ub <= 1:\n                x = x1 + ua * (x2 - x1)\n                y = y1 + ua * (y2 - y1)\n                m = QtCore.QPointF((x3 + x4) / 2, (y3 + y4) / 2)\n                d = labelme.utils.distance(m - QtCore.QPointF(x2, y2))\n                yield d, i, (x, y)\n\n    # These two, along with a call to adjustSize are required for the\n    # scroll area.\n    def sizeHint(self):\n        return self.minimumSizeHint()\n\n    def minimumSizeHint(self):\n        if self.pixmap:\n            return self.scale * self.pixmap.size()\n        return super(Canvas, self).minimumSizeHint()\n\n    def wheelEvent(self, ev):\n        if QT5:\n            mods = ev.modifiers()\n            delta = ev.angleDelta()\n            if QtCore.Qt.ControlModifier == int(mods):\n                # with Ctrl/Command key\n                # zoom\n                self.zoomRequest.emit(delta.y(), ev.pos())\n            else:\n                # scroll\n                self.scrollRequest.emit(delta.x(), QtCore.Qt.Horizontal)\n                self.scrollRequest.emit(delta.y(), QtCore.Qt.Vertical)\n",
  "    cleaned_comments: list[str] = list(map(clean_text, all_comments))\n    comments: list[str] = choices(population=cleaned_comments, k=10)\n    comments: list[Document] = [Document(page_content=comment) for comment in comments if is_acceptable_len(comment)]\n    \ndata_dir = \"./agent_nelly/data_analysis/data\"\nfeatures_dir = \"features\"\nsave_features_dir = path.join(data_dir, features_dir, \"features.json\")\n\nwith open(save_features_dir, 'r') as f:\n    topics: list[str] = json.load(f)\n\ntopic_assignment_msg: str = \"\"\"\nYou are provided with a detailed summary for the review of the product {product}. You will also be \ngiven a comment, which is a reaction to the product review. Please analyze the  \n\nList of topics: {topics}\nComments: {comments}\n\"\"\"\n\n",
  "    image_paths = Column(ScalarListType())\n    image_urls = Column(ScalarListType())\n    \n\nclass Tag(Base):\n    __tablename__ = \"tag\"\n\n    id = Column(String(), primary_key=True)\n    name = Column('name', String(30), unique=True)\n    slides = relationship('Slide', secondary='slide_tag',\n        lazy='dynamic', backref=\"tag\")  # M-to-M for quote and tag\n    \n    \nclass Category(Base):\n    __tablename__ = \"category\"\n\n    id = Column(String(), primary_key=True)\n    name = Column('name', String(50), unique=True)\n    slides = relationship('Slide', backref='category')",
  "def load_model(model_path: str) -> Pipeline:\n    \"\"\"Load a saved model.\"\"\"\n    try:\n        model: Pipeline = load(model_path)\n    except FileNotFoundError:\n        logging.error(f'There is no such model \"{model_path}\".')\n    return model\n\n\ndef send_email():\n    logging.info('Sending email.')\n    secrets_path = app_config.secret_file\n    gmail_client = get_gmail_client(secrets_path)\n    message = create_message()\n    message = send_message(gmail_client, message)\n    logging.info('Email Sent.')\n    logging.info(message)\n",
  "        os.makedirs(osp.join(args.output_dir, \"Visualization\"))\n    print(\"Creating dataset:\", args.output_dir)\n\n    now = datetime.datetime.now()\n\n    data = dict(\n        info=dict(\n            description=None,\n            url=None,\n            version=None,\n            year=now.year,\n            contributor=None,\n            date_created=now.strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n        ),\n        licenses=[\n            dict(\n                url=None,\n                id=0,\n                name=None,\n            )\n        ],\n        images=[\n            # license, url, file_name, height, width, date_captured, id\n        ],\n        type=\"instances\",\n        annotations=[\n            # segmentation, area, iscrowd, image_id, bbox, category_id, id\n        ],\n        categories=[\n            # supercategory, id, name\n        ],\n    )\n\n    class_name_to_id = {}\n    for i, line in enumerate(open(args.labels).readlines()):\n        class_id = i - 1  # starts with -1\n        class_name = line.strip()\n        if class_id == -1:\n            assert class_name == \"__ignore__\"\n            continue\n",
  "from celery_app import celery_app\nimport logging\nfrom play_list import get_youtube_client, get_channel_names, workflow\nfrom youtube import YouTube\n\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n\n\n@celery_app.task\ndef create_daily_playlist() -> None:\n    client_secret_file: str = 'client_secret.json'\n    logging.info('Getting the youtube client.')\n    youtube: YouTube = get_youtube_client(client_secret_file)\n    logging.info('Getting the channel names.')\n    channel_names: list[str] = get_channel_names()[:2]\n    logging.info('Fetched the channel names: ')\n    logging.info(channel_names)\n    playlist_name: str = 'Daily Videos'\n    logging.info('Fetching and adding latest videos to the playlist \"%s\".', playlist_name)\n    playlist_items: list[str] = workflow(youtube, channel_names, playlist_name)\n    if playlist_items:\n        logging.info('Added the following playlist items: ')\n        logging.info(playlist_items)\n        logging.info('Notifying via email.')\n    return playlist_items\n\n\n@celery_app.task\ndef clear_daily_playlist() -> None:\n    logging.info('Clearing daily playlist.')",
  "from datetime import datetime\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom sqlalchemy import ForeignKey\nfrom ..database import Base\n\n\nclass Post(Base):\n    __tablename__ = 'posts'\n    \n    id: Mapped[str] = mapped_column(primary_key=True)\n    author_id: Mapped[str] = mapped_column(ForeignKey('users.id'))\n    location: Mapped[str]\n    text: Mapped[str]\n    image_url: Mapped[str]\n    date_published: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    date_updated: Mapped[datetime] = mapped_column(onupdate=datetime.utcnow, default_factory=datetime.utcnow)\n    \n    author = relationship('User', back_populates='posts')\n    bookmarks = relationship('Bookmark', back_populates='post')\n    likes = relationship('Like', back_populates='post')\n    comments = relationship('Comment', back_populates='post')\n    views = relationship('View', back_populates='post')",
  "\"\"\"This module resgisters the application extensions.\n\nExample:\n    To register the extensions:\n        register_extensions(app)\n\n@Author: Lyle Okoth\n@Date: 28/06/2023\n@Portfolio: https://lyleokoth.oryks-sytem.com\n\"\"\"\nfrom flask import Flask\n\nfrom .extensions import bcrypt, cors\n\n\ndef register_extensions(app: Flask) -> None:\n    \"\"\"Register the application extensions.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        The Flask app instance.\n    \"\"\"\n    bcrypt.init_app(app)\n    cors.init_app(app)",
  "    credentials_dir: str = GoogleDirectories.drive.value\n    credentials_file_name: Optional[str] = 'credentials.json'\n\n    auth: GoogleOAuth = GoogleOAuth(\n        secrets_file=secrets_file,\n        scopes=scopes,\n        api_service_name=api_service_name,\n        api_version=api_version,\n        credentials_dir=credentials_dir,\n        credentials_file_name=credentials_file_name\n    )\n\n    drive_client = auth.authenticate_google_server()\n    return drive_client\n\n\ndef get_youtube_client() -> YouTube:\n    client_secrets_file: str = \"/home/lyle/oryks/backend/api/libraries/youtube.json\"\n    youtube: YouTube = YouTube(client_secret_file=client_secrets_file)\n    return youtube",
  "    # channel_playlists = get_channel_playlists('UC5WVOSvL9bc6kwCMXXeFLLw')\n    # playlist_items = get_playlist_items('PLouh1K1d9jkYZo8h1zPH3P1ScAWA8gxbu')\n    # playlist_video_ids = list(map(get_playlist_item_video_id, playlist_items))\n    # playlist_videos = get_videos(playlist_video_ids)\n    video_comments = get_video_comments('pIzyo4cCGxU')\n    print(video_comments)\n\nif __name__ == '__main__':\n    main()",
  "def create_post(post_data: CreatePost, post_image: dict, session: Session):\n    post_image_url: str = save_post_photo(post_image)\n    post: Post = Post(\n        id='Post_' + str(uuid4()),\n        author_id=post_data.author_id,\n        location=post_data.location,\n        text=post_data.text,\n        image_url=post_image_url\n    )\n    with session() as db:\n        db.add(post)\n        db.commit()\n        db.refresh(post)\n    return post",
  "import imgviz\nfrom qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\n\nimport labelme.ai\nimport labelme.utils\nfrom labelme import QT5\nfrom labelme.logger import logger\nfrom labelme.shape import Shape\n\n# TODO(unknown):\n# - [maybe] Find optimal epsilon value.\n\n\nCURSOR_DEFAULT = QtCore.Qt.ArrowCursor\nCURSOR_POINT = QtCore.Qt.PointingHandCursor\nCURSOR_DRAW = QtCore.Qt.CrossCursor\nCURSOR_MOVE = QtCore.Qt.ClosedHandCursor\nCURSOR_GRAB = QtCore.Qt.OpenHandCursor\n\nMOVE_SPEED = 5.0\n\n\nclass Canvas(QtWidgets.QWidget):\n    zoomRequest = QtCore.Signal(int, QtCore.QPoint)\n    scrollRequest = QtCore.Signal(int, int)\n    newShape = QtCore.Signal()\n    selectionChanged = QtCore.Signal(list)\n    shapeMoved = QtCore.Signal()\n    drawingPolygon = QtCore.Signal(bool)\n    vertexSelected = QtCore.Signal(bool)\n\n    CREATE, EDIT = 0, 1\n\n    # polygon, rectangle, line, or point\n    _createMode = \"polygon\"\n\n    _fill_drawing = False\n\n",
  "class User(Base):\n    __tablename__ = 'users'\n    \n    id: Mapped[str] = mapped_column(primary_key=True)\n    first_name: Mapped[str]\n    last_name: Mapped[str]\n    email_address: Mapped[str] = mapped_column(unique=True)\n    password: Mapped[str]\n    registration_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    role: Mapped[str] = mapped_column(default='user')\n    activated: Mapped[bool] = mapped_column(default=False)\n    profile_picture_url: Mapped[str] = mapped_column(default='default.jpeg')\n    \n    posts = relationship('Post', back_populates='author')\n    bookmarks = relationship('Bookmark', back_populates='author')\n    likes = relationship('Like', back_populates='author')\n    comments = relationship('Comment', back_populates='author')\n    views = relationship('View', back_populates='author')\n    \n    @staticmethod\n    def hash_password(password: str) -> str:\n        return bcrypt.generate_password_hash(password).decode(\"utf-8\")\n\n    def check_password(self, password: str) -> bool:\n        return bcrypt.check_password_hash(self.password, password)",
  "from ..schemas.user import UserCreate\nfrom sqlalchemy.orm import Session\nfrom ....extensions.extensions import bcrypt\nfrom ..models.user import User\nfrom ..schemas.user import User as Userschemas\nfrom ..schemas.user import (\n    GetUser, GetUsers, ActivateUser, LoginUser, RequestPasswordReset, PasswordReset\n)\nfrom typing import Optional\nfrom jwt import ExpiredSignatureError, InvalidTokenError\nfrom uuid import uuid4\nfrom typing import Callable",
  "@post.route(\"/update\", methods=[\"PUT\"])\ndef update_one_post():\n    \"\"\"Update a post.\"\"\"\n    if request.method == 'GET':\n        return {'success': 'post creation form'}, HTTPStatus.OK\n    elif request.method == 'PUT':\n        try:\n            post_data = UpdatePost(\n                **request.form\n            )\n        except ValidationError:\n            return {'Error': 'The data provided is invalid or incomplete!'}, HTTPStatus.BAD_REQUEST\n        try:\n            user_data = GetUser(user_id=post_data.author_id)\n            user: User = get_user(session=get_db, user_data=user_data)\n            if not user:\n                return {'Error': f'User with id {user_data.user_id} does not exists'}, HTTPStatus.NOT_FOUND \n            post: Post = get_post(session=get_db, post_data=post_data)\n            if not post:\n                return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n            if user.id != post.author_id:\n                return {'Error': 'You can only update your own post!'}, HTTPStatus.FORBIDDEN\n            post: Post = update_post(post_data=post_data, post_image=request.files, session=get_db) \n        except (OperationalError, IntegrityError) as e:\n            print(e)\n            # Send email to\n            return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n        resp = CreatedPost(\n            id=post.id,\n            location=post.location,\n            text=post.text,\n            image_url=post.image_url,\n            author_id=post.author_id,\n            date_published=post.date_published\n        )\n        return resp.model_dump_json(indent=4), HTTPStatus.CREATED",
  "import torch\nfrom tqdm import tqdm\nfrom torch.nn import CrossEntropyLoss\nfrom torch import optim\nfrom torchvision.transforms import Compose, Resize, RandomCrop, ToTensor, Normalize\nfrom torch.utils.tensorboard import SummaryWriter\nfrom utils import save_checkpoint, load_checkpoint, print_examples\nfrom create_dataset import get_loader\nfrom model import CNNToRNN\n\n\ndef train():\n    transforms = Compose(\n        [\n            Resize((356, 356)),\n            RandomCrop((299, 299)),\n            ToTensor(),\n            Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ]\n    )\n\n    train_loader, dataset = get_loader(\n        images_dir=\"raw-data/Images\",\n        captions_file=\"raw-data/captions.txt\",\n        transforms=transforms,\n        num_workers=2,\n    )\n\n    torch.backends.cudnn.benchmark = True\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    load_model = False\n    save_model = False\n    train_CNN = False\n\n    # Hyperparameters\n    embed_size = 256\n    hidden_size = 256\n    vocab_size = len(dataset.vocabulary)\n    num_layers = 1\n    learning_rate = 3e-4\n",
  "\n    # Message Dialogs. #\n    def hasLabels(self):\n        if self.noShapes():\n            self.errorMessage(\n                \"No objects labeled\",\n                \"You must label at least one object to save the file.\",\n            )\n            return False\n        return True\n\n    def hasLabelFile(self):\n        if self.filename is None:\n            return False\n\n        label_file = self.getLabelFile()\n        return osp.exists(label_file)\n\n    def mayContinue(self):\n        if not self.dirty:\n            return True\n        mb = QtWidgets.QMessageBox\n        msg = self.tr('Save annotations to \"{}\" before closing?').format(self.filename)\n        answer = mb.question(\n            self,\n            self.tr(\"Save annotations?\"),\n            msg,\n            mb.Save | mb.Discard | mb.Cancel,\n            mb.Save,\n        )\n        if answer == mb.Discard:\n            return True\n        elif answer == mb.Save:\n            self.saveFile()\n            return True\n        else:  # answer == mb.Cancel\n            return False\n\n    def errorMessage(self, title, message):\n        return QtWidgets.QMessageBox.critical(\n",
  "        self.labelPreview.setHidden(True)\n\n        box = QtWidgets.QVBoxLayout()\n        box.addWidget(self.labelPreview)\n        box.addStretch()\n\n        self.setFixedSize(self.width() + 300, self.height())\n        self.layout().addLayout(box, 1, 3, 1, 1)\n        self.currentChanged.connect(self.onChange)\n\n    def onChange(self, path):\n        if path.lower().endswith(\".json\"):\n            with open(path, \"r\") as f:\n                data = json.load(f)\n                self.labelPreview.setText(json.dumps(data, indent=4, sort_keys=False))\n            self.labelPreview.label.setAlignment(\n                QtCore.Qt.AlignLeft | QtCore.Qt.AlignTop\n            )\n            self.labelPreview.setHidden(False)\n        else:\n            pixmap = QtGui.QPixmap(path)\n            if pixmap.isNull():\n                self.labelPreview.clear()\n                self.labelPreview.setHidden(True)\n            else:\n                self.labelPreview.setPixmap(\n                    pixmap.scaled(\n                        self.labelPreview.width() - 30,\n                        self.labelPreview.height() - 30,\n                        QtCore.Qt.KeepAspectRatio,\n                        QtCore.Qt.SmoothTransformation,\n                    )\n                )\n                self.labelPreview.label.setAlignment(QtCore.Qt.AlignCenter)\n                self.labelPreview.setHidden(False)\n",
  "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ[\"SECRET_KEY\"]\n    db_conn_string = 'sqlite:///./butterfly.db'\n    SQLALCHEMY_DATABASE_URI = db_conn_string\n    SQLALCHEMY_TRACK_MODIFICATIONS = False",
  "from helpers import redis\n\n\ndef analyzed_quotes():\n    sub = redis.pubsub()\n    sub.subscribe('analyzed_quotes')\n    for message in sub.listen():\n        if message and isinstance(message['data'], str):\n            quote: dict = message['data']\n            print(quote)\n            \nif __name__ == '__main__':\n    while True:\n        analyzed_quotes()",
  "def get_posts(session: Session, post_data: GetPosts):\n    with session() as db:\n        posts: list[Post] = db.query(Post).offset(post_data.offset).limit(post_data.limit).all()\n        for post in posts:\n            post.author\n        return posts\n\ndef delete_post(session: Session, post_data: GetPost):\n    with session() as db:\n        post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        db.delete(post)\n        db.commit()\n        \n    return post",
  "        else:\n            raise ValueError(\"Unsupported completion: {}\".format(completion))\n        completer.setModel(self.labelList.model())\n        self.edit.setCompleter(completer)\n\n    def addLabelHistory(self, label):\n        if self.labelList.findItems(label, QtCore.Qt.MatchExactly):\n            return\n        self.labelList.addItem(label)\n        if self._sort_labels:\n            self.labelList.sortItems()\n\n    def labelSelected(self, item):\n        self.edit.setText(item.text())\n\n    def validate(self):\n        text = self.edit.text()\n        if hasattr(text, \"strip\"):\n            text = text.strip()\n        else:\n            text = text.trimmed()\n        if text:\n            self.accept()\n\n    def labelDoubleClicked(self, item):\n        self.validate()\n\n    def postProcess(self):\n        text = self.edit.text()\n        if hasattr(text, \"strip\"):\n            text = text.strip()\n        else:\n            text = text.trimmed()\n        self.edit.setText(text)\n\n    def updateFlags(self, label_new):\n        # keep state of shared flags\n        flags_old = self.getFlags()\n\n        flags_new = {}\n",
  "from http import HTTPStatus\n\nfrom flask import Flask, Response, jsonify, make_response\n\n\ndef handle_resource_not_found(exeption: Exception) -> Response:\n    \"\"\"Handle all resource not found errors.\n\n    Called when an requested resource is not found on the server.\n\n    Parameters\n    ----------\n    exception: Exception\n        The exception that was raised. This is a subclass of Exception.\n\n    Returns\n    -------\n    Response:\n        A string consiting of json data and response code.\n    \"\"\"\n    return make_response(jsonify({\"error\": str(exeption)}), HTTPStatus.NOT_FOUND)",
  "    except HttpError as error:\n        print(F'An error occurred: {error}')\n        create_message = None\n    return create_message\n\ndef send_message(gmail_client, message):\n    try:\n        send_message = (gmail_client.users().messages().send\n                        (userId=\"me\", body=message).execute())\n        print(F'Message Id: {send_message[\"id\"]}')\n    except HttpError as error:\n        print(F'An error occurred: {error}')\n        send_message = None\n    return send_message\n\ndef get_gmail_client(secrets_file: str):\n    oauth: OAuth = OAuth(secrets_file=secrets_file)\n    gmail_client = oauth.authenticate()\n    return gmail_client",
  "        self.captions: pd.Series = self.df[\"caption\"]\n        \n        # Build vocabulary\n        self.vocabulary: Vocabulary = Vocabulary(freq_threshold=freq_threshold)\n        self.vocabulary.build_vocab(self.captions.tolist())\n        \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n        caption: str = self.captions[index]\n        img_id: str = self.images[index]\n        \n        image: Image = Image.open(os.path.join(self.images_dir, img_id)).convert(\"RGB\")\n        if self.transforms:\n            image = self.transforms(image)\n            \n        numericalized_caption: list[int] = [self.vocabulary.stoi[\"<SOS>\"]]\n        numericalized_caption += self.vocabulary.numericalize(caption)\n        numericalized_caption.append(self.vocabulary.stoi[\"<EOS>\"])\n        \n        return image, torch.tensor(numericalized_caption)\n            \n\nclass MyCollate:\n    def __init__(self, pad_idx: int) -> None:\n        self.pad_idx: int = pad_idx\n        \n    def __call__(self, batch: tuple[torch.Tensor, torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:\n        imgs = [item[0].unsqueeze(dim=0) for item in batch]\n        imgs = torch.cat(tensors=imgs, dim=0)\n        targets = [item[1] for item in batch]\n        targets = pad_sequence(sequences=targets, batch_first=False, padding_value=self.pad_idx)\n        \n        return imgs, targets\n    \n    \ndef get_loader(\n    images_dir: str,\n    captions_file: str,\n",
  "You are given the comments by various users on the review of {product}. Use the comments to answer \nthe questions that follow. When answering questions, try to list out your answer, with each answer \non its own separate line. If you do not know the answer, just say that you do not know. DO NOT MAKE \nSTUFF UP.\n---------\n{context}\nQuestion: {question}\nHelpful answer: \n\"\"\"\n\nproduct: str = \"iphone 15 pro max\"\ntemplate = PromptTemplate.from_template(template_str)\ntemplate = template.partial(product=product)\n\nvectordb = Chroma(\n    persist_directory=persist_directory,\n    embedding_function=embeddings\n)\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, api_key=api_key),\n    chain_type=\"stuff\",\n    return_source_documents=True,\n    retriever=vectordb.as_retriever(search_kwargs={\"k\": 10}),\n    chain_type_kwargs={\"prompt\": template}\n)\n\nwhile True:\n    query = input(\"User: \")\n    res = qa_chain.invoke(query)\n    print(res[\"result\"])",
  "    chat = OpenAI(temperature=0, api_key=api_key)\n    try:\n        chain = topic_assign_tmpl | chat | output_parser\n        res = chain.invoke(inputs)\n    except Exception:\n        pass\n    else:\n        print(res)\n        res = [\n            {\n                \"comment_id\": c.doc_id,\n                \"comment\": x[c.doc_id],\n                \"sentiment\": c.sentiment,\n                \"features\": c.topics\n            }\n            for c in res.comment\n        ]\n        print(res)\n        for y in res:\n            data.append(y)\n        with open('analysis.json', 'w') as f:\n            json.dump(data, fp=f, indent=4)\n        sleep(5)\n",
  "\nif __name__ == \"__main__\":\n    main()\n",
  "    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n    long_description=LONG_DESCRIPTION,\n    url='https://youtube-wrapper.readthedocs.io/en/latest/index.html',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Operating System :: OS Independent'\n    ],\n)\n",
  "\n# @app.before_request\n    # def rate_limit_request():\n    #     if request_is_rate_limited(r, 'admin', 10, timedelta(seconds=60)):\n    #         return {'Error': 'You have exceeded the allowed requests'}, HTTPStatus.TOO_MANY_REQUESTS\n",
  "\n        for i in range(self.uniqLabelList.count()):\n            label_i = self.uniqLabelList.item(i).data(Qt.UserRole)\n            if self._config[\"validate_label\"] in [\"exact\"]:\n                if label_i == label:\n                    return True\n        return False\n\n    def editLabel(self, item=None):\n        if item and not isinstance(item, LabelListWidgetItem):\n            raise TypeError(\"item must be LabelListWidgetItem type\")\n\n        if not self.canvas.editing():\n            return\n        if not item:\n            item = self.currentItem()\n        if item is None:\n            return\n        shape = item.shape()\n        if shape is None:\n            return\n        text, flags, group_id, description = self.labelDialog.popUp(\n            text=shape.label,\n            flags=shape.flags,\n            group_id=shape.group_id,\n            description=shape.description,\n        )\n        if text is None:\n            return\n        if not self.validateLabel(text):\n            self.errorMessage(\n                self.tr(\"Invalid label\"),\n                self.tr(\"Invalid label '{}' with validation type '{}'\").format(\n                    text, self._config[\"validate_label\"]\n                ),\n            )\n            return\n        shape.label = text\n        shape.flags = flags\n        shape.group_id = group_id\n",
  "#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}\n\n# Enable or disable spider middlewares\n# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    \"slidesmodel.middlewares.SlidesmodelSpiderMiddleware\": 543,\n#}\n\n# Enable or disable downloader middlewares\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#DOWNLOADER_MIDDLEWARES = {\n#    \"slidesmodel.middlewares.SlidesmodelDownloaderMiddleware\": 543,\n#}\n\n# Enable or disable extensions\n# See https://docs.scrapy.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    \"scrapy.extensions.telnet.TelnetConsole\": None,\n#}\n\n# Configure item pipelines\n# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\nITEM_PIPELINES = {\n   \"slidesmodel.pipelines.SlidesmodelPipeline\": 300,\n   \"slidesmodel.pipelines.MyImagesPipeline\": 1,\n   \"slidesmodel.pipelines.SaveSlidesPipeline\": 200,\n   \"slidesmodel.pipelines.DuplicatesPipeline\": 100,\n}\n\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n",
  "def create_logger(env=\"development\"):\n    app_logger = create_dev_logger()\n    if env == \"production\":\n        app_logger = create_prod_logger()\n    return app_logger\n\n\napp_logger = create_logger()\napp_logger.addHandler(logstash.TCPLogstashHandler(host='localhost', port=5959, version=1))",
  "        class_name_to_id[class_name] = class_id\n        data[\"categories\"].append(\n            dict(\n                supercategory=None,\n                id=class_id,\n                name=class_name,\n            )\n        )\n\n    out_ann_file = osp.join(args.output_dir, \"annotations.json\")\n    label_files = glob.glob(osp.join(args.input_dir, \"*.json\"))\n    for image_id, filename in enumerate(label_files):\n        print(\"Generating dataset from:\", filename)\n\n        label_file = labelme.LabelFile(filename=filename)\n\n        base = osp.splitext(osp.basename(filename))[0]\n        out_img_file = osp.join(args.output_dir, \"JPEGImages\", base + \".jpg\")\n\n        img = labelme.utils.img_data_to_arr(label_file.imageData)\n        imgviz.io.imsave(out_img_file, img)\n        data[\"images\"].append(\n            dict(\n                license=0,\n                url=None,\n                file_name=osp.relpath(out_img_file, osp.dirname(out_ann_file)),\n                height=img.shape[0],\n                width=img.shape[1],\n                date_captured=None,\n                id=image_id,\n            )\n        )\n\n        masks = {}  # for area\n        segmentations = collections.defaultdict(list)  # for segmentation\n        for shape in label_file.shapes:\n            points = shape[\"points\"]\n            label = shape[\"label\"]\n            group_id = shape.get(\"group_id\")\n            shape_type = shape.get(\"shape_type\", \"polygon\")\n",
  "            continue\n        else:\n            save_processed_file(\n                file_path=module_path, processed_module_code=new_module_code\n            )\n            format_file(module_path)\n            class_source_queue.task_done()\n",
  "from __future__ import annotations\n\nimport ast\nfrom abc import ABC, abstractmethod\nfrom ast import AST, FunctionDef\n\nfrom .helpers import parse_src\n\n\nclass Parser(ABC):\n    @abstractmethod\n    def set_next(self, parser: Parser) -> Parser:\n        pass\n\n    @abstractmethod\n    def parse(self, docstring: str) -> str:\n        pass\n\n\nclass AbstractParser(Parser):\n    _next_parser: Parser = None\n\n    def set_next(self, parser: Parser) -> Parser:\n        self._next_parser = parser\n        return parser\n\n    @abstractmethod\n    def parse(self, docstring: str) -> str:\n        if self._next_parser:\n            return self._next_parser.parse(docstring)\n        print(\"Unable to parse the docstring generated.\")\n        print(\"################################\")\n        print(docstring)\n        print(\"################################\")\n        return None\n\n\nclass DefaultParser(AbstractParser):\n    def parse(self, docstring: str) -> str:\n        try:\n",
  "from langchain_community.document_loaders.generic import GenericLoader\nfrom langchain_community.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain_community.document_loaders.blob_loaders.youtube_audio import (\n    YoutubeAudioLoader,\n)\nfrom os import path\n\n# Two Karpathy lecture videos\nurls = [\"https://www.youtube.com/watch?v=cBpGq-vDr2Y\"]\n\n# Directory to save audio files\ndata_dir = \"data\"\nvideo_data_dir = \"data\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"iphone_15_marques_review\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\n\nloader = GenericLoader(\n    YoutubeAudioLoader(urls, save_video_dir), OpenAIWhisperParser(api_key=api_key)\n)\ndocs = loader.load()\n\nfull_transcript = \"\"\nfor doc in docs:\n    full_transcript += doc.page_content\n\nwith open(save_transcript_dir, \"w\", encoding=\"utf-8\") as f:\n    f.write(full_transcript)\n\nprint(full_transcript)\n",
  "from dotenv import load_dotenv\nload_dotenv()\n# from assistant.utils.channel_utils import get_channel_latest_video, get_favorite_channels_latest_videos\n# from assistant.utils.playlist_utils import add_video_to_youtube_playlist\nfrom assistant.agent import get_agent_executor\n# from assistant.tools.playlist.helpers import list_playlist_videos\n# from assistant.tools.comment.helpers import list_video_comments\nfrom assistant.agent import get_tools\nfrom assistant.tools.comment.helpers import (\n    list_video_comments, find_my_comments, find_author_comments, list_comment_replies\n)\nfrom assistant.tools.channel.helpers import find_my_youtube_username\n\ntitle: str = 'Real Engineering'\n# print(get_favorite_channels_latest_videos())\n# title: str = 'How Nebula Works from Real Engineering'\n# playlist: str = 'Daily Videos'\n# add_video_to_youtube_playlist(title, playlist)\n# query = 'When was the youtube channel Ark Invest created?'\n# print(agent_executor.invoke({\"input\": query})['output'])\n# print(list_playlist_videos(title, title))\n#PLx7ERghZ6LoOKkmL4oeLoqWousfkKpdM_\n# print(list_video_comments('How Nebula Works', max_results=10))\n# query = 'When was my youtube channel created?'\n# agent_executor = get_agent_executor()\n# print(agent_executor.invoke({\"input\": query})['output'])\n# tools = get_tools(query)\n# print(len(tools))\n# t = [tool.description for tool in tools]\n# print(t)\n# print(find_author_comments('Trapping Rain Water - Google Interview Question - Leetcode 42', '@NeetCode'))\n\nquery = \"List all the replies to the comments by neetcode on the video titled 'Trapping Rain Water - Google Interview Question - Leetcode 42'\"\nagent_executor = get_agent_executor()\nprint(agent_executor.invoke({\"input\": query})['output'])\n# print(list_comment_replies('neetcode', 'Trapping Rain Water - Google Interview Question - Leetcode 42'))",
  "        if fit_to_content is None:\n            fit_to_content = {\"row\": False, \"column\": True}\n        self._fit_to_content = fit_to_content\n\n        super(LabelDialog, self).__init__(parent)\n        self.edit = LabelQLineEdit()\n        self.edit.setPlaceholderText(text)\n        self.edit.setValidator(labelme.utils.labelValidator())\n        self.edit.editingFinished.connect(self.postProcess)\n        if flags:\n            self.edit.textChanged.connect(self.updateFlags)\n        self.edit_group_id = QtWidgets.QLineEdit()\n        self.edit_group_id.setPlaceholderText(\"Group ID\")\n        self.edit_group_id.setValidator(\n            QtGui.QRegExpValidator(QtCore.QRegExp(r\"\\d*\"), None)\n        )\n        layout = QtWidgets.QVBoxLayout()\n        if show_text_field:\n            layout_edit = QtWidgets.QHBoxLayout()\n            layout_edit.addWidget(self.edit, 6)\n            layout_edit.addWidget(self.edit_group_id, 2)\n            layout.addLayout(layout_edit)\n        # buttons\n        self.buttonBox = bb = QtWidgets.QDialogButtonBox(\n            QtWidgets.QDialogButtonBox.Ok | QtWidgets.QDialogButtonBox.Cancel,\n            QtCore.Qt.Horizontal,\n            self,\n        )\n        bb.button(bb.Ok).setIcon(labelme.utils.newIcon(\"done\"))\n        bb.button(bb.Cancel).setIcon(labelme.utils.newIcon(\"undo\"))\n        bb.accepted.connect(self.validate)\n        bb.rejected.connect(self.reject)\n        layout.addWidget(bb)\n        # label_list\n        self.labelList = QtWidgets.QListWidget()\n        if self._fit_to_content[\"row\"]:\n            self.labelList.setHorizontalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOff)\n        if self._fit_to_content[\"column\"]:\n            self.labelList.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOff)\n        self._sort_labels = sort_labels\n",
  "            if not self.selectedShapes or (\n                self.hShape is not None and self.hShape not in self.selectedShapes\n            ):\n                self.selectShapePoint(pos, multiple_selection_mode=group_mode)\n                self.repaint()\n            self.prevPoint = pos\n\n    def mouseReleaseEvent(self, ev):\n        if ev.button() == QtCore.Qt.RightButton:\n            menu = self.menus[len(self.selectedShapesCopy) > 0]\n            self.restoreCursor()\n            if not menu.exec_(self.mapToGlobal(ev.pos())) and self.selectedShapesCopy:\n                # Cancel the move by deleting the shadow copy.\n                self.selectedShapesCopy = []\n                self.repaint()\n        elif ev.button() == QtCore.Qt.LeftButton:\n            if self.editing():\n                if (\n                    self.hShape is not None\n                    and self.hShapeIsSelected\n                    and not self.movingShape\n                ):\n                    self.selectionChanged.emit(\n                        [x for x in self.selectedShapes if x != self.hShape]\n                    )\n\n        if self.movingShape and self.hShape:\n            index = self.shapes.index(self.hShape)\n            if self.shapesBackups[-1][index].points != self.shapes[index].points:\n                self.storeShapes()\n                self.shapeMoved.emit()\n\n            self.movingShape = False\n\n    def endMove(self, copy):\n        assert self.selectedShapes and self.selectedShapesCopy\n        assert len(self.selectedShapesCopy) == len(self.selectedShapes)\n        if copy:\n            for i, shape in enumerate(self.selectedShapesCopy):\n                self.shapes.append(shape)\n",
  "      You an agent who converts detailed travel plans into a simple list of locations.\n\n      The itinerary will be denoted by four hashtags. Convert it into\n      list of places that they should visit. Try to include the specific address of each location.\n\n      Your output should always contain the start and end point of the trip, and may also include a list\n      of waypoints. It should also include a mode of transit. The number of waypoints cannot exceed 20.\n      If you can't infer the mode of transit, make a best guess given the trip location.\n\n      For example:\n\n      ####\n      Itinerary for a 2-day driving trip within London:\n      - Day 1:\n        - Start at Buckingham Palace (The Mall, London SW1A 1AA)\n        - Visit the Tower of London (Tower Hill, London EC3N 4AB)\n        - Explore the British Museum (Great Russell St, Bloomsbury, London WC1B 3DG)\n        - Enjoy shopping at Oxford Street (Oxford St, London W1C 1JN)\n        - End the day at Covent Garden (Covent Garden, London WC2E 8RF)\n      - Day 2:\n        - Start at Westminster Abbey (20 Deans Yd, Westminster, London SW1P 3PA)\n        - Visit the Churchill War Rooms (Clive Steps, King Charles St, London SW1A 2AQ)\n        - Explore the Natural History Museum (Cromwell Rd, Kensington, London SW7 5BD)\n        - End the trip at the Tower Bridge (Tower Bridge Rd, London SE1 2UP)\n      #####\n\n      Output:\n      Start: Buckingham Palace, The Mall, London SW1A 1AA\n      End: Tower Bridge, Tower Bridge Rd, London SE1 2UP\n      Waypoints: [\"Tower of London, Tower Hill, London EC3N 4AB\", \"British Museum, Great Russell St, Bloomsbury, London WC1B 3DG\", \"Oxford St, London W1C 1JN\", \"Covent Garden, London WC2E 8RF\",\"Westminster, London SW1A 0AA\", \"St. James's Park, London\", \"Natural History Museum, Cromwell Rd, Kensington, London SW7 5BD\"]\n      Transit: driving\n\n      Transit can be only one of the following options: \"driving\", \"train\", \"bus\" or \"flight\".\n\n      {format_instructions}\n    \"\"\"\n\n        self.human_template = \"\"\"\n      ####{agent_suggestion}####\n    \"\"\"\n",
  "from itemadapter import ItemAdapter\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.exceptions import DropItem\nfrom os import path, mkdir\nfrom scrapy.http import Response\nfrom scrapy import Request, Spider\nfrom scrapy import Item\nfrom pathlib import PurePosixPath\nfrom urllib.parse import urlparse\nfrom slidesmodel.models import db_connect, Tag, Category, Slide, create_table, create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport uuid\nimport logging\n\n\nclass SlidesmodelPipeline:\n    def process_item(self, item: Item, spider: Spider):\n        return item\n    \nclass MyImagesPipeline(ImagesPipeline):\n    def file_path(self, request: Request, response: Response = None, info=None, *, item=None):\n        slide_name: str = request.meta['title']\n        return f\"{slide_name}/\" + PurePosixPath(urlparse(request.url).path).name\n    \n    def get_media_requests(self, item: Item, info):\n        for image_url in item[\"image_urls\"]:\n            yield Request(image_url, meta={\"title\": item[\"title\"]})\n            \n\nclass SaveSlidesPipeline(object):\n    def __init__(self):\n        \"\"\"\n        Initializes database connection and sessionmaker\n        Creates tables\n        \"\"\"\n        engine = db_connect()\n        create_table(engine)\n        self.Session = sessionmaker(bind=engine)\n\n\n",
  "@post.route(\"/load_more_comments\", methods=[\"GET\"])\ndef load_more_comments():\n    \"\"\"Get a single post.\"\"\"\n    offset: str = request.args.get('offset', 0)\n    limit: str = request.args.get('limit', 10)\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        comments: list[Comment] = list_post_comments(session=get_db, post_data=post_data, offset=offset, limit=limit)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    post_comments = []\n    for comment in comments:\n        comment_author: PostAuthor = PostAuthor(\n            id=comment.author.id,\n            profile_picture=url_for('static', filename=f'img/{comment.author.profile_picture_url}'),\n            name=comment.author.first_name\n        )\n        comment_schema: CommentSchema = CommentSchema(\n            author=comment_author,\n            text=comment.comment_text\n        )\n        post_comments.append(comment_schema.model_dump())\n    return post_comments",
  "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport argparse\nimport glob\nimport os\nimport os.path as osp\nimport sys\n\nimport imgviz\n\nimport labelme\n\ntry:\n    import lxml.builder\n    import lxml.etree\nexcept ImportError:\n    print(\"Please install lxml:\\n\\n    pip install lxml\\n\")\n    sys.exit(1)\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"input_dir\", help=\"input annotated directory\")\n    parser.add_argument(\"output_dir\", help=\"output dataset directory\")\n    parser.add_argument(\"--labels\", help=\"labels file\", required=True)\n    parser.add_argument(\"--noviz\", help=\"no visualization\", action=\"store_true\")\n    args = parser.parse_args()\n\n    if osp.exists(args.output_dir):\n        print(\"Output directory already exists:\", args.output_dir)\n        sys.exit(1)\n    os.makedirs(args.output_dir)\n    os.makedirs(osp.join(args.output_dir, \"JPEGImages\"))\n    os.makedirs(osp.join(args.output_dir, \"Annotations\"))\n    if not args.noviz:\n        os.makedirs(osp.join(args.output_dir, \"AnnotationsVisualization\"))\n",
  "from langchain.agents import AgentType, initialize_agent\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.tools import BaseTool, StructuredTool, Tool, tool\nfrom dotenv import load_dotenv\nfrom pydantic.v1 import BaseModel, Field\nfrom typing import Optional, Type\nfrom pydantic_settings import BaseSettings\nfrom langchain.callbacks.manager import (\n    AsyncCallbackManagerForToolRun,\n    CallbackManagerForToolRun,\n)\nfrom youtube import YouTube\nfrom youtube.models import Search\nfrom youtube.resources.schemas import (\n    CreatePlaylistSchema, CreatePlaylistSnippet, CreateStatus, CreatePlaylistItem, CreatePlaylistItemSnippet,\n    VideoResourceId, YouTubeRequest, SearchPart, SearchOptionalParameters, SearchFilter, \n    YouTubeResponse\n)\n\n\nload_dotenv()\n\nclass Config(BaseSettings):\n    open_ai_token: str\n\nconfig: Config = Config()\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()\n\nclass YouTubeChannelTitleSearch(BaseModel):\n    title: str\n\n\nclass YouTubeChannelTitleSearchTool(BaseTool):\n    name = \"youtube_title_channel_search\"\n    description = \"\"\"\n    useful when you need to find information about a channel when provided with the title. \n    To use this tool you must provide the channel title.\n    \"\"\"\n",
  "from scrapy import Item, Field\nfrom itemloaders.processors import TakeFirst, MapCompose, Join\nimport re\n\n\ndef remove_html_tags(description: str) -> str:\n    html_pattern = \"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\" \n    return re.sub(html_pattern, '', description)\n\ndef remove_unicode_chars(text: str) -> str:\n    return text.replace(u\"\\xa0\", \"\")\n\ndef num_of_slides(text: str) -> int:\n    vals = [val for val in list(text) if val.isdigit()]\n    return \"\".join(vals)\n\n\nclass SlidesModelItem(Item):\n    title = Field(output_processor=TakeFirst())\n    category = Field(output_processor=TakeFirst())\n    description = Field(\n        input_processor=MapCompose(remove_html_tags, remove_unicode_chars),\n        output_processor=Join()\n    )\n    tags = Field()\n    slides_count = Field(\n        input_processor=MapCompose(num_of_slides),\n        output_processor=TakeFirst()\n    )\n    colors = Field()\n    image_urls = Field()\n    images = Field()\n",
  "def create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like",
  "    return timestamps\n\ndef partition_video_segments(video_id: str) -> TimeStamps:\n    video_segments: TimeStamps = get_timestamps(video_id=video_id)\n    return video_segments\n        \ndef get_description(video_id: str) -> str:\n    video_path: str = path.join(descriptions_dir, f\"{video_id}.txt\")\n    if not path.exists(video_path):\n        description: str = download_description(video_id=video_id)\n        save_description(description=description, video_id=video_id)\n    else:\n        with open(video_path, \"r\", encoding=\"utf-8\") as f:\n            description: str = f.read()\n    return description\n\n\ndef download_description(video_id: str) -> None:\n    response: YouTubeListResponse = youtube_client.find_video_by_id(video_id=video_id)\n    video: Video = response.items[0]\n    description: str = video.snippet.description\n    return description\n    \n    \nparser = PydanticOutputParser(pydantic_object=TimeStamps)\n\nsegment_str: str = (\"\"\"Extract the time stamps and their titles from the following text. Only\"\"\" \n                    \"\"\" include valid time stamps.\\n{format_instructions}\\ntext: ```{text}```\"\"\"\n)\n\ndef get_video_segments(video_description: str, segment_str: str = segment_str, \n                       llm: BaseLanguageModel = gemma_2b):\n    template: PromptTemplate = PromptTemplate(template=segment_str, \n                    input_variables=[\"text\"],\n                    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n                                              )\n    chain = template | llm | parser\n    inputs: dict[str, str] = {\n        \"text\": video_description\n    }\n",
  "import logging.config\nimport logstash\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef create_dev_logger():\n    \"\"\"Create the application logger.\"\"\"\n    config = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"standard\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n            },\n            \"json\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n                \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n            },\n        },\n        \"handlers\": {\n            \"standard\": {\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"json\",\n            },\n        },\n        \"loggers\": {\"\": {\"handlers\": [\"standard\"], \"level\": logging.INFO}},\n    }\n\n    logging.config.dictConfig(config)\n\n    logger = logging.getLogger(__name__)\n\n    return logger",
  "import collections\nimport threading\n\nimport imgviz\nimport numpy as np\nimport onnxruntime\nimport skimage\n\nfrom ..logger import logger\nfrom . import _utils\n\n\nclass EfficientSam:\n    def __init__(self, encoder_path, decoder_path):\n        self._encoder_session = onnxruntime.InferenceSession(encoder_path)\n        self._decoder_session = onnxruntime.InferenceSession(decoder_path)\n\n        self._lock = threading.Lock()\n        self._image_embedding_cache = collections.OrderedDict()\n\n        self._thread = None\n\n    def set_image(self, image: np.ndarray):\n        with self._lock:\n            self._image = image\n            self._image_embedding = self._image_embedding_cache.get(\n                self._image.tobytes()\n            )\n\n        if self._image_embedding is None:\n            self._thread = threading.Thread(\n                target=self._compute_and_cache_image_embedding\n            )\n            self._thread.start()\n\n    def _compute_and_cache_image_embedding(self):\n        with self._lock:\n            logger.debug(\"Computing image embedding...\")\n            image = imgviz.rgba2rgb(self._image)\n            batched_images = image.transpose(2, 0, 1)[None].astype(np.float32) / 255.0\n",
  "#!/usr/bin/env python\n\nimport argparse\nimport sys\n\nimport imgviz\nimport matplotlib.pyplot as plt\n\nfrom labelme import utils\nfrom labelme.label_file import LabelFile\n\nPY2 = sys.version_info[0] == 2\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"json_file\")\n    args = parser.parse_args()\n\n    label_file = LabelFile(args.json_file)\n    img = utils.img_data_to_arr(label_file.imageData)\n\n    label_name_to_value = {\"_background_\": 0}\n    for shape in sorted(label_file.shapes, key=lambda x: x[\"label\"]):\n        label_name = shape[\"label\"]\n        if label_name in label_name_to_value:\n            label_value = label_name_to_value[label_name]\n        else:\n            label_value = len(label_name_to_value)\n            label_name_to_value[label_name] = label_value\n    lbl, _ = utils.shapes_to_label(img.shape, label_file.shapes, label_name_to_value)\n\n    label_names = [None] * (max(label_name_to_value.values()) + 1)\n    for name, value in label_name_to_value.items():\n        label_names[value] = name\n    lbl_viz = imgviz.label2rgb(\n        lbl,\n        imgviz.asgray(img),\n        label_names=label_names,\n        font_size=30,\n",
  "            enabled=False,\n        )\n        createRectangleMode = action(\n            self.tr(\"Create Rectangle\"),\n            lambda: self.toggleDrawMode(False, createMode=\"rectangle\"),\n            shortcuts[\"create_rectangle\"],\n            \"objects\",\n            self.tr(\"Start drawing rectangles\"),\n            enabled=False,\n        )\n        createCircleMode = action(\n            self.tr(\"Create Circle\"),\n            lambda: self.toggleDrawMode(False, createMode=\"circle\"),\n            shortcuts[\"create_circle\"],\n            \"objects\",\n            self.tr(\"Start drawing circles\"),\n            enabled=False,\n        )\n        createLineMode = action(\n            self.tr(\"Create Line\"),\n            lambda: self.toggleDrawMode(False, createMode=\"line\"),\n            shortcuts[\"create_line\"],\n            \"objects\",\n            self.tr(\"Start drawing lines\"),\n            enabled=False,\n        )\n        createPointMode = action(\n            self.tr(\"Create Point\"),\n            lambda: self.toggleDrawMode(False, createMode=\"point\"),\n            shortcuts[\"create_point\"],\n            \"objects\",\n            self.tr(\"Start drawing points\"),\n            enabled=False,\n        )\n        createLineStripMode = action(\n            self.tr(\"Create LineStrip\"),\n            lambda: self.toggleDrawMode(False, createMode=\"linestrip\"),\n            shortcuts[\"create_linestrip\"],\n            \"objects\",\n            self.tr(\"Start drawing linestrip. Ctrl+LeftClick ends creation.\"),\n",
  "import ast\nfrom _ast import ClassDef, FunctionDef\nfrom ast import NodeTransformer\nfrom typing import Any\n\nfrom pydantic import BaseModel, Field\n\nfrom .config import Config\nfrom .helpers import (\n    generate_class_docstring,\n    generate_function_docstring,\n    get_class_docstring,\n    get_class_methods_docstrings,\n    get_function_docstring,\n    get_module_source_code,\n    make_docstring_node,\n)\n\n\nclass FunctionDocStringWriter(NodeTransformer, BaseModel):\n    module_path: str = Field(description='The path to this module')\n    function_name: str = Field(\n        description='The name of the function to generate docstrings'\n    )\n    function_code: str = Field(description='The source code for this function')\n    config: Config = Field(description='The application configurations.')\n\n    @property\n    def module_code(self) -> str:\n        return get_module_source_code(self.module_path)\n\n    def visit_FunctionDef(self, node: FunctionDef) -> Any:\n        docstring: str = ast.get_docstring(node=node)\n        if node.name == self.function_name and (\n            self.config.overwrite_function_docstring or not docstring\n        ):\n            function_code: str = ast.get_source_segment(\n                source=self.module_code, node=node, padded=True\n            )\n            function_and_docstring: str = generate_function_docstring(\n",
  "def add_user(user: User) -> User:\n    with get_db() as session:\n        session.add(user)\n        session.commit()\n        session.refresh(user)\n    return user\n\ndef add_post(post: Post) -> Post:\n    with get_db() as session:\n        session.add(post)\n        session.commit()\n        session.refresh(post)\n    return post\n\ndef add_likes(likes: list[Like]) -> None:\n    with get_db() as session:\n        for like in likes:\n            session.add(like)\n        session.commit()\n        \ndef add_bookmarks(bookmarks: list[Bookmark]) -> None:\n    with get_db() as session:\n        for bookmark in bookmarks:\n            session.add(bookmark)\n        session.commit()\n    \ndef add_comments(comments: list[Comment]) -> None:\n    with get_db() as session:\n        for comment in comments:\n            session.add(comment)\n        session.commit()",
  "            'youtube.resources.playlist',\n            'youtube.resources.playlist_item',\n            'youtube.resources.comment_thread',\n            'youtube.resources.channel',\n            'youtube.resources.activity',\n            'youtube.resources.subscription',\n            'youtube.exceptions',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n    long_description=LONG_DESCRIPTION,\n    url='https://youtube-wrapper.readthedocs.io/en/latest/index.html',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Operating System :: OS Independent'\n    ],\n)\n",
  "# MIT License\n# Copyright (c) Kentaro Wada\n\nimport base64\nimport io\n\nimport numpy as np\nimport PIL.ExifTags\nimport PIL.Image\nimport PIL.ImageOps\n\n\ndef img_data_to_pil(img_data):\n    f = io.BytesIO()\n    f.write(img_data)\n    img_pil = PIL.Image.open(f)\n    return img_pil\n\n\ndef img_data_to_arr(img_data):\n    img_pil = img_data_to_pil(img_data)\n    img_arr = np.array(img_pil)\n    return img_arr\n\n\ndef img_b64_to_arr(img_b64):\n    img_data = base64.b64decode(img_b64)\n    img_arr = img_data_to_arr(img_data)\n    return img_arr\n\n\ndef img_pil_to_data(img_pil):\n    f = io.BytesIO()\n    img_pil.save(f, format=\"PNG\")\n    img_data = f.getvalue()\n    return img_data\n\n\ndef img_arr_to_b64(img_arr):\n    img_data = img_arr_to_data(img_arr)\n",
  "        self.addDockWidget(Qt.RightDockWidgetArea, self.label_dock)\n        self.addDockWidget(Qt.RightDockWidgetArea, self.shape_dock)\n        self.addDockWidget(Qt.RightDockWidgetArea, self.file_dock)\n\n        # Actions\n        action = functools.partial(utils.newAction, self)\n        shortcuts = self._config[\"shortcuts\"]\n        quit = action(\n            self.tr(\"&Quit\"),\n            self.close,\n            shortcuts[\"quit\"],\n            \"quit\",\n            self.tr(\"Quit application\"),\n        )\n        open_ = action(\n            self.tr(\"&Open\\n\"),\n            self.openFile,\n            shortcuts[\"open\"],\n            \"open\",\n            self.tr(\"Open image or label file\"),\n        )\n        opendir = action(\n            self.tr(\"Open Dir\"),\n            self.openDirDialog,\n            shortcuts[\"open_dir\"],\n            \"open\",\n            self.tr(\"Open Dir\"),\n        )\n        openNextImg = action(\n            self.tr(\"&Next Image\"),\n            self.openNextImg,\n            shortcuts[\"open_next\"],\n            \"next\",\n            self.tr(\"Open next (hold Ctl+Shift to copy labels)\"),\n            enabled=False,\n        )\n        openPrevImg = action(\n            self.tr(\"&Prev Image\"),\n            self.openPrevImg,\n            shortcuts[\"open_prev\"],\n",
  "from langchain.output_parsers import PydanticOutputParser\nfrom langchain.pydantic_v1 import Field, BaseModel\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import OpenAI\nimport re\nimport json\nfrom langchain.docstore.document import Document\nfrom random import choices\nfrom langchain.base_language import BaseLanguageModel\n\nfile_path: str = \"comments.json\"\napi_key: str = \"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\"\n\n\ndef lower(text: str) -> str:\n    return text.lower().strip()\n\n\ndef remove_urls(text: str) -> str:\n    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n    text = re.sub(url_pattern, \"\", text)\n    return text\n\n\ndef remove_punctuations(text: str) -> str:\n    punctuation_pattern = r\"[^\\w\\s]\"\n    cleaned = re.sub(punctuation_pattern, \"\", text)\n    return cleaned\n\n\ndef clean_text(text: str) -> str:\n    text = lower(text)\n    text = remove_urls(text)\n    text = remove_punctuations(text)\n    return text\n\n\ndef is_acceptable_len(text: str, l=15) -> bool:\n    return len(text.split()) >= l\n\n",
  "from datetime import datetime\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\nfrom ..database import Base\nfrom sqlalchemy import ForeignKey\n\n\nclass Comment(Base):\n    __tablename__ = 'comments'\n    \n    id: Mapped[str] = mapped_column(primary_key=True)\n    author_id: Mapped[str] = mapped_column(ForeignKey('users.id'))\n    post_id: Mapped[str] = mapped_column(ForeignKey('posts.id'))\n    comment_text: Mapped[str]\n    comment_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    \n    author = relationship('User', back_populates='comments')\n    post = relationship('Post', back_populates='comments')",
  "#         outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n#         # outputs shape: (1, N, hidden_size)\n\n#         predictions = self.fc(outputs)\n\n#         # predictions shape: (1, N, length_target_vocabulary) to send it to\n#         # loss function we want it to be (N, length_target_vocabulary) so we're\n#         # just gonna remove the first dim\n#         predictions = predictions.squeeze(0)\n\n#         return predictions, hidden, cell\n\n\n# class Seq2Seq(nn.Module):\n#     def __init__(self, encoder, decoder):\n#         super(Seq2Seq, self).__init__()\n#         self.encoder = encoder\n#         self.decoder = decoder\n\n#     def forward(self, source, target, teacher_force_ratio=0.5):\n#         batch_size = source.shape[1]\n#         target_len = target.shape[0]\n#         target_vocab_size = len(english.vocab)\n\n#         outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n\n#         hidden, cell = self.encoder(source)\n\n#         # Grab the first input to the Decoder which will be <SOS> token\n#         x = target[0]\n\n#         for t in range(1, target_len):\n#             # Use previous hidden, cell as context from encoder at start\n#             output, hidden, cell = self.decoder(x, hidden, cell)\n\n#             # Store next output prediction\n#             outputs[t] = output\n\n#             # Get the best word the Decoder predicted (index in the vocabulary)\n#             best_guess = output.argmax(1)\n",
  "import logging.config\nimport logstash\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef create_dev_logger():\n    \"\"\"Create the application logger.\"\"\"\n    config = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"standard\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n            },\n            \"json\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n                \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n            },\n        },\n        \"handlers\": {\n            \"standard\": {\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"json\",\n            },\n        },\n        \"loggers\": {\"\": {\"handlers\": [\"standard\"], \"level\": logging.INFO}},\n    }\n\n    logging.config.dictConfig(config)\n\n    logger = logging.getLogger(__name__)\n\n    return logger",
  "    os.makedirs(osp.join(args.output_dir, \"JPEGImages\"))\n    os.makedirs(osp.join(args.output_dir, \"SegmentationClass\"))\n    if not args.nonpy:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationClassNpy\"))\n    if not args.noviz:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationClassVisualization\"))\n    if not args.noobject:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationObject\"))\n        if not args.nonpy:\n            os.makedirs(osp.join(args.output_dir, \"SegmentationObjectNpy\"))\n        if not args.noviz:\n            os.makedirs(osp.join(args.output_dir, \"SegmentationObjectVisualization\"))\n    print(\"Creating dataset:\", args.output_dir)\n\n    if osp.exists(args.labels):\n        with open(args.labels) as f:\n            labels = [label.strip() for label in f if label]\n    else:\n        labels = [label.strip() for label in args.labels.split(\",\")]\n\n    class_names = []\n    class_name_to_id = {}\n    for i, label in enumerate(labels):\n        class_id = i - 1  # starts with -1\n        class_name = label.strip()\n        class_name_to_id[class_name] = class_id\n        if class_id == -1:\n            assert class_name == \"__ignore__\"\n            continue\n        elif class_id == 0:\n            assert class_name == \"_background_\"\n        class_names.append(class_name)\n    class_names = tuple(class_names)\n    print(\"class_names:\", class_names)\n    out_class_names_file = osp.join(args.output_dir, \"class_names.txt\")\n    with open(out_class_names_file, \"w\") as f:\n        f.writelines(\"\\n\".join(class_names))\n    print(\"Saved class_names:\", out_class_names_file)\n\n    for filename in sorted(glob.glob(osp.join(args.input_dir, \"*.json\"))):\n",
  "from youtube.models import (\n    Playlist, PlaylistItem, Search\n)\nfrom api.database.models import Video\nfrom youtube import YouTube\nfrom youtube.resources.schemas import (\n    SearchPart, SearchFilter, SearchOptionalParameters\n)\nfrom youtube.resources.schemas import (\n    YouTubeResponse, CreateStatus, CreatePlaylistSnippet, CreatePlaylistSchema,\n    VideoResourceId, CreatePlaylistItemSnippet, CreatePlaylistItem, YouTubeRequest\n)\nfrom redis import Redis\nimport logging\nfrom dotenv import load_dotenv\nfrom config import RedisSettings, Config\nfrom api.database.models import Channel\nfrom api.database.crud import get_all_channels, get_channel_by_title\nfrom api.database.database import get_db\nfrom json import loads, dumps\nfrom datetime import timedelta\n\n\nload_dotenv()\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n\nredis_config: RedisSettings = RedisSettings()\nredis: Redis = Redis(\n    host=redis_config.redis_host,\n    port=redis_config.redis_port,\n    decode_responses=True\n)\nconfig: Config = Config()\n\n\ndef get_youtube_client(client_secret_file: str) -> YouTube:\n    logging.info('Creating the YouTube client.')\n    youtube: YouTube = YouTube(client_secret_file=client_secret_file)\n    logging.info('Authenticating the user.')\n    youtube.authenticate()\n",
  "        print(\"Generating dataset from:\", filename)\n\n        label_file = labelme.LabelFile(filename=filename)\n\n        base = osp.splitext(osp.basename(filename))[0]\n        out_img_file = osp.join(args.output_dir, \"JPEGImages\", base + \".jpg\")\n        out_clsp_file = osp.join(args.output_dir, \"SegmentationClass\", base + \".png\")\n        if not args.nonpy:\n            out_cls_file = osp.join(\n                args.output_dir, \"SegmentationClassNpy\", base + \".npy\"\n            )\n        if not args.noviz:\n            out_clsv_file = osp.join(\n                args.output_dir,\n                \"SegmentationClassVisualization\",\n                base + \".jpg\",\n            )\n        if not args.noobject:\n            out_insp_file = osp.join(\n                args.output_dir, \"SegmentationObject\", base + \".png\"\n            )\n            if not args.nonpy:\n                out_ins_file = osp.join(\n                    args.output_dir, \"SegmentationObjectNpy\", base + \".npy\"\n                )\n            if not args.noviz:\n                out_insv_file = osp.join(\n                    args.output_dir,\n                    \"SegmentationObjectVisualization\",\n                    base + \".jpg\",\n                )\n\n        img = labelme.utils.img_data_to_arr(label_file.imageData)\n        imgviz.io.imsave(out_img_file, img)\n\n        cls, ins = labelme.utils.shapes_to_label(\n            img_shape=img.shape,\n            shapes=label_file.shapes,\n            label_name_to_value=class_name_to_id,\n        )\n",
  "from itemadapter import ItemAdapter\nfrom scrapy.pipelines.images import ImagesPipeline\nfrom scrapy.exceptions import DropItem\nfrom os import path, mkdir\nfrom scrapy.http import Response\nfrom scrapy import Request, Spider\nfrom scrapy import Item\nfrom pathlib import PurePosixPath\nfrom urllib.parse import urlparse\nfrom slidesmodel.models import db_connect, Tag, Category, Slide, create_table, create_engine\nfrom sqlalchemy.orm import sessionmaker\nimport uuid\nimport logging\n\n\nclass SlidesmodelPipeline:\n    def process_item(self, item: Item, spider: Spider):\n        return item\n    \nclass MyImagesPipeline(ImagesPipeline):\n    def file_path(self, request: Request, response: Response = None, info=None, *, item=None):\n        slide_name: str = request.meta['title']\n        return f\"{slide_name}/\" + PurePosixPath(urlparse(request.url).path).name\n    \n    def get_media_requests(self, item: Item, info):\n        for image_url in item[\"image_urls\"]:\n            yield Request(image_url, meta={\"title\": item[\"title\"]})\n            \n\nclass SaveSlidesPipeline(object):\n    def __init__(self):\n        \"\"\"\n        Initializes database connection and sessionmaker\n        Creates tables\n        \"\"\"\n        engine = db_connect()\n        create_table(engine)\n        self.Session = sessionmaker(bind=engine)\n\n\n",
  "from collections.abc import Iterator\nfrom typing import Optional\nfrom youtube import YouTube\nfrom youtube.models import Search, Video\nfrom youtube.schemas import (\n    SearchOptionalParameters,\n    SearchPart,\n    YouTubeListResponse,\n    YouTubeRequest,\n    YouTubeResponse,\n)\nfrom youtube.models import Comment\nfrom youtube.schemas import (\n    CommentThreadFilter,\n    CommentThreadOptionalParameters,\n    CommentThreadPart,\n    YouTubeRequest,\n)\nimport json\n\n\ndef get_video_id(video_title: str) -> str:\n    \"\"\"Get video id given the title.\"\"\"\n    part: SearchPart = SearchPart()\n    optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n        q=video_title, maxResults=1, type=[\"video\"]\n    )\n    search_request: YouTubeRequest = YouTubeRequest(\n        part=part, optional_parameters=optional_parameters\n    )\n    search_results: YouTubeResponse = youtube_client.search(search_request)\n    search_result: Search = search_results.items[0]\n    return search_result.resource_id\n\n\ndef list_video_comments(video_id: str, max_results: Optional[int] = 2500) -> None:\n    \"\"\"List a given videos comments\"\"\"\n    # video_id: str = get_video_id(video_title)\n    part: CommentThreadPart = CommentThreadPart()\n    filter: CommentThreadFilter = CommentThreadFilter(videoId=video_id)\n",
  "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy.linkextractors import LinkExtractor \n\n\nclass SlidesLinkExtractor(Spider):\n    name: str = \"links-extractor\"\n    \n    start_urls: list[str] = [\n        \"https://slidesgo.com/\"\n    ]\n    \n    def __init__(self, name=None, **kwargs): \n        super().__init__(name, **kwargs) \n  \n        self.link_extractor = LinkExtractor(unique=True) \n  \n    def parse(self, response: Response, **kwargs: Any) -> Any: \n        self.logger.info(\"Links spider\")\n        links = response.css('li.w-1\\/2 a::attr(href)') \n  \n        for link in links: \n            yield {\n                    \"url\": link.get(), \n                }",
  "#         eventType='live',\n#         type=['video']\n#     )\n#     search = YouTubeRequest(part=part, optional_parameters=optional_parameters)\n#     results: list[Search] = youtube.search(search).items\n#     results: dict[str, Any] = [result.model_dump() for result in results]\n#     with open('live-news.json', 'w', encoding='utf-8') as f:\n#         dump(results, f, indent=4, default=str)\n#     print(results)\n    \n# search_save()\n# part: Part = CommentThreadPart()\n# filter: Filter = CommentThreadFilter(videoId='crYum29M-VE')\n# optional: OptionalParameters = CommentThreadOptionalParameters(\n#     maxResults=10\n# )\n# req: YouTubeRequest = YouTubeRequest(\n#     part=part,\n#     optional_parameters=optional,\n#     filter=filter\n# )\n# res: YouTubeResponse = youtube.find_video_comments(request=req)\n# print(res)\nprint(youtube.list_activities())",
  "        QtCore.QLocale.system().name(),\n        osp.dirname(osp.abspath(__file__)) + \"/translate\",\n    )\n    app = QtWidgets.QApplication(sys.argv)\n    app.setApplicationName(__appname__)\n    app.setWindowIcon(newIcon(\"icon\"))\n    app.installTranslator(translator)\n    win = MainWindow(\n        config=config,\n        filename=filename,\n        output_file=output_file,\n        output_dir=output_dir,\n    )\n\n    if reset_config:\n        logger.info(\"Resetting Qt config: %s\" % win.settings.fileName())\n        win.settings.clear()\n        sys.exit(0)\n\n    win.show()\n    win.raise_()\n    sys.exit(app.exec_())\n\n\n# this main block is required to generate executable by pyinstaller\nif __name__ == \"__main__\":\n    main()\n",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "print(parse_events(events.items))",
  "        # Since loading the file may take some time,\n        # make sure it runs in the background.\n        if self.filename is not None:\n            self.queueEvent(functools.partial(self.loadFile, self.filename))\n\n        # Callbacks:\n        self.zoomWidget.valueChanged.connect(self.paintCanvas)\n\n        self.populateModeActions()\n\n        # self.firstStart = True\n        # if self.firstStart:\n        #    QWhatsThis.enterWhatsThisMode()\n\n    def menu(self, title, actions=None):\n        menu = self.menuBar().addMenu(title)\n        if actions:\n            utils.addActions(menu, actions)\n        return menu\n\n    def toolbar(self, title, actions=None):\n        toolbar = ToolBar(title)\n        toolbar.setObjectName(\"%sToolBar\" % title)\n        # toolbar.setOrientation(Qt.Vertical)\n        toolbar.setToolButtonStyle(Qt.ToolButtonTextUnderIcon)\n        if actions:\n            utils.addActions(toolbar, actions)\n        self.addToolBar(Qt.TopToolBarArea, toolbar)\n        return toolbar\n\n    # Support Functions\n\n    def noShapes(self):\n        return not len(self.labelList)\n\n    def populateModeActions(self):\n        tool, menu = self.actions.tool, self.actions.menu\n        self.tools.clear()\n        utils.addActions(self.tools, tool)\n        self.canvas.menus[0].clear()\n",
  "class LoggedInUser(BaseModel):\n    email_address: str\n    access_token: str\n    refresh_token: str\n    \nclass RequestPasswordReset(BaseModel):\n    user_id: str\n    email_address: str\n    \nclass RequestPasswordResetToken(RequestPasswordReset):\n    password_reset_token: str\n    \nclass PasswordReset(BaseModel):\n    email_address: str\n    password_reset_token: str\n    password: str\n    confirm_password: str",
  "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom schemas import Model, UntrainedModel\nfrom os import path\nfrom config.config import app_config\nfrom datetime import datetime\n\n\nnames = [\n    \"Nearest Neighbors\",\n    \"Linear SVM\",\n    \"RBF SVM\",\n    \"Gaussian Process\",\n    \"Decision Tree\",\n    \"Random Forest\",\n    \"Neural Net\",\n    \"AdaBoost\",\n    \"Naive Bayes\",\n    \"QDA\",\n]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025, random_state=42),\n    SVC(gamma=2, C=1, random_state=42),\n    GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n    DecisionTreeClassifier(random_state=42),\n    RandomForestClassifier(\n        max_depth=5, n_estimators=10, max_features=1, random_state=42\n    ),\n    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n    AdaBoostClassifier(random_state=42),\n",
  "import json\n\nfrom qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\n\n\nclass ScrollAreaPreview(QtWidgets.QScrollArea):\n    def __init__(self, *args, **kwargs):\n        super(ScrollAreaPreview, self).__init__(*args, **kwargs)\n\n        self.setWidgetResizable(True)\n\n        content = QtWidgets.QWidget(self)\n        self.setWidget(content)\n\n        lay = QtWidgets.QVBoxLayout(content)\n\n        self.label = QtWidgets.QLabel(content)\n        self.label.setWordWrap(True)\n\n        lay.addWidget(self.label)\n\n    def setText(self, text):\n        self.label.setText(text)\n\n    def setPixmap(self, pixmap):\n        self.label.setPixmap(pixmap)\n\n    def clear(self):\n        self.label.clear()\n\n\nclass FileDialogPreview(QtWidgets.QFileDialog):\n    def __init__(self, *args, **kwargs):\n        super(FileDialogPreview, self).__init__(*args, **kwargs)\n        self.setOption(self.DontUseNativeDialog, True)\n\n        self.labelPreview = ScrollAreaPreview(self)\n        self.labelPreview.setFixedSize(300, 300)\n",
  "from api import create_app\nfrom api.helpers import generate_data, post_data\nimport os\n\n\napp = create_app()\n\ndef seed_data():\n    data = generate_data(count=1)\n    url: str = os.environ.get('url', 'http://127.0.0.1:8000/predict')\n    post_data(data=data, url=url)\n    \nif __name__ == '__main__':\n    seed_data()",
  "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport argparse\nimport glob\nimport os\nimport os.path as osp\nimport sys\n\nimport imgviz\nimport numpy as np\n\nimport labelme\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"input_dir\", help=\"Input annotated directory\")\n    parser.add_argument(\"output_dir\", help=\"Output dataset directory\")\n    parser.add_argument(\n        \"--labels\", help=\"Labels file or comma separated text\", required=True\n    )\n    parser.add_argument(\n        \"--noobject\", help=\"Flag not to generate object label\", action=\"store_true\"\n    )\n    parser.add_argument(\n        \"--nonpy\", help=\"Flag not to generate .npy files\", action=\"store_true\"\n    )\n    parser.add_argument(\n        \"--noviz\", help=\"Flag to disable visualization\", action=\"store_true\"\n    )\n    args = parser.parse_args()\n\n    if osp.exists(args.output_dir):\n        print(\"Output directory already exists:\", args.output_dir)\n        sys.exit(1)\n    os.makedirs(args.output_dir)\n",
  "    n_classes = 4\n    maizenet = MaizeNet(n_classes)\n    maizenet.load_state_dict(torch.load(model_path, map_location=torch.device('cpu') ))\n    return maizenet\n\ndef preprocess_image(image):\n    mean = np.array([0.5, 0.5, 0.5])\n    std = np.array([0.25, 0.25, 0.25])\n    data_transform = transforms.Compose([\n            transforms.RandomResizedCrop(224), # resize and crop image to 224 x 224 pixels\n            transforms.RandomHorizontalFlip(), # flip the images horizontally\n            transforms.ToTensor(), # convert to pytorch tensor data type\n            transforms.Normalize(mean, std) # normalize the input image dataset.\n        ])\n    transformed_image = data_transform(image).to('cpu')\n    transformed_image = torch.unsqueeze(transformed_image, 0)\n    return transformed_image\n\ndef evaluate_image(image, model):\n    transformed_image = preprocess_image(image)\n    labels = ['Maize Leaf Rust', 'Northern Leaf Blight', 'Healthy', 'Gray Leaf Spot']\n    model.eval()\n    prediction = F.softmax(model(transformed_image), dim = 1)\n    data = {\n        'Maize Leaf Rust': round(float(prediction[0][0]), 4) * 100,\n        'Northern Leaf Blight': round(float(prediction[0][1]) * 100, 4),\n        'Healthy': round(float(prediction[0][2]), 4) * 100,\n        'Gray Leaf Spot': round(float(prediction[0][3]) * 100, 4)\n    }\n    prediction = prediction.argmax()\n    return labels[prediction], data\n",
  "\n        delete = action(\n            self.tr(\"Delete Polygons\"),\n            self.deleteSelectedShape,\n            shortcuts[\"delete_polygon\"],\n            \"cancel\",\n            self.tr(\"Delete the selected polygons\"),\n            enabled=False,\n        )\n        duplicate = action(\n            self.tr(\"Duplicate Polygons\"),\n            self.duplicateSelectedShape,\n            shortcuts[\"duplicate_polygon\"],\n            \"copy\",\n            self.tr(\"Create a duplicate of the selected polygons\"),\n            enabled=False,\n        )\n        copy = action(\n            self.tr(\"Copy Polygons\"),\n            self.copySelectedShape,\n            shortcuts[\"copy_polygon\"],\n            \"copy_clipboard\",\n            self.tr(\"Copy selected polygons to clipboard\"),\n            enabled=False,\n        )\n        paste = action(\n            self.tr(\"Paste Polygons\"),\n            self.pasteSelectedShape,\n            shortcuts[\"paste_polygon\"],\n            \"paste\",\n            self.tr(\"Paste copied polygons\"),\n            enabled=False,\n        )\n        undoLastPoint = action(\n            self.tr(\"Undo last point\"),\n            self.canvas.undoLastPoint,\n            shortcuts[\"undo_last_point\"],\n            \"undo\",\n            self.tr(\"Undo last drawn point\"),\n            enabled=False,\n",
  "from .oryks_google_oauth import GoogleSlidesScope, GoogleOAuth, GoogleDirectories\nfrom typing import Optional\nfrom .ml import AnalyzedVideo, analayze_video, create_presentation\nfrom .ml.slide_requests import create_slide\n\nsecrets_file: str = \"/home/lyle/oryks/backend/api/libraries/slide.json\"\nscopes: list[str] = [\n    GoogleSlidesScope.slides.value,\n    GoogleSlidesScope.drive.value\n]\napi_service_name: str = \"slides\"\napi_version: str = \"v1\"\ncredentials_dir: str = GoogleDirectories.slides.value\ncredentials_file_name: Optional[str] = 'credentials.json'\n\nauth: GoogleOAuth = GoogleOAuth(\n    secrets_file=secrets_file,\n    scopes=scopes,\n    api_service_name=api_service_name,\n    api_version=api_version,\n    credentials_dir=credentials_dir\n)\n\n# slide_client = auth.authenticate_google_server()\n\n# video_transcript: str = \"\"\n# analyzed_video: AnalyzedVideo = analayze_video(video_transcript=video_transcript)\n# presentation_name: str = \"YouTube Video\"\n# response: dict = create_presentation(presentation_name=presentation_name, \n#                                      slide_client=slide_client, analyzed_video=analyzed_video)\n# presentation_id: str = \"1UutpJTI9VOp7u_5iBGCHnKV-YwljkV61HYrrvJMyVAg\"\n# response: dict = create_slide(presentation_id=presentation_id, slide_client=slide_client)\n\nfrom .youtube_helper import main\n\nmain()\n",
  "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "        train_time=train_results['train_time']\n    )\n    logging.info('Posting the model metrics.')\n    tuned_model.post_model_metrics(app_config, redis)\n    return {\n        'Model Name': train_results['model_name'],\n        'Train Time': train_results['train_time'],\n        'Metrics': train_results['metrics']\n    }\n    ",
  "            \n    def parse_link(self, response: Response, **kwargs: Any) -> Any:\n        # slide_item = response.meta[\"slide_item\"]\n        # loader = ItemLoader(item=slide_item, response=response)\n        # loader.add_css(field_name=\"tags\", css=\".Sm-tags a.mr-2::text\")\n        # loader.add_css(field_name=\"description\", css=\".product-text p\")\n        # loader.add_css(field_name=\"slides_count\", css='h4 small::text')\n        # loader.add_css(field_name=\"colors\", css='li.color a::text')\n        # loader.add_css(field_name=\"image_urls\", css='a.preview-link img::attr(src)')\n        # add slide link\n        # yield loader.load_item()\n        categories: list[dict] = []\n        cats = response.css('span.cat-links a')\n        for cat in cats:\n            category = cat.css('::text').get()\n            category_link = cat.css('::attr(href)').get()\n            categories.append({\n                \"category\": category,\n                \"link\": category_link\n            })\n        \n        yield {\n            \"categories\": categories,\n            \"title\": response.css('h1::text').get(),\n            \"problem\": response.css('.post-content p').getall(),\n            \"io\": response.css('.io').get(),\n            \"solutions\": response.css('h2::text').getall(), \n            \"link\": response.url,\n            \"code\": response.css('.c-line').getall()\n        }",
  "from datetime import datetime\nfrom uuid import uuid4\nfrom redis_om import Migrator\nfrom redis_om.model import NotFoundError\nfrom api.database.models import Video\nfrom youtube.models import Search\nfrom youtube import YouTube\nfrom youtube.resources.schemas import(\n    SearchFilter, SearchPart, SearchOptionalParameters, YouTubeRequest, YouTubeResponse\n)\n\n\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()\n\nMigrator().run()\n\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q='Python programming',\n#     maxResults=2,\n#     type=['video']\n# )\n# search: YouTubeRequest = YouTubeRequest(part=part, optional_parameters=optional_parameters)\n# response: YouTubeResponse = youtube.search(search)\n# search_resp: Search = response.items[0]\n\n# video: Video = Video(**search_resp.model_dump(exclude={'thumbnails'}))\n# print(video)\nvideos: list[Video] = Video.find().all()\n# for video in videos:\n#     video.expire(num_seconds=1)\nprint(videos)",
  "import torch\nimport os\nfrom torch import nn\nfrom torchvision import transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport random\n\n\nclass MaizeNet(nn.Module):\n  def __init__(self, K) -> None:\n      super(MaizeNet, self).__init__()\n\n      self.conv_layers = nn.Sequential(\n          # convolution 1\n          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.MaxPool2d(2),\n          # Convolution 2\n          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.MaxPool2d(2),\n          # Convolution 3\n          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
  "        self.tuned_model_ids = []\n        for model_path, _ in best_models:\n            logging.info(model_path)\n            model_name: str = model_path.split('/')[-1]\n            for model in models:\n                if model_name == model.classifier_name:\n                    train_config: TrainConfig = self.create_train_config(model.model, model.classifier_name, model.save_path)\n                    res = tune_model.apply_async((train_config,), \n                        link=train_tuned_model.s(train_config,)\n                    )\n                    self.tuned_model_ids.append(res.id)\n                    logging.info('%s queued for tuning and retraining.', model_name)\n                        \n    def get_tuned_models(self):\n        best_model_names = [name.split('/')[-1] for name, _ in self.get_best_models(start=-3, end=-1)]\n        while self.tuned_model_ids:\n            for index, id in enumerate(self.tuned_model_ids):\n                res: AsyncResult = AsyncResult(id)\n                if res.ready():\n                    logging.info('Tuned Model result for %s is ready.', res.result['name'])\n                    logging.info(res.result)\n                    self.tuned_model_ids.pop(index)\n                    best_model_names.remove(res.result['name'])\n                names = ', '.join(best_model_names)\n                if names:\n                    logging.info('Tuned Model result for %s are not ready.', names)\n                sleep(3)\n                \n    def create_train_config(self, model: BaseEstimator, name: str, save_path: str) -> TrainConfig:\n        (train_features, train_labels), (test_features, test_labels) = self.get_train_test_data()\n        train_config: TrainConfig = TrainConfig(\n            preprocessor=self.preprocessor,\n            model=model,\n            classifier_name=name,\n            save_path=save_path,\n            train_features=train_features,\n            train_labels=train_labels,\n            test_features=test_features,\n            test_labels=test_labels\n        )\n",
  "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\n\nfrom calendar_assistant.usecases.agent import agent_executor\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent_executor.invoke({\"input\": message.content})['output']\n    await msg.update()",
  "\"\"\"This module declares the extensions used by the application.\"\"\"\nfrom flask_bcrypt import Bcrypt\nfrom flask_cors import CORS\nfrom flask_login import LoginManager\nfrom flask_mail import Mail\nfrom flask_marshmallow import Marshmallow\nfrom flask_migrate import Migrate\nfrom flask_sqlalchemy import SQLAlchemy\n\ncors = CORS()\ndb = SQLAlchemy()\nmigrate = Migrate()\nma = Marshmallow()\nbcrypt = Bcrypt()\nlogin_manager = LoginManager()\nmail = Mail()\n",
  "    YouTubeChannelDetailsTool(),\n    DeleteYoutubePlaylistsTool(),\n    InsertVideoIntoPlaylistTool(),\n    CreatePlaylistTool(),\n    ListChannelPlaylistsTool(),\n    MyYouTubeChannelDetailsTool(),\n    FindUserCommentsTool(),\n    FindMyCommentsTool(),\n    ListVideoCommentRepliesTool(),\n    ReplyCommentTool(),\n]\n\n\ndef get_tools(query: str, tools: list[Tool] = tools) -> str:\n    \"\"\"Get the agent tools.\"\"\"\n    documents: list[Document] = [\n        Document(page_content=tool.description, metadata={\"index\": i})\n        for i, tool in enumerate(tools)\n    ]\n    vectore_store = FAISS.from_documents(documents, OpenAIEmbeddings())\n    retriver = vectore_store.as_retriever()\n    retrieved = retriver.get_relevant_documents(query)\n    return [tools[document.metadata[\"index\"]] for document in retrieved]\n\n\ndef get_agent_executor():\n    \"\"\"Get the agent\"\"\"\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\n                \"system\",\n                \"You are a funny and friendly youtube assistant. Your task is to help the user with tasks related to youtube..\",\n            ),\n            (\"user\", \"{input}\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n        ]\n    )\n\n    functions = [format_tool_to_openai_function(t) for t in tools]\n\n",
  "# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n\n\n# useful for handling different item types with a single interface\nfrom itemadapter import ItemAdapter\n\n\nclass LeetcodePipeline:\n    def process_item(self, item, spider):\n        return item\n",
  "\"\"\"This module declares application exceptions.\"\"\"\n\n\nclass DatabaseNotConnectedException(Exception):\n    \"\"\"Raised when the database is not connected.\"\"\"\n",
  "    plt.tight_layout()\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "def create_post(post_data: CreatePost, post_image: dict, session: Session):\n    post_image_url: str = save_post_photo(post_image)\n    post: Post = Post(\n        id='Post_' + str(uuid4()),\n        author_id=post_data.author_id,\n        location=post_data.location,\n        text=post_data.text,\n        image_url=post_image_url\n    )\n    with session() as db:\n        db.add(post)\n        db.commit()\n        db.refresh(post)\n    return post",
  "import distutils.spawn\nimport os\nimport re\nimport shlex\nimport subprocess\nimport sys\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n\ndef get_version():\n    filename = \"labelme/__init__.py\"\n    with open(filename) as f:\n        match = re.search(r\"\"\"^__version__ = ['\"]([^'\"]*)['\"]\"\"\", f.read(), re.M)\n    if not match:\n        raise RuntimeError(\"{} doesn't contain __version__\".format(filename))\n    version = match.groups()[0]\n    return version\n\n\ndef get_install_requires():\n    install_requires = [\n        \"gdown\",\n        \"imgviz>=1.7.5\",\n        \"matplotlib\",\n        \"natsort>=7.1.0\",\n        \"numpy\",\n        \"onnxruntime>=1.14.1,!=1.16.0\",\n        \"Pillow>=2.8\",\n        \"PyYAML\",\n        \"qtpy!=1.11.2\",\n        \"scikit-image\",\n        \"termcolor\",\n    ]\n\n    # Find python binding for qt with priority:\n    # PyQt5 -> PySide2\n    # and PyQt5 is automatically installed on Python3.\n    QT_BINDING = None\n",
  "from typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass Config(BaseModel):\n    path: set[str] = Field(description='The path to the source code directory')\n    overwrite_function_docstring: Optional[bool] = Field(\n        description='Whether or not to overwrite the existing function docstring',\n        default=False,\n    )\n    overwrite_class_docstring: Optional[bool] = Field(\n        description='Whether or not to overwrite the existing class docstring',\n        default=False,\n    )\n    overwrite_class_methods_docstring: Optional[bool] = Field(\n        description='Whether or not to overwrite the existing class methods docstring',\n        default=False,\n    )\n    documentation_style: Optional[str] = Field(\n        description='The format of documentation to use',\n        default='Numpy-Style',\n        enum=['Numpy-Style', 'Google-Style', 'Sphinx-Style'],\n    )\n    directories_ignore: set[str] = Field(\n        description='Directories to ignore',\n        default={'venv', '.venv', '__pycache__', '.git', 'build', 'dist', 'docs'},\n    )\n    files_ignore: set[str] = Field(\n        description='Files to ignore',\n        default_factory=set,\n    )\n",
  "chain = topic_assign_tmpl | chat | output_parser\nres = chain.invoke(inputs)\nprint(res)\n",
  "\nquery: str = \"\"\"\nFind the id of the youtube channel \"Ark Invest\", then using the id, find the number of subcribers \nfor the channel.\n\"\"\"\n\nres = agent.run(query)\nprint(res)",
  "import logging\n\nfrom .agent_state import AgentState\nfrom .states import State\nfrom .ui import BaseUI\n\n\nclass AgentNelly:\n    def __init__(self, ui: BaseUI, initial_state: State) -> None:\n        self._ui: BaseUI = ui\n        self._ui.agent = self\n        self._ui.launch()\n        self._agent_state = AgentState()\n        self.transition_to(initial_state)\n\n    @property\n    def ui(self) -> BaseUI:\n        return self._ui\n\n    @property\n    def agent_state(self) -> AgentState:\n        return self._agent_state\n\n    def transition_to(self, state: State) -> None:\n        if state:\n            logging.info(\"Transitioning to the state: %s\", type(state).__name__)\n            self._state = state\n            self._state.agent = self\n        else:\n            self._state = None\n\n    def analyze_product_review(self) -> None:\n        while self._state:\n            try:\n                self._state.execute()\n            except KeyboardInterrupt:\n                from .ui.utils import (agent_confirm_prompt,\n                                       agent_question_prompt)\n\n                end_chat: bool = agent_confirm_prompt(\n",
  "            'youtube.resources.mixins'\n        ]\n        ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n    long_description=LONG_DESCRIPTION,\n    url='https://youtube-wrapper.readthedocs.io/en/latest/index.html',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Operating System :: OS Independent'\n    ],\n)\n",
  "from .register_blueprints import register_blueprints",
  "from sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, MappedAsDataclass\nfrom sqlalchemy.orm import sessionmaker\nfrom ...config.config import BaseConfig\nfrom contextlib import contextmanager\nfrom flask import current_app\n\n\nclass Base(MappedAsDataclass, DeclarativeBase):\n    pass\n\nSQLALCHEMY_DATABASE_URI = BaseConfig().db_conn_string\nengine = create_engine(SQLALCHEMY_DATABASE_URI)\nSession = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n\ndef create_all():\n    Base.metadata.create_all(bind=engine)\n    \ndef drop_all():\n    Base.metadata.drop_all(bind=engine)\n\n@contextmanager\ndef get_db():\n    try:\n        db = Session()\n        yield db\n    finally:\n        db.close()",
  "# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# https://doc.scrapy.org/en/latest/topics/items.html\n\nfrom scrapy.item import Item, Field\nfrom itemloaders.processors import MapCompose, TakeFirst\nfrom datetime import datetime\n\n\ndef remove_quotes(text):\n    # strip the unicode quotes\n    text = text.strip(u'\\u201c'u'\\u201d')\n    return text\n\n\ndef convert_date(text):\n    # convert string March 14, 1879 to Python date\n    return datetime.strptime(text, '%B %d, %Y')\n\n\ndef parse_location(text):\n    # parse location \"in Ulm, Germany\"\n    # this simply remove \"in \", you can further parse city, state, country, etc.\n    return text[3:]\n\ndef parse_url(url: str) -> str:\n    url: str = [url.split('/')[-2]]\n    try:\n        int(url)\n    except:\n        return '1'\n    return url\n    \nclass TagItem(Item):\n    name = Field()\n\nclass QuoteItemSchema(Item):\n",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom crewai import Crew\nfrom textwrap import dedent\n\nfrom product_review_agents import ProductReviewAgents\nfrom product_review_tasks import ProductReviewTasks\n\n\nclass ProductReviewCrew:\n  def __init__(self, product):\n    self.product = product\n\n  def run(self):\n    agents = ProductReviewAgents()\n    tasks = ProductReviewTasks()\n\n    research_analyst_agent = agents.research_analyst()\n\n    research_task = tasks.research(research_analyst_agent, self.product)\n\n    crew = Crew(\n      agents=[\n        research_analyst_agent,\n      ],\n      tasks=[\n        research_task,\n      ],\n      verbose=True\n    )\n\n    result = crew.kickoff()\n    return result\n\nif __name__ == \"__main__\":\n  print(\"## Welcome to Product Analysis Crew\")\n  print('-------------------------------')\n  company = input(\n    dedent(\"\"\"\n      What is the product you want to analyze?\n",
  "from .find_product_reviews_tool import FindProductReviewTools\nfrom .find_product_tool import FindProductVideoTools",
  "from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom experiment_config import ExperimentConfig\n\n\ndef create_numeric_pipeline() -> Pipeline:\n    num_pipeline: Pipeline = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', StandardScaler())\n    ])\n    return num_pipeline\n\ndef create_categorical_pipeline() -> Pipeline:\n    cat_pipeline: Pipeline = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('encoder', OneHotEncoder())\n    ])\n    return cat_pipeline\n\ndef create_experiment_pipeline(experiment_config: ExperimentConfig) -> ColumnTransformer:\n    preprocessor: ColumnTransformer = ColumnTransformer(\n        transformers=[\n            ('drop_columns', 'drop', experiment_config.columns_to_drop),\n            ('num', create_numeric_pipeline(), experiment_config.numerical_features),\n            ('cat', create_categorical_pipeline(), experiment_config.categorical_features)\n        ],\n        remainder='passthrough'\n    )\n    return preprocessor",
  "import ast\nfrom queue import Empty, Queue\n\nfrom .config import Config\nfrom .docstring_writer import ClassDocStringWriter, FunctionDocStringWriter\nfrom .helpers import (\n    format_file,\n    get_class_source,\n    get_functions_source,\n    get_module_source_code,\n    save_processed_file,\n)\n\n\ndef queue_unprocessed_functions_methods(\n    functions_source_queue: Queue, classes_source_queue: Queue, module_path_queue: Queue\n) -> None:\n    while True:\n        try:\n            module_path: str = module_path_queue.get()\n            functions: list[str] = get_functions_source(module_path)\n            for function_name, function_code in functions:\n                functions_source_queue.put((module_path, function_name, function_code))\n            classes: list[str] = get_class_source(module_path)\n            for class_name, class_code in classes:\n                classes_source_queue.put((module_path, class_name, class_code))\n        except Empty:\n            continue\n        else:\n            module_path_queue.task_done()\n\n\ndef generate_function_docstrings(functions_source_queue: Queue, config: Config) -> None:\n    \"\"\"Generate docstrings for this file.\"\"\"\n    while True:\n        try:\n            module_path, function_name, function_code = functions_source_queue.get()\n            module_tree = ast.parse(get_module_source_code(module_path))\n            transformer = FunctionDocStringWriter(\n                module_path=module_path,\n",
  "    def process_item(self, item: Item, spider: Spider):\n        \"\"\"Save quotes in the database\n        This method is called for every item pipeline component\n        \"\"\"\n        session = self.Session()\n        \n        category = Category()\n        slide = Slide()\n        tag = Tag()\n        \n        slide.id = str(uuid.uuid4())\n        slide.description = item[\"description\"]\n        slide.title = item[\"title\"]\n        slide.image_urls = item[\"image_urls\"]\n        slide.image_paths = [image[\"path\"] for image in item[\"images\"]]\n        slide.colors = item[\"colors\"]\n        \n        category.id = str(uuid.uuid4())\n        if item.get(\"category\"):\n            category.name = item[\"category\"]\n        else:\n            category.name = \"\"\n\n        # check whether the category exists\n        exist_category = session.query(Category).filter_by(name=category.name).first()\n        if exist_category is not None:  # the current category exists\n            slide.category = exist_category\n        else:\n            slide.category = category\n\n        # check whether the current quote has tags or not\n        for tag_name in item[\"tags\"]:\n            tag = Tag(name=tag_name, id=str(uuid.uuid4()))\n            # check whether the current tag already exists in the database\n            exist_tag = session.query(Tag).filter_by(name=tag.name).first()\n            if exist_tag is not None:  # the current tag exists\n                tag = exist_tag\n            slide.tags.append(tag)\n\n        try:\n",
  "from qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\n\n\nclass ZoomWidget(QtWidgets.QSpinBox):\n    def __init__(self, value=100):\n        super(ZoomWidget, self).__init__()\n        self.setButtonSymbols(QtWidgets.QAbstractSpinBox.NoButtons)\n        self.setRange(1, 1000)\n        self.setSuffix(\" %\")\n        self.setValue(value)\n        self.setToolTip(\"Zoom Level\")\n        self.setStatusTip(self.toolTip())\n        self.setAlignment(QtCore.Qt.AlignCenter)\n\n    def minimumSizeHint(self):\n        height = super(ZoomWidget, self).minimumSizeHint().height()\n        fm = QtGui.QFontMetrics(self.font())\n        width = fm.width(str(self.maximum()))\n        return QtCore.QSize(width, height)\n",
  "\n    def moveShape(self):\n        self.canvas.endMove(copy=False)\n        self.setDirty()\n\n    def openDirDialog(self, _value=False, dirpath=None):\n        if not self.mayContinue():\n            return\n\n        defaultOpenDirPath = dirpath if dirpath else \".\"\n        if self.lastOpenDir and osp.exists(self.lastOpenDir):\n            defaultOpenDirPath = self.lastOpenDir\n        else:\n            defaultOpenDirPath = osp.dirname(self.filename) if self.filename else \".\"\n\n        targetDirPath = str(\n            QtWidgets.QFileDialog.getExistingDirectory(\n                self,\n                self.tr(\"%s - Open Directory\") % __appname__,\n                defaultOpenDirPath,\n                QtWidgets.QFileDialog.ShowDirsOnly\n                | QtWidgets.QFileDialog.DontResolveSymlinks,\n            )\n        )\n        self.importDirImages(targetDirPath)\n\n    @property\n    def imageList(self):\n        lst = []\n        for i in range(self.fileListWidget.count()):\n            item = self.fileListWidget.item(i)\n            lst.append(item.text())\n        return lst\n\n    def importDroppedImageFiles(self, imageFiles):\n        extensions = [\n            \".%s\" % fmt.data().decode().lower()\n            for fmt in QtGui.QImageReader.supportedImageFormats()\n        ]\n\n",
  "\ndef _compute_mask_from_points(\n    image_size, decoder_session, image, image_embedding, points, point_labels\n):\n    input_point = np.array(points, dtype=np.float32)\n    input_label = np.array(point_labels, dtype=np.int32)\n\n    onnx_coord = np.concatenate([input_point, np.array([[0.0, 0.0]])], axis=0)[\n        None, :, :\n    ]\n    onnx_label = np.concatenate([input_label, np.array([-1])], axis=0)[None, :].astype(\n        np.float32\n    )\n\n    scale, new_height, new_width = _compute_scale_to_resize_image(\n        image_size=image_size, image=image\n    )\n    onnx_coord = (\n        onnx_coord.astype(float)\n        * (new_width / image.shape[1], new_height / image.shape[0])\n    ).astype(np.float32)\n\n    onnx_mask_input = np.zeros((1, 1, 256, 256), dtype=np.float32)\n    onnx_has_mask_input = np.array([-1], dtype=np.float32)\n\n    decoder_inputs = {\n        \"image_embeddings\": image_embedding,\n        \"point_coords\": onnx_coord,\n        \"point_labels\": onnx_label,\n        \"mask_input\": onnx_mask_input,\n        \"has_mask_input\": onnx_has_mask_input,\n        \"orig_im_size\": np.array(image.shape[:2], dtype=np.float32),\n    }\n\n    masks, _, _ = decoder_session.run(None, decoder_inputs)\n    mask = masks[0, 0]  # (1, 1, H, W) -> (H, W)\n    mask = mask > 0.0\n\n    MIN_SIZE_RATIO = 0.05\n    skimage.morphology.remove_small_objects(\n",
  "\n#             # With probability of teacher_force_ratio we take the actual next word\n#             # otherwise we take the word that the Decoder predicted it to be.\n#             # Teacher Forcing is used so that the model gets used to seeing\n#             # similar inputs at training and testing time, if teacher forcing is 1\n#             # then inputs at test time might be completely different than what the\n#             # network is used to. This was a long comment.\n#             x = target[t] if random.random() < teacher_force_ratio else best_guess\n\n#         return outputs\n\n\n# ### We're ready to define everything we need for training our Seq2Seq model ###\n\n# # Training hyperparameters\n# num_epochs = 100\n# learning_rate = 0.001\n# batch_size = 64\n\n# # Model hyperparameters\n# load_model = False\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# input_size_encoder = len(german.vocab)\n# input_size_decoder = len(english.vocab)\n# output_size = len(english.vocab)\n# encoder_embedding_size = 300\n# decoder_embedding_size = 300\n# hidden_size = 1024  # Needs to be the same for both RNN's\n# num_layers = 2\n# enc_dropout = 0.5\n# dec_dropout = 0.5\n\n# # Tensorboard to get nice loss plot\n# writer = SummaryWriter(f\"runs/loss_plot\")\n# step = 0\n\n# train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n#     (train_data, valid_data, test_data),\n#     batch_size=batch_size,\n#     sort_within_batch=True,\n",
  "from langchain.chains import StuffDocumentsChain\nfrom langchain.chains.llm import LLMChain\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders.text import TextLoader\nfrom os import path\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms.base import BaseLLM\nfrom langchain_openai import ChatOpenAI, OpenAI\n\n\ndata_dir = \"./agent_nelly/data_analysis/data\"\nsummary_dir = \"summary\"\nsave_transcript_dir = path.join(data_dir, summary_dir, \"summary.txt\")\n\napi_key: str = \"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\"\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n\n\ntemplate_str: str = \"\"\"\nYou are provided with the transcript for a youtube video. The video is a review of the product {product}. \nReturn a JSON object with a single key ```features``` which is a list of all the {product} features mentioned.\nTranscript: {text} \n\"\"\"\n\nproduct: str = \"iphone 15 pro max\"\ntemplate = PromptTemplate.from_template(template_str)\ntemplate = template.partial(product=product)\n\napi_key: str = \"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\"\nchat: BaseLLM = ChatOpenAI(temperature=0, api_key=api_key)\nllm: BaseLLM = OpenAI(temperature=0, api_key=api_key)\n\nwith open(save_transcript_dir, 'r') as f:\n    summry: str = f.read()\n    \nchain = template | llm\nres = chain.invoke({\"text\": summry})\nprint(res)",
  "from youtube import YouTube\nfrom youtube.models import Search\nfrom youtube.resources.schemas import (\n    CreatePlaylistSchema, CreatePlaylistSnippet, CreateStatus, CreatePlaylistItem, CreatePlaylistItemSnippet,\n    VideoResourceId, YouTubeRequest, SearchPart, SearchOptionalParameters, SearchFilter,\n    CommentThreadPart, CommentThreadFilter, CommentThreadOptionalParameters, YouTubeResponse,\n    Part, Filter, OptionalParameters\n)\nfrom typing import Any\n\n\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()\n# part = Part()\n# optional_parameters: OptionalParameters = OptionalParameters(\n#     q='news',\n#     maxResults=2,\n#     eventType='live',\n#     type=['video']\n# )\n# optional_parameters: OptionalParameters = OptionalParameters(\n#     q='Python programming',\n#     maxResults=2,\n#     type=['video', 'channel', 'playlist'],\n# )\n# search = SearchSchema(part=part, optional_parameters=optional_parameters)\n\n# print(youtube.search(search))\n# search_iterator = youtube.get_search_iterator(search)\n# print(next(search_iterator))\n# print(next(search_iterator))\n# print(next(search_iterator))\n# print(youtube.find_video_by_id('rfscVS0vtbw'))\n# print(youtube.find_channel_by_name('East Meets West'))\n# print(youtube.get_video_ratings(['s7AvT7cGdSo']))\n# print(youtube.find_most_popular_video_by_regionn(region_code='KE'))\n# print(youtube.rate_video('s7AvT7cGdSo', 'like'))\n# print(youtube.update_video())\n# print(youtube.upload_video())\n",
  "\n    def boundedMoveVertex(self, pos):\n        index, shape = self.hVertex, self.hShape\n        point = shape[index]\n        if self.outOfPixmap(pos):\n            pos = self.intersectionPoint(point, pos)\n        shape.moveVertexBy(index, pos - point)\n\n    def boundedMoveShapes(self, shapes, pos):\n        if self.outOfPixmap(pos):\n            return False  # No need to move\n        o1 = pos + self.offsets[0]\n        if self.outOfPixmap(o1):\n            pos -= QtCore.QPointF(min(0, o1.x()), min(0, o1.y()))\n        o2 = pos + self.offsets[1]\n        if self.outOfPixmap(o2):\n            pos += QtCore.QPointF(\n                min(0, self.pixmap.width() - o2.x()),\n                min(0, self.pixmap.height() - o2.y()),\n            )\n        # XXX: The next line tracks the new position of the cursor\n        # relative to the shape, but also results in making it\n        # a bit \"shaky\" when nearing the border and allows it to\n        # go outside of the shape's area for some reason.\n        # self.calculateOffsets(self.selectedShapes, pos)\n        dp = pos - self.prevPoint\n        if dp:\n            for shape in shapes:\n                shape.moveBy(dp)\n            self.prevPoint = pos\n            return True\n        return False\n\n    def deSelectShape(self):\n        if self.selectedShapes:\n            self.setHiding(False)\n            self.selectionChanged.emit([])\n            self.hShapeIsSelected = False\n            self.update()\n\n",
  "def create_post(post_data: CreatePost, post_image: dict, session: Session):\n    post_image_url: str = save_post_photo(post_image)\n    post: Post = Post(\n        id='Post_' + str(uuid4()),\n        author_id=post_data.author_id,\n        location=post_data.location,\n        text=post_data.text,\n        image_url=post_image_url\n    )\n    with session() as db:\n        db.add(post)\n        db.commit()\n        db.refresh(post)\n    return post",
  "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport argparse\nimport glob\nimport os\nimport os.path as osp\nimport sys\n\nimport imgviz\nimport numpy as np\n\nimport labelme\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"input_dir\", help=\"Input annotated directory\")\n    parser.add_argument(\"output_dir\", help=\"Output dataset directory\")\n    parser.add_argument(\n        \"--labels\", help=\"Labels file or comma separated text\", required=True\n    )\n    parser.add_argument(\n        \"--noobject\", help=\"Flag not to generate object label\", action=\"store_true\"\n    )\n    parser.add_argument(\n        \"--nonpy\", help=\"Flag not to generate .npy files\", action=\"store_true\"\n    )\n    parser.add_argument(\n        \"--noviz\", help=\"Flag to disable visualization\", action=\"store_true\"\n    )\n    args = parser.parse_args()\n\n    if osp.exists(args.output_dir):\n        print(\"Output directory already exists:\", args.output_dir)\n        sys.exit(1)\n    os.makedirs(args.output_dir)\n",
  "import os\nfrom argparse import ArgumentParser, Namespace\nfrom os import path\n\nfrom .config import Config\n\n\ndef parse_arguments() -> Namespace:\n    parser = ArgumentParser(\n        prog=\"docstring-generator\",\n        description=\"Generate docstrings for your python projects\",\n        epilog=\"Thanks for using %(prog)s! :)\",\n    )\n    parser.add_argument(\"--path\", nargs=\"*\", default=[\".\"], type=str)\n    parser.add_argument(\"--config-file\", nargs=\"?\", default=\"\", type=str)\n    parser.add_argument(\"--OPENAI_API_KEY\", nargs=\"?\", default=\"\", type=str)\n    parser.add_argument(\n        \"--overwrite-function-docstring\", nargs=\"?\", default=False, type=bool\n    )\n    parser.add_argument(\"--directories-ignore\", nargs=\"*\", default=[], type=str)\n    parser.add_argument(\"--files-ignore\", nargs=\"*\", default=[], type=str)\n    parser.add_argument(\n        \"--documentation-style\",\n        nargs=\"?\",\n        default=\"Numpy-Style\",\n        choices=[\"Numpy-Style\", \"Google-Style\", \"Sphinx-Style\"],\n        type=str,\n    )\n    args = parser.parse_args()\n    paths: list[str] = args.path\n    for entry in paths:\n        if not path.exists(entry):\n            print(f\"The target path '{entry}' doesn't exist\")\n            raise SystemExit(1)\n    if args.OPENAI_API_KEY:\n        os.environ[\"OPENAI_API_KEY\"] = args.OPENAI_API_KEY\n    if not os.environ.get(\"OPENAI_API_KEY\", None):\n        print(\"You have not provided the open ai api key.\")\n        raise SystemExit(1)\n    return args\n",
  "# -*- encoding: utf-8 -*-\n\nimport html\n\nfrom qtpy import QtWidgets\nfrom qtpy.QtCore import Qt\n\nfrom .escapable_qlist_widget import EscapableQListWidget\n\n\nclass UniqueLabelQListWidget(EscapableQListWidget):\n    def mousePressEvent(self, event):\n        super(UniqueLabelQListWidget, self).mousePressEvent(event)\n        if not self.indexAt(event.pos()).isValid():\n            self.clearSelection()\n\n    def findItemByLabel(self, label):\n        for row in range(self.count()):\n            item = self.item(row)\n            if item.data(Qt.UserRole) == label:\n                return item\n\n    def createItemFromLabel(self, label):\n        if self.findItemByLabel(label):\n            raise ValueError(\"Item for label '{}' already exists\".format(label))\n\n        item = QtWidgets.QListWidgetItem()\n        item.setData(Qt.UserRole, label)\n        return item\n\n    def setItemLabel(self, item, label, color=None):\n        qlabel = QtWidgets.QLabel()\n        if color is None:\n            qlabel.setText(\"{}\".format(label))\n        else:\n            qlabel.setText(\n                '{} <font color=\"#{:02x}{:02x}{:02x}\">●</font>'.format(\n                    html.escape(label), *color\n                )\n            )\n",
  "    if hasattr(args, \"labels\"):\n        if os.path.isfile(args.labels):\n            with codecs.open(args.labels, \"r\", encoding=\"utf-8\") as f:\n                args.labels = [line.strip() for line in f if line.strip()]\n        else:\n            args.labels = [line for line in args.labels.split(\",\") if line]\n\n    if hasattr(args, \"label_flags\"):\n        if os.path.isfile(args.label_flags):\n            with codecs.open(args.label_flags, \"r\", encoding=\"utf-8\") as f:\n                args.label_flags = yaml.safe_load(f)\n        else:\n            args.label_flags = yaml.safe_load(args.label_flags)\n\n    config_from_args = args.__dict__\n    config_from_args.pop(\"version\")\n    reset_config = config_from_args.pop(\"reset_config\")\n    filename = config_from_args.pop(\"filename\")\n    output = config_from_args.pop(\"output\")\n    config_file_or_yaml = config_from_args.pop(\"config\")\n    config = get_config(config_file_or_yaml, config_from_args)\n\n    if not config[\"labels\"] and config[\"validate_label\"]:\n        logger.error(\n            \"--labels must be specified with --validatelabel or \"\n            \"validate_label: true in the config file \"\n            \"(ex. ~/.labelmerc).\"\n        )\n        sys.exit(1)\n\n    output_file = None\n    output_dir = None\n    if output is not None:\n        if output.endswith(\".json\"):\n            output_file = output\n        else:\n            output_dir = output\n\n    translator = QtCore.QTranslator()\n    translator.load(\n",
  "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchtext.datasets import Multi30k\nfrom torchtext.data import Field, BucketIterator\nimport numpy as np\nimport spacy\nimport random\nfrom torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\nfrom utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n\nspacy_ger = spacy.load(\"de\")\nspacy_eng = spacy.load(\"en\")\n\n\ndef tokenize_ger(text):\n    return [tok.text for tok in spacy_ger.tokenizer(text)]\n\n\ndef tokenize_eng(text):\n    return [tok.text for tok in spacy_eng.tokenizer(text)]\n\n\ngerman = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n\nenglish = Field(\n    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n)\n\ntrain_data, valid_data, test_data = Multi30k.splits(\n    exts=(\".de\", \".en\"), fields=(german, english)\n)\n\ngerman.build_vocab(train_data, max_size=10000, min_freq=2)\nenglish.build_vocab(train_data, max_size=10000, min_freq=2)\n\n\n# class Encoder(nn.Module):\n#     def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n#         super(Encoder, self).__init__()\n",
  "from langchain.chains import RetrievalQA\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom os import path\n\ndata_dir = \"data\"\nvideo_data_dir = \"data\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"iphone_15_marques_review\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\nwith open(save_transcript_dir, \"r\") as f:\n    video_transcript = f.read()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=150)\nsplits = text_splitter.split_text(video_transcript)\n\nembeddings = OpenAIEmbeddings(api_key=api_key)\nvectordb = FAISS.from_texts(splits, embeddings)\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, api_key=api_key),\n    chain_type=\"stuff\",\n    retriever=vectordb.as_retriever(),\n)\n\nfeatures: list[str] = [\n    \"5G connectivity\",\n    \"A15 Bionic chip\",\n    \"ProMotion display\",\n    \"Ceramic Shield front cover\",\n    \"Triple-camera system\",\n    \"LiDAR scanner\",\n    \"Night mode\",\n    \"Cinematic mode\",\n    \"Dolby Vision HDR recording\",\n    \"MagSafe charging\",\n",
  "# Define here the models for your spider middleware\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass SlidesmodelSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(self, response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(self, response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, or item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(self, response, exception, spider):\n        # Called when a spider or process_spider_input() method\n",
  "\"\"\"This module contains routes for the app.\"\"\"\nfrom flask import Blueprint, flash, jsonify, redirect, render_template, request, url_for\nfrom http import HTTPStatus\nfrom ..database.schemas.post import (\n    CreatePost, CreatedPost, GetPost, GetPosts, UpdatePost, PostSchema, PostAuthor\n)\nfrom ..database.crud.post import (\n    create_post, get_post, get_posts, delete_post, update_post\n)\nfrom ..database.models.post import Post\nfrom ..database.database import get_db\nfrom pydantic import ValidationError\nfrom sqlalchemy.exc import OperationalError, IntegrityError\nfrom ..database.models.user import User\nfrom ..database.crud.user import get_user\nfrom ..database.schemas.user import GetUser\nfrom ..database.models.bookmark import Bookmark\nfrom ..database.crud.bookmark import list_post_bookmarks\nfrom ..database.schemas.activity import ActivityCreated, RepeatableActivityCreated, CommentCreated\nfrom ..database.crud.like import list_post_likes\nfrom ..database.models.like import Like\nfrom ..database.models.comment import Comment\nfrom ..database.models.view import View\nfrom ..database.schemas.comment import CommentSchema\nfrom ..database.crud.view import (\n    list_post_views\n)\nfrom ..database.crud.comment import list_post_comments\nfrom ..home.helpers import load_posts\n\npost = Blueprint(\"post\", __name__)",
  "                    question=\"Are you sure you want to end this chat?\"\n                )\n                if end_chat:\n                    agent_question_prompt(\"Goodbye\")\n                    break\n",
  "from email.message import EmailMessage\nfrom base64 import urlsafe_b64encode\nfrom googleapiclient.errors import HttpError\nfrom oauth import OAuth\n\n\ndef create_draft(gmail_client) -> dict:\n    try:\n        message = EmailMessage()\n        message.set_content('This is automated draft mail')\n        message['To'] = 'lyleokothdev@gmail.com'\n        message['From'] = 'lyceokoth@gmail.com'\n        message['Subject'] = 'Automated draft'\n        # encoded message\n        encoded_message = urlsafe_b64encode(message.as_bytes()).decode()\n        create_message = {\n            'message': {\n                'raw': encoded_message\n            }\n        }\n        draft = gmail_client.users().drafts().create(userId=\"me\",body=create_message).execute()\n        print(f'Draft id: {draft[\"id\"]}\\nDraft message: {draft[\"message\"]}')\n    except HttpError as error:\n        print(f'An error occurred: {error}')\n        draft = None\n\n    return draft\n\ndef create_message():\n    try:\n        message = EmailMessage()\n        message.set_content('This is automated draft mail')\n        message['To'] = 'lyleokothdev@gmail.com'\n        message['From'] = 'lyceokoth@gmail.com'\n        message['Subject'] = 'Automated draft'\n        # encoded message\n        encoded_message = urlsafe_b64encode(message.as_bytes()).decode()\n        create_message = {\n            'raw': encoded_message\n        }\n",
  "        Returns\n        -------\n\n        \"\"\"\n        validation_agent = LLMChain(\n            llm=self.chat_model,\n            prompt=self.validation_prompt.chat_prompt,\n            output_parser=self.validation_prompt.parser,\n            output_key=\"validation_output\",\n            verbose=debug,\n        )\n\n        overall_chain = SequentialChain(\n            chains=[validation_agent],\n            input_variables=[\"query\", \"format_instructions\"],\n            output_variables=[\"validation_output\"],\n            verbose=debug,\n        )\n\n        return overall_chain\n\n    def _set_up_agent_chain(self, debug=True):\n        \"\"\"\n\n        Parameters\n        ----------\n        debug\n\n        Returns\n        -------\n\n        \"\"\"\n        travel_agent = LLMChain(\n            llm=self.chat_model,\n            prompt=self.itinerary_prompt.chat_prompt,\n            verbose=debug,\n            output_key=\"agent_suggestion\",\n        )\n\n        parser = LLMChain(\n",
  "# flake8: noqa\n\nimport logging\nimport sys\n\nfrom qtpy import QT_VERSION\n\n\n__appname__ = \"labelme\"\n\n# Semantic Versioning 2.0.0: https://semver.org/\n# 1. MAJOR version when you make incompatible API changes;\n# 2. MINOR version when you add functionality in a backwards-compatible manner;\n# 3. PATCH version when you make backwards-compatible bug fixes.\n# e.g., 1.0.0a0, 1.0.0a1, 1.0.0b0, 1.0.0rc0, 1.0.0, 1.0.0.post0\n__version__ = \"5.4.1\"\n\nQT4 = QT_VERSION[0] == \"4\"\nQT5 = QT_VERSION[0] == \"5\"\ndel QT_VERSION\n\nPY2 = sys.version[0] == \"2\"\nPY3 = sys.version[0] == \"3\"\ndel sys\n\nfrom labelme.label_file import LabelFile\nfrom labelme import testing\nfrom labelme import utils\n",
  "                self.labelFile.imagePath,\n            )\n            self.otherData = self.labelFile.otherData\n        else:\n            self.imageData = LabelFile.load_image_file(filename)\n            if self.imageData:\n                self.imagePath = filename\n            self.labelFile = None\n        image = QtGui.QImage.fromData(self.imageData)\n\n        if image.isNull():\n            formats = [\n                \"*.{}\".format(fmt.data().decode())\n                for fmt in QtGui.QImageReader.supportedImageFormats()\n            ]\n            self.errorMessage(\n                self.tr(\"Error opening file\"),\n                self.tr(\n                    \"<p>Make sure <i>{0}</i> is a valid image file.<br/>\"\n                    \"Supported image formats: {1}</p>\"\n                ).format(filename, \",\".join(formats)),\n            )\n            self.status(self.tr(\"Error reading %s\") % filename)\n            return False\n        self.image = image\n        self.filename = filename\n        if self._config[\"keep_prev\"]:\n            prev_shapes = self.canvas.shapes\n        self.canvas.loadPixmap(QtGui.QPixmap.fromImage(image))\n        flags = {k: False for k in self._config[\"flags\"] or []}\n        if self.labelFile:\n            self.loadLabels(self.labelFile.shapes)\n            if self.labelFile.flags is not None:\n                flags.update(self.labelFile.flags)\n        self.loadFlags(flags)\n        if self._config[\"keep_prev\"] and self.noShapes():\n            self.loadShapes(prev_shapes, replace=False)\n            self.setDirty()\n        else:\n            self.setClean()\n",
  "import chainlit as cl\nfrom assistant.utils.assistant_utils import welcome_user\nfrom assistant.agent import get_agent_executor\n\n\n@cl.on_chat_start\nasync def start():\n    res = await cl.AskUserMessage(content=\"What is your name?\", timeout=30).send()\n    if res:\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        msg.content = welcome_user(user_name=res['content'])\n        await msg.update()\n        \n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    query: str = message.content\n    agent_executor = get_agent_executor(query)\n    msg.content = agent_executor.invoke({\"input\": query})['output']\n    await msg.update()",
  "def create_post(post_data: CreatePost, post_image: dict, session: Session):\n    post_image_url: str = save_post_photo(post_image)\n    post: Post = Post(\n        id='Post_' + str(uuid4()),\n        author_id=post_data.author_id,\n        location=post_data.location,\n        text=post_data.text,\n        image_url=post_image_url\n    )\n    with session() as db:\n        db.add(post)\n        db.commit()\n        db.refresh(post)\n    return post",
  "                option.palette.color(QPalette.Active, QPalette.Text),\n            )\n\n        textRect = style.subElementRect(QStyle.SE_ItemViewItemText, options)\n\n        if index.column() != 0:\n            textRect.adjust(5, 0, 0, 0)\n\n        thefuckyourshitup_constant = 4\n        margin = (option.rect.height() - options.fontMetrics.height()) // 2\n        margin = margin - thefuckyourshitup_constant\n        textRect.setTop(textRect.top() + margin)\n\n        painter.translate(textRect.topLeft())\n        painter.setClipRect(textRect.translated(-textRect.topLeft()))\n        self.doc.documentLayout().draw(painter, ctx)\n\n        painter.restore()\n\n    def sizeHint(self, option, index):\n        thefuckyourshitup_constant = 4\n        return QtCore.QSize(\n            int(self.doc.idealWidth()),\n            int(self.doc.size().height() - thefuckyourshitup_constant),\n        )\n\n\nclass LabelListWidgetItem(QtGui.QStandardItem):\n    def __init__(self, text=None, shape=None):\n        super(LabelListWidgetItem, self).__init__()\n        self.setText(text or \"\")\n        self.setShape(shape)\n\n        self.setCheckable(True)\n        self.setCheckState(Qt.Checked)\n        self.setEditable(False)\n        self.setTextAlignment(Qt.AlignBottom)\n\n    def clone(self):\n        return LabelListWidgetItem(self.text(), self.shape())\n",
  "    os.makedirs(osp.join(args.output_dir, \"JPEGImages\"))\n    os.makedirs(osp.join(args.output_dir, \"SegmentationClass\"))\n    if not args.nonpy:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationClassNpy\"))\n    if not args.noviz:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationClassVisualization\"))\n    if not args.noobject:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationObject\"))\n        if not args.nonpy:\n            os.makedirs(osp.join(args.output_dir, \"SegmentationObjectNpy\"))\n        if not args.noviz:\n            os.makedirs(osp.join(args.output_dir, \"SegmentationObjectVisualization\"))\n    print(\"Creating dataset:\", args.output_dir)\n\n    if osp.exists(args.labels):\n        with open(args.labels) as f:\n            labels = [label.strip() for label in f if label]\n    else:\n        labels = [label.strip() for label in args.labels.split(\",\")]\n\n    class_names = []\n    class_name_to_id = {}\n    for i, label in enumerate(labels):\n        class_id = i - 1  # starts with -1\n        class_name = label.strip()\n        class_name_to_id[class_name] = class_id\n        if class_id == -1:\n            assert class_name == \"__ignore__\"\n            continue\n        elif class_id == 0:\n            assert class_name == \"_background_\"\n        class_names.append(class_name)\n    class_names = tuple(class_names)\n    print(\"class_names:\", class_names)\n    out_class_names_file = osp.join(args.output_dir, \"class_names.txt\")\n    with open(out_class_names_file, \"w\") as f:\n        f.writelines(\"\\n\".join(class_names))\n    print(\"Saved class_names:\", out_class_names_file)\n\n    for filename in sorted(glob.glob(osp.join(args.input_dir, \"*.json\"))):\n",
  "        self.toggleActions(True)\n        self.canvas.setFocus()\n        self.status(str(self.tr(\"Loaded %s\")) % osp.basename(str(filename)))\n        return True\n\n    def resizeEvent(self, event):\n        if (\n            self.canvas\n            and not self.image.isNull()\n            and self.zoomMode != self.MANUAL_ZOOM\n        ):\n            self.adjustScale()\n        super(MainWindow, self).resizeEvent(event)\n\n    def paintCanvas(self):\n        assert not self.image.isNull(), \"cannot paint null image\"\n        self.canvas.scale = 0.01 * self.zoomWidget.value()\n        self.canvas.adjustSize()\n        self.canvas.update()\n\n    def adjustScale(self, initial=False):\n        value = self.scalers[self.FIT_WINDOW if initial else self.zoomMode]()\n        value = int(100 * value)\n        self.zoomWidget.setValue(value)\n        self.zoom_values[self.filename] = (self.zoomMode, value)\n\n    def scaleFitWindow(self):\n        \"\"\"Figure out the size of the pixmap to fit the main widget.\"\"\"\n        e = 2.0  # So that no scrollbars are generated.\n        w1 = self.centralWidget().width() - e\n        h1 = self.centralWidget().height() - e\n        a1 = w1 / h1\n        # Calculate a new scale value based on the pixmap's aspect ratio.\n        w2 = self.canvas.pixmap.width() - 0.0\n        h2 = self.canvas.pixmap.height() - 0.0\n        a2 = w2 / h2\n        return w1 / w2 if a2 >= a1 else h1 / h2\n\n    def scaleFitWidth(self):\n        # The epsilon does not seem to work too well here.\n",
  "import PIL.Image\nimport PIL.ImageEnhance\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\nfrom qtpy.QtCore import Qt\n\nfrom .. import utils\n\n\nclass BrightnessContrastDialog(QtWidgets.QDialog):\n    def __init__(self, img, callback, parent=None):\n        super(BrightnessContrastDialog, self).__init__(parent)\n        self.setModal(True)\n        self.setWindowTitle(\"Brightness/Contrast\")\n\n        self.slider_brightness = self._create_slider()\n        self.slider_contrast = self._create_slider()\n\n        formLayout = QtWidgets.QFormLayout()\n        formLayout.addRow(self.tr(\"Brightness\"), self.slider_brightness)\n        formLayout.addRow(self.tr(\"Contrast\"), self.slider_contrast)\n        self.setLayout(formLayout)\n\n        assert isinstance(img, PIL.Image.Image)\n        self.img = img\n        self.callback = callback\n\n    def onNewValue(self, value):\n        brightness = self.slider_brightness.value() / 50.0\n        contrast = self.slider_contrast.value() / 50.0\n\n        img = self.img\n        img = PIL.ImageEnhance.Brightness(img).enhance(brightness)\n        img = PIL.ImageEnhance.Contrast(img).enhance(contrast)\n\n        img_data = utils.img_pil_to_data(img)\n        qimage = QtGui.QImage.fromData(img_data)\n        self.callback(qimage)\n\n    def _create_slider(self):\n",
  "from typing import Optional\nfrom youtube.schemas import (\n    SearchPart, SearchOptionalParameters, YouTubeResponse, YouTubeRequest\n)\nfrom youtube.schemas import (\n    CommentThreadFilter, CommentThreadOptionalParameters, CommentThreadPart\n)\nfrom youtube.models import Search, Comment\nfrom .extensions import youtube_client\nfrom collections.abc import Iterator\n\n\ndef advanced_video_search( \n    query: str,\n    channel_id: Optional[str] = None,\n    max_results: Optional[int] = 10,\n    order: Optional[str] = None,\n    published_after: Optional[str] = None,\n    published_before: Optional[str] = None,\n    region_code: Optional[str] = None,\n    relevance_language: Optional[str] = 'en',\n    video_caption: Optional[str] = None,\n    video_category_id: Optional[str] = None,\n    video_definition: Optional[str] = None,\n    video_dimension: Optional[str] = None,\n    video_duration: Optional[str] = None,\n    video_paid_product_placement: Optional[str] = None,\n    video_syndicated: Optional[str] = None,\n    video_type: Optional[str] = 'any'\n    ) -> list[Search]:\n    \"\"\"Search the given channel for the given videos.\"\"\"\n    search_part: SearchPart = SearchPart()\n    optional_params: SearchOptionalParameters = SearchOptionalParameters(\n        channelId=channel_id,\n        q=query,\n        maxResults=max_results,\n        order=order,\n        publishedAfter=published_after,\n        publishedBefore=published_before,\n        regionCode=region_code,\n",
  "        QtWidgets.QApplication.setOverrideCursor(cursor)\n\n    def restoreCursor(self):\n        QtWidgets.QApplication.restoreOverrideCursor()\n\n    def resetState(self):\n        self.restoreCursor()\n        self.pixmap = None\n        self.shapesBackups = []\n        self.update()\n",
  "    print(\"Creating dataset:\", args.output_dir)\n\n    class_names = []\n    class_name_to_id = {}\n    for i, line in enumerate(open(args.labels).readlines()):\n        class_id = i - 1  # starts with -1\n        class_name = line.strip()\n        class_name_to_id[class_name] = class_id\n        if class_id == -1:\n            assert class_name == \"__ignore__\"\n            continue\n        elif class_id == 0:\n            assert class_name == \"_background_\"\n        class_names.append(class_name)\n    class_names = tuple(class_names)\n    print(\"class_names:\", class_names)\n    out_class_names_file = osp.join(args.output_dir, \"class_names.txt\")\n    with open(out_class_names_file, \"w\") as f:\n        f.writelines(\"\\n\".join(class_names))\n    print(\"Saved class_names:\", out_class_names_file)\n\n    for filename in glob.glob(osp.join(args.input_dir, \"*.json\")):\n        print(\"Generating dataset from:\", filename)\n\n        label_file = labelme.LabelFile(filename=filename)\n\n        base = osp.splitext(osp.basename(filename))[0]\n        out_img_file = osp.join(args.output_dir, \"JPEGImages\", base + \".jpg\")\n        out_xml_file = osp.join(args.output_dir, \"Annotations\", base + \".xml\")\n        if not args.noviz:\n            out_viz_file = osp.join(\n                args.output_dir, \"AnnotationsVisualization\", base + \".jpg\"\n            )\n\n        img = labelme.utils.img_data_to_arr(label_file.imageData)\n        imgviz.io.imsave(out_img_file, img)\n\n        maker = lxml.builder.ElementMaker()\n        xml = maker.annotation(\n            maker.folder(),\n",
  "from sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, MappedAsDataclass\nfrom sqlalchemy.orm import sessionmaker\nfrom ...config.config import BaseConfig\nfrom contextlib import contextmanager\nfrom flask import current_app\n\n\nclass Base(MappedAsDataclass, DeclarativeBase):\n    pass\n\nSQLALCHEMY_DATABASE_URI = BaseConfig().db_conn_string\nengine = create_engine(SQLALCHEMY_DATABASE_URI)\nSession = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n\ndef create_all():\n    Base.metadata.create_all(bind=engine)\n    \ndef drop_all():\n    Base.metadata.drop_all(bind=engine)\n\n@contextmanager\ndef get_db():\n    try:\n        db = Session()\n        yield db\n    finally:\n        db.close()",
  "query = \"\"\"\n        I want to do a three day trip across Kenya's Rift valley.\n        \"\"\"\ntravel_agent = Agent(\n   open_ai_api_key=secrets['OPENAI_API_KEY'],\n   debug=True,\n)\n\nitinerary, list_of_places, validation = travel_agent.suggest_travel(query)\nprint(validation)\nprint(itinerary)\nprint(list_of_places)",
  "\n        otherData = {}\n        for key, value in data.items():\n            if key not in keys:\n                otherData[key] = value\n\n        # Only replace data after everything is loaded.\n        self.flags = flags\n        self.shapes = shapes\n        self.imagePath = imagePath\n        self.imageData = imageData\n        self.filename = filename\n        self.otherData = otherData\n\n    @staticmethod\n    def _check_image_height_and_width(imageData, imageHeight, imageWidth):\n        img_arr = utils.img_b64_to_arr(imageData)\n        if imageHeight is not None and img_arr.shape[0] != imageHeight:\n            logger.error(\n                \"imageHeight does not match with imageData or imagePath, \"\n                \"so getting imageHeight from actual image.\"\n            )\n            imageHeight = img_arr.shape[0]\n        if imageWidth is not None and img_arr.shape[1] != imageWidth:\n            logger.error(\n                \"imageWidth does not match with imageData or imagePath, \"\n                \"so getting imageWidth from actual image.\"\n            )\n            imageWidth = img_arr.shape[1]\n        return imageHeight, imageWidth\n\n    def save(\n        self,\n        filename,\n        shapes,\n        imagePath,\n        imageHeight,\n        imageWidth,\n        imageData=None,\n        otherData=None,\n",
  "        return None\n\n    def process_response(self, request, response, spider):\n        # Called with the response returned from the downloader.\n\n        # Must either;\n        # - return a Response object\n        # - return a Request object\n        # - or raise IgnoreRequest\n        return response\n\n    def process_exception(self, request, exception, spider):\n        # Called when a download handler or a process_request()\n        # (from other downloader middleware) raises an exception.\n\n        # Must either:\n        # - return None: continue processing this exception\n        # - return a Response object: stops process_exception() chain\n        # - return a Request object: stops process_exception() chain\n        pass\n\n    def spider_opened(self, spider):\n        spider.logger.info(\"Spider opened: %s\" % spider.name)\n",
  "from torch.nn import Module, Linear, ReLU, Embedding, LSTM, Dropout\nfrom torchvision.models import inception_v3, Inception_V3_Weights\nfrom torch import Tensor\nimport torch\n\n\nclass EncoderCNN(Module):\n    def __init__(self, embed_size: int, train_cnn: bool = False, dropout: float = 0.5) -> None:\n        super().__init__()\n        self.train_cnn: bool = train_cnn\n        self.inception = inception_v3(weights=Inception_V3_Weights.DEFAULT, aux_logits=True)\n        self.inception.fc = Linear(in_features=self.inception.fc.in_features, out_features=embed_size)\n        self.relu = ReLU()\n        self.dropout = Dropout(p=dropout)\n        \n    def forward(self, images: Tensor) -> Tensor:\n        features = self.inception(images)\n        for name, param in self.inception.named_parameters():\n            if \"fc.name\" in name or \"fc.bias\" in name:\n                param.requires_grad = True\n            else:\n                param.requires_grad = self.train_cnn\n                \n        return self.dropout(self.relu(features.logits))\n                \n\nclass DecoderRNN(Module):\n    def __init__(self, embed_size: int, hidden_size: int, vocab_size: int, num_layers: int, dropout: float = 0.5) -> None:\n        super().__init__()\n        self.embed = Embedding(num_embeddings=vocab_size, embedding_dim=embed_size)\n        self.lstm = LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers)\n        self.linear = Linear(in_features=embed_size, out_features=vocab_size)\n        self.dropout = Dropout(p=dropout)\n        \n    def forward(self, features, captions):\n        embeddings = self.dropout(self.embed(captions))\n        embeddings = torch.cat((features.unsqueeze(0), embeddings), dim=0)\n        hiddens, _ = self.lstm(embeddings)\n        outputs = self.linear(hiddens)\n        return outputs\n",
  "\"\"\"\n\nsentiment_template = PromptTemplate(template=sentiment_msg, input_variables=[\"comment\"])\n\n\nclass PositiveComment(BaseModel):\n    doc_id: int = Field(description=\"The doc_id from the input\")\n    topics: list[str] = Field(\n        description=\"List of the relevant topics for the customer review. Include only topics from the list provided.\",\n        default_factory=list,\n    )\n    sentiment: str = Field(\n        description=\"Sentiment of the topic\", enum=[\"positive\", \"neutral\", \"negative\"]\n    )\n\n\nclass NegativeComment(BaseModel):\n    doc_id: int = Field(description=\"The doc_id from the input\")\n    topics: list[str] = Field(\n        description=\"List of the relevant topics for the customer review. Include only topics from the list provided.\",\n        default_factory=list,\n    )\n    sentiment: str = Field(\n        description=\"Sentiment of the topic\", enum=[\"positive\", \"neutral\", \"negative\"]\n    )\n\n\npositive_parser = PydanticOutputParser(pydantic_object=PositiveComment)\nnegative_parser = PydanticOutputParser(pydantic_object=NegativeComment)\n\ntopic_assg_msg: str = \"\"\"\nBelow is a customer comment in JSON format with the following keys:\n1. doc_id - identifier of the comment\n2. comment - the user comment\n\nPlease analyze the provided comments and identify the main topics and sentiment. Include only the \ntopics provided below:\nTopics with a short description: {topics}\n\nComment:\n",
  "\"\"\"This module contains routes for the app.\"\"\"\nfrom flask import Blueprint, render_template, jsonify, request, url_for\nfrom http import HTTPStatus\nfrom ..database.schemas.activity import (\n    ActivityCreated, CreateActivity, RepeatableActivityCreated,\n    CreateComment, CommentCreated)\nfrom ..database.models import (\n    User, Post, Comment, Bookmark, Like, View\n)\nfrom ..database.schemas.user import GetUser\nfrom ..database.schemas.post import GetPost\nfrom ..database.database import get_db\nfrom ..database.crud.user import get_user, get_random_user\nfrom ..database.crud.post import get_post\nfrom ..database.crud.bookmark import (\n    create_bookmark, delete_bookmark, list_user_bookmarks, has_bookmarked\n)\nfrom ..database.crud.view import (\n    create_view, list_user_views, has_viewed\n)\nfrom ..database.crud.like import (\n    create_like, delete_like, list_user_likes, has_liked, list_post_likes, \n    get_key_like\n)\nfrom ..database.crud.comment import (\n    create_comment, list_user_comments, list_post_comments\n)\nfrom pydantic import ValidationError\nfrom sqlalchemy.exc import OperationalError, IntegrityError\nfrom ..database.schemas.post import (\n    CreatePost, CreatedPost, GetPost, GetPosts, UpdatePost, PostSchema, PostAuthor, \n    PostLike, KeyComment\n)\nfrom ..database.crud.post import (\n    create_post, get_post, get_posts, delete_post, update_post\n)\nfrom ..database.crud.comment import get_key_comment",
  "          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.MaxPool2d(2),\n          # Convolution 4\n          nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(256),\n          nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(256),\n          nn.MaxPool2d(2),\n      )\n\n      self.dense_layers = nn.Sequential(\n          # Dropout layer\n          nn.Dropout(0.5),\n          # first fully connected layer\n          nn.Linear(224*224, 1024),\n          # Relu activation function\n          nn.ReLU(),\n          nn.Dropout(0.4),\n          # Final output layer\n          nn.Linear(1024, K),\n      )\n\n  def forward(self, output):\n    # Convolution Layers\n    out = self.conv_layers(output)\n\n    # Flatten the layers\n    out = out.view(-1, 224*224)\n\n    # Fully connected Dense Layers\n    out = self.dense_layers(out)\n\n    return out\n\n\ndef load_model(model_path: str = os.environ['MODEL_PATH']):\n    \"\"\"Load the pytorch model.\"\"\"\n",
  "            self.fileListWidget.currentRow() != self.imageList.index(filename)\n        ):\n            self.fileListWidget.setCurrentRow(self.imageList.index(filename))\n            self.fileListWidget.repaint()\n            return\n\n        self.resetState()\n        self.canvas.setEnabled(False)\n        if filename is None:\n            filename = self.settings.value(\"filename\", \"\")\n        filename = str(filename)\n        if not QtCore.QFile.exists(filename):\n            self.errorMessage(\n                self.tr(\"Error opening file\"),\n                self.tr(\"No such file: <b>%s</b>\") % filename,\n            )\n            return False\n        # assumes same name, but json extension\n        self.status(str(self.tr(\"Loading %s...\")) % osp.basename(str(filename)))\n        label_file = osp.splitext(filename)[0] + \".json\"\n        if self.output_dir:\n            label_file_without_path = osp.basename(label_file)\n            label_file = osp.join(self.output_dir, label_file_without_path)\n        if QtCore.QFile.exists(label_file) and LabelFile.is_label_file(label_file):\n            try:\n                self.labelFile = LabelFile(label_file)\n            except LabelFileError as e:\n                self.errorMessage(\n                    self.tr(\"Error opening file\"),\n                    self.tr(\n                        \"<p><b>%s</b></p>\"\n                        \"<p>Make sure <i>%s</i> is a valid label file.\"\n                    )\n                    % (e, label_file),\n                )\n                self.status(self.tr(\"Error reading %s\") % label_file)\n                return False\n            self.imageData = self.labelFile.imageData\n            self.imagePath = osp.join(\n                osp.dirname(label_file),\n",
  "    \"A15 Bionic chip\",\n    \"ProMotion display\",\n    \"Ceramic Shield front cover\",\n    \"Triple-camera system\",\n    \"LiDAR scanner\",\n    \"Night mode\",\n    \"Cinematic mode\",\n    \"Dolby Vision HDR recording\",\n    \"MagSafe charging\",\n    \"Face ID\",\n    \"Water and dust resistance\",\n    \"iOS 15\",\n    \"Improved battery life\",\n    \"Siri voice recognition\",\n    \"Apple Pay\",\n    \"Apple Fitness+ integration\",\n    \"Apple Arcade subscription\",\n    \"Apple Music\",\n    \"iMessage\",\n    \"App Store\",\n    \"iCloud storage\",\n    \"Privacy features\",\n]\n# start: int = 0\n# step: int = 3\n# while start < len(features):\n#     f: list[str] = features[start: start + step]\n#     chain = features_description_template | llm\n#     res = chain.invoke({\"product\": \"iphone 13 pro\", \"features\": f})\n#     print(res)\n#     start += step\nwith open(save_transcript_dir, \"r\") as f:\n    video_transcript = f.read()\n    \ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=0)\nsplits = text_splitter.split_text(video_transcript)\nfeatures_covered = []\nfor doc in splits:\n    chain = features_covered_template | llm\n    res = chain.invoke({\"transcript\": doc, \"product\": \"iphone 13 pro\", \"features\": features})\n",
  "def generate_class_docstring(class_code: str, config: Config) -> str:\n    prompt_formatted_str: str = get_class_prompt_template(\n        class_code=class_code, config=config\n    )\n    class_and_docstring = llm.invoke(prompt_formatted_str)\n    return class_and_docstring\n\n\ndef get_class_docstring(class_and_docstring: str) -> str:\n    \"\"\"Get the class docstring.\"\"\"\n    class_tree = ast.parse(class_and_docstring)\n    for node in class_tree.body:\n        if isinstance(node, ClassDef):\n            cls_docstring: str = ast.get_docstring(node)\n            return cls_docstring",
  "\nfrom datetime import timedelta\nfrom redis import Redis\n\ndef request_is_rate_limited(r: Redis, key: str, limit: int, period: timedelta):\n    if r.setnx(key, limit):\n        r.expire(key, int(period.total_seconds()))\n    bucket_val = r.get(key)\n    if bucket_val and int(bucket_val) > 0:\n        r.decrby(key, 1)\n        return False\n    return True\n",
  "import argparse\nimport base64\nimport json\nimport os\nimport os.path as osp\n\nimport imgviz\nimport PIL.Image\n\nfrom labelme import utils\nfrom labelme.logger import logger\n\n\ndef main():\n    logger.warning(\n        \"DEPRECATED: This script will be removed in the near future. \"\n        \"Please use `labelme_export_json` instead.\"\n    )\n    logger.warning(\n        \"NOTE: This script is aimed to demonstrate how to convert a JSON file \"\n        \"to a single image dataset. so it won't handle multiple JSON files to \"\n        \"generate a real-use dataset.\"\n    )\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"json_file\")\n    parser.add_argument(\"-o\", \"--out\", default=None)\n    args = parser.parse_args()\n\n    json_file = args.json_file\n\n    if args.out is None:\n        out_dir = osp.basename(json_file).replace(\".\", \"_\")\n        out_dir = osp.join(osp.dirname(json_file), out_dir)\n    else:\n        out_dir = args.out\n    if not osp.exists(out_dir):\n        os.mkdir(out_dir)\n\n    data = json.load(open(json_file))\n",
  "from create_dataset import dataloader, FlickrDataset, Dataset\nfrom torchvision.transforms import Compose, ToTensor, Resize\nfrom model import EncoderCNN, DecoderRNN, CNNToRNN\nfrom torch.nn import Module\nimport torch\nfrom PIL import Image\n\nembed_size: int = 256\nhidden_size: int = 256\nnum_layers: int = 3\nvocab_size: int = 2994\n\nencoder: Module = EncoderCNN(embed_size=embed_size)\ndecoder: Module = DecoderRNN(embed_size=embed_size, hidden_size=hidden_size, vocab_size=vocab_size, \n                             num_layers=num_layers)\nmodel: Module = CNNToRNN(embed_size=embed_size, hidden_size=hidden_size, vocab_size=vocab_size, \n                         num_layers=num_layers)\n\n\nfor i, (images, captions) in enumerate(dataloader):\n    print(images.shape)\n    print(captions.shape)\n    break\n# print(captions)\n\ndataset: Dataset = FlickrDataset(\n    images_dir=\"raw-data/Images\", \n    captions_file=\"raw-data/captions.txt\", \n    transforms=Compose([\n        Resize((299, 299)),\n        ToTensor()\n    ]))\n    \n# features = encoder(images)\n# print(features.shape)\n# print(features.unsqueeze(0).shape)\n# embedings = decoder.embed(captions)\n# print(embedings.size())\n# x = torch.cat((features.unsqueeze(0), embedings), dim=0)\n# print(x.shape)\n",
  "from typing import Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass Config(BaseModel):\n    root_directory: list[str] = Field(\n        description=\"The path to the source code directory\"\n    )\n    directories_ignore: set[str] = Field(\n        description=\"Directories to ignore\",\n        default=set([\"venv\", \".venv\", \"__pycache__\", \".git\", \"build\", \"dist\", \"docs\"]),\n    )\n    files_ignore: set[str] = Field(\n        description=\"Files to ignore\",\n        default_factory=set,\n    )\n    overwrite_function_docstring: Optional[bool] = Field(\n        description=\"Whether or not to overwrite the existing function docstring\",\n        default=False,\n    )\n    documentation_style: Optional[str] = Field(\n        description=\"The format of documentation to use\",\n        default=\"Numpy-Style\",\n        enum=[\"Numpy-Style\", \"Google-Style\", \"Sphinx-Style\"],\n    )\n",
  "agent = get_agent_executor()\n# query = \"What are the main features of the iphone 15?\"\n# query = \"What are some of the complaints about iphone 15?\"\n# query = \"What features of the iphone 15 do its users love most?\"\nquery = \"What are the pros and cons of the iphone 15?\"\nres = agent.invoke({\"input\": query})\nprint(res)\n",
  "    def mousePressEvent(self, ev):\n        if QT5:\n            pos = self.transformPos(ev.localPos())\n        else:\n            pos = self.transformPos(ev.posF())\n\n        is_shift_pressed = ev.modifiers() & QtCore.Qt.ShiftModifier\n\n        if ev.button() == QtCore.Qt.LeftButton:\n            if self.drawing():\n                if self.current:\n                    # Add point to existing shape.\n                    if self.createMode == \"polygon\":\n                        self.current.addPoint(self.line[1])\n                        self.line[0] = self.current[-1]\n                        if self.current.isClosed():\n                            self.finalise()\n                    elif self.createMode in [\"rectangle\", \"circle\", \"line\"]:\n                        assert len(self.current.points) == 1\n                        self.current.points = self.line.points\n                        self.finalise()\n                    elif self.createMode == \"linestrip\":\n                        self.current.addPoint(self.line[1])\n                        self.line[0] = self.current[-1]\n                        if int(ev.modifiers()) == QtCore.Qt.ControlModifier:\n                            self.finalise()\n                    elif self.createMode in [\"ai_polygon\", \"ai_mask\"]:\n                        self.current.addPoint(\n                            self.line.points[1],\n                            label=self.line.point_labels[1],\n                        )\n                        self.line.points[0] = self.current.points[-1]\n                        self.line.point_labels[0] = self.current.point_labels[-1]\n                        if ev.modifiers() & QtCore.Qt.ControlModifier:\n                            self.finalise()\n                elif not self.outOfPixmap(pos):\n                    # Create new shape.\n                    self.current = Shape(\n                        shape_type=\"points\"\n                        if self.createMode in [\"ai_polygon\", \"ai_mask\"]\n",
  "import json\nimport os.path as osp\n\nfrom labelme.utils import image as image_module\nfrom labelme.utils import shape as shape_module\n\nhere = osp.dirname(osp.abspath(__file__))\ndata_dir = osp.join(here, \"../data\")\n\n\ndef get_img_and_data():\n    json_file = osp.join(data_dir, \"annotated_with_data/apc2016_obj3.json\")\n    with open(json_file) as f:\n        data = json.load(f)\n    img_b64 = data[\"imageData\"]\n    img = image_module.img_b64_to_arr(img_b64)\n    return img, data\n\n\ndef get_img_and_lbl():\n    img, data = get_img_and_data()\n\n    label_name_to_value = {\"__background__\": 0}\n    for shape in data[\"shapes\"]:\n        label_name = shape[\"label\"]\n        label_value = len(label_name_to_value)\n        label_name_to_value[label_name] = label_value\n\n    n_labels = max(label_name_to_value.values()) + 1\n    label_names = [None] * n_labels\n    for label_name, label_value in label_name_to_value.items():\n        label_names[label_value] = label_name\n\n    lbl, _ = shape_module.shapes_to_label(\n        img.shape, data[\"shapes\"], label_name_to_value\n    )\n    return img, lbl, label_names\n",
  "from .user import User\nfrom .post import Post\nfrom .like import Like\nfrom .bookmark import Bookmark\nfrom .view import View\nfrom .view import View\nfrom .comment import Comment",
  "from qtpy import QtCore\nfrom qtpy import QtGui\nfrom qtpy import QtWidgets\nfrom qtpy.QtCore import Qt\nfrom qtpy.QtGui import QPalette\nfrom qtpy.QtWidgets import QStyle\n\n\n# https://stackoverflow.com/a/2039745/4158863\nclass HTMLDelegate(QtWidgets.QStyledItemDelegate):\n    def __init__(self, parent=None):\n        super(HTMLDelegate, self).__init__()\n        self.doc = QtGui.QTextDocument(self)\n\n    def paint(self, painter, option, index):\n        painter.save()\n\n        options = QtWidgets.QStyleOptionViewItem(option)\n\n        self.initStyleOption(options, index)\n        self.doc.setHtml(options.text)\n        options.text = \"\"\n\n        style = (\n            QtWidgets.QApplication.style()\n            if options.widget is None\n            else options.widget.style()\n        )\n        style.drawControl(QStyle.CE_ItemViewItem, options, painter)\n\n        ctx = QtGui.QAbstractTextDocumentLayout.PaintContext()\n\n        if option.state & QStyle.State_Selected:\n            ctx.palette.setColor(\n                QPalette.Text,\n                option.palette.color(QPalette.Active, QPalette.HighlightedText),\n            )\n        else:\n            ctx.palette.setColor(\n                QPalette.Text,\n",
  "# score = bleu(test_data[1:100], model, german, english, device)\n# print(f\"Bleu score {score*100:.2f}\")",
  "\n            outputs = model(imgs, captions[:-1])\n            loss = criterion(\n                outputs.reshape(-1, outputs.shape[2]), captions.reshape(-1)\n            )\n\n            writer.add_scalar(\"Training loss\", loss.item(), global_step=step)\n            step += 1\n\n            optimizer.zero_grad()\n            loss.backward(loss)\n            optimizer.step()\n\n\nif __name__ == \"__main__\":\n    train()",
  "\n    if orientation == 1:\n        # do nothing\n        return image\n    elif orientation == 2:\n        # left-to-right mirror\n        return PIL.ImageOps.mirror(image)\n    elif orientation == 3:\n        # rotate 180\n        return image.transpose(PIL.Image.ROTATE_180)\n    elif orientation == 4:\n        # top-to-bottom mirror\n        return PIL.ImageOps.flip(image)\n    elif orientation == 5:\n        # top-to-left mirror\n        return PIL.ImageOps.mirror(image.transpose(PIL.Image.ROTATE_270))\n    elif orientation == 6:\n        # rotate 270\n        return image.transpose(PIL.Image.ROTATE_270)\n    elif orientation == 7:\n        # top-to-right mirror\n        return PIL.ImageOps.mirror(image.transpose(PIL.Image.ROTATE_90))\n    elif orientation == 8:\n        # rotate 90\n        return image.transpose(PIL.Image.ROTATE_90)\n    else:\n        return image\n",
  "        for comment_thread in comment_threads:\n            comment: Comment = comment_thread.snippet.top_level_comment\n            video_comments.append(comment)\n            comment_count += 1\n            if comment_count > 30:\n                done = True\n                break\n    return video_comments",
  "\n    unique_label_values = np.unique(label)\n\n    logger.info(\"Label image shape: {}\".format(label.shape))\n    logger.info(\"Label values: {}\".format(unique_label_values.tolist()))\n    if label_names is not None:\n        logger.info(\n            \"Label names: {}\".format(\n                [\n                    \"{}:{}\".format(label_value, label_names[label_value])\n                    for label_value in unique_label_values\n                ]\n            )\n        )\n\n    if args.image:\n        num_cols = 2\n    else:\n        num_cols = 1\n\n    plt.figure(figsize=(num_cols * 6, 5))\n\n    plt.subplot(1, num_cols, 1)\n    plt.title(args.label_png)\n    label_viz = imgviz.label2rgb(\n        label=label, label_names=label_names, font_size=label.shape[1] // 30\n    )\n    plt.imshow(label_viz)\n\n    if image is not None:\n        plt.subplot(1, num_cols, 2)\n        label_viz_with_overlay = imgviz.label2rgb(\n            label=label,\n            image=image,\n            label_names=label_names,\n            font_size=label.shape[1] // 30,\n        )\n        plt.title(\"{}\\n{}\".format(args.label_png, args.image))\n        plt.imshow(label_viz_with_overlay)\n\n",
  "        Image.open(\"test_examples/boat.png\").convert(\"RGB\")\n    ).unsqueeze(0)\n    print(\"Example 4 CORRECT: A small boat in the ocean\")\n    print(\n        \"Example 4 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img4.to(device), dataset.vocabulary))\n    )\n    test_img5 = transform(\n        Image.open(\"test_examples/horse.png\").convert(\"RGB\")\n    ).unsqueeze(0)\n    print(\"Example 5 CORRECT: A cowboy riding a horse in the desert\")\n    print(\n        \"Example 5 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img5.to(device), dataset.vocabulary))\n    )\n    model.train()\n\n\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\ndef load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    step = checkpoint[\"step\"]\n    return step",
  "def generate_posts(authors: list[User], count: int = 100) -> list[Post]:\n    \"\"\"Generate posts.\"\"\"\n    cities = [fake.city() for _ in range(10)]\n    posts_text = [fake.text() for _ in range(count)]\n    dates_published = (datetime.now() + timedelta(minutes=random.randint(1,60)) for _ in range(count))\n    post_images = [f'feed-{i}.jpg' for i in range(1,8)]\n    return [\n        Post(\n            id='Post_' + str(uuid4()),\n            author_id=random.choice(authors).id,\n            location=random.choice(cities),\n            text=text,\n            image_url=random.choice(post_images),\n            date_published=d\n        )\n        for text, d in zip(posts_text, dates_published)\n    ]\n    \ndef generate_likes(users: list[User], posts: list[Post], likes_count: int = 100) -> list[Like]:\n    \"\"\"Generate likes.\"\"\"\n    likes: list[Like] = []\n    ids = set()\n    for _ in range(likes_count):\n        author_id: str = random.choice(users).id\n        post_id: str = random.choice(posts).id\n        like: Like = Like(author_id=author_id, post_id=post_id)\n        if (author_id, post_id) not in ids:\n            likes.append(like)\n        ids.add((author_id, post_id))\n    return likes",
  "from fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom .routers import register_routers\n\n\norigins = [\n    \"http://localhost\",\n    \"http://localhost:8080\",\n]\n\ndef create_app():\n    app = FastAPI()\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    register_routers(app=app)\n    \n    @app.get('/health', tags=['Health'])\n    async def get():\n        return {'Success': 'Up!'}\n    \n    return app",
  "            self, title, \"<p><b>%s</b></p>%s\" % (title, message)\n        )\n\n    def currentPath(self):\n        return osp.dirname(str(self.filename)) if self.filename else \".\"\n\n    def toggleKeepPrevMode(self):\n        self._config[\"keep_prev\"] = not self._config[\"keep_prev\"]\n\n    def removeSelectedPoint(self):\n        self.canvas.removeSelectedPoint()\n        self.canvas.update()\n        if not self.canvas.hShape.points:\n            self.canvas.deleteShape(self.canvas.hShape)\n            self.remLabels([self.canvas.hShape])\n            if self.noShapes():\n                for action in self.actions.onShapesPresent:\n                    action.setEnabled(False)\n        self.setDirty()\n\n    def deleteSelectedShape(self):\n        yes, no = QtWidgets.QMessageBox.Yes, QtWidgets.QMessageBox.No\n        msg = self.tr(\n            \"You are about to permanently delete {} polygons, \" \"proceed anyway?\"\n        ).format(len(self.canvas.selectedShapes))\n        if yes == QtWidgets.QMessageBox.warning(\n            self, self.tr(\"Attention\"), msg, yes | no, yes\n        ):\n            self.remLabels(self.canvas.deleteSelected())\n            self.setDirty()\n            if self.noShapes():\n                for action in self.actions.onShapesPresent:\n                    action.setEnabled(False)\n\n    def copyShape(self):\n        self.canvas.endMove(copy=True)\n        for shape in self.canvas.selectedShapes:\n            self.addLabel(shape)\n        self.labelList.clearSelection()\n        self.setDirty()\n",
  "from os import path\nimport json\nfrom random import choices, choice\nfrom langchain.docstore.document import Document\nimport re\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import OpenAI\nfrom langchain.pydantic_v1 import BaseModel, Field\nfrom langchain.output_parsers import PydanticOutputParser\nfrom langchain_core.runnables import RunnableBranch\nfrom langchain_core.output_parsers import StrOutputParser\n\n\napi_key: str = \"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\"\nllm = OpenAI(temperature=0, api_key=api_key)\nfile_path: str = \"comments.json\"\n\n\ndef lower(text: str) -> str:\n    return text.lower().strip()\n\n\ndef remove_urls(text: str) -> str:\n    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n    text = re.sub(url_pattern, \"\", text)\n    return text\n\n\ndef remove_punctuations(text: str) -> str:\n    punctuation_pattern = r\"[^\\w\\s]\"\n    cleaned = re.sub(punctuation_pattern, \"\", text)\n    return cleaned\n\n\ndef clean_text(text: str) -> str:\n    text = lower(text)\n    text = remove_urls(text)\n    text = remove_punctuations(text)\n    return text\n\n",
  "@post.route(\"/delete\", methods=[\"DELETE\"])\ndef delete_one_post():\n    \"\"\"Delete a post.\"\"\"\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        post = delete_post(get_db, GetPost(post_id=request.args.get('post_id')))\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    resp = CreatedPost(\n            id=post.id,\n            location=post.location,\n            text=post.text,\n            image_url=post.image_url,\n            author_id=post.author_id,\n            date_published=post.date_published\n        )\n    return resp.model_dump_json(indent=4), HTTPStatus.OK",
  "from langchain.output_parsers import PydanticOutputParser\nfrom langchain.pydantic_v1 import Field, BaseModel\nfrom langchain.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain_openai import ChatOpenAI, OpenAI\nimport re\nimport json\nfrom langchain.docstore.document import Document\nfrom random import choices\nfrom os import path\n\n\nfile_path: str = \"comments.json\"\napi_key: str = \"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\"\n\n\ndef lower(text: str) -> str:\n    return text.lower().strip()\n\n\ndef remove_urls(text: str) -> str:\n    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n    text = re.sub(url_pattern, \"\", text)\n    return text\n\n\ndef remove_punctuations(text: str) -> str:\n    punctuation_pattern = r\"[^\\w\\s]\"\n    cleaned = re.sub(punctuation_pattern, \"\", text)\n    return cleaned\n\n\ndef clean_text(text: str) -> str:\n    text = lower(text)\n    text = remove_urls(text)\n    text = remove_punctuations(text)\n    return text\n\n\ndef is_acceptable_len(text: str, l=15) -> bool:\n    return len(text.split()) >= l\n",
  "        inverted_dict: dict = {value: key for key, value in dct.items()}\n        return inverted_dict\n    \n    def build_vocab(self, sentence_list: list[list[str]]) -> None:\n        idx: int = max(self.itos.keys())\n        word_frequencies: dict[str, int] = defaultdict(int)\n\n        for sentence in sentence_list:\n            for word in self.tokenize(sentence):\n                word_frequencies[word] += 1\n                if word not in self.stoi and word_frequencies[word] == self.freq_threshold:\n                    idx += 1\n                    self.stoi[word] = idx\n                    self.itos[idx] = word\n    \n    def numericalize(self, text: str) -> list[int]:\n        tokenized_txt: list[str] = self.tokenize(text)\n        \n        return [\n            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n            for token in tokenized_txt\n        ]\n        \n    def textualize(self, vector: list[int]) -> list[str]:\n        return [\n            self.itos[i.item()] if i.item() in self.itos else self.itos[3]\n            for i in vector\n        ]\n    \n\n\nclass FlickrDataset(Dataset):\n    def __init__(self, images_dir: str, captions_file: str, freq_threshold: int = 5, transforms = None) -> None:\n        super().__init__()\n        self.images_dir: str = images_dir\n        self.df: pd.DataFrame = pd.read_csv(captions_file)\n        self.transforms = transforms\n        \n        # Get the image, captions\n        self.images: pd.Series = self.df[\"image\"]\n",
  "        assert self.current\n        if self.createMode == \"ai_polygon\":\n            # convert points to polygon by an AI model\n            assert self.current.shape_type == \"points\"\n            points = self._ai_model.predict_polygon_from_points(\n                points=[[point.x(), point.y()] for point in self.current.points],\n                point_labels=self.current.point_labels,\n            )\n            self.current.setShapeRefined(\n                points=[QtCore.QPointF(point[0], point[1]) for point in points],\n                point_labels=[1] * len(points),\n                shape_type=\"polygon\",\n            )\n        elif self.createMode == \"ai_mask\":\n            # convert points to mask by an AI model\n            assert self.current.shape_type == \"points\"\n            mask = self._ai_model.predict_mask_from_points(\n                points=[[point.x(), point.y()] for point in self.current.points],\n                point_labels=self.current.point_labels,\n            )\n            y1, x1, y2, x2 = imgviz.instances.masks_to_bboxes([mask])[0].astype(int)\n            self.current.setShapeRefined(\n                shape_type=\"mask\",\n                points=[QtCore.QPointF(x1, y1), QtCore.QPointF(x2, y2)],\n                point_labels=[1, 1],\n                mask=mask[y1 : y2 + 1, x1 : x2 + 1],\n            )\n        self.current.close()\n\n        self.shapes.append(self.current)\n        self.storeShapes()\n        self.current = None\n        self.setHiding(False)\n        self.newShape.emit()\n        self.update()\n\n    def closeEnough(self, p1, p2):\n        # d = distance(p1 - p2)\n        # m = (p1-p2).manhattanLength()\n        # print \"d %.2f, m %d, %.2f\" % (d, m, d - m)\n",
  "    num_epochs = 100\n\n    # for tensorboard\n    writer = SummaryWriter(\"runs/flickr\")\n    step = 0\n\n    # initialize model, loss etc\n    model = CNNToRNN(embed_size, hidden_size, vocab_size, num_layers).to(device)\n    criterion = CrossEntropyLoss(ignore_index=dataset.vocabulary.stoi[\"<PAD>\"])\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    # Only finetune the CNN\n    for name, param in model.encoder_cnn.inception.named_parameters():\n        if \"fc.weight\" in name or \"fc.bias\" in name:\n            param.requires_grad = True\n        else:\n            param.requires_grad = False\n\n    if load_model:\n        step = load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n\n    model.train()\n\n    for epoch in range(num_epochs):\n        # Uncomment the line below to see a couple of test cases\n        print_examples(model, device, dataset)\n\n        if save_model:\n            checkpoint = {\n                \"state_dict\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"step\": step,\n            }\n            save_checkpoint(checkpoint)\n\n        for idx, (imgs, captions) in tqdm(\n            enumerate(train_loader), total=len(train_loader), leave=False\n        ):\n            imgs = imgs.to(device)\n            captions = captions.to(device)\n",
  "from langchain.chains import RetrievalQA\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain.vectorstores.chroma import Chroma\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.docstore.document import Document\nfrom langchain.prompts import PromptTemplate\nfrom os import path\nimport json\nfrom random import choices\n\ndata_dir = \"data\"\nvideo_data_dir = \"data\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"iphone_15_marques_review\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\npersist_directory = path.join(data_dir, \"vectore_store\")\n\napi_key: str = \"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\"\nfile_path: str = \"comments.json\"\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n    comments: list[str] = choices(population=all_comments, k=50)\n    comments: list[Document] = [Document(page_content=comment) for comment in all_comments]\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30)\nsplit_docs = text_splitter.split_documents(comments)\n\nembeddings = OpenAIEmbeddings(api_key=api_key)\n# vectordb = FAISS.from_texts(splits, embeddings)\n# vectordb = FAISS.from_documents(documents=comments, embedding=embeddings)\n# vectordb = Chroma.from_documents(\n#     documents=split_docs,\n#     embedding=embeddings,\n#     persist_directory=persist_directory\n# )\n\ntemplate_str: str = \"\"\"\n",
  "def send_email_local(user_email_address: str, message: str) -> None:\n    pass\n\ndef send_email_aws_ses(user_email_address: str, message: str) -> None:\n    pass\n\ndef send_account_activation_email(user_email_address: str, message: str) -> None:\n    pass\n\ndef send_password_reset_email(user_email_address: str, message: str) -> None:\n    pass\n\ndef generate_account_activation_email(message: str) -> None:\n    pass\n\ndef generate_password_reset_email(message: str) -> None:\n    pass",
  "\n\nchannel_file_path: str = \"channels.json\"\nproduct: str = \"iphone 15 pro\"\nchannel: str = \"Marques Brownlee\"\nvideo_file_path: str = \"videos.json\"\ncomments_file_path: str = \"comments_1.json\"\n# save_data(file_path=channel_file_path, data=list(get_channels(product=product)))\n# channels: list[dict] = load_data(file_path=channel_file_path)\n\n# videos: list[dict] = get_videos(product=product, channel=channel)\n# save_data(file_path=video_file_path, data=list(get_videos(product=product, channel=channel)))\n# videos: list[dict] = load_data(file_path=video_file_path)\n\n# save_data(file_path=comments_file_path, data=list(get_video_comments(video_id='cBpGq-vDr2Y', max_results=100)))\ncomments: list[dict] = load_data(file_path=comments_file_path)\nconsole = Console()\nbatch: int = 10\nfrom time import sleep\n# with Live(create_comments_table(comments[:batch])) as live:\n#     index: int = 0\n#     for i in range(batch, len(comments)):\n#         live.update(create_comments_table(comments[i: i+batch]))\n#         sleep(0.1)\n        \n# from collections import deque\n# queue = deque(maxlen=10, iterable=comments[:batch])\n# with Live(create_comments_table(table_data=queue)) as live:\n#     for data in comments[batch:]:\n#         queue.append(data)\n#         live.update(create_comments_table(table_data=queue))\n#         sleep(0.5)\n# from collections import deque\n# queue = deque(maxlen=10)\n# iterator = get_video_comments(video_id='cBpGq-vDr2Y', max_results=100)\n# for _ in range(batch):\n#     queue.append(next(iterator))\n# with Live(create_comments_table(table_data=queue)) as live:\n#     for data in iterator:\n#         queue.append(data)\n",
  "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\"✅ Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\"❌ Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file\n",
  "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ[\"SECRET_KEY\"]\n    db_conn_string = 'sqlite:///./butterfly.db'\n    SQLALCHEMY_DATABASE_URI = db_conn_string\n    SQLALCHEMY_TRACK_MODIFICATIONS = False",
  "    def removeItem(self, item):\n        index = self.model().indexFromItem(item)\n        self.model().removeRows(index.row(), 1)\n\n    def selectItem(self, item):\n        index = self.model().indexFromItem(item)\n        self.selectionModel().select(index, QtCore.QItemSelectionModel.Select)\n\n    def findItemByShape(self, shape):\n        for row in range(self.model().rowCount()):\n            item = self.model().item(row, 0)\n            if item.shape() == shape:\n                return item\n        raise ValueError(\"cannot find shape: {}\".format(shape))\n\n    def clear(self):\n        self.model().clear()\n",
  "                \"elementProperties\": {\n                    \"pageObjectId\": page_id,\n                    \"size\": {\"height\": emu4M, \"width\": emu4M},\n                    \"transform\": {\n                        \"scaleX\": 1,\n                        \"scaleY\": 1,\n                        \"translateX\": 100000,\n                        \"translateY\": 100000,\n                        \"unit\": \"EMU\",\n                    },\n                },\n            }\n        }\n    )\n\n    # Execute the request.\n    body = {\"requests\": requests}\n    response = (\n        slide_client.presentations()\n        .batchUpdate(presentationId=presentation_id, body=body)\n        .execute()\n    )\n    create_image_response = response.get(\"replies\")[0].get(\"createImage\")\n    print(f\"Created image with ID: {(create_image_response.get('objectId'))}\")\n\n    return response\n  except HttpError as error:\n    print(f\"An error occurred: {error}\")\n    print(\"Images not created\")\n    return error",
  "\nfrom sqlalchemy import create_engine, Column, Table, ForeignKey, MetaData\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy import (\n    Integer, String, Date, DateTime, Float, Boolean, Text)\nfrom scrapy.utils.project import get_project_settings\nfrom sqlalchemy_utils import ScalarListType\n\n\nBase = declarative_base()\n\ndef db_connect():\n    \"\"\"\n    Performs database connection using database settings from settings.py.\n    Returns sqlalchemy engine instance\n    \"\"\"\n    settings: dict = get_project_settings()\n    connection_string: str = settings.get(\"CONNECTION_STRING\")\n    return create_engine(connection_string)\n\ndef create_table(engine):\n    Base.metadata.create_all(engine)\n    \n    \nslide_tag = Table('slide_tag', Base.metadata,\n    Column('slide_id', Integer, ForeignKey('slide.id')),\n    Column('tag_id', Integer, ForeignKey('tag.id'))\n)\n\nclass Slide(Base):\n    __tablename__ = \"slide\"\n\n    id = Column(String(), primary_key=True)\n    title = Column('title', String())\n    description = Column('description', Text())\n    category_id = Column(String(), ForeignKey('category.id'))\n    tags = relationship('Tag', secondary='slide_tag',\n        lazy='dynamic', backref=\"slide\")  # M-to-M for quote and tag\n    colors = Column(ScalarListType())\n",
  "# print(youtube.find_channel_by_name('The Joy Ride'))\n# print(youtube.find_channel_playlists('UCCjULCQvh2cQQLzYe4DC2Nw'))\n# print(youtube.find_my_playlists())\n# snippet: CreatePlaylistSnippet = CreatePlaylistSnippet(\n#     title='Another Test Playlist 5'\n# )\n# playlist_schema: CreatePlaylistSchema = CreatePlaylistSchema(\n#     snippet=snippet\n# )\n# print(youtube.insert_playlist(playlist_schema))\n# snippet: CreatePlaylistSnippet = CreatePlaylistSnippet(\n#     title='Another Test Playlist 6',\n#     description='New description.',\n#     defaultLanguage='en'\n# )\n# playlist_schema: CreatePlaylistSchema = CreatePlaylistSchema(\n#     snippet=snippet,\n#     status=CreateStatus(privacyStatus='public')\n# )\n# print(youtube.update_playlist('PL_26vmg8W_AfJWy6SVtoSmtYWimhexwF7', playlist_schema))\n# print(youtube.delete_playlist('PL_26vmg8W_AfeubZM4lQJiBU8UbCl-R3L'))\n# print(youtube.find_channel_by_name('Isaac Author'))\n# print(youtube.find_playlist_items('PLgCR4dyaQRlq0SM6y7cQqspDnfqiNHfWf'))\n# print(youtube.find_playlist_items_by_ids(['UExnQ1I0ZHlhUVJscTBTTTZ5N2NRcXNwRG5mcWlOSGZXZi5EMEEwRUY5M0RDRTU3NDJC', \n#                         'UExnQ1I0ZHlhUVJscTBTTTZ5N2NRcXNwRG5mcWlOSGZXZi45NDk1REZENzhEMzU5MDQz', \n#                         'UExnQ1I0ZHlhUVJscTBTTTZ5N2NRcXNwRG5mcWlOSGZXZi41MzJCQjBCNDIyRkJDN0VD']))\n\n# video_resource: VideoResourceId = VideoResourceId(videoId='j0OvCL-6ic4')\n# snippet: CreatePlaylistItemSnippet = CreatePlaylistItemSnippet(\n#     playlistId='PL_26vmg8W_AfJWy6SVtoSmtYWimhexwF7',\n#     resourceId=video_resource\n# )\n# create = CreatePlaylistItem(snippet=snippet)\n# print(youtube.insert_playlist_item(create))\n# playlist_id='PL_26vmg8W_AfJWy6SVtoSmtYWimhexwF7', \n# playlist_item_id='UExfMjZ2bWc4V19BZkpXeTZTVnRvU210WVdpbWhleHdGNy41MzJCQjBCNDIyRkJDN0VD'\n# video_id='j0OvCL-6ic4' \n# position=6\n# print(youtube.update_playlist_item(playlist_id, playlist_item_id, video_id, position))\n# print(youtube.delete_playlist_item('UExnQ1I0ZHlhUVJsclpDZEtoN2ZQb1FwejVGYXI3Xy1HSS4yODlGNEE0NkRGMEEzMEQy'))\n",
  "#         AttendeeSchema(email='sbrin@example.com')\n#     ],\n#     reminders=RemindersSchema(\n#         useDefault=False,\n#         overrides=[\n#             ReminderSchema(method='email', minutes=10),\n#             ReminderSchema(method='popup', minutes=20)\n#         ]\n#     )\n# )\n# created_event = google_calendar.create_event(create_event)\n# print(created_event)\ntoday = d.today()\nyear = today.year\nmonth = today.month\nday = today.day\ntime_min: datetime = datetime(year=year, month=month, day=25, hour=0, minute=1)\ntime_min: datetime = datetime.astimezone(time_min, pytz.timezone('Africa/Nairobi'))\ntime_min: str = str(time_min.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\ntime_max: datetime = datetime(year=year, month=month, day=day, hour=23, minute=59)\ntime_max: datetime = datetime.astimezone(time_max, pytz.timezone('Africa/Nairobi'))\ntime_max: str = str(time_max.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\nreq = ListCalendarEvents(\n    timeMin=time_min\n)\nevents = google_calendar.list_calendar_events(req)\nprint(events.items)\ndef parse_events(events: list[Event]) -> str:\n    event_str: str = \"\"\n    for i, event in enumerate(events, start=1):\n        event_str: str = f\"\\n{i}. \"\n        start_time: str = event.start.date_time.time()\n        end_time: str = event.end.date_time.time()\n        title: str = event.summary\n        location: str = event.location\n        event_str += f'From {start_time} to {end_time} you will {title} at {location}.'\n    return event_str\n# print(time_min)\n# print(time_max)\n# print(datetime.astimezone(datetime.now(), pytz.timezone('Africa/Nairobi')))\n",
  "    transforms,\n    batch_size: int = 8,\n    num_workers: int = 2,\n    shuffle: bool = True,\n    pin_memory: bool = True,\n    ) -> DataLoader:\n    dataset: Dataset = FlickrDataset(images_dir=images_dir, captions_file=captions_file, transforms=transforms)\n    pad_idx: int = dataset.vocabulary.stoi[\"<PAD>\"]\n    loader: DataLoader = DataLoader(\n        dataset=dataset, \n        batch_size=batch_size, \n        shuffle=shuffle, \n        num_workers=num_workers, \n        pin_memory=pin_memory, \n        collate_fn=MyCollate(pad_idx=pad_idx)\n    )\n    return loader, dataset\n\n\ndataloader: DataLoader = get_loader(\n    images_dir=\"raw-data/Images\",\n    captions_file=\"raw-data/captions.txt\",\n    transforms=Compose([\n        Resize((299, 299)),\n        ToTensor()\n    ])\n)\n\n# for i, (images, captions) in enumerate(dataloader):\n#     print(images.shape)\n#     print(captions.shape)\n#     break\n# print(captions[0])\n# dataset: Dataset = FlickrDataset(\n#     images_dir=\"raw-data/Images\", \n#     captions_file=\"raw-data/captions.txt\", \n#     transforms=Compose([\n#         Resize((224, 224)),\n#         ToTensor()\n#     ]))\n",
  "def save_post_photo_aws_s3(post_image: dict) -> None:\n    \"\"\"Save the uploadeded post image.\"\"\"\n    file: FileStorage = post_image['post_image']\n    if file and allowed_file(file.filename):\n        filename = f'{secrets.token_hex(8)}.{get_file_extension(file.filename)}'\n        # Use celery task\n        return filename\n    return ''\n\ndef no_save_post_photo(post_image: dict) -> None:\n    \"\"\"Save the uploadeded post image.\"\"\"\n    file: FileStorage = post_image['post_image']\n    if file and allowed_file(file.filename):\n        filename = f'{secrets.token_hex(8)}.{get_file_extension(file.filename)}'\n        return filename\n    return ''\n\n\ndef save_post_photo(post_image: dict, save_location: str = '') -> str:\n    \"\"\"Save the uploadeded post image.\"\"\"\n    save_photo_funcs: dict[str, Callable[[dict], str]] = {\n        'locally': save_post_photo_locally,\n        'aws_s3': save_post_photo_aws_s3,\n        'default': no_save_post_photo\n    }\n    if save_photo_funcs.get(save_location):\n        filename: str = save_photo_funcs[save_location](post_image)\n    else:\n        filename: str = save_photo_funcs['default'](post_image)\n    return filename",
  "from youtube import YouTube\nfrom youtube.models import Channel\nfrom youtube.resources.schemas import YouTubeResponse\n\n\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()\n\nchannel_name: str = 'Ticker Symbol You'\nsearch_response: YouTubeResponse = youtube.find_channel_by_name(channel_name)\nprint(search_response.items[0])",
  "        print(\"Generating dataset from:\", filename)\n\n        label_file = labelme.LabelFile(filename=filename)\n\n        base = osp.splitext(osp.basename(filename))[0]\n        out_img_file = osp.join(args.output_dir, \"JPEGImages\", base + \".jpg\")\n        out_clsp_file = osp.join(args.output_dir, \"SegmentationClass\", base + \".png\")\n        if not args.nonpy:\n            out_cls_file = osp.join(\n                args.output_dir, \"SegmentationClassNpy\", base + \".npy\"\n            )\n        if not args.noviz:\n            out_clsv_file = osp.join(\n                args.output_dir,\n                \"SegmentationClassVisualization\",\n                base + \".jpg\",\n            )\n        if not args.noobject:\n            out_insp_file = osp.join(\n                args.output_dir, \"SegmentationObject\", base + \".png\"\n            )\n            if not args.nonpy:\n                out_ins_file = osp.join(\n                    args.output_dir, \"SegmentationObjectNpy\", base + \".npy\"\n                )\n            if not args.noviz:\n                out_insv_file = osp.join(\n                    args.output_dir,\n                    \"SegmentationObjectVisualization\",\n                    base + \".jpg\",\n                )\n\n        img = labelme.utils.img_data_to_arr(label_file.imageData)\n        imgviz.io.imsave(out_img_file, img)\n\n        cls, ins = labelme.utils.shapes_to_label(\n            img_shape=img.shape,\n            shapes=label_file.shapes,\n            label_name_to_value=class_name_to_id,\n        )\n",
  "    GOOGLE_OAUTH_CLIENT_SECRET = os.environ.get(\"GOOGLE_OAUTH_CLIENT_SECRET\")\n    OAUTHLIB_INSECURE_TRANSPORT = os.environ.get(\"OAUTHLIB_INSECURE_TRANSPORT\")\n    OAUTHLIB_RELAX_TOKEN_SCOPE = os.environ.get(\"OAUTHLIB_RELAX_TOKEN_SCOPE \" )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "\n    def labelSelectionChanged(self):\n        if self._noSelectionSlot:\n            return\n        if self.canvas.editing():\n            selected_shapes = []\n            for item in self.labelList.selectedItems():\n                selected_shapes.append(item.shape())\n            if selected_shapes:\n                self.canvas.selectShapes(selected_shapes)\n            else:\n                self.canvas.deSelectShape()\n\n    def labelItemChanged(self, item):\n        shape = item.shape()\n        self.canvas.setShapeVisible(shape, item.checkState() == Qt.Checked)\n\n    def labelOrderChanged(self):\n        self.setDirty()\n        self.canvas.loadShapes([item.shape() for item in self.labelList])\n\n    # Callback functions:\n\n    def newShape(self):\n        \"\"\"Pop-up and give focus to the label editor.\n\n        position MUST be in global coordinates.\n        \"\"\"\n        items = self.uniqLabelList.selectedItems()\n        text = None\n        if items:\n            text = items[0].data(Qt.UserRole)\n        flags = {}\n        group_id = None\n        description = \"\"\n        if self._config[\"display_label_popup\"] or not text:\n            previous_text = self.labelDialog.edit.text()\n            text, flags, group_id, description = self.labelDialog.popUp(text)\n            if not text:\n                self.labelDialog.edit.setText(previous_text)\n",
  "that can be used during the creation of a youtube video that reviews the product for users. Only \nreturn a JSON object with the key ``features``.\nProduct: {product}\n\"\"\"\n\nproduct_features_description_template: str = \"\"\"\nYou will be provided by a list of product features as well as a product name. Your task is to \nprovide a detailed description of each feature. Only return a JSON object with each feature as \na key.\nProduct Name: {product}\nProduct features: {features}\n\"\"\"\n\nfeatures_covered_template_str: str = \"\"\"\nYou will be provided with the transcript for a youtube video that reviews a product. The product name \nwill also be provided as well as the features of the given product. Your task will be to find all the \nfeatures of the product that are found in the feature list and are also covered in the transcript. For \neach feature covered in the transcript, provide a short summary of what is covered. Only consider the \nfeatures in the feature list. Only return a valid JSON object with each feature as a key and a short \nsummary.\nProduct: {product}\nFeatures: {features}\nTranscript: {transcript}\n\"\"\"\n\n\nfeatures_template = PromptTemplate(\n    template=product_features_template_str, input_variables=[\"product\"]\n)\nfeatures_description_template = PromptTemplate(\n    template=product_features_description_template,\n    input_variables=[\"product\", \"features\"],\n)\nfeatures_covered_template = PromptTemplate(\n    template=features_covered_template_str, input_variables=[\"product\", \"transcript\", \"features\"]\n)\n\nproduct: str = \"iphone 13 pro\"\nfeatures: list[str] = [\n    \"5G connectivity\",\n",
  "    )\n\n    label_name_to_value = {\"_background_\": 0}\n    for shape in shapes:\n        label_name = shape[\"label\"]\n        if label_name in label_name_to_value:\n            label_value = label_name_to_value[label_name]\n        else:\n            label_value = len(label_name_to_value)\n            label_name_to_value[label_name] = label_value\n\n    lbl, _ = shapes_to_label(img_shape, shapes, label_name_to_value)\n    return lbl, label_name_to_value\n\n\ndef masks_to_bboxes(masks):\n    if masks.ndim != 3:\n        raise ValueError(\"masks.ndim must be 3, but it is {}\".format(masks.ndim))\n    if masks.dtype != bool:\n        raise ValueError(\n            \"masks.dtype must be bool type, but it is {}\".format(masks.dtype)\n        )\n    bboxes = []\n    for mask in masks:\n        where = np.argwhere(mask)\n        (y1, x1), (y2, x2) = where.min(0), where.max(0) + 1\n        bboxes.append((y1, x1, y2, x2))\n    bboxes = np.asarray(bboxes, dtype=np.float32)\n    return bboxes\n",
  "from youtube import YouTube\n\n\nclient_secrets_file = '/home/lyle/Downloads/search.json'\nyoutube_client = YouTube(client_secret_file=client_secrets_file)\nyoutube_client_object = youtube_client.authenticate()\nyoutube_client.youtube_client = youtube_client_object",
  "# Scrapy settings for slidesgo project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     https://docs.scrapy.org/en/latest/topics/settings.html\n#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = \"slidesgo\"\n\nSPIDER_MODULES = [\"slidesgo.spiders\"]\nNEWSPIDER_MODULE = \"slidesgo.spiders\"\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = \"slidesgo (+http://www.yourdomain.com)\"\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = True\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n",
  "from ..database.crud.user import get_random_user\nfrom ..database.crud.post import get_posts\nfrom ..database.crud.like import list_post_likes, get_key_like, has_liked\nfrom ..database.crud.comment import get_key_comment, list_post_comments\nfrom ..database.crud.bookmark import has_bookmarked\nfrom ..database.database import get_db\nfrom ..database.models import (\n    User, Post, Like, Bookmark, Comment\n)\nfrom ..database.schemas.post import (\n    GetPosts, PostAuthor, GetPost, PostLike, KeyComment, PostSchema\n)\nfrom ..database.schemas.activity import CreateActivity\nfrom flask import url_for\nfrom pydantic import ValidationError\nfrom sqlalchemy.exc import OperationalError, IntegrityError\nfrom datetime import datetime",
  "from typing import Generator, Optional, Iterator\nfrom pydantic import BaseModel, Field\nfrom youtube import YouTube\nfrom youtube.models import Channel, Comment, Search, Video\nfrom youtube.schemas import (SearchOptionalParameters, SearchPart,\n                             YouTubeListResponse, YouTubeRequest,\n                             YouTubeResponse)\nimport json\nfrom rich.table import Table\nfrom rich.console import Console\nfrom rich import box\nfrom rich.live import Live\n\n\nclient_secrets_file = \"/home/lyle/Downloads/search.json\"\nyoutube_client = YouTube(client_secret_file=client_secrets_file)\nyoutube_client_object = youtube_client.authenticate()\nyoutube_client.youtube_client = youtube_client_object\n\n\ndef get_channel_id(channel_name: str) -> str:\n    \"\"\"Get the channel id.\"\"\"\n    response: YouTubeResponse = youtube_client.find_channel_by_name(channel_name)\n    search_result: Search = response.items[0]\n    return search_result.resource_id\n\n\ndef search_youtube_channels(product: str, max_results: int = 5) -> list[Search]:\n    search_part: SearchPart = SearchPart()\n    query: str = f\"latest {product} review\"\n    optional_params: SearchOptionalParameters = SearchOptionalParameters(\n        q=query,\n        maxResults=max_results,\n        type=[\"channel\"],\n    )\n    search_schema: YouTubeRequest = YouTubeRequest(\n        part=search_part, optional_parameters=optional_params\n    )\n    response: YouTubeResponse = youtube_client.search(search_schema)\n    items: list[Search] = response.items\n",
  "from typing import Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass AgentState(BaseModel):\n    product: Optional[str] = Field(\n        description=\"The product being reviewed\", default=None\n    )\n    channel: Optional[str] = Field(description=\"The youtube channel used\", default=None)\n    video: Optional[str] = Field(description=\"The video being reviewed\", default=None)\n    transcript: Optional[str] = Field(description=\"The video transcript\", default=None)\n    comments: Optional[list[str]] = Field(\n        description=\"The video comments\", default_factory=list\n    )\n    summary: Optional[str] = Field(description=\"The video summary\", default=None)\n    analysis_summary: Optional[str] = Field(\n        description=\"The video analysis_summary\", default=None\n    )\n    features: Optional[str] = Field(\n        description=\"The product features reviewed\", default=None\n    )\n    questions: Optional[list[str]] = Field(\n        description=\"The questions that the analyst had\", default_factory=list\n    )\n",
  "    logging.info('Request authenticated.')\n    return youtube\n\n\ndef create_playlist(title: str, \n                    description: str, \n                    youtube: YouTube,\n                    default_language: str = 'en', \n                    privacy_status: str = 'public') -> Playlist:\n    snippet: CreatePlaylistSnippet = CreatePlaylistSnippet(\n        title=title,\n        description=description,\n        defaultLanguage=default_language\n    )\n    create_schema: CreatePlaylistSchema = CreatePlaylistSchema(\n        snippet=snippet,\n        status=CreateStatus(privacyStatus=privacy_status)\n    )\n    playlist: Playlist = youtube.insert_playlist(create_schema)\n    return playlist\n\n\ndef get_playlists() -> dict[str, dict]:\n    playlists: dict[str, str] = {\n        'Daily Videos': {\n            'id': 'PL_26vmg8W_AcEEl_Bo2AhziS-93r6b8bu',\n            'url': 'https://www.youtube.com/playlist?list=PL_26vmg8W_AcEEl_Bo2AhziS-93r6b8bu'\n        }\n    }\n    return playlists\n\n\ndef get_playlist_id(name: str) -> str:\n    playlists: dict[str, dict] = get_playlists()\n    return playlists[name]['id']\n    \n    \ndef get_playlist_url(name: str) -> str:\n    playlists: dict[str, dict] = get_playlists()\n    return playlists[name]['url']\n",
  "\n        # Application state.\n        self.image = QtGui.QImage()\n        self.imagePath = None\n        self.recentFiles = []\n        self.maxRecent = 7\n        self.otherData = None\n        self.zoom_level = 100\n        self.fit_window = False\n        self.zoom_values = {}  # key=filename, value=(zoom_mode, zoom_value)\n        self.brightnessContrast_values = {}\n        self.scroll_values = {\n            Qt.Horizontal: {},\n            Qt.Vertical: {},\n        }  # key=filename, value=scroll_value\n\n        if filename is not None and osp.isdir(filename):\n            self.importDirImages(filename, load=False)\n        else:\n            self.filename = filename\n\n        if config[\"file_search\"]:\n            self.fileSearch.setText(config[\"file_search\"])\n            self.fileSearchChanged()\n\n        # XXX: Could be completely declarative.\n        # Restore application settings.\n        self.settings = QtCore.QSettings(\"labelme\", \"labelme\")\n        self.recentFiles = self.settings.value(\"recentFiles\", []) or []\n        size = self.settings.value(\"window/size\", QtCore.QSize(600, 500))\n        position = self.settings.value(\"window/position\", QtCore.QPoint(0, 0))\n        state = self.settings.value(\"window/state\", QtCore.QByteArray())\n        self.resize(size)\n        self.move(position)\n        # or simply:\n        # self.restoreGeometry(settings['window/geometry']\n        self.restoreState(state)\n\n        # Populate the File menu dynamically.\n        self.updateFileMenu()\n",
  "from .google_drive import GoogleDrive\n",
  "@post.route(\"/create\", methods=[\"POST\", \"GET\"])\ndef create_new_post():\n    \"\"\"Create a new post.\"\"\"\n    if request.method == 'GET':\n        return {'success': 'post creation form'}, HTTPStatus.OK\n    elif request.method == 'POST':\n        try:\n            post_data = CreatePost(**request.form) \n        except ValidationError:\n            return {'Error': 'The data provided is invalid or incomplete!'}, HTTPStatus.BAD_REQUEST\n        try:\n            user_data = GetUser(user_id=post_data.author_id)\n            user = get_user(session=get_db, user_data=user_data)\n            if not user:\n                return {'Error': f'User with id {user_data.user_id} does not exists'}, HTTPStatus.NOT_FOUND \n            post: Post = create_post(post_data=post_data, post_image=request.files, session=get_db) \n        except (OperationalError, IntegrityError) as e:\n            print(e)\n            # Send email to\n            return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n        resp = CreatedPost(\n            id=post.id,\n            location=post.location,\n            text=post.text,\n            image_url=post.image_url,\n            author_id=post.author_id,\n            date_published=post.date_published\n        )\n        return resp.model_dump_json(indent=4), HTTPStatus.CREATED",
  "            \"insertText\": {\n                \"objectId\": element_id,\n                \"insertionIndex\": 0,\n                \"text\": \"New Box Text Inserted!\",\n            }\n        },\n    ]\n\n    # Execute the request.\n    body = {\"requests\": requests}\n    response = (\n        slide_client.presentations()\n        .batchUpdate(presentationId=presentation_id, body=body)\n        .execute()\n    )\n    create_shape_response = response.get(\"replies\")[0].get(\"createShape\")\n    print(f\"Created textbox with ID:{(create_shape_response.get('objectId'))}\")\n  except HttpError as error:\n    print(f\"An error occurred: {error}\")\n\n    return error\n\n  return response\n\n\ndef create_image(presentation_id: str, page_id: str, slide_client: Any):\n  try:\n    IMAGE_URL = (\n        \"https://www.google.com/images/branding/\"\n        \"googlelogo/2x/googlelogo_color_272x92dp.png\"\n    )\n    # pylint: disable=invalid-name\n    requests = []\n    image_id = \"MyImage_11\"\n    emu4M = {\"magnitude\": 4000000, \"unit\": \"EMU\"}\n    requests.append(\n        {\n            \"createImage\": {\n                \"objectId\": image_id,\n                \"url\": IMAGE_URL,\n",
  "    def changeOutputDirDialog(self, _value=False):\n        default_output_dir = self.output_dir\n        if default_output_dir is None and self.filename:\n            default_output_dir = osp.dirname(self.filename)\n        if default_output_dir is None:\n            default_output_dir = self.currentPath()\n\n        output_dir = QtWidgets.QFileDialog.getExistingDirectory(\n            self,\n            self.tr(\"%s - Save/Load Annotations in Directory\") % __appname__,\n            default_output_dir,\n            QtWidgets.QFileDialog.ShowDirsOnly\n            | QtWidgets.QFileDialog.DontResolveSymlinks,\n        )\n        output_dir = str(output_dir)\n\n        if not output_dir:\n            return\n\n        self.output_dir = output_dir\n\n        self.statusBar().showMessage(\n            self.tr(\"%s . Annotations will be saved/loaded in %s\")\n            % (\"Change Annotations Dir\", self.output_dir)\n        )\n        self.statusBar().show()\n\n        current_filename = self.filename\n        self.importDirImages(self.lastOpenDir, load=False)\n\n        if current_filename in self.imageList:\n            # retain currently selected file\n            self.fileListWidget.setCurrentRow(self.imageList.index(current_filename))\n            self.fileListWidget.repaint()\n\n    def saveFile(self, _value=False):\n        assert not self.image.isNull(), \"cannot save empty image\"\n        if self.labelFile:\n            # DL20180323 - overwrite when in directory\n            self._saveFile(self.labelFile.filename)\n",
  "        ins[cls == -1] = 0  # ignore it.\n\n        # class label\n        labelme.utils.lblsave(out_clsp_file, cls)\n        if not args.nonpy:\n            np.save(out_cls_file, cls)\n        if not args.noviz:\n            clsv = imgviz.label2rgb(\n                cls,\n                imgviz.rgb2gray(img),\n                label_names=class_names,\n                font_size=15,\n                loc=\"rb\",\n            )\n            imgviz.io.imsave(out_clsv_file, clsv)\n\n        if not args.noobject:\n            # instance label\n            labelme.utils.lblsave(out_insp_file, ins)\n            if not args.nonpy:\n                np.save(out_ins_file, ins)\n            if not args.noviz:\n                instance_ids = np.unique(ins)\n                instance_names = [str(i) for i in range(max(instance_ids) + 1)]\n                insv = imgviz.label2rgb(\n                    ins,\n                    imgviz.rgb2gray(img),\n                    label_names=instance_names,\n                    font_size=15,\n                    loc=\"rb\",\n                )\n                imgviz.io.imsave(out_insv_file, insv)\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "@staticmethod\n    def hash_password(password: str) -> str:\n        return bcrypt.generate_password_hash(password).decode(\"utf-8\")\n\n    def check_password(self, password: str) -> bool:\n        return bcrypt.check_password_hash(self.password, password)\n    \n    @staticmethod\n    def encode_auth_token(user_id: int):\n        try:\n            payload = {\n                \"exp\": datetime.utcnow() + timedelta(days=0, hours=2),\n                \"iat\": datetime.utcnow(),\n                \"sub\": user_id,\n            }\n            return jwt.encode(payload, current_app.config.get(\"SECRET_KEY\"), algorithm=\"HS256\")\n        except Exception as e:\n            return e\n        \n    @staticmethod\n    def decode_auth_token(auth_token: str):\n        try:\n            payload = jwt.decode(auth_token, current_app.config.get(\"SECRET_KEY\"), algorithms=\"HS256\")\n            return payload[\"sub\"]\n        except (ExpiredSignatureError, InvalidTokenError) as e:\n            raise e",
  "            (self._image_embedding,) = self._encoder_session.run(\n                output_names=None,\n                input_feed={\"batched_images\": batched_images},\n            )\n            if len(self._image_embedding_cache) > 10:\n                self._image_embedding_cache.popitem(last=False)\n            self._image_embedding_cache[self._image.tobytes()] = self._image_embedding\n            logger.debug(\"Done computing image embedding.\")\n\n    def _get_image_embedding(self):\n        if self._thread is not None:\n            self._thread.join()\n            self._thread = None\n        with self._lock:\n            return self._image_embedding\n\n    def predict_mask_from_points(self, points, point_labels):\n        return _compute_mask_from_points(\n            decoder_session=self._decoder_session,\n            image=self._image,\n            image_embedding=self._get_image_embedding(),\n            points=points,\n            point_labels=point_labels,\n        )\n\n    def predict_polygon_from_points(self, points, point_labels):\n        mask = self.predict_mask_from_points(points=points, point_labels=point_labels)\n        return _utils.compute_polygon_from_mask(mask=mask)\n\n\ndef _compute_mask_from_points(\n    decoder_session, image, image_embedding, points, point_labels\n):\n    input_point = np.array(points, dtype=np.float32)\n    input_label = np.array(point_labels, dtype=np.float32)\n\n    # batch_size, num_queries, num_points, 2\n    batched_point_coords = input_point[None, None, :, :]\n    # batch_size, num_queries, num_points\n    batched_point_labels = input_label[None, None, :]\n",
  "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\"✅ Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\"❌ Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file\n",
  "def handle_unsupported_media_type(exeption: Exception) -> Response:\n    \"\"\"Handle all unsupported media type errors.\n\n    This method is called when a a request does not supply the data or the data supplied is\n    invalid.\n\n    Parameters\n    ----------\n    exception: Exception\n        The exception that was raised. This is a subclass of Exception.\n\n    Returns\n    -------\n    Response:\n        A string consiting of json data and response code.\n    \"\"\"\n    return make_response(jsonify({\"error\": str(exeption)}), HTTPStatus.UNSUPPORTED_MEDIA_TYPE)\n\n\ndef register_error_handlers(app: Flask) -> None:\n    \"\"\"Register the error handlers.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        The Flask app instance.\n    \"\"\"\n    app.register_error_handler(HTTPStatus.NOT_FOUND, handle_resource_not_found)\n    app.register_error_handler(HTTPStatus.METHOD_NOT_ALLOWED, handle_method_not_allowed)\n    app.register_error_handler(HTTPStatus.INTERNAL_SERVER_ERROR, handle_internal_server_error)\n    app.register_error_handler(HTTPStatus.UNSUPPORTED_MEDIA_TYPE, handle_unsupported_media_type)",
  "from .view import code",
  "\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"\n",
  "@post.route(\"/likes\", methods=[\"GET\"])\ndef get_post_likes():\n    \"\"\"Get a posts likes.\"\"\"\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        likes: list[Bookmark] = list_post_likes(session=get_db, post_data=post_data)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    resp = [\n        ActivityCreated(\n            user_id=like.author_id,\n            post_id=like.post_id,\n            date_created=like.like_date\n        ).model_dump()\n        for like in likes\n    ]\n    return resp, HTTPStatus.OK",
  "from qtpy import QtWidgets\nfrom qtpy.QtCore import Qt\n\n\nclass EscapableQListWidget(QtWidgets.QListWidget):\n    def keyPressEvent(self, event):\n        super(EscapableQListWidget, self).keyPressEvent(event)\n        if event.key() == Qt.Key_Escape:\n            self.clearSelection()\n",
  "from os import path\n\nfrom langchain.chains import StuffDocumentsChain\nfrom langchain.chains.llm import LLMChain\nfrom langchain.llms.base import BaseLLM\nfrom langchain.prompts import PromptTemplate\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders.text import TextLoader\nfrom langchain_openai import ChatOpenAI, OpenAI\nfrom langchain.docstore.document import Document\n\nwith open('analysis.json', 'r') as f:\n    import json\n    analy = json.load(f)\n\napi_key: str = \"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\"\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n\n\ntemplate_str: str = \"\"\"\nYou are provided with the coments of various users to the review of the {product}\n\nPlease provide a detailed summary of the users comments. Make sure to identify the features \nthat the users loved as well as those that they hated.\ncomments: {comments}\ndetailed summary: \n\"\"\"\n\nproduct: str = \"Apple vision pro\"\ntemplate = PromptTemplate.from_template(template_str)\ntemplate = template.partial(product=product)\n\napi_key: str = \"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\"\nchat: BaseLLM = ChatOpenAI(temperature=0, api_key=api_key)\nllm: BaseLLM = OpenAI(temperature=0, api_key=api_key)\n\nllm_chain = LLMChain(llm=chat, prompt=template)\nstuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"comments\")\n\n",
  "        return train_config",
  "\ndef get_video_comments(video_id: str, max_results: Optional[int] = 10) -> Generator:\n    \"\"\"List a given videos comments\"\"\"\n    comment_iterator: Iterator = youtube_client.get_comments_iterator(video_id=video_id)\n    done: bool = False\n    comment_count: int = 0\n    for comment_threads in comment_iterator:\n        if done:\n            break\n        for comment_thread in comment_threads:\n            comment: Comment = comment_thread.snippet.top_level_comment\n            comment = parse_comment(comment=comment)\n            # comment = Data(\n            #     id=comment[\"comment_id\"],\n            #     comment=comment[\"comment\"],\n            #     likes=comment[\"likes\"],\n            #     date=comment[\"date_published\"],\n            # )\n            yield comment\n            comment_count += 1\n            if comment_count > max_results:\n                done = True\n                break\n            \n            \ndef create_comments_table(table_data: list[dict]) -> Table:\n    table: Table = Table(row_styles=[\"dim\", \"\"],leading=1, box=box.MINIMAL_DOUBLE_HEAD)\n    table.add_column(header=\"[b]Comment Id\", justify=\"left\", style=\"dark_orange\")\n    table.add_column(header=\"Comment\", justify=\"left\", style=\"light_coral\")\n    table.add_column(header=\"[b]Likes\", justify=\"left\", style=\"yellow2\")\n    table.add_column(header=\"Date\", justify=\"center\", style=\"violet\")\n    table.columns[0].header_style = \"bold chartreuse1\"\n    table.columns[1].header_style = \"bold dark_goldenrod\"\n    table.columns[2].header_style = \"bold chartreuse1\"\n    table.columns[3].header_style = \"bold dark_goldenrod\"\n    table.border_style = \"bright_yellow\"\n    table.pad_edge = True\n    for row in table_data:\n        table.add_row(row[\"comment_id\"], row[\"comment\"], str(row[\"likes\"]), row[\"date_published\"])\n    return table\n",
  "        packages=find_packages(),\n        description=\"Image Polygonal Annotation with Python\",\n        long_description=get_long_description(),\n        long_description_content_type=\"text/markdown\",\n        author=\"Kentaro Wada\",\n        author_email=\"www.kentaro.wada@gmail.com\",\n        url=\"https://github.com/wkentaro/labelme\",\n        install_requires=get_install_requires(),\n        license=\"GPLv3\",\n        keywords=\"Image Annotation, Machine Learning\",\n        classifiers=[\n            \"Development Status :: 5 - Production/Stable\",\n            \"Intended Audience :: Developers\",\n            \"Intended Audience :: Science/Research\",\n            \"Natural Language :: English\",\n            \"Operating System :: OS Independent\",\n            \"Programming Language :: Python\",\n            \"Programming Language :: Python :: 3.5\",\n            \"Programming Language :: Python :: 3.6\",\n            \"Programming Language :: Python :: 3.7\",\n            \"Programming Language :: Python :: 3.8\",\n            \"Programming Language :: Python :: 3.9\",\n            \"Programming Language :: Python :: 3 :: Only\",\n        ],\n        package_data={\"labelme\": [\"icons/*\", \"config/*.yaml\", \"translate/*\"]},\n        entry_points={\n            \"console_scripts\": [\n                \"labelme=labelme.__main__:main\",\n                \"labelme_draw_json=labelme.cli.draw_json:main\",\n                \"labelme_draw_label_png=labelme.cli.draw_label_png:main\",\n                \"labelme_json_to_dataset=labelme.cli.json_to_dataset:main\",\n                \"labelme_export_json=labelme.cli.export_json:main\",\n                \"labelme_on_docker=labelme.cli.on_docker:main\",\n            ],\n        },\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "        search_resp: Search = search_responses[0]\n        video: Video = Video(**search_resp.model_dump(exclude={'thumbnails'}))\n        video_str: str = dumps(video.dict(), default=str)\n        logging.info('caching the retrieved video.')\n        redis.set(name=f'latest:{channel_id}', value=video_str)\n        logging.info('Successfully cached the retrieved video.')\n        logging.info('Setting an expiration time of %d for the cached video.', config.expiration_time)\n        redis.setex(f'latest:{channel_id}', value=video_str, time=timedelta(seconds=config.expiration_time))\n    return video\n\ndef add_video_to_playlist(video: Video, \n                          playlist_id: str, \n                          youtube: YouTube, \n                          position: int = 0) -> PlaylistItem | None:\n    playlist_item: PlaylistItem = None\n    if redis.setnx(name=f'{playlist_id}:{video.resource_id}', value=video.resource_id):\n        logging.info('The video \"%s\" odes not exist in playlist, adding it.', video.title)\n        resource_id: VideoResourceId = VideoResourceId(videoId=video.resource_id)\n        snippet: CreatePlaylistItemSnippet = CreatePlaylistItemSnippet(\n            playlistId=playlist_id,\n            resourceId=resource_id,\n            position=position\n        )\n        create: CreatePlaylistItem = CreatePlaylistItem(snippet=snippet)\n        logging.info('Inserting \"%s\" into playlist.', video.title)\n        playlist_item: PlaylistItem = youtube.insert_playlist_item(create)\n        logging.info('Inserted \"%s\" to playlist.', video.title)\n        logging.info('Adding \"%s\" to \"unwatched list\".', video.title)\n        video.save()\n        logging.info('Added \"%s\" to \"unwatched list\".', video.title)\n        logging.info('Setting the video expiration time of %d for video.', config.expiration_time)\n        video.expire(num_seconds=3600)\n    return playlist_item\n\n\ndef delete_video_playlist(playlist_item_id: str, youtube: YouTube) -> None:\n    youtube.delete_playlist_item(playlist_item_id)\n    \n    \ndef workflow(youtube: YouTube, channel_names: list[str], playlist_name: str = 'Daily Videos'):\n",
  "\n\nclass ProductFeatures(BaseModel):\n    display: str\n    design: str\n    perfomance: str\n    camera: str\n\n\n@tool(args_schema=UserQuery)\ndef google_search_tool(query: str, result_count: int) -> str:\n    \"\"\"Search for the latest information from the web using Google.\"\"\"\n    google_search = GoogleSearchAPIWrapper(\n        google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID, k=3\n    )\n    google_search.k = result_count\n    return google_search.run(query=query)\n\n\nchat_model.bind(functions=[convert_to_openai_function(google_search_tool)])\nprompt = ChatPromptTemplate.from_messages(\n    messages=[\n        (\n            \"system\",\n            \"You are a very good product analyst for apple products. Your task is to find out the most accurate detailed information on various apple products.\",\n        ),\n        (\"human\", \"{request}\"),\n    ]\n)\n\n# analyst_chain = prompt | chat_model\n\n# res = analyst_chain.invoke(\n#     {\"request\": \"What are all the features of the iphone 13 pro max?\"}\n# )\n\n# print(res)\n\nproduct_features_template_str: str = \"\"\"\nYou will be provided with a product name. Your task will be to list all all the product,s features \n",
  "\ndef is_acceptable_len(text: str, l: int = 20) -> bool:\n    return len(text.split()) >= l\n\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n    cleaned_comments: list[str] = list(map(clean_text, all_comments))\n    comments: list[str] = choices(population=cleaned_comments, k=10)\n    docs: list[Document] = [\n        Document(page_content=comment)\n        for comment in comments\n        if is_acceptable_len(comment)\n    ]\n    comments: list[dict[str, str | int]] = [\n        {\"doc_id\": i + 1, \"comment\": docs[i].page_content} for i in range(len(docs))\n    ]\n\ndata_dir = \"./agent_nelly/data_analysis/data\"\nfeatures_dir = \"features\"\nsave_features_dir = path.join(data_dir, features_dir, \"features.json\")\n\nwith open(save_features_dir, 'r') as f:\n    topics: list[str] = json.load(f)\n\ncomment: dict = choice(comments)\n\n\nsentiment_msg: str = \"\"\"\nBelow is a customer comment in JSON format with the following keys:\n1. doc_id - identifier of the comment\n2. comment - the user comment\n\nPlease analyze the comment and identify the sentiment. The sentiment can be negative, neutral or \npositive. Only return a single string, the sentiment.\n\nComment:\n```\n{comment}\n```\n",
  "\ndef add_module_to_queue(module_path: str, module_path_queue: Queue):\n    module_path_queue.put(module_path)\n\n\ndef get_node_source(node, module_src: str) -> str:\n    return ast.get_source_segment(source=module_src, node=node)\n\n\ndef get_functions_source(module_path: str) -> list[str]:\n    functions_src: list[str] = []\n    module_src = get_module_source_code(module_path)\n    module_tree = ast.parse(module_src)\n    for node in module_tree.body:\n        if isinstance(node, FunctionDef):\n            function_src: str = get_node_source(node=node, module_src=module_src)\n            functions_src.append((node.name, function_src))\n    return functions_src\n\n\ndef get_class_source(module_path: str) -> None:\n    class_src: list[str] = []\n    module_src = get_module_source_code(module_path)\n    module_tree = ast.parse(module_src)\n    for node in module_tree.body:\n        if isinstance(node, ClassDef):\n            classsrc: str = get_node_source(node=node, module_src=module_src)\n            class_src.append((node.name, classsrc))\n    return class_src\n\n\nclass DirectoryIterator:\n    def __init__(self, config: Config):\n        self.config: Config = config\n        self.queue: deque[str] = deque(self.config.path)\n\n    def __iter__(self) -> Iterator:\n        return self\n\n    def __next__(self) -> list[str]:\n",
  "    agent = cl.user_session.get(\"agent\")\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({\"input\": message.content})[\"output\"]\n    await msg.update()",
  "                function_code=function_code, config=self.config\n            )\n            try:\n                function_docstring: str = get_function_docstring(function_and_docstring)\n            except Exception:\n                new_docstring_node = make_docstring_node(function_and_docstring)\n            else:\n                new_docstring_node = make_docstring_node(function_docstring)\n            node.body.insert(0, new_docstring_node)\n        return node\n\n\nclass ClassDocStringWriter(NodeTransformer, BaseModel):\n    module_path: str = Field(description='The path to this module')\n    class_name: str = Field(description='The name of the class to generate docstrings')\n    class_code: str = Field(description='The source code for this class')\n    config: Config = Field(description='The application configurations.')\n\n    @property\n    def module_code(self) -> str:\n        return get_module_source_code(self.module_path)\n\n    def visit_ClassDef(self, node: ClassDef) -> Any:\n        docstring: str = ast.get_docstring(node=node)\n        if node.name == self.class_name and (\n            self.config.overwrite_class_docstring or not docstring\n        ):\n            class_code: str = ast.get_source_segment(\n                source=self.module_code, node=node, padded=True\n            )\n            class_and_docstring: str = generate_class_docstring(\n                class_code=class_code, config=self.config\n            )\n            try:\n                class_docstring: str = get_class_docstring(class_and_docstring)\n            except Exception:\n                class_docstring = class_and_docstring\n                new_docstring_node = make_docstring_node(class_and_docstring)\n                class_docstring = class_and_docstring\n            else:\n",
  "        ins[cls == -1] = 0  # ignore it.\n\n        # class label\n        labelme.utils.lblsave(out_clsp_file, cls)\n        if not args.nonpy:\n            np.save(out_cls_file, cls)\n        if not args.noviz:\n            clsv = imgviz.label2rgb(\n                cls,\n                imgviz.rgb2gray(img),\n                label_names=class_names,\n                font_size=15,\n                loc=\"rb\",\n            )\n            imgviz.io.imsave(out_clsv_file, clsv)\n\n        if not args.noobject:\n            # instance label\n            labelme.utils.lblsave(out_insp_file, ins)\n            if not args.nonpy:\n                np.save(out_ins_file, ins)\n            if not args.noviz:\n                instance_ids = np.unique(ins)\n                instance_names = [str(i) for i in range(max(instance_ids) + 1)]\n                insv = imgviz.label2rgb(\n                    ins,\n                    imgviz.rgb2gray(img),\n                    label_names=instance_names,\n                    font_size=15,\n                    loc=\"rb\",\n                )\n                imgviz.io.imsave(out_insv_file, insv)\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "\n@celery.task(name=\"train_model_task\")\ndef train_model_task(train_config: TrainConfig):\n    train_results: dict = fit_pipeline(train_config=train_config)\n    trained_model: TrainedModel = TrainedModel(\n        classifier_name=train_results['model_name'],\n        train_date=datetime.now(),\n        save_path=path.join(app_config.models_dir, 'trained', train_results['model_name']),\n        owner='Lyle Okoth',\n        metrics=train_results['metrics'],\n        train_time=train_results['train_time']\n    )\n    trained_model.post_model_metrics(app_config, redis)\n    return {\n        'Model Name': train_results['model_name'],\n        'Train Time': train_results['train_time'],\n        'Metrics': train_results['metrics']\n    }\n    \n\n@celery.task(name='tune_model')\ndef tune_model(train_config: TrainConfig):\n    train_features = train_config.preprocessor.fit_transform(train_config.train_features)\n    test_features = train_config.preprocessor.fit_transform(train_config.test_features)\n    clf = GridSearchCV(train_config.model, hyperparameters[train_config.classifier_name], cv=10)\n    best_model = clf.fit(train_features, train_config.train_labels.values.ravel())\n    best_params = best_model.best_estimator_.get_params()\n    preds = best_model.predict(test_features)\n    accuracy = accuracy_score(preds, train_config.test_labels)\n    return {\n        'params': best_params,\n        'acuracy': accuracy,\n        'name': train_config.classifier_name\n    }\n    \ndef fit_pipeline(train_config: TrainConfig, model_params: dict = {}, train: bool = True) -> dict:\n    logging.info('Training and saving the tuned model')\n    untrained_model: BaseEstimator = train_config.model\n    pipeline: Pipeline = Pipeline(steps=[\n            ('preprocessor', train_config.preprocessor),\n",
  "@staticmethod\n    def hash_password(password: str) -> str:\n        return bcrypt.generate_password_hash(password).decode(\"utf-8\")\n\n    def check_password(self, password: str) -> bool:\n        return bcrypt.check_password_hash(self.password, password)\n    \n    @staticmethod\n    def encode_auth_token(user_id: int):\n        try:\n            payload = {\n                \"exp\": datetime.utcnow() + timedelta(days=0, hours=2),\n                \"iat\": datetime.utcnow(),\n                \"sub\": user_id,\n            }\n            return jwt.encode(payload, current_app.config.get(\"SECRET_KEY\"), algorithm=\"HS256\")\n        except Exception as e:\n            return e\n        \n    @staticmethod\n    def decode_auth_token(auth_token: str):\n        try:\n            payload = jwt.decode(auth_token, current_app.config.get(\"SECRET_KEY\"), algorithms=\"HS256\")\n            return payload[\"sub\"]\n        except (ExpiredSignatureError, InvalidTokenError) as e:\n            raise e",
  "# channel_list = ['Asianometry', '']\n# watched_list = []\n# playlist_id = 'PL_26vmg8W_AfJWy6SVtoSmtYWimhexwF7'\n# playlist_title = ''\n# channel_name = 'Asianometry'\n# channel_id = ''\n# video_id = ''\n# channels = youtube.find_channel_by_name(channel_name)\n# for channel in channels.items:\n#     if channel.title == channel_name:\n#         channel_id = channel.channel_id\n# part = Part()\n# optional_parameters: OptionalParameters = OptionalParameters(\n#     q='',\n#     maxResults=1,\n#     type=['video'],\n#     channelId=channel_id,\n#     order='date'\n# )\n# search = SearchSchema(part=part, optional_parameters=optional_parameters)\n# search_result = youtube.search(search)\n# videos = search_result.items\n# latest_video = videos[0]\n# video_id = latest_video.resource_id\n# video_resource: VideoResourceId = VideoResourceId(videoId=video_id)\n# snippet: CreatePlaylistItemSnippet = CreatePlaylistItemSnippet(\n#     playlistId=playlist_id,\n#     resourceId=video_resource\n# )\n# create = CreatePlaylistItem(snippet=snippet)\n# playlist_item = youtube.insert_playlist_item(create)\n# print(f'Added {playlist_item.snippet.title} to the playlist.')\n# print(youtube.get_video_categories())\n\n# def search_save():\n#     from json import dump\n#     part: SearchPart = SearchPart()\n#     optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#         q='israel palestine conflict',\n#         maxResults=5,\n",
  "# Scrapy settings for slidesmodel project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     https://docs.scrapy.org/en/latest/topics/settings.html\n#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = \"slidesmodel\"\n\nSPIDER_MODULES = [\"slidesmodel.spiders\"]\nNEWSPIDER_MODULE = \"slidesmodel.spiders\"\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = \"slidesmodel (+http://www.yourdomain.com)\"\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n",
  "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A chatbot that enables the user interact with youtube over chat.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos', 'chat with youtube',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'oryks-youtube',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='youtube-assistant',\n    packages=find_packages(\n        include=[\n            'assistant',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n",
  "from scrapy import Item, Field\nfrom itemloaders.processors import TakeFirst, MapCompose, Join\nimport re\n\n\ndef remove_html_tags(description: str) -> str:\n    html_pattern = \"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\" \n    return re.sub(html_pattern, '', description)\n\ndef remove_unicode_chars(text: str) -> str:\n    return text.replace(u\"\\xa0\", \"\")\n\ndef num_of_slides(text: str) -> int:\n    vals = [val for val in list(text) if val.isdigit()]\n    return \"\".join(vals)\n\n\nclass SlidesModelItem(Item):\n    title = Field(output_processor=TakeFirst())\n    category = Field(output_processor=TakeFirst())\n    description = Field(\n        input_processor=MapCompose(remove_html_tags, remove_unicode_chars),\n        output_processor=Join()\n    )\n    tags = Field()\n    slides_count = Field(\n        input_processor=MapCompose(num_of_slides),\n        output_processor=TakeFirst()\n    )\n    colors = Field()\n    image_urls = Field()\n    images = Field()\n",
  "        )\n        generate_functions_docstring_thread.start()\n\n    for _ in range(1):\n        generate_class_docstring_thread: Thread = Thread(\n            target=generate_class_docstrings,\n            args=(class_source_queue, config),\n            daemon=True,\n        )\n        generate_class_docstring_thread.start()\n\n    queue_modules.join()\n    module_path_queue.join()\n    functions_source_queue.join()\n    class_source_queue.join()\n",
  "    )\n    parser.add_argument(\n        \"--labels\",\n        help=\"comma separated list of labels OR file containing labels\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--validatelabel\",\n        dest=\"validate_label\",\n        choices=[\"exact\"],\n        help=\"label validation types\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--keep-prev\",\n        action=\"store_true\",\n        help=\"keep annotation of previous frame\",\n        default=argparse.SUPPRESS,\n    )\n    parser.add_argument(\n        \"--epsilon\",\n        type=float,\n        help=\"epsilon to find nearest vertex on canvas\",\n        default=argparse.SUPPRESS,\n    )\n    args = parser.parse_args()\n\n    if args.version:\n        print(\"{0} {1}\".format(__appname__, __version__))\n        sys.exit(0)\n\n    logger.setLevel(getattr(logging, args.logger_level.upper()))\n\n    if hasattr(args, \"flags\"):\n        if os.path.isfile(args.flags):\n            with codecs.open(args.flags, \"r\", encoding=\"utf-8\") as f:\n                args.flags = [line.strip() for line in f if line.strip()]\n        else:\n            args.flags = [line for line in args.flags.split(\",\") if line]\n\n",
  "    def undoLastPoint(self):\n        if not self.current or self.current.isClosed():\n            return\n        self.current.popPoint()\n        if len(self.current) > 0:\n            self.line[0] = self.current[-1]\n        else:\n            self.current = None\n            self.drawingPolygon.emit(False)\n        self.update()\n\n    def loadPixmap(self, pixmap, clear_shapes=True):\n        self.pixmap = pixmap\n        if self._ai_model:\n            self._ai_model.set_image(\n                image=labelme.utils.img_qt_to_arr(self.pixmap.toImage())\n            )\n        if clear_shapes:\n            self.shapes = []\n        self.update()\n\n    def loadShapes(self, shapes, replace=True):\n        if replace:\n            self.shapes = list(shapes)\n        else:\n            self.shapes.extend(shapes)\n        self.storeShapes()\n        self.current = None\n        self.hShape = None\n        self.hVertex = None\n        self.hEdge = None\n        self.update()\n\n    def setShapeVisible(self, shape, value):\n        self.visible[shape] = value\n        self.update()\n\n    def overrideCursor(self, cursor):\n        self.restoreCursor()\n        self._cursor = cursor\n",
  "def create_like(session: Session, activity: CreateActivity) -> Like:\n    with session() as db:\n        like: Like = Like(\n            author_id=activity.user_id,\n            post_id=activity.post_id\n        )\n        db.add(like)\n        db.commit()\n        db.refresh(like)\n    return like",
  "    )\n    documents: list[Document] = loader.load()\n    full_transcript: str = \"\"\n    for document in documents:\n        full_transcript += document.page_content\n    return full_transcript\n\ndef analayze_video(video_transcript: str):\n    \"\"\"Break a video into the slide components.\n    \n    The video is to be broken down into:\n    1. The Cover - summary details about this video\n    2. Index - a shortcut to other slides\n    3. The slides\n    \n    The cover\n    ---------\n    Contains the video name and channel presenting the video\n    \n    Index\n    -----\n    Contains links to the other slides and their titles\n    \n    The slides\n    -----------\n    Consist of the slide title and a bullet of points\n    \"\"\"\n    pass\n",
  "from queue import Queue\n\nfrom langchain_openai import OpenAI\n\nmodules_path_queue: Queue = Queue()\nfunctions_source_code_queue: Queue = Queue()\nclass_source_code_queue: Queue = Queue()\nfailed_modules_queue: Queue = Queue()\nllm = OpenAI(temperature=0)\n",
  "from youtube import YouTube\nfrom youtube.models import Search\nfrom youtube.schemas import (\n        YouTubeRequest, YouTubeListResponse, YouTubeResponse,\n        SearchFilter, SearchOptionalParameters, SearchPart\n)\nfrom typing import Iterator\n\n\nclient_secrets_file = \"/home/lyle/oryks/backend/api/libraries/youtube.json\"\ndef get_youtube_client(client_secrets_file: str = client_secrets_file) -> YouTube:\n    youtube: YouTube = YouTube(client_secret_file=client_secrets_file)\n    client = youtube.authenticate()\n    youtube.youtube_client = client\n    return youtube\n\nyoutube: YouTube = get_youtube_client(client_secrets_file=\"/home/lyle/Downloads/test.json\")\n\n\n# query: str = ''\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q=query,\n#     type=['video'],\n#     channelId=\"UCtAcpQcYerN8xxZJYTfWBMw\"\n# )\n# search_request: YouTubeRequest = YouTubeRequest(\n#     part=part, \n#     optional_parameters=optional_parameters\n# )\n# search_results: YouTubeResponse = youtube.search(search_request)\n# search_iterator: Iterator = youtube.get_search_iterator(search_request)\n# # res: YouTubeResponse = youtube.find_channel_by_name(display_name=\"Umar Jamil\")\n# # print(res.items[0])\n# res = next(search_iterator)\n# final = []\n# for x in search_iterator:\n#         for search in x:\n#                 final.append(\n#                         dict(\n",
  "\n#     print(f\"Translated example sentence: \\n {translated_sentence}\")\n\n#     model.train()\n\n#     for batch_idx, batch in enumerate(train_iterator):\n#         # Get input and targets and get to cuda\n#         inp_data = batch.src.to(device)\n#         target = batch.trg.to(device)\n\n#         # Forward prop\n#         output = model(inp_data, target)\n\n#         # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n#         # doesn't take input in that form. For example if we have MNIST we want to have\n#         # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n#         # way that we have output_words * batch_size that we want to send in into\n#         # our cost function, so we need to do some reshapin. While we're at it\n#         # Let's also remove the start token while we're at it\n#         output = output[1:].reshape(-1, output.shape[2])\n#         target = target[1:].reshape(-1)\n\n#         optimizer.zero_grad()\n#         loss = criterion(output, target)\n\n#         # Back prop\n#         loss.backward()\n\n#         # Clip to avoid exploding gradient issues, makes sure grads are\n#         # within a healthy range\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n\n#         # Gradient descent step\n#         optimizer.step()\n\n#         # Plot to tensorboard\n#         writer.add_scalar(\"Training loss\", loss, global_step=step)\n#         step += 1\n\n\n",
  "from typing import Any\nimport json\nfrom googleapiclient.errors import HttpError\n\n\ndef get_presentation(presentation_id: str, slide_client: Any) -> Any:\n    presentation = (\n        slide_client.presentations().get(presentationId=presentation_id).execute()\n    )\n    return presentation\n\n\ndef get_slides(presentation: Any) -> Any:\n    slides = presentation.get(\"slides\")\n    return slides\n\n\ndef create_blank_presentation(title: str, slide_client: Any) -> dict:\n    body: dict = {\"title\": title}\n    presentation = slide_client.presentations().create(body=body).execute()\n    print(f\"Created blank presentation with the id: {presentation.get('presentationId')}\")\n    presentation_name: str = f\"{title.casefold().strip().replace(' ', '_')}.json\"\n    with open(presentation_name, \"w\") as f:\n        json.dump(presentation, f)\n    return presentation\n    \n\ndef create_slide(presentation_id: str, page_id: str, slide_client: Any) -> dict:\n    create_slides_request = [\n        {\n            \"createSlide\": {\n                \"objectId\": page_id,\n                \"insertionIndex\": \"1\",\n                \"slideLayoutReference\": {\n                    \"predefinedLayout\": \"TITLE_AND_TWO_COLUMNS\"\n                }\n            }\n        }\n    ]\n    request_body = {\n",
  "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel\n\n\nnames = [\n    \"Nearest Neighbors\",\n    \"Linear SVM\",\n    \"RBF SVM\",\n    \"Gaussian Process\",\n    \"Decision Tree\",\n    \"Random Forest\",\n    \"Neural Net\",\n    \"AdaBoost\",\n    \"Naive Bayes\",\n    \"QDA\",\n]\nknn = dict(\n    leaf_size=list(range(1, 15)),\n    n_neighbors=list(range(1, 10)),\n    p=[1, 2]\n)\n\ngaussian_process = dict(\n    kernel=[1*RBF(), 1*DotProduct(), 1*Matern(),  1*RationalQuadratic(), 1*WhiteKernel()]\n)\n\ndecision_tree = dict(\n    criterion=['gini', 'entropy'],\n    max_depth=list(range(1, 10)),\n    min_samples_split=list(range(1, 10)),\n    min_samples_leaf=list(range(1, 10))\n)\n\nhyperparameters: dict[str, dict] = {\n    \"Nearest Neighbors\": knn,\n    \"Gaussian Process\": gaussian_process,\n    \"Decision Tree\": decision_tree\n}",
  "        )\n        removePoint = action(\n            text=\"Remove Selected Point\",\n            slot=self.removeSelectedPoint,\n            shortcut=shortcuts[\"remove_selected_point\"],\n            icon=\"edit\",\n            tip=\"Remove selected point from polygon\",\n            enabled=False,\n        )\n\n        undo = action(\n            self.tr(\"Undo\\n\"),\n            self.undoShapeEdit,\n            shortcuts[\"undo\"],\n            \"undo\",\n            self.tr(\"Undo last add and edit of shape\"),\n            enabled=False,\n        )\n\n        hideAll = action(\n            self.tr(\"&Hide\\nPolygons\"),\n            functools.partial(self.togglePolygons, False),\n            shortcuts[\"hide_all_polygons\"],\n            icon=\"eye\",\n            tip=self.tr(\"Hide all polygons\"),\n            enabled=False,\n        )\n        showAll = action(\n            self.tr(\"&Show\\nPolygons\"),\n            functools.partial(self.togglePolygons, True),\n            shortcuts[\"show_all_polygons\"],\n            icon=\"eye\",\n            tip=self.tr(\"Show all polygons\"),\n            enabled=False,\n        )\n        toggleAll = action(\n            self.tr(\"&Toggle\\nPolygons\"),\n            functools.partial(self.togglePolygons, None),\n            shortcuts[\"toggle_all_polygons\"],\n            icon=\"eye\",\n",
  "        a.setIcon(newIcon(icon))\n    if shortcut is not None:\n        if isinstance(shortcut, (list, tuple)):\n            a.setShortcuts(shortcut)\n        else:\n            a.setShortcut(shortcut)\n    if tip is not None:\n        a.setToolTip(tip)\n        a.setStatusTip(tip)\n    if slot is not None:\n        a.triggered.connect(slot)\n    if checkable:\n        a.setCheckable(True)\n    a.setEnabled(enabled)\n    a.setChecked(checked)\n    return a\n\n\ndef addActions(widget, actions):\n    for action in actions:\n        if action is None:\n            widget.addSeparator()\n        elif isinstance(action, QtWidgets.QMenu):\n            widget.addMenu(action)\n        else:\n            widget.addAction(action)\n\n\ndef labelValidator():\n    return QtGui.QRegExpValidator(QtCore.QRegExp(r\"^[^ \\t].+\"), None)\n\n\nclass struct(object):\n    def __init__(self, **kwargs):\n        self.__dict__.update(kwargs)\n\n\ndef distance(p):\n    return sqrt(p.x() * p.x() + p.y() * p.y())\n\n",
  "        self.actions.createPointMode.setEnabled(True)\n        self.actions.createLineStripMode.setEnabled(True)\n        self.actions.createAiPolygonMode.setEnabled(True)\n        self.actions.createAiMaskMode.setEnabled(True)\n        title = __appname__\n        if self.filename is not None:\n            title = \"{} - {}\".format(title, self.filename)\n        self.setWindowTitle(title)\n\n        if self.hasLabelFile():\n            self.actions.deleteFile.setEnabled(True)\n        else:\n            self.actions.deleteFile.setEnabled(False)\n\n    def toggleActions(self, value=True):\n        \"\"\"Enable/Disable widgets which depend on an opened image.\"\"\"\n        for z in self.actions.zoomActions:\n            z.setEnabled(value)\n        for action in self.actions.onLoadActive:\n            action.setEnabled(value)\n\n    def queueEvent(self, function):\n        QtCore.QTimer.singleShot(0, function)\n\n    def status(self, message, delay=5000):\n        self.statusBar().showMessage(message, delay)\n\n    def resetState(self):\n        self.labelList.clear()\n        self.filename = None\n        self.imagePath = None\n        self.imageData = None\n        self.labelFile = None\n        self.otherData = None\n        self.canvas.resetState()\n\n    def currentItem(self):\n        items = self.labelList.selectedItems()\n        if items:\n            return items[0]\n",
  "#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"\n",
  "        \n    def get_default_credentials_path(self) -> str:\n        \"\"\"Generate the default api token file location.\"\"\"\n        credentials_dir: str = self.create_default_credentials_path()\n        credentials_file_path = path.join(credentials_dir, self.credentials_file_name)\n        return credentials_file_path\n\n    def get_credentials(self) -> Credentials:\n        \"\"\"Get the credentials.\"\"\"\n        credentials: Credentials = None\n        credentials_path: str = self.get_default_credentials_path()\n        try:\n            with open(credentials_path, 'r', encoding='utf-8') as creds:\n                credentials = Credentials(**load(creds))\n        except FileNotFoundError:\n            pass\n        return credentials\n    \n    def generate_credentials(self) -> Credentials:\n        flow = InstalledAppFlow.from_client_secrets_file(self.secrets_file, self.scopes)\n        credentials = flow.run_local_server(port=0)\n        return credentials\n    \n    def save_credentials(self, credentials: Credentials) -> None:\n        credentials_dict = self.credentials_to_dict(credentials)\n        credentials_path: str = self.get_default_credentials_path()\n        with open(credentials_path, 'w', encoding='utf-8') as f:\n            dump(credentials_dict, f)\n            \n    def credentials_expired(self, credentials: Credentials) -> bool:\n        # youtube_client = self.get_youtube_client(credentials=credentials)\n        # youtube_find_request = youtube_client.search().list(q='', part='id')\n        # try:\n        #     youtube_find_request.execute()\n        # except RefreshError:\n        #     return True\n        # return False\n        return False\n            \n    def get_gmail_client(self, credentials: Credentials) -> Any:\n",
  "from oryks_google_oauth import GoogleOAuth, YouTubeScopes\n\n\nclient_secret_file: str = '/home/lyle/Professional Projects/youtube/client_secret.json'\napi_service_name: str = 'youtube'\napi_version: str = 'v3'\ncredentials_dir: str = '.youtube'\nscopes: list[str] = [YouTubeScopes.youtube.value]\noauth: GoogleOAuth = GoogleOAuth(\n    secrets_file=client_secret_file,\n    scopes=scopes,\n    api_service_name=api_service_name,\n    api_version=api_version,\n    credentials_dir=credentials_dir\n)\nyoutube_client = oauth.authenticate_google_server()\nyoutube_find_request = youtube_client.search().list(q='python programming videos', part='id, snippet')\nprint(youtube_find_request.execute())\n",
  "        )\n\n    def _update_shape_color(self, shape):\n        r, g, b = self._get_rgb_by_label(shape.label)\n        shape.line_color = QtGui.QColor(r, g, b)\n        shape.vertex_fill_color = QtGui.QColor(r, g, b)\n        shape.hvertex_fill_color = QtGui.QColor(255, 255, 255)\n        shape.fill_color = QtGui.QColor(r, g, b, 128)\n        shape.select_line_color = QtGui.QColor(255, 255, 255)\n        shape.select_fill_color = QtGui.QColor(r, g, b, 155)\n\n    def _get_rgb_by_label(self, label):\n        if self._config[\"shape_color\"] == \"auto\":\n            item = self.uniqLabelList.findItemByLabel(label)\n            if item is None:\n                item = self.uniqLabelList.createItemFromLabel(label)\n                self.uniqLabelList.addItem(item)\n                rgb = self._get_rgb_by_label(label)\n                self.uniqLabelList.setItemLabel(item, label, rgb)\n            label_id = self.uniqLabelList.indexFromItem(item).row() + 1\n            label_id += self._config[\"shift_auto_shape_color\"]\n            return LABEL_COLORMAP[label_id % len(LABEL_COLORMAP)]\n        elif (\n            self._config[\"shape_color\"] == \"manual\"\n            and self._config[\"label_colors\"]\n            and label in self._config[\"label_colors\"]\n        ):\n            return self._config[\"label_colors\"][label]\n        elif self._config[\"default_shape_color\"]:\n            return self._config[\"default_shape_color\"]\n        return (0, 255, 0)\n\n    def remLabels(self, shapes):\n        for shape in shapes:\n            item = self.labelList.findItemByShape(shape)\n            self.labelList.removeItem(item)\n\n    def loadShapes(self, shapes, replace=True):\n        self._noSelectionSlot = True\n        for shape in shapes:\n",
  "\n@pytest.mark.gui\ndef test_MainWindow_open_json(qtbot):\n    json_files = [\n        osp.join(data_dir, \"annotated_with_data/apc2016_obj3.json\"),\n        osp.join(data_dir, \"annotated/2011_000003.json\"),\n    ]\n    for json_file in json_files:\n        labelme.testing.assert_labelfile_sanity(json_file)\n\n        win = labelme.app.MainWindow(filename=json_file)\n        qtbot.addWidget(win)\n        _win_show_and_wait_imageData(qtbot, win)\n        win.close()\n\n\ndef create_MainWindow_with_directory(qtbot):\n    directory = osp.join(data_dir, \"raw\")\n    win = labelme.app.MainWindow(filename=directory)\n    qtbot.addWidget(win)\n    _win_show_and_wait_imageData(qtbot, win)\n    return win\n\n\n@pytest.mark.gui\ndef test_MainWindow_openNextImg(qtbot):\n    win = create_MainWindow_with_directory(qtbot)\n    win.openNextImg()\n\n\n@pytest.mark.gui\ndef test_MainWindow_openPrevImg(qtbot):\n    win = create_MainWindow_with_directory(qtbot)\n    win.openNextImg()\n\n\n@pytest.mark.gui\ndef test_MainWindow_annotate_jpg(qtbot):\n    tmp_dir = tempfile.mkdtemp()\n    input_file = osp.join(data_dir, \"raw/2011_000003.jpg\")\n",
  "# hiddens, _ = decoder.lstm(x)\n# print(hiddens.shape)\n# output = decoder.linear(hiddens)\n# print(output.shape)\n# outputs = model(images, captions)\n# print(outputs.shape)\n\n# transforms=Compose([\n#     Resize((299, 299)),\n#     ToTensor()\n# ])\n# img_path = \"/home/lyle/oryks/finetune-image-captioning-model/raw-data/Images/667626_18933d713e.jpg\"\n# img = Image.open(img_path)\n# trans = transforms(img)\n# print(trans.unsqueeze(0).shape)\n# res = model.caption_image(image=trans.unsqueeze(0), vocabulary=dataset.vocabulary)\n",
  "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "def generate_data(\n    user_count: int = 200, \n    posts_count: int = 500, \n    likes_count: int = 2000, \n    comments_count: int = 1000,\n    bookmarks_count: int = 1500\n    ):\n    users = generate_users(user_count)\n    users = [\n        add_user(user) for user in users\n    ]\n    posts: list[Post] = generate_posts(users, count=posts_count)\n    posts: list[Post] = [\n        add_post(post) for post in posts\n    ]\n    likes: list[Like] = generate_likes(users, posts, likes_count=likes_count)\n    add_likes(likes)\n    \n    comments: list[Comment] = generate_comments(users, posts, comments_count=comments_count)\n    add_comments(comments)\n    \n    bookmarks: list[Bookmark] = generate_bookmarks(users, posts, bookmarks_count=bookmarks_count)\n    add_bookmarks(bookmarks)",
  "                        self.drawVertex(negative_vrtx_path, i)\n            else:\n                line_path.moveTo(self.points[0])\n                # Uncommenting the following line will draw 2 paths\n                # for the 1st vertex, and make it non-filled, which\n                # may be desirable.\n                # self.drawVertex(vrtx_path, 0)\n\n                for i, p in enumerate(self.points):\n                    line_path.lineTo(p)\n                    self.drawVertex(vrtx_path, i)\n                if self.isClosed():\n                    line_path.lineTo(self.points[0])\n\n            painter.drawPath(line_path)\n            if vrtx_path.length() > 0:\n                painter.drawPath(vrtx_path)\n                painter.fillPath(vrtx_path, self._vertex_fill_color)\n            if self.fill and self.mask is None:\n                color = self.select_fill_color if self.selected else self.fill_color\n                painter.fillPath(line_path, color)\n\n            pen.setColor(QtGui.QColor(255, 0, 0, 255))\n            painter.setPen(pen)\n            painter.drawPath(negative_vrtx_path)\n            painter.fillPath(negative_vrtx_path, QtGui.QColor(255, 0, 0, 255))\n\n    def drawVertex(self, path, i):\n        d = self.point_size / self.scale\n        shape = self.point_type\n        point = self.points[i]\n        if i == self._highlightIndex:\n            size, shape = self._highlightSettings[self._highlightMode]\n            d *= size\n        if self._highlightIndex is not None:\n            self._vertex_fill_color = self.hvertex_fill_color\n        else:\n            self._vertex_fill_color = self.vertex_fill_color\n        if shape == self.P_SQUARE:\n            path.addRect(point.x() - d / 2, point.y() - d / 2, d, d)\n",
  "    out_file = osp.join(tmp_dir, \"2011_000003.json\")\n\n    config = labelme.config.get_default_config()\n    win = labelme.app.MainWindow(\n        config=config,\n        filename=input_file,\n        output_file=out_file,\n    )\n    qtbot.addWidget(win)\n    _win_show_and_wait_imageData(qtbot, win)\n\n    label = \"whole\"\n    points = [\n        (100, 100),\n        (100, 238),\n        (400, 238),\n        (400, 100),\n    ]\n    shapes = [\n        dict(\n            label=label,\n            group_id=None,\n            points=points,\n            shape_type=\"polygon\",\n            mask=None,\n            flags={},\n            other_data={},\n        )\n    ]\n    win.loadLabels(shapes)\n    win.saveFile()\n\n    labelme.testing.assert_labelfile_sanity(out_file)\n    shutil.rmtree(tmp_dir)\n",
  "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\nfrom codecs import open\nfrom os import path\n\nHERE = path.abspath(path.dirname(__file__))\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\nDESCRIPTION = 'A python library for generating documentation for python projects.'\nkey_words = ['dosctrings', 'documentation']\ninstall_requires = [\n    'langchain',\n    'langchain-openai',\n    'black',\n    'pydantic',\n    'pydantic-settings',\n]\nsetup(\n    name='oryks-docstring-generator',\n    packages=find_packages(include=['docstring_generator']),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n    long_description=LONG_DESCRIPTION,\n    url='https://youtube-wrapper.readthedocs.io/en/latest/index.html',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Operating System :: OS Independent',\n",
  "\n\ndef get_class_methods_docstrings(class_and_docstring: str) -> dict[str, str]:\n    \"\"\"Get a class methods docstrings.\"\"\"\n    class_methods: dict[str, str] = {}\n    class_tree = ast.parse(class_and_docstring)\n    for node in class_tree.body:\n        if isinstance(node, ClassDef):\n            for class_node in node.body:\n                if isinstance(class_node, FunctionDef):\n                    class_methods[class_node.name] = ast.get_docstring(class_node)\n    return class_methods\n\n\ndef make_docstring_node(docstr: str):\n    constant_str: Constant = Constant(docstr)\n    return Expr(value=constant_str)\n\n\ndef get_function_docstring(function_and_docstring: str) -> str:\n    \"\"\"Get the function docstring.\"\"\"\n    function_tree = ast.parse(function_and_docstring)\n    for node in function_tree.body:\n        if isinstance(node, (FunctionDef, AsyncFunctionDef)):\n            function_docstring: str = ast.get_docstring(node)\n            return function_docstring\n\n\ndef get_module_source_code(module_path: str) -> str:\n    \"\"\"Get the source code for a given module.\"\"\"\n    with open(module_path, 'r') as f:\n        return f.read()\n\n\ndef add_module_code_to_queue(module_path: str, module_source_queue: Queue):\n    module_src: str = ''\n    if module_path:\n        module_src = get_module_source_code(module_path)\n    module_source_queue.put((module_path, module_src))\n\n",
  "class GetPosts(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10\n    \nclass PostAuthor(BaseModel):\n    id: str\n    profile_picture: str\n    name: str\n    \nclass PostLike(BaseModel):\n    liked: bool\n    liked_by: Optional[list[PostAuthor]] = Field(default_factory=list)\n    key_like: Optional[PostAuthor] = None\n    likes_count: Optional[int] = Field(default=0)\n    \nclass KeyComment(BaseModel):\n    author: PostAuthor\n    text: str\n    comments_count: int\n    \nclass PostSchema(BaseModel):\n    id: str\n    text: str\n    image: str\n    author: PostAuthor\n    date_published: str\n    location: str\n    like: PostLike\n    bookmarked: bool\n    key_comment: Optional[KeyComment] = None",
  "full_chain = {\n    \"sentiment\": sentiment_chain,\n    \"comment\": lambda input: input['comment'],\n    \"topics\": lambda input: input['topics']\n} | branch\n\nres = full_chain.invoke({'comment': comment, \"topics\": topics})\nprint(comment)\nprint(res)\n",
  "        self,\n        label=None,\n        line_color=None,\n        shape_type=None,\n        flags=None,\n        group_id=None,\n        description=None,\n        mask=None,\n    ):\n        self.label = label\n        self.group_id = group_id\n        self.points = []\n        self.point_labels = []\n        self.shape_type = shape_type\n        self._shape_raw = None\n        self._points_raw = []\n        self._shape_type_raw = None\n        self.fill = False\n        self.selected = False\n        self.flags = flags\n        self.description = description\n        self.other_data = {}\n        self.mask = mask\n\n        self._highlightIndex = None\n        self._highlightMode = self.NEAR_VERTEX\n        self._highlightSettings = {\n            self.NEAR_VERTEX: (4, self.P_ROUND),\n            self.MOVE_VERTEX: (1.5, self.P_SQUARE),\n        }\n\n        self._closed = False\n\n        if line_color is not None:\n            # Override the class line_color attribute\n            # with an object attribute. Currently this\n            # is used for drawing the pending line a different color.\n            self.line_color = line_color\n\n    def setShapeRefined(self, shape_type, points, point_labels, mask=None):\n",
  "import logging.config\nimport logstash\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef create_dev_logger():\n    \"\"\"Create the application logger.\"\"\"\n    config = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"standard\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n            },\n            \"json\": {\n                \"format\": \"%(asctime)s %(name)s %(levelname)s %(message)s\",\n                \"datefmt\": \"%Y-%m-%dT%H:%M:%S%z\",\n                \"class\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n            },\n        },\n        \"handlers\": {\n            \"standard\": {\n                \"class\": \"logging.StreamHandler\",\n                \"formatter\": \"json\",\n            },\n        },\n        \"loggers\": {\"\": {\"handlers\": [\"standard\"], \"level\": logging.INFO}},\n    }\n\n    logging.config.dictConfig(config)\n\n    logger = logging.getLogger(__name__)\n\n    return logger",
  "\n    return app",
  "from langchain.prompts.chat import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field\nfrom dotenv import load_dotenv\nfrom pathlib import Path\nimport os\nfrom models import Trip\n\n\ndef load_secets():\n    load_dotenv()\n    env_path = Path(\".\") / \".env\"\n    load_dotenv(dotenv_path=env_path)\n\n    open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n    google_palm_key = os.getenv(\"GOOGLE_PALM_API_KEY\")\n\n    return {\n        \"OPENAI_API_KEY\": open_ai_key,\n        \"GOOGLE_PALM_API_KEY\": google_palm_key,\n    }\n\n\nclass Validation(BaseModel):\n    plan_is_valid: str = Field(\n        description=\"This field is 'yes' if the plan is feasible, 'no' otherwise\"\n    )\n    updated_request: str = Field(description=\"Your update to the plan\")\n\n\nclass ValidationTemplate(object):\n    def __init__(self):\n        self.system_template = \"\"\"\n      You are a travel agent who helps users make exciting travel plans.\n\n      The user's request will be denoted by four hashtags. Determine if the user's\n",
  "            label_file = osp.splitext(filename)[0] + \".json\"\n            if self.output_dir:\n                label_file_without_path = osp.basename(label_file)\n                label_file = osp.join(self.output_dir, label_file_without_path)\n            item = QtWidgets.QListWidgetItem(filename)\n            item.setFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable)\n            if QtCore.QFile.exists(label_file) and LabelFile.is_label_file(label_file):\n                item.setCheckState(Qt.Checked)\n            else:\n                item.setCheckState(Qt.Unchecked)\n            self.fileListWidget.addItem(item)\n        self.openNextImg(load=load)\n\n    def scanAllImages(self, folderPath):\n        extensions = [\n            \".%s\" % fmt.data().decode().lower()\n            for fmt in QtGui.QImageReader.supportedImageFormats()\n        ]\n\n        images = []\n        for root, dirs, files in os.walk(folderPath):\n            for file in files:\n                if file.lower().endswith(tuple(extensions)):\n                    relativePath = os.path.normpath(osp.join(root, file))\n                    images.append(relativePath)\n        images = natsort.os_sorted(images)\n        return images\n",
  "    table.add_column(header=\"[b]Comments\", justify=\"left\", style=\"yellow2\")\n    table.add_column(header=\"Likes\", justify=\"left\", style=\"magenta3\")\n    table.add_column(header=\"[b]Date\", justify=\"center\", style=\"violet\")\n    table.columns[0].header_style = \"bold chartreuse1\"\n    table.columns[1].header_style = \"bold dark_goldenrod\"\n    table.columns[2].header_style = \"bold chartreuse1\"\n    table.columns[3].header_style = \"bold dark_goldenrod\"\n    table.columns[4].header_style = \"bold chartreuse1\"\n    table.border_style = \"bright_yellow\"\n    table.pad_edge = True\n    for row in table_data:\n        table.add_row(row[\"title\"], str(row[\"views\"]), str(row[\"comments\"]), str(row[\"likes\"]), row[\"date\"])\n    return table\n\n\ndef parse_comment(comment: Comment) -> dict:\n    return {\n        \"comment_id\": comment.id,\n        \"comment\": comment.snippet.text_display,\n        \"likes\": comment.snippet.like_count,\n        \"date_published\": str(comment.snippet.published_at),\n    }\n    \n    \nclass Data(BaseModel):\n    id: str\n    comment: str\n    sentiment: Optional[str] = Field(\n        description=\"The comment sentiment\",\n        enum=[\"neutral\", \"positive\", \"negative\"],\n        default=None,\n    )\n    features: Optional[list[str]] = Field(\n        description=\"The features mentioned in the comment\", default_factory=list\n    )\n    likes: Optional[int] = Field(description=\"The number of likes\", default=None)\n    date: Optional[str] = Field(\n        description=\"The date when the comment was posted\", default=None\n    )\n\n",
  "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n    POSTGRES_HOST = os.environ[\"POSTGRES_HOST\"]\n    POSTGRES_DB = os.environ[\"POSTGRES_DB\"]\n    POSTGRES_PORT = os.environ[\"POSTGRES_PORT\"]\n    POSTGRES_USER = os.environ[\"POSTGRES_USER\"]\n    POSTGRES_PASSWORD = os.environ[\"POSTGRES_PASSWORD\"]\n    # db_conn_string = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n    db_conn_string = os.environ.get(\"SQLALCHEMY_DATABASE_URI\", 'sqlite:///./oryks.db')\n    SQLALCHEMY_DATABASE_URI = db_conn_string\n    SQLALCHEMY_TRACK_MODIFICATIONS = False\n    MAIL_USERNAME = os.environ[\"MAIL_USERNAME\"]\n    MAIL_PASSWORD = os.environ[\"MAIL_PASSWORD\"]\n    MAIL_SERVER = os.environ[\"MAIL_SERVER\"]\n    MAIL_PORT = os.environ[\"MAIL_PORT\"]\n    MAIL_USE_SSL = os.environ[\"MAIL_USE_SSL\"]\n    MAIL_DEFAULT_SENDER = os.environ[\"MAIL_DEFAULT_SENDER\"]\n    PASSWORD_RESET_SALT = os.environ.get(\"PASSWORD_RESET_SALT\", \"salt\")\n    GOOGLE_OAUTH_CLIENT_ID = os.environ.get(\"GOOGLE_OAUTH_CLIENT_ID\")\n",
  "\ndata_dir: str = \"/home/lyle/oryks/backend/api/libraries/data\"\ndescriptions_dir: str = path.join(data_dir, \"descriptions\")\nsegments_dir: str = path.join(data_dir, \"segments\")\n\nclass TimeStamp(BaseModel):\n    start_time: Optional[str] = Field(description=\"Start time\")\n    end_time: Optional[str] = Field(description=\"End time\")\n    title: Optional[str] = Field(description=\"The time stamp title\")\n    \nclass TimeStamps(BaseModel):\n    time_stamps: list[TimeStamp]\n\ndef save_description(description: str, video_id: str) -> None:\n    video_path: str = path.join(descriptions_dir, f\"{video_id}.txt\")\n    with open(video_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(description)\n        \n        \ndef save_timestamps(timestamps: TimeStamps, video_id: str) -> None:\n    video_path: str = path.join(segments_dir, f\"{video_id}.json\")\n    with open(video_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(timestamps.dict(), f, indent=4)\n        \n        \ndef load_timestamps(video_id: str) -> TimeStamps:\n    video_path: str = path.join(segments_dir, f\"{video_id}.json\")\n    with open(video_path, \"r\", encoding=\"utf-8\") as f:\n        timestamps: TimeStamps = TimeStamps(**json.load(f))\n    return timestamps\n\n\ndef get_timestamps(video_id: str) -> TimeStamps:\n    video_path: str = path.join(segments_dir, f\"{video_id}.json\")\n    if not path.exists(video_path):\n        description: str = get_description(video_id=video_id)\n        timestamps: TimeStamps = get_video_segments(video_description=description)\n        save_timestamps(timestamps=timestamps, video_id=video_id)\n    else:\n        timestamps: TimeStamps = load_timestamps(video_id=video_id)\n",
  "\"\"\"\n\nsentiment_template = PromptTemplate(template=sentiment_msg, input_variables=[\"comment\"])\n\n\nclass PositiveComment(BaseModel):\n    doc_id: int = Field(description=\"The doc_id from the input\")\n    topics: list[str] = Field(\n        description=\"List of the relevant topics for the customer review. Include only topics from the list provided.\",\n        default_factory=list,\n    )\n    sentiment: str = Field(\n        description=\"Sentiment of the topic\", enum=[\"positive\", \"neutral\", \"negative\"]\n    )\n\n\nclass NegativeComment(BaseModel):\n    doc_id: int = Field(description=\"The doc_id from the input\")\n    topics: list[str] = Field(\n        description=\"List of the relevant topics for the customer review. Include only topics from the list provided.\",\n        default_factory=list,\n    )\n    sentiment: str = Field(\n        description=\"Sentiment of the topic\", enum=[\"positive\", \"neutral\", \"negative\"]\n    )\n\n\npositive_parser = PydanticOutputParser(pydantic_object=PositiveComment)\nnegative_parser = PydanticOutputParser(pydantic_object=NegativeComment)\n\ntopic_assg_msg: str = \"\"\"\nBelow is a customer comment in JSON format with the following keys:\n1. doc_id - identifier of the comment\n2. comment - the user comment\n\nPlease analyze the provided comments and identify the main topics and sentiment. Include only the \ntopics provided below:\nTopics with a short description: {topics}\n\nComment:\n",
  "    agent = cl.user_session.get(\"agent\")\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({\"input\": message.content})[\"output\"]\n    await msg.update()",
  "from celery import Celery\nfrom pydantic_settings import BaseSettings\nfrom dotenv import load_dotenv\nfrom redis import Redis\nfrom json import dumps\n\nload_dotenv()\n\n\nclass BaseConfig(BaseSettings):\n    celery_broker_url: str\n    celery_result_backend: str\n    redis_host: str\n    \nconfig = BaseConfig()\n\ncelery = Celery(__name__)\ncelery.conf.broker_url = config.celery_broker_url\ncelery.conf.result_backend = config.celery_result_backend\nredis: Redis = Redis(host=config.redis_host, port=6379, db=0, decode_responses=True)\n\n@celery.task(name=\"analyze_quote\")\ndef analyze_quote(quote: dict) -> dict:\n    analyzed_quote: dict = quote\n    analyzed_quote.update({'result': 'Some result'})\n    redis.publish('analyzed_quotes', dumps(analyzed_quote))\n    return analyzed_quote\n\n\n@celery.task(name=\"send_email\")\ndef send_email(quote: dict) -> dict:\n    \n    return analyzed_quote",
  "from celery_app import celery_app\n\n\nif __name__ == '__main__':\n    args = ['worker', '--loglevel=INFO']\n    # celery_app.autodiscover_tasks(['tasks'])\n    celery_app.worker_main(argv=args)",
  "@post.route(\"/posts\", methods=[\"GET\"])\ndef get_all_posts():\n    \"\"\"Get many post post.\"\"\"\n    offset: str = request.args.get('offset')\n    limit: str = request.args.get('limit')\n    try:\n        posts = get_posts(get_db, GetPosts(offset=offset, limit=limit))\n    except (OperationalError, IntegrityError) as e:\n            print(e)\n            # Send email to\n            return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    created_posts = []\n    for post in posts:\n        post_author: PostAuthor = PostAuthor(\n            id=post.author.id,\n            profile_picture=url_for('static', filename='img/default.jpeg'),\n            name=post.author.first_name\n        )\n        post_schema: PostSchema = PostSchema(\n            id=post.id,\n            text=post.text,\n            image=url_for('static', filename=f'img/{post.image_url}'),\n            location=post.location,\n            date_published='10',\n            author=post_author\n        ).model_dump()\n        created_posts.append(post_schema)",
  "            new_tree = transformer.visit(src_tree)\n            ast.fix_missing_locations(new_tree)\n            new_module_code = ast.unparse(new_tree)\n            print(new_module_code)\n            save_src(file_path=file_path, new_src=new_module_code)\n            format_file(file_path=file_path)\n            function_code_queue.task_done()\n        except Empty:\n            print(\"Terminating the function processing..\")\n            break\n",
  "from pydantic import BaseModel\nfrom typing import Optional\nfrom datetime import datetime\n\n\nclass CreateActivity(BaseModel):\n    user_id: str\n    post_id: str\n    \n\nclass ActivityCreated(CreateActivity):\n    date_created: datetime\n    \nclass RepeatableActivityCreated(ActivityCreated):\n    id: str\n    \nclass GetRepeatableActivity(BaseModel):\n    id: str\n    \nclass CreateComment(CreateActivity):\n    comment: str\n    \nclass CommentCreated(CreateComment):\n    comment_id: str\n    date_created: datetime",
  "    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',\n    long_description=LONG_DESCRIPTION,\n    url='https://youtube-wrapper.readthedocs.io/en/latest/index.html',\n    author='Lyle Okoth',\n    author_email='lyceokoth@gmail.com',\n    license='MIT',\n    install_requires=install_requires,\n    keywords=key_words,\n    classifiers=[\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Operating System :: OS Independent'\n    ],\n)\n",
  "# import openai\nimport logging\nimport time\n# for Palm\nfrom langchain.llms import GooglePalm\n# for OpenAI\nfrom langchain.chat_models import ChatGooglePalm, ChatOpenAI\nfrom langchain.chains import LLMChain, SequentialChain\nfrom prompt_templates import (\n    ValidationTemplate, load_secets, MappingTemplate, ItineraryTemplate)\n\n\nlogging.basicConfig(level=logging.INFO)\n\nclass Agent(object):\n    def __init__(\n        self,\n        open_ai_api_key,\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        debug=True,\n    ):\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.INFO)\n        self._openai_key = open_ai_api_key\n\n        self.chat_model = ChatOpenAI(model=model, temperature=temperature, openai_api_key=self._openai_key)\n        self.validation_prompt = ValidationTemplate()\n        self.itinerary_prompt = ItineraryTemplate()\n        self.mapping_prompt = MappingTemplate()\n        self.validation_chain = self._set_up_validation_chain(debug)\n        self.agent_chain = self._set_up_agent_chain(debug)\n\n    def _set_up_validation_chain(self, debug=True):\n        \"\"\"\n\n        Parameters\n        ----------\n        debug\n\n",
  "          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.MaxPool2d(2),\n          # Convolution 4\n          nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(256),\n          nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(256),\n          nn.MaxPool2d(2),\n      )\n\n      self.dense_layers = nn.Sequential(\n          # Dropout layer\n          nn.Dropout(0.5),\n          # first fully connected layer\n          nn.Linear(224*224, 1024),\n          # Relu activation function\n          nn.ReLU(),\n          nn.Dropout(0.4),\n          # Final output layer\n          nn.Linear(1024, K),\n      )\n\n  def forward(self, output):\n    # Convolution Layers\n    out = self.conv_layers(output)\n\n    # Flatten the layers\n    out = out.view(-1, 224*224)\n\n    # Fully connected Dense Layers\n    out = self.dense_layers(out)\n\n    return out\n\n\ndef load_model(model_path: str = os.environ['MODEL_PATH']):\n    \"\"\"Load the pytorch model.\"\"\"\n",
  "\n    def setEditing(self, value=True):\n        self.mode = self.EDIT if value else self.CREATE\n        if self.mode == self.EDIT:\n            # CREATE -> EDIT\n            self.repaint()  # clear crosshair\n        else:\n            # EDIT -> CREATE\n            self.unHighlight()\n            self.deSelectShape()\n\n    def unHighlight(self):\n        if self.hShape:\n            self.hShape.highlightClear()\n            self.update()\n        self.prevhShape = self.hShape\n        self.prevhVertex = self.hVertex\n        self.prevhEdge = self.hEdge\n        self.hShape = self.hVertex = self.hEdge = None\n\n    def selectedVertex(self):\n        return self.hVertex is not None\n\n    def selectedEdge(self):\n        return self.hEdge is not None\n\n    def mouseMoveEvent(self, ev):\n        \"\"\"Update line with last point and current coordinates.\"\"\"\n        try:\n            if QT5:\n                pos = self.transformPos(ev.localPos())\n            else:\n                pos = self.transformPos(ev.posF())\n        except AttributeError:\n            return\n\n        self.prevMovePoint = pos\n        self.restoreCursor()\n\n        is_shift_pressed = ev.modifiers() & QtCore.Qt.ShiftModifier\n",
  "                        else self.createMode\n                    )\n                    self.current.addPoint(pos, label=0 if is_shift_pressed else 1)\n                    if self.createMode == \"point\":\n                        self.finalise()\n                    elif (\n                        self.createMode in [\"ai_polygon\", \"ai_mask\"]\n                        and ev.modifiers() & QtCore.Qt.ControlModifier\n                    ):\n                        self.finalise()\n                    else:\n                        if self.createMode == \"circle\":\n                            self.current.shape_type = \"circle\"\n                        self.line.points = [pos, pos]\n                        if (\n                            self.createMode in [\"ai_polygon\", \"ai_mask\"]\n                            and is_shift_pressed\n                        ):\n                            self.line.point_labels = [0, 0]\n                        else:\n                            self.line.point_labels = [1, 1]\n                        self.setHiding()\n                        self.drawingPolygon.emit(True)\n                        self.update()\n            elif self.editing():\n                if self.selectedEdge():\n                    self.addPointToEdge()\n                elif (\n                    self.selectedVertex()\n                    and int(ev.modifiers()) == QtCore.Qt.ShiftModifier\n                ):\n                    # Delete point if: left-click + SHIFT on a point\n                    self.removeSelectedPoint()\n\n                group_mode = int(ev.modifiers()) == QtCore.Qt.ControlModifier\n                self.selectShapePoint(pos, multiple_selection_mode=group_mode)\n                self.prevPoint = pos\n                self.repaint()\n        elif ev.button() == QtCore.Qt.RightButton and self.editing():\n            group_mode = int(ev.modifiers()) == QtCore.Qt.ControlModifier\n",
  "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n\ndef get_file_extension(filename: str) -> str:\n    if '.' in filename and filename.rsplit('.', 1)[1].lower():\n        return filename.rsplit('.', 1)[1].lower()\n    return ''\n\ndef allowed_file(filename: str) -> bool:\n    file_extension: str = get_file_extension(filename)\n    if file_extension and file_extension in ALLOWED_EXTENSIONS:\n        return True\n    return False\n\n\ndef save_post_photo_locally(post_image: dict) -> None:\n    \"\"\"Save the uploadeded post image.\"\"\"\n    file: FileStorage = post_image['post_image']\n    upload_folder = os.path.join(current_app.root_path, 'static', 'img')\n    if file and allowed_file(file.filename):\n        filename = f'{secrets.token_hex(8)}.{get_file_extension(file.filename)}' \n        # Use celery task\n        file.save(os.path.join(upload_folder, filename))\n        return filename\n    return ''",
  "            return\n\n        # Just hovering over the canvas, 2 possibilities:\n        # - Highlight shapes\n        # - Highlight vertex\n        # Update shape/vertex fill and tooltip value accordingly.\n        self.setToolTip(self.tr(\"Image\"))\n        for shape in reversed([s for s in self.shapes if self.isVisible(s)]):\n            # Look for a nearby vertex to highlight. If that fails,\n            # check if we happen to be inside a shape.\n            index = shape.nearestVertex(pos, self.epsilon / self.scale)\n            index_edge = shape.nearestEdge(pos, self.epsilon / self.scale)\n            if index is not None:\n                if self.selectedVertex():\n                    self.hShape.highlightClear()\n                self.prevhVertex = self.hVertex = index\n                self.prevhShape = self.hShape = shape\n                self.prevhEdge = self.hEdge\n                self.hEdge = None\n                shape.highlightVertex(index, shape.MOVE_VERTEX)\n                self.overrideCursor(CURSOR_POINT)\n                self.setToolTip(self.tr(\"Click & drag to move point\"))\n                self.setStatusTip(self.toolTip())\n                self.update()\n                break\n            elif index_edge is not None and shape.canAddPoint():\n                if self.selectedVertex():\n                    self.hShape.highlightClear()\n                self.prevhVertex = self.hVertex\n                self.hVertex = None\n                self.prevhShape = self.hShape = shape\n                self.prevhEdge = self.hEdge = index_edge\n                self.overrideCursor(CURSOR_POINT)\n                self.setToolTip(self.tr(\"Click to create point\"))\n                self.setStatusTip(self.toolTip())\n                self.update()\n                break\n            elif shape.containsPoint(pos):\n                if self.selectedVertex():\n                    self.hShape.highlightClear()\n",
  "from langchain_community.document_loaders.generic import GenericLoader\nfrom langchain_community.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain_community.document_loaders.blob_loaders.youtube_audio import (\n    YoutubeAudioLoader,\n)\nfrom langchain_core.documents import Document\nfrom os import path\n\n# Two Karpathy lecture videos\nurls = [\"https://www.youtube.com/watch?v=altvPR7x9IA\"]\n\n# Directory to save audio files\ndata_dir = \"data\"\nvideo_data_dir = \"video\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"sample\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\n\nloader = GenericLoader(\n    YoutubeAudioLoader(urls, save_video_dir), OpenAIWhisperParser(api_key=api_key)\n)\ndocs = loader.load()\n\nfull_transcript = \"\"\nfor doc in docs:\n    full_transcript += doc.page_content\n\nwith open(save_transcript_dir, \"w\", encoding=\"utf-8\") as f:\n    f.write(full_transcript)\n\nprint(full_transcript)\n\n\ndef transcribe_video(video_id: str, save_video_dir: str, api_key: str) -> str:\n    url: str = f\"https://www.youtube.com/watch?v={video_id}\"\n    loader: GenericLoader = GenericLoader(\n        YoutubeAudioLoader([url], save_video_dir), OpenAIWhisperParser(api_key=api_key)\n",
  "# -*- encoding: utf-8 -*-\n\nimport pytest\n\nfrom labelme.widgets import LabelListWidget\nfrom labelme.widgets import LabelListWidgetItem\n\n\n@pytest.mark.gui\ndef test_LabelListWidget(qtbot):\n    widget = LabelListWidget()\n\n    item = LabelListWidgetItem(text=\"person <font color='red'>●</fon>\")\n    widget.addItem(item)\n    item = LabelListWidgetItem(text=\"dog <font color='blue'>●</fon>\")\n    widget.addItem(item)\n\n    widget.show()\n    qtbot.addWidget(widget)\n    qtbot.waitExposed(widget)\n",
  "        image_file = files[0]\n        image_data = image_file.content # byte values of the image\n        image = Image.open(io.BytesIO(image_data))\n        model = load_model()\n        predicted_label, predictions = evaluate_image(image, model)\n        analysis_text: str = f\"\"\"\n            After analyzing the image you uploaded, here is what I found:\n            Maize Leaf Rust probability: {predictions['Maize Leaf Rust']}%\n            Northern Leaf Blight probability: {predictions['Northern Leaf Blight']}%\n            Healthy probability: {predictions['Healthy']}%\n            Gray Leaf Spot probability: {predictions['Gray Leaf Spot']}%\n            Your plant is most likely infected with {predicted_label}.\n            \"\"\"\n        elements = [\n            cl.Image(\n                name=\"image2\", display=\"inline\", content=image_data\n                ), \n            cl.Text(name=\"simple_text\", content=analysis_text, display=\"inline\", size='large')\n        ]\n        await cl.Message(content=f\"Maize image with {predicted_label}!\", elements=elements).send()\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run('Tell me some facts about the maize disease leaf rust especially in relation to kenya.')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Tell me some facts about the maize disease {predicted_label} especially in relation to kenya.')\n        await msg.update()\n        await msg.send()\n        await cl.sleep(1)\n        msg.content = agent.run(f'Get me aggrovets in {user_location}, Kenya')\n        await msg.update()\n        await cl.Message(content='Feel free to ask me more questions about maize plant diseases and how to deal with them.').send()\n    else:\n        await cl.Message(content='Currently cannot detect pests. Still working on that model.').send()\n    \n\n@cl.on_message\nasync def main(message: cl.Message):\n",
  "# posts = [\n    #     CreatedPost(\n    #         id=post.id,\n    #         location=post.location,\n    #         text=post.text,\n    #         image_url=post.image_url,\n    #         author_id=post.author_id,\n    #         date_published=post.date_published\n    #     ).model_dump()\n    #     for post in posts\n    # ]\n    return created_posts, HTTPStatus.OK\n\n@post.route(\"/load_more_posts\", methods=[\"GET\"])\ndef load_more_posts():\n    \"\"\"Get a single post.\"\"\"\n    offset: str = request.args.get('offset', 0)\n    limit: str = request.args.get('limit', 10)\n    more_posts = load_posts(limit=int(limit), offset=int(offset))\n    return more_posts",
  "        Args:\n            i (int): The vertex index\n            action (int): The action\n            (see Shape.NEAR_VERTEX and Shape.MOVE_VERTEX)\n        \"\"\"\n        self._highlightIndex = i\n        self._highlightMode = action\n\n    def highlightClear(self):\n        \"\"\"Clear the highlighted point\"\"\"\n        self._highlightIndex = None\n\n    def copy(self):\n        return copy.deepcopy(self)\n\n    def __len__(self):\n        return len(self.points)\n\n    def __getitem__(self, key):\n        return self.points[key]\n\n    def __setitem__(self, key, value):\n        self.points[key] = value\n",
  "    os.makedirs(osp.join(args.output_dir, \"JPEGImages\"))\n    os.makedirs(osp.join(args.output_dir, \"SegmentationClass\"))\n    if not args.nonpy:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationClassNpy\"))\n    if not args.noviz:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationClassVisualization\"))\n    if not args.noobject:\n        os.makedirs(osp.join(args.output_dir, \"SegmentationObject\"))\n        if not args.nonpy:\n            os.makedirs(osp.join(args.output_dir, \"SegmentationObjectNpy\"))\n        if not args.noviz:\n            os.makedirs(osp.join(args.output_dir, \"SegmentationObjectVisualization\"))\n    print(\"Creating dataset:\", args.output_dir)\n\n    if osp.exists(args.labels):\n        with open(args.labels) as f:\n            labels = [label.strip() for label in f if label]\n    else:\n        labels = [label.strip() for label in args.labels.split(\",\")]\n\n    class_names = []\n    class_name_to_id = {}\n    for i, label in enumerate(labels):\n        class_id = i - 1  # starts with -1\n        class_name = label.strip()\n        class_name_to_id[class_name] = class_id\n        if class_id == -1:\n            assert class_name == \"__ignore__\"\n            continue\n        elif class_id == 0:\n            assert class_name == \"_background_\"\n        class_names.append(class_name)\n    class_names = tuple(class_names)\n    print(\"class_names:\", class_names)\n    out_class_names_file = osp.join(args.output_dir, \"class_names.txt\")\n    with open(out_class_names_file, \"w\") as f:\n        f.writelines(\"\\n\".join(class_names))\n    print(\"Saved class_names:\", out_class_names_file)\n\n    for filename in sorted(glob.glob(osp.join(args.input_dir, \"*.json\"))):\n",
  "from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service as ChromeService\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.chrome.options import Options\ni\n\noptions = Options()\noptions.add_argument(\"--headless=new\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\ndriver.get(\"https://leetcode.com/problems/remove-linked-list-elements\")\nparagraphs = driver.find_elements(By.TAG_NAME, \"p\")\nprint(paragraphs)\ndriver.quit()",
  "        cx, cy = xy[0]\n        r = point_size\n        draw.ellipse([cx - r, cy - r, cx + r, cy + r], outline=1, fill=1)\n    else:\n        assert len(xy) > 2, \"Polygon must have points more than 2\"\n        draw.polygon(xy=xy, outline=1, fill=1)\n    mask = np.array(mask, dtype=bool)\n    return mask\n\n\ndef shapes_to_label(img_shape, shapes, label_name_to_value):\n    cls = np.zeros(img_shape[:2], dtype=np.int32)\n    ins = np.zeros_like(cls)\n    instances = []\n    for shape in shapes:\n        points = shape[\"points\"]\n        label = shape[\"label\"]\n        group_id = shape.get(\"group_id\")\n        if group_id is None:\n            group_id = uuid.uuid1()\n        shape_type = shape.get(\"shape_type\", None)\n\n        cls_name = label\n        instance = (cls_name, group_id)\n\n        if instance not in instances:\n            instances.append(instance)\n        ins_id = instances.index(instance) + 1\n        cls_id = label_name_to_value[cls_name]\n\n        mask = shape_to_mask(img_shape[:2], points, shape_type)\n        cls[mask] = cls_id\n        ins[mask] = ins_id\n\n    return cls, ins\n\n\ndef labelme_shapes_to_label(img_shape, shapes):\n    logger.warn(\n        \"labelme_shapes_to_label is deprecated, so please use \" \"shapes_to_label.\"\n",
  "from .set_config import set_configuration",
  "@post.route(\"/bookmarks\", methods=[\"GET\"])\ndef get_post_bookmarks():\n    \"\"\"Bookmark a single post.\"\"\"\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        bookmarks: list[Bookmark] = list_post_bookmarks(session=get_db, post_data=post_data)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    resp = [\n        ActivityCreated(\n            user_id=bookmark.author_id,\n            post_id=bookmark.post_id,\n            date_created=bookmark.bookmark_date\n        ).model_dump()\n        for bookmark in bookmarks\n    ]\n    return resp, HTTPStatus.OK",
  "\n\ndef get_all_modules(config: Config, source_code_queue: Queue) -> None:\n    \"\"\"Iterate throug all the directories from the root directory.\"\"\"\n    for entry in config.root_directory:\n        if path.isfile(entry):\n            source_code_queue.put(entry)\n        else:\n            directory_iterator: DirectoryIterator = DirectoryIterator(config=config)\n            for modules in directory_iterator:\n                for module in modules:\n                    source_code_queue.put(module)\n",
  "            enabled=False,\n        )\n        zoomOut = action(\n            self.tr(\"&Zoom Out\"),\n            functools.partial(self.addZoom, 0.9),\n            shortcuts[\"zoom_out\"],\n            \"zoom-out\",\n            self.tr(\"Decrease zoom level\"),\n            enabled=False,\n        )\n        zoomOrg = action(\n            self.tr(\"&Original size\"),\n            functools.partial(self.setZoom, 100),\n            shortcuts[\"zoom_to_original\"],\n            \"zoom\",\n            self.tr(\"Zoom to original size\"),\n            enabled=False,\n        )\n        keepPrevScale = action(\n            self.tr(\"&Keep Previous Scale\"),\n            self.enableKeepPrevScale,\n            tip=self.tr(\"Keep previous zoom scale\"),\n            checkable=True,\n            checked=self._config[\"keep_prev_scale\"],\n            enabled=True,\n        )\n        fitWindow = action(\n            self.tr(\"&Fit Window\"),\n            self.setFitWindow,\n            shortcuts[\"fit_window\"],\n            \"fit-window\",\n            self.tr(\"Zoom follows window size\"),\n            checkable=True,\n            enabled=False,\n        )\n        fitWidth = action(\n            self.tr(\"Fit &Width\"),\n            self.setFitWidth,\n            shortcuts[\"fit_width\"],\n            \"fit-width\",\n",
  "def get_posts(session: Session, post_data: GetPosts):\n    with session() as db:\n        posts: list[Post] = db.query(Post).offset(post_data.offset).limit(post_data.limit).all()\n        for post in posts:\n            post.author\n        return posts\n\ndef delete_post(session: Session, post_data: GetPost):\n    with session() as db:\n        post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        db.delete(post)\n        db.commit()\n        \n    return post",
  "    \"\"\"Get a video thumbnail.\"\"\"\n    thumbnail_key: dict[str, Any] = {}\n    if data.get('high'):\n        thumbnail_key = data.get('high')\n    elif data.get('medium'):\n        thumbnail_key = data.get('high')\n    elif data.get('standard'):\n        thumbnail_key = data.get('high')\n    else:\n        thumbnail_key = data.get('high')\n    return thumbnail_key.get('url')\n\ndef get_caption(data: dict[str, Any]) -> str:\n    return data.get('title', 'Caption')\n\ndef get_description(data: dict[str, Any]) -> str:\n    return data.get('description', 'Description')\n\nst.title(\"Live News Bot.\")\n\n# React to user input\nif prompt := st.chat_input(\"What is up?\"):\n    # Display user message in chat message container\n    with st.chat_message('user'):\n        st.markdown(f'Finding latest news videos mentioning \"{prompt}\"')\n    # Display assistant response in chat message container\n    with st.spinner('Searching for the latest live news coverage...'):\n        search_results: list[dict[str, Any]] = search_news(prompt)\n    # search_results: list[dict[str, Any]] = load_data()\n    for search_result in search_results: \n        video_id: str = search_result.get('resource_id')\n        with st.spinner('Loading the news piece...'):\n            video: dict[str, Any] = search_video(video_id)\n        with st.chat_message(\"assistant\"):\n            url: str = f'https://www.youtube.com/watch?v={video_id}'\n            st.video(url)\n            st.markdown(get_description(video['snippet']))\n\n# videos: list[dict[str, Any]] = load_data()\n# video: dict[str, Any] = search_video(videos[0].get('resource_id'))\n",
  "\n            s.append(shape)\n        self.loadShapes(s)\n\n    def loadFlags(self, flags):\n        self.flag_widget.clear()\n        for key, flag in flags.items():\n            item = QtWidgets.QListWidgetItem(key)\n            item.setFlags(item.flags() | Qt.ItemIsUserCheckable)\n            item.setCheckState(Qt.Checked if flag else Qt.Unchecked)\n            self.flag_widget.addItem(item)\n\n    def saveLabels(self, filename):\n        lf = LabelFile()\n\n        def format_shape(s):\n            data = s.other_data.copy()\n            data.update(\n                dict(\n                    label=s.label.encode(\"utf-8\") if PY2 else s.label,\n                    points=[(p.x(), p.y()) for p in s.points],\n                    group_id=s.group_id,\n                    description=s.description,\n                    shape_type=s.shape_type,\n                    flags=s.flags,\n                    mask=None if s.mask is None else utils.img_arr_to_b64(s.mask),\n                )\n            )\n            return data\n\n        shapes = [format_shape(item.shape()) for item in self.labelList]\n        flags = {}\n        for i in range(self.flag_widget.count()):\n            item = self.flag_widget.item(i)\n            key = item.text()\n            flag = item.checkState() == Qt.Checked\n            flags[key] = flag\n        try:\n            imagePath = osp.relpath(self.imagePath, osp.dirname(filename))\n            imageData = self.imageData if self._config[\"store_data\"] else None\n",
  "                createLineStripMode,\n                createAiPolygonMode,\n                createAiMaskMode,\n                editMode,\n                edit,\n                duplicate,\n                copy,\n                paste,\n                delete,\n                undo,\n                undoLastPoint,\n                removePoint,\n            ),\n            onLoadActive=(\n                close,\n                createMode,\n                createRectangleMode,\n                createCircleMode,\n                createLineMode,\n                createPointMode,\n                createLineStripMode,\n                createAiPolygonMode,\n                createAiMaskMode,\n                editMode,\n                brightnessContrast,\n            ),\n            onShapesPresent=(saveAs, hideAll, showAll, toggleAll),\n        )\n\n        self.canvas.vertexSelected.connect(self.actions.removePoint.setEnabled)\n\n        self.menus = utils.struct(\n            file=self.menu(self.tr(\"&File\")),\n            edit=self.menu(self.tr(\"&Edit\")),\n            view=self.menu(self.tr(\"&View\")),\n            help=self.menu(self.tr(\"&Help\")),\n            recentFiles=QtWidgets.QMenu(self.tr(\"Open &Recent\")),\n            labelList=labelMenu,\n        )\n\n",
  "from sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, MappedAsDataclass\nfrom sqlalchemy.orm import sessionmaker\nfrom ...config.config import BaseConfig\nfrom contextlib import contextmanager\nfrom flask import current_app\n\n\nclass Base(MappedAsDataclass, DeclarativeBase):\n    pass\n\nSQLALCHEMY_DATABASE_URI = BaseConfig().db_conn_string\nengine = create_engine(SQLALCHEMY_DATABASE_URI)\nSession = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n\ndef create_all():\n    Base.metadata.create_all(bind=engine)\n    \ndef drop_all():\n    Base.metadata.drop_all(bind=engine)\n\n@contextmanager\ndef get_db():\n    try:\n        db = Session()\n        yield db\n    finally:\n        db.close()",
  "import os.path as osp\nimport shutil\nimport tempfile\n\nimport pytest\n\nimport labelme.app\nimport labelme.config\nimport labelme.testing\n\nhere = osp.dirname(osp.abspath(__file__))\ndata_dir = osp.join(here, \"data\")\n\n\ndef _win_show_and_wait_imageData(qtbot, win):\n    win.show()\n\n    def check_imageData():\n        assert hasattr(win, \"imageData\")\n        assert win.imageData is not None\n\n    qtbot.waitUntil(check_imageData)  # wait for loadFile\n\n\n@pytest.mark.gui\ndef test_MainWindow_open(qtbot):\n    win = labelme.app.MainWindow()\n    qtbot.addWidget(win)\n    win.show()\n    win.close()\n\n\n@pytest.mark.gui\ndef test_MainWindow_open_img(qtbot):\n    img_file = osp.join(data_dir, \"raw/2011_000003.jpg\")\n    win = labelme.app.MainWindow(filename=img_file)\n    qtbot.addWidget(win)\n    _win_show_and_wait_imageData(qtbot, win)\n    win.close()\n\n",
  "def update_post(post_data: UpdatePost, post_image: dict, session: Session):\n    post_image_url: str = save_post_photo(post_image)\n    with session() as db:\n        post: Post = db.query(Post).filter(Post.id == post_data.post_id).first()\n        if post_data.location:\n            post.location = post_data.location\n        if post_data.text:\n            post.text = post_data.text\n        if post_image_url:\n            post.image_url = post_image_url\n        db.commit()\n        db.refresh(post)\n    return post\n\ndef get_post(session: Session, post_data: GetPost):\n    with session() as db:\n        post = db.query(Post).filter(Post.id == post_data.post_id).first()\n    return post",
  "    features_covered.append(res)\n    print(res)\nprint(features_covered)\n# print(len(splits))\n# for split in splits:\n#     print(split)\n#     print(\"###################\")",
  "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "import ast\nimport subprocess\nfrom ast import AST, Constant, Expr\nfrom os import path\nfrom openai import RateLimitError\nimport sys\n\nfrom .config import Config\nfrom .llms import chatgpt\nfrom .templates import function_prompt\n\n\ndef read_src(file_path: str) -> str:\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        return f.read()\n\n\ndef save_src(file_path: str, new_src: str) -> str:\n    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n        return f.write(new_src)\n\n\ndef parse_src(file_src: str) -> AST:\n    return ast.parse(file_src)\n\n\ndef print_src(src_tree: AST) -> None:\n    print(ast.dump(src_tree, indent=4))\n\n\nfunction_dcstr: str = '''\ndef subtract(a: int | float, b: int | float) -> int | float:\n    \"\"\"Subtracts two numbers\n\n    Parameters\n    ----------\n    a : int or float\n        The first number to subtract.\n    b : int or float\n        The second number to subtract.\n",
  "from qtpy import QtCore\nfrom qtpy import QtWidgets\n\n\nclass ToolBar(QtWidgets.QToolBar):\n    def __init__(self, title):\n        super(ToolBar, self).__init__(title)\n        layout = self.layout()\n        m = (0, 0, 0, 0)\n        layout.setSpacing(0)\n        layout.setContentsMargins(*m)\n        self.setContentsMargins(*m)\n        self.setWindowFlags(self.windowFlags() | QtCore.Qt.FramelessWindowHint)\n\n    def addAction(self, action):\n        if isinstance(action, QtWidgets.QWidgetAction):\n            return super(ToolBar, self).addAction(action)\n        btn = QtWidgets.QToolButton()\n        btn.setDefaultAction(action)\n        btn.setToolButtonStyle(self.toolButtonStyle())\n        self.addWidget(btn)\n\n        # center align\n        for i in range(self.layout().count()):\n            if isinstance(self.layout().itemAt(i).widget(), QtWidgets.QToolButton):\n                self.layout().itemAt(i).setAlignment(QtCore.Qt.AlignCenter)\n",
  "#                                 id=search.resource_id,\n#                                 title=search.title\n#                         )\n#                 )\n# print(final)       ",
  "def delete_user(session: Session, user_data: GetUser):\n    with session() as db:\n        user = db.query(User).filter(User.id == user_data.user_id).first()\n        db.delete(user)\n        db.commit()\n        \n    return user\n\n\ndef user_account_active(session: Session, user_data: GetUser):\n    with session() as db:\n        user: User = db.query(User).filter(User.id == user_data.user_id).first()\n    return user.activated",
  "# channel_playlists = youtube.find_channel_playlists('UC5WVOSvL9bc6kwCMXXeFLLw')\n# print(channel_playlists)\n# search_iterator = youtube.find_playlist_items('PLsyeobzWxl7poL9JTVyndKe62ieoN-MZ3', max_results=25)\n# print(next(search_iterator))\n# print(youtube.search())",
  "import copy\nimport math\n\nimport numpy as np\nimport skimage.measure\nfrom qtpy import QtCore\nfrom qtpy import QtGui\n\nimport labelme.utils\nfrom labelme.logger import logger\n\n# TODO(unknown):\n# - [opt] Store paths instead of creating new ones at each paint.\n\n\nclass Shape(object):\n    # Render handles as squares\n    P_SQUARE = 0\n\n    # Render handles as circles\n    P_ROUND = 1\n\n    # Flag for the handles we would move if dragging\n    MOVE_VERTEX = 0\n\n    # Flag for all other handles on the current shape\n    NEAR_VERTEX = 1\n\n    # The following class variables influence the drawing of all shape objects.\n    line_color = None\n    fill_color = None\n    select_line_color = None\n    select_fill_color = None\n    vertex_fill_color = None\n    hvertex_fill_color = None\n    point_type = P_ROUND\n    point_size = 8\n    scale = 1.0\n\n    def __init__(\n",
  "import torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n\ndef print_examples(model, device, dataset):\n    transform = transforms.Compose(\n        [\n            transforms.Resize((299, 299)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ]\n    )\n\n    model.eval()\n    test_img1 = transform(Image.open(\"test_examples/dog.jpg\").convert(\"RGB\")).unsqueeze(\n        0\n    )\n    print(\"Example 1 CORRECT: Dog on a beach by the ocean\")\n    print(\n        \"Example 1 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img1.to(device), dataset.vocabulary))\n    )\n    test_img2 = transform(\n        Image.open(\"test_examples/child.jpg\").convert(\"RGB\")\n    ).unsqueeze(0)\n    print(\"Example 2 CORRECT: Child holding red frisbee outdoors\")\n    print(\n        \"Example 2 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img2.to(device), dataset.vocabulary))\n    )\n    test_img3 = transform(Image.open(\"test_examples/bus.png\").convert(\"RGB\")).unsqueeze(\n        0\n    )\n    print(\"Example 3 CORRECT: Bus driving by parked cars\")\n    print(\n        \"Example 3 OUTPUT: \"\n        + \" \".join(model.caption_image(test_img3.to(device), dataset.vocabulary))\n    )\n    test_img4 = transform(\n",
  "def gemma_extraction(video_id: str):\n    description: str = get_description(video_id=video_id)\n    template: PromptTemplate = PromptTemplate(template=segment_str_gemma, \n                    input_variables=[\"text\"]\n                                              )\n    chain = template | llama_2b \n    inputs: dict[str, str] = {\n        \"text\": description\n    }\n    res = chain.invoke(inputs)\n    print(res)\n    \n    \ndef get_channel_id(channel_name: str, youtube: YouTube = get_youtube_client()) -> str:\n    response: YouTubeResponse = youtube.find_channel_by_name(display_name=channel_name)\n    search_result: Search = response.items[0]\n    channel_id: str = search_result.channel_id\n    return channel_id\n\ndef get_channel_playlists(channel_name: str, youtube: YouTube = get_youtube_client()) -> list[str]:\n    # channel_id: str = get_channel_id(channel_name=channel_name, youtube=youtube)\n    channel_id: str = \"UC_mYaQAE6-71rjSN6CeCA-g\"\n    response: YouTubeListResponse = youtube.find_channel_playlists(channel_id=channel_id)\n    playlists: list[Playlist] = response.items\n    playlist_ids: list[str] = [playlist.id for playlist in playlists]\n    return playlist_ids\n    \n\ndef main(video_id: str = video_id):\n    # output: TimeStamps = partition_video_segments(video_id=video_id)\n    # print(output)    \n    # gemma_extraction(video_id=video_id)\n    channel_name: str = \"neetcode\"\n    playlist_ids: list[str] = get_channel_playlists(channel_name=channel_name)\n    print(playlist_ids)\n    \n    ",
  "\n    try:\n        import PyQt5  # NOQA\n\n        QT_BINDING = \"pyqt5\"\n    except ImportError:\n        pass\n\n    if QT_BINDING is None:\n        try:\n            import PySide2  # NOQA\n\n            QT_BINDING = \"pyside2\"\n        except ImportError:\n            pass\n\n    if QT_BINDING is None:\n        # PyQt5 can be installed via pip for Python3\n        # 5.15.3, 5.15.4 won't work with PyInstaller\n        install_requires.append(\"PyQt5!=5.15.3,!=5.15.4\")\n        QT_BINDING = \"pyqt5\"\n\n    del QT_BINDING\n\n    if os.name == \"nt\":  # Windows\n        install_requires.append(\"colorama\")\n\n    return install_requires\n\n\ndef get_long_description():\n    with open(\"README.md\") as f:\n        long_description = f.read()\n    try:\n        # when this package is being released\n        import github2pypi\n\n        return github2pypi.replace_url(\n            slug=\"wkentaro/labelme\", content=long_description, branch=\"main\"\n        )\n",
  "#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport argparse\nimport glob\nimport os\nimport os.path as osp\nimport sys\n\nimport imgviz\nimport numpy as np\n\nimport labelme\n\n\ndef main():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"input_dir\", help=\"Input annotated directory\")\n    parser.add_argument(\"output_dir\", help=\"Output dataset directory\")\n    parser.add_argument(\n        \"--labels\", help=\"Labels file or comma separated text\", required=True\n    )\n    parser.add_argument(\n        \"--noobject\", help=\"Flag not to generate object label\", action=\"store_true\"\n    )\n    parser.add_argument(\n        \"--nonpy\", help=\"Flag not to generate .npy files\", action=\"store_true\"\n    )\n    parser.add_argument(\n        \"--noviz\", help=\"Flag to disable visualization\", action=\"store_true\"\n    )\n    args = parser.parse_args()\n\n    if osp.exists(args.output_dir):\n        print(\"Output directory already exists:\", args.output_dir)\n        sys.exit(1)\n    os.makedirs(args.output_dir)\n",
  "                url=\"https://github.com/labelmeai/efficient-sam/releases/download/onnx-models-20231225/efficient_sam_vits_decoder.onnx\",  # NOQA\n                md5=\"d9372f4a7bbb1a01d236b0508300b994\",\n            ),\n        )\n\n\nMODELS = [\n    SegmentAnythingModelVitB,\n    SegmentAnythingModelVitL,\n    SegmentAnythingModelVitH,\n    EfficientSamVitT,\n    EfficientSamVitS,\n]\n",
  "\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "from api import create_app\n\n\napp = create_app()",
  "@post.route(\"/comments\", methods=[\"GET\"])\ndef get_post_comments():\n    \"\"\"Get a posts comments.\"\"\"\n    offset: str = request.args.get('offset', 0)\n    limit: str = request.args.get('limit', 10)\n    try:\n        post_data = GetPost(post_id=request.args.get('post_id'))\n    except ValidationError:\n        return {'error': 'Invalid input: you probably did not include the post id.'}, HTTPStatus.BAD_REQUEST\n    try:\n        post: Post = get_post(session=get_db, post_data=post_data)\n        if not post:\n            return {'Error': f'post with id {post_data.post_id} does not exists'}, HTTPStatus.NOT_FOUND\n        comments: list[Comment] = list_post_comments(session=get_db, post_data=post_data, offset=offset, limit=limit)\n    except (OperationalError, IntegrityError) as e:\n        print(e)\n        # Send email to\n        return {'Error': 'The application is experiencing a tempoary error. Please try again in a few minutes.'}, HTTPStatus.INTERNAL_SERVER_ERROR\n    resp = [\n        CommentCreated(\n            user_id=comment.author_id,\n            post_id=comment.post_id,\n            date_created=comment.comment_date,\n            comment_id=comment.id,\n            comment=comment.comment_text\n        ).model_dump()\n        for comment in comments\n    ]\n    return resp, HTTPStatus.OK",
  "#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}\n\n# Enable or disable spider middlewares\n# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    \"leetcode.middlewares.LeetcodeSpiderMiddleware\": 543,\n#}\n\n# Enable or disable downloader middlewares\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\nDOWNLOADER_MIDDLEWARES = {\n    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,\n    'scrapy.downloadermiddlewares.retry.RetryMiddleware': None,\n    'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware': 400,\n    'scrapy_fake_useragent.middleware.RetryUserAgentMiddleware': 401,\n}\nFAKEUSERAGENT_PROVIDERS = [\n    'scrapy_fake_useragent.providers.FakeUserAgentProvider',  # This is the first provider we'll try\n    'scrapy_fake_useragent.providers.FakerProvider',  # If FakeUserAgentProvider fails, we'll use faker to generate a user-agent string for us\n    'scrapy_fake_useragent.providers.FixedUserAgentProvider',  # Fall back to USER_AGENT value\n]\n\n# Enable or disable extensions\n# See https://docs.scrapy.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    \"scrapy.extensions.telnet.TelnetConsole\": None,\n#}\n\n# Configure item pipelines\n# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n#ITEM_PIPELINES = {\n#    \"leetcode.pipelines.LeetcodePipeline\": 300,\n#}\n\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n",
  "# posts = [\n    #     CreatedPost(\n    #         id=post.id,\n    #         location=post.location,\n    #         text=post.text,\n    #         image_url=post.image_url,\n    #         author_id=post.author_id,\n    #         date_published=post.date_published\n    #     ).model_dump()\n    #     for post in posts\n    # ]\n    return created_posts, HTTPStatus.OK\n\n@post.route(\"/load_more_posts\", methods=[\"GET\"])\ndef load_more_posts():\n    \"\"\"Get a single post.\"\"\"\n    offset: str = request.args.get('offset', 0)\n    limit: str = request.args.get('limit', 10)\n    more_posts = load_posts(limit=int(limit), offset=int(offset))\n    return more_posts",
  "        elif shape == self.P_ROUND:\n            path.addEllipse(point, d / 2.0, d / 2.0)\n        else:\n            assert False, \"unsupported vertex shape\"\n\n    def nearestVertex(self, point, epsilon):\n        min_distance = float(\"inf\")\n        min_i = None\n        for i, p in enumerate(self.points):\n            dist = labelme.utils.distance(p - point)\n            if dist <= epsilon and dist < min_distance:\n                min_distance = dist\n                min_i = i\n        return min_i\n\n    def nearestEdge(self, point, epsilon):\n        min_distance = float(\"inf\")\n        post_i = None\n        for i in range(len(self.points)):\n            line = [self.points[i - 1], self.points[i]]\n            dist = labelme.utils.distancetoline(point, line)\n            if dist <= epsilon and dist < min_distance:\n                min_distance = dist\n                post_i = i\n        return post_i\n\n    def containsPoint(self, point):\n        if self.mask is not None:\n            y = np.clip(\n                int(round(point.y() - self.points[0].y())),\n                0,\n                self.mask.shape[0] - 1,\n            )\n            x = np.clip(\n                int(round(point.x() - self.points[0].x())),\n                0,\n                self.mask.shape[1] - 1,\n            )\n            return self.mask[y, x]\n        return self.makePath().contains(point)\n",
  "        mask, min_size=mask.sum() * MIN_SIZE_RATIO, out=mask\n    )\n\n    if 0:\n        imgviz.io.imsave(\"mask.jpg\", imgviz.label2rgb(mask, imgviz.rgb2gray(image)))\n    return mask\n",
  "    agent = cl.user_session.get(\"agent\")\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({\"input\": message.content})[\"output\"]\n    await msg.update()",
  "    assert widget.labelList.count() == 4\n    widget.addLabelHistory(\"bicycle\")\n    assert widget.labelList.count() == 4\n    item = widget.labelList.item(0)\n    assert item.text() == \"bicycle\"\n\n\n@pytest.mark.gui\ndef test_LabelDialog_popUp(qtbot):\n    labels = [\"cat\", \"dog\", \"person\"]\n    widget = LabelDialog(labels=labels, sort_labels=True)\n    qtbot.addWidget(widget)\n\n    # popUp(text='cat')\n\n    def interact():\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_P)  # enter 'p' for 'person'  # NOQA\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Enter)  # NOQA\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Enter)  # NOQA\n\n    QtCore.QTimer.singleShot(500, interact)\n    label, flags, group_id, description = widget.popUp(\"cat\")\n    assert label == \"person\"\n    assert flags == {}\n    assert group_id is None\n    assert description == \"\"\n\n    # popUp()\n\n    def interact():\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Enter)  # NOQA\n        qtbot.keyClick(widget.edit, QtCore.Qt.Key_Enter)  # NOQA\n\n    QtCore.QTimer.singleShot(500, interact)\n    label, flags, group_id, description = widget.popUp()\n    assert label == \"person\"\n    assert flags == {}\n    assert group_id is None\n    assert description == \"\"\n\n",
  "                    maker.bndbox(\n                        maker.xmin(str(xmin)),\n                        maker.ymin(str(ymin)),\n                        maker.xmax(str(xmax)),\n                        maker.ymax(str(ymax)),\n                    ),\n                )\n            )\n\n        if not args.noviz:\n            captions = [class_names[label] for label in labels]\n            viz = imgviz.instances2rgb(\n                image=img,\n                labels=labels,\n                bboxes=bboxes,\n                captions=captions,\n                font_size=15,\n            )\n            imgviz.io.imsave(out_viz_file, viz)\n\n        with open(out_xml_file, \"wb\") as f:\n            f.write(lxml.etree.tostring(xml, pretty_print=True))\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "\n        validation_test = validation_result[\"validation_output\"].dict()\n        t2 = time.time()\n        self.logger.info(\"Time to validate request: {}\".format(round(t2 - t1, 2)))\n\n        if validation_test[\"plan_is_valid\"].lower() == \"no\":\n            self.logger.warning(\"User request was not valid!\")\n            print(\"\\n######\\n Travel plan is not valid \\n######\\n\")\n            print(validation_test[\"updated_request\"])\n            return None, None, validation_result\n\n        else:\n            # plan is valid\n            self.logger.info(\"Query is valid\")\n            self.logger.info(\"Getting travel suggestions\")\n            t1 = time.time()\n\n            self.logger.info(\n                \"User request is valid, calling agent (model is {})\".format(\n                    self.chat_model.model_name\n                )\n            )\n\n            agent_result = self.agent_chain(\n                {\n                    \"query\": query,\n                    \"format_instructions\": self.mapping_prompt.parser.get_format_instructions(),\n                }\n            )\n\n            trip_suggestion = agent_result[\"agent_suggestion\"]\n            list_of_places = agent_result[\"mapping_list\"].dict()\n            t2 = time.time()\n            self.logger.info(\"Time to get suggestions: {}\".format(round(t2 - t1, 2)))\n\n            return trip_suggestion, list_of_places, validation_result\n\n\nsecrets = load_secets()    \n\n",
  "from setuptools import find_packages, setup\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nVERSION = '0.5.1'\nDESCRIPTION = 'A python library that wraps around the YouTube V3 API. You can use it find and manage YouTube resources including Videos, Playlists, Channels and Comments.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'google-api-python-client',\n    'google-auth-oauthlib'\n]\n\nsetup(\n    name='ayv',\n    packages=find_packages(\n        include=[\n            'youtube',\n            'youtube.oauth',\n            'youtube.models',\n            'youtube.resources',\n            'youtube.resources.video',\n            'youtube.exceptions',\n            'youtube.resources.channel',\n            'youtube.resources.playlist',\n            'youtube.resources.playlist_item',\n            'youtube.resources.comment_thread',\n",
  "            \"prev\",\n            self.tr(\"Open prev (hold Ctl+Shift to copy labels)\"),\n            enabled=False,\n        )\n        save = action(\n            self.tr(\"&Save\\n\"),\n            self.saveFile,\n            shortcuts[\"save\"],\n            \"save\",\n            self.tr(\"Save labels to file\"),\n            enabled=False,\n        )\n        saveAs = action(\n            self.tr(\"&Save As\"),\n            self.saveFileAs,\n            shortcuts[\"save_as\"],\n            \"save-as\",\n            self.tr(\"Save labels to a different file\"),\n            enabled=False,\n        )\n\n        deleteFile = action(\n            self.tr(\"&Delete File\"),\n            self.deleteFile,\n            shortcuts[\"delete_file\"],\n            \"delete\",\n            self.tr(\"Delete current label file\"),\n            enabled=False,\n        )\n\n        changeOutputDir = action(\n            self.tr(\"&Change Output Dir\"),\n            slot=self.changeOutputDirDialog,\n            shortcut=shortcuts[\"save_to\"],\n            icon=\"open\",\n            tip=self.tr(\"Change where annotations are loaded/saved\"),\n        )\n\n        saveAuto = action(\n            text=self.tr(\"Save &Automatically\"),\n",
  "\n    Returns\n    -------\n    int or float\n        The result of subtracting b from a.\n    \"\"\"\n    return a - b\n'''\n\n\ndef generate_doc_string(src_code: str, config: Config) -> str:\n    prompt_formatted_str: str = function_prompt.format(\n        function_code=src_code, documentation_style=config.documentation_style\n    )\n    # function_and_docstring: str = chatgpt.invoke(prompt_formatted_str)\n    # return function_and_docstring\n    return function_dcstr\n\n\ndef make_docstring_node(docstr: str):\n    constant_str: Constant = Constant(docstr)\n    return Expr(value=constant_str)\n\n\ndef format_file(file_path: str) -> None:\n    \"\"\"Format the file using black.\"\"\"\n    if path.exists(file_path):\n        subprocess.run([\"black\", file_path], capture_output=True)\n",
  "            self.tr(\"Fill Drawing Polygon\"),\n            self.canvas.setFillDrawing,\n            None,\n            \"color\",\n            self.tr(\"Fill polygon while drawing\"),\n            checkable=True,\n            enabled=True,\n        )\n        if self._config[\"canvas\"][\"fill_drawing\"]:\n            fill_drawing.trigger()\n\n        # Lavel list context menu.\n        labelMenu = QtWidgets.QMenu()\n        utils.addActions(labelMenu, (edit, delete))\n        self.labelList.setContextMenuPolicy(Qt.CustomContextMenu)\n        self.labelList.customContextMenuRequested.connect(self.popLabelListMenu)\n\n        # Store actions for further handling.\n        self.actions = utils.struct(\n            saveAuto=saveAuto,\n            saveWithImageData=saveWithImageData,\n            changeOutputDir=changeOutputDir,\n            save=save,\n            saveAs=saveAs,\n            open=open_,\n            close=close,\n            deleteFile=deleteFile,\n            toggleKeepPrevMode=toggle_keep_prev_mode,\n            delete=delete,\n            edit=edit,\n            duplicate=duplicate,\n            copy=copy,\n            paste=paste,\n            undoLastPoint=undoLastPoint,\n            undo=undo,\n            removePoint=removePoint,\n            createMode=createMode,\n            editMode=editMode,\n            createRectangleMode=createRectangleMode,\n            createCircleMode=createCircleMode,\n",
  "from youtube import YouTube\nfrom youtube.models import Search\nfrom youtube.schemas import (\n        YouTubeRequest, YouTubeListResponse, YouTubeResponse,\n        SearchFilter, SearchOptionalParameters, SearchPart\n)\nfrom typing import Iterator\n\n\nclient_secrets_file = \"/home/lyle/oryks/backend/api/libraries/youtube.json\"\ndef get_youtube_client(client_secrets_file: str = client_secrets_file) -> YouTube:\n    youtube: YouTube = YouTube(client_secret_file=client_secrets_file)\n    client = youtube.authenticate()\n    youtube.youtube_client = client\n    return youtube\n\nyoutube: YouTube = get_youtube_client(client_secrets_file=\"/home/lyle/Downloads/test.json\")\n\n\n# query: str = ''\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q=query,\n#     type=['video'],\n#     channelId=\"UCtAcpQcYerN8xxZJYTfWBMw\"\n# )\n# search_request: YouTubeRequest = YouTubeRequest(\n#     part=part, \n#     optional_parameters=optional_parameters\n# )\n# search_results: YouTubeResponse = youtube.search(search_request)\n# search_iterator: Iterator = youtube.get_search_iterator(search_request)\n# # res: YouTubeResponse = youtube.find_channel_by_name(display_name=\"Umar Jamil\")\n# # print(res.items[0])\n# res = next(search_iterator)\n# final = []\n# for x in search_iterator:\n#         for search in x:\n#                 final.append(\n#                         dict(\n",
  "from langchain.llms import OpenAI\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nopen_ai = OpenAI(temperature=0)\ngoogle = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
  "import whisper\n\nmodel = whisper.load_model(\"medium.en\")\nresult = model.transcribe(\"code.wav\")\nprint(result[\"text\"])",
  "import argparse\nimport codecs\nimport logging\nimport os\nimport os.path as osp\nimport sys\n\nimport yaml\nfrom qtpy import QtCore\nfrom qtpy import QtWidgets\n\nfrom labelme import __appname__\nfrom labelme import __version__\nfrom labelme.app import MainWindow\nfrom labelme.config import get_config\nfrom labelme.logger import logger\nfrom labelme.utils import newIcon\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--version\", \"-V\", action=\"store_true\", help=\"show version\")\n    parser.add_argument(\"--reset-config\", action=\"store_true\", help=\"reset qt config\")\n    parser.add_argument(\n        \"--logger-level\",\n        default=\"debug\",\n        choices=[\"debug\", \"info\", \"warning\", \"fatal\", \"error\"],\n        help=\"logger level\",\n    )\n    parser.add_argument(\"filename\", nargs=\"?\", help=\"image or label filename\")\n    parser.add_argument(\n        \"--output\",\n        \"-O\",\n        \"-o\",\n        help=\"output file or directory (if it ends with .json it is \"\n        \"recognized as file, else as directory)\",\n    )\n    default_config_file = os.path.join(os.path.expanduser(\"~\"), \".labelmerc\")\n    parser.add_argument(\n        \"--config\",\n",
  "    \"Face ID\",\n    \"Water and dust resistance\",\n    \"iOS 15\",\n    \"Improved battery life\",\n    \"Siri voice recognition\",\n    \"Apple Pay\",\n    \"Apple Fitness+ integration\",\n    \"Apple Arcade subscription\",\n    \"Apple Music\",\n    \"iMessage\",\n    \"App Store\",\n    \"iCloud storage\",\n    \"Privacy features\",\n]\n\nfor feature in features:\n    print(\"#######################################################\")\n    query = f\"What does the video cover in relation to {feature}?\"\n    print(qa_chain.invoke(query))\n    print(\"#######################################################\")\n",
  "        self.zoomMode = self.FIT_WIDTH if value else self.MANUAL_ZOOM\n        self.adjustScale()\n\n    def enableKeepPrevScale(self, enabled):\n        self._config[\"keep_prev_scale\"] = enabled\n        self.actions.keepPrevScale.setChecked(enabled)\n\n    def onNewBrightnessContrast(self, qimage):\n        self.canvas.loadPixmap(QtGui.QPixmap.fromImage(qimage), clear_shapes=False)\n\n    def brightnessContrast(self, value):\n        dialog = BrightnessContrastDialog(\n            utils.img_data_to_pil(self.imageData),\n            self.onNewBrightnessContrast,\n            parent=self,\n        )\n        brightness, contrast = self.brightnessContrast_values.get(\n            self.filename, (None, None)\n        )\n        if brightness is not None:\n            dialog.slider_brightness.setValue(brightness)\n        if contrast is not None:\n            dialog.slider_contrast.setValue(contrast)\n        dialog.exec_()\n\n        brightness = dialog.slider_brightness.value()\n        contrast = dialog.slider_contrast.value()\n        self.brightnessContrast_values[self.filename] = (brightness, contrast)\n\n    def togglePolygons(self, value):\n        flag = value\n        for item in self.labelList:\n            if value is None:\n                flag = item.checkState() == Qt.Unchecked\n            item.setCheckState(Qt.Checked if flag else Qt.Unchecked)\n\n    def loadFile(self, filename=None):\n        \"\"\"Load the specified file, or the last opened file if None.\"\"\"\n        # changing fileListWidget loads file\n        if filename in self.imageList and (\n",
  "import json\n\nfrom flask import request, Flask\n\nfrom ..config.logger_config import app_logger\nfrom .rate_limiter import request_is_rate_limited\nfrom redis import Redis\nfrom datetime import timedelta\nfrom http import HTTPStatus\n\nr = Redis(host='localhost', port=6379, db=0)\n\n\ndef log_post_request():\n    request_data = {\n        \"method\": request.method,\n        \"url root\": request.url_root,\n        \"user agent\": request.user_agent,\n        \"scheme\": request.scheme,\n        \"remote address\": request.remote_addr,\n        \"headers\": request.headers,\n    }\n    if request.args:\n        request_data[\"args\"] = request.args\n    if request.form:\n        request_data[\"data\"] = request.form\n    else:\n        request_data[\"data\"] = request.json\n    if request.cookies:\n        request_data[\"cookies\"] = request.cookies\n    if request.files:\n        request_data[\"image\"] = {\n            \"filename\": request.files[\"Image\"].filename,\n            \"content type\": request.files[\"Image\"].content_type,\n            \"size\": len(request.files[\"Image\"].read()) // 1000,\n        }\n    app_logger.info(str(request_data))",
  "    img_b64 = base64.b64encode(img_data).decode(\"utf-8\")\n    return img_b64\n\n\ndef img_arr_to_data(img_arr):\n    img_pil = PIL.Image.fromarray(img_arr)\n    img_data = img_pil_to_data(img_pil)\n    return img_data\n\n\ndef img_data_to_png_data(img_data):\n    with io.BytesIO() as f:\n        f.write(img_data)\n        img = PIL.Image.open(f)\n\n        with io.BytesIO() as f:\n            img.save(f, \"PNG\")\n            f.seek(0)\n            return f.read()\n\n\ndef img_qt_to_arr(img_qt):\n    w, h, d = img_qt.size().width(), img_qt.size().height(), img_qt.depth()\n    bytes_ = img_qt.bits().asstring(w * h * d // 8)\n    img_arr = np.frombuffer(bytes_, dtype=np.uint8).reshape((h, w, d // 8))\n    return img_arr\n\n\ndef apply_exif_orientation(image):\n    try:\n        exif = image._getexif()\n    except AttributeError:\n        exif = None\n\n    if exif is None:\n        return image\n\n    exif = {PIL.ExifTags.TAGS[k]: v for k, v in exif.items() if k in PIL.ExifTags.TAGS}\n\n    orientation = exif.get(\"Orientation\", None)\n",
  "chatgpt: BaseLLM = ChatOpenAI(temperature=0, api_key=api_key)\n\ntools: list[Tool] = [\n    GoogleSearchTool(),\n]\n\n\ndef get_agent_executor():\n    \"\"\"Get the agent\"\"\"\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\n                \"system\",\n                \"You are a very useful assistant. Your task will be to asnswer the users question. Be very friendly and professional.\",\n            ),\n            (\"user\", \"{input}\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n        ]\n    )\n\n    functions = [format_tool_to_openai_function(t) for t in tools]\n\n    llm_with_tools = chatgpt.bind(functions=functions)\n\n    agent = (\n        {\n            \"input\": lambda x: x[\"input\"],\n            \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n                x[\"intermediate_steps\"]\n            ),\n        }\n        | prompt\n        | llm_with_tools\n        | OpenAIFunctionsAgentOutputParser()\n    )\n\n    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n    return agent_executor\n\n\n",
  "    def deleteSelected(self):\n        deleted_shapes = []\n        if self.selectedShapes:\n            for shape in self.selectedShapes:\n                self.shapes.remove(shape)\n                deleted_shapes.append(shape)\n            self.storeShapes()\n            self.selectedShapes = []\n            self.update()\n        return deleted_shapes\n\n    def deleteShape(self, shape):\n        if shape in self.selectedShapes:\n            self.selectedShapes.remove(shape)\n        if shape in self.shapes:\n            self.shapes.remove(shape)\n        self.storeShapes()\n        self.update()\n\n    def duplicateSelectedShapes(self):\n        if self.selectedShapes:\n            self.selectedShapesCopy = [s.copy() for s in self.selectedShapes]\n            self.boundedShiftShapes(self.selectedShapesCopy)\n            self.endMove(copy=True)\n        return self.selectedShapes\n\n    def boundedShiftShapes(self, shapes):\n        # Try to move in one direction, and if it fails in another.\n        # Give up if both fail.\n        point = shapes[0][0]\n        offset = QtCore.QPointF(2.0, 2.0)\n        self.offsets = QtCore.QPoint(), QtCore.QPoint()\n        self.prevPoint = point\n        if not self.boundedMoveShapes(shapes, point - offset):\n            self.boundedMoveShapes(shapes, point + offset)\n\n    def paintEvent(self, event):\n        if not self.pixmap:\n            return super(Canvas, self).paintEvent(event)\n\n",
  "            self._image_embedding = _compute_image_embedding(\n                image_size=self._image_size,\n                encoder_session=self._encoder_session,\n                image=self._image,\n            )\n            if len(self._image_embedding_cache) > 10:\n                self._image_embedding_cache.popitem(last=False)\n            self._image_embedding_cache[self._image.tobytes()] = self._image_embedding\n            logger.debug(\"Done computing image embedding.\")\n\n    def _get_image_embedding(self):\n        if self._thread is not None:\n            self._thread.join()\n            self._thread = None\n        with self._lock:\n            return self._image_embedding\n\n    def predict_mask_from_points(self, points, point_labels):\n        return _compute_mask_from_points(\n            image_size=self._image_size,\n            decoder_session=self._decoder_session,\n            image=self._image,\n            image_embedding=self._get_image_embedding(),\n            points=points,\n            point_labels=point_labels,\n        )\n\n    def predict_polygon_from_points(self, points, point_labels):\n        mask = self.predict_mask_from_points(points=points, point_labels=point_labels)\n        return _utils.compute_polygon_from_mask(mask=mask)\n\n\ndef _compute_scale_to_resize_image(image_size, image):\n    height, width = image.shape[:2]\n    if width > height:\n        scale = image_size / width\n        new_height = int(round(height * scale))\n        new_width = image_size\n    else:\n        scale = image_size / height\n",
  "from dotenv import load_dotenv\n\nload_dotenv()\nimport logging\nfrom logging import Handler\n\nfrom rich.logging import RichHandler\n\nfrom .agent_nelly import AgentNelly\nfrom .logger import create_logger\nfrom .states import Introduction\nfrom .ui import RichUI\n\nif __name__ == \"__main__\":\n    handlers: list[Handler] = [RichHandler()]\n    create_logger(handlers=handlers)\n    logging.getLogger().setLevel(logging.WARN)\n    from .states import QA, DataAnalysis\n\n    agent_nelly = AgentNelly(ui=RichUI(), initial_state=Introduction())\n    agent_nelly.analyze_product_review()\n",
  "from concurrent.futures import ThreadPoolExecutor\nfrom queue import Queue\nfrom threading import Lock\n\nfrom .config import Config\nfrom .directory_iterators import get_all_modules\nfrom .docstring_writer import process_file, process_function\n\n\ndef generate_project_docstrings(\n    config: Config, source_code_queue: Queue, function_code_queue: Queue\n) -> None:\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        executor.submit(get_all_modules, config, source_code_queue)\n        executor.submit(process_file, source_code_queue, function_code_queue)\n        executor.submit(process_function, config, function_code_queue)\n    source_code_queue.join()\n    function_code_queue.join()\n",
  "from os import path\nimport json\nfrom random import choices\nfrom langchain.docstore.document import Document\nimport re\nfrom langchain.prompts import ChatPromptTemplate\n\n\napi_key: str = \"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\"\nfile_path: str = \"comments.json\"\n\n\ndef lower(text: str) -> str:\n    return text.lower().strip()\n\n# def remove_tags(text: str) -> str:\n#     pattern = r'<.*?>'\n#     text = re.sub()\n\ndef remove_urls(text: str) -> str:\n    url_pattern = r'https?://\\S+|www\\.\\S+'\n    text = re.sub(url_pattern, \"\", text)\n    return text\n\ndef remove_punctuations(text: str) -> str:\n    punctuation_pattern = r'[^\\w\\s]'\n    cleaned = re.sub(punctuation_pattern, \"\", text)\n    return cleaned\n\ndef clean_text(text: str) -> str:\n    text = lower(text)\n    text = remove_urls(text)\n    text = remove_punctuations(text)\n    return text\n\ndef is_acceptable_len(text: str, l=6) -> bool:\n    return len(text.split()) >= l\n\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    all_comments: list[str] = json.load(fp=f)\n",
  "from zipfile import ZipFile\nfrom os import path, mkdir\nimport os\n\n\ndef download_data():\n    pass\n\n\ndef extract_archive(archive_path: str, archive_name: str, extract_path: str = None) -> None:\n    if not extract_path:\n        extract_path: str = \"raw-data\"\n        if not path.exists(extract_path):\n            mkdir(extract_path)\n    archive_path: str = path.join(archive_path, archive_name)\n    with ZipFile(file=archive_path, mode=\"r\") as z_object:\n        z_object.extractall(path=extract_path)\n        \n ",
  "def handle_unsupported_media_type(exeption: Exception) -> Response:\n    \"\"\"Handle all unsupported media type errors.\n\n    This method is called when a a request does not supply the data or the data supplied is\n    invalid.\n\n    Parameters\n    ----------\n    exception: Exception\n        The exception that was raised. This is a subclass of Exception.\n\n    Returns\n    -------\n    Response:\n        A string consiting of json data and response code.\n    \"\"\"\n    return make_response(jsonify({\"error\": str(exeption)}), HTTPStatus.UNSUPPORTED_MEDIA_TYPE)\n\n\ndef register_error_handlers(app: Flask) -> None:\n    \"\"\"Register the error handlers.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        The Flask app instance.\n    \"\"\"\n    app.register_error_handler(HTTPStatus.NOT_FOUND, handle_resource_not_found)\n    app.register_error_handler(HTTPStatus.METHOD_NOT_ALLOWED, handle_method_not_allowed)\n    app.register_error_handler(HTTPStatus.INTERNAL_SERVER_ERROR, handle_internal_server_error)\n    app.register_error_handler(HTTPStatus.UNSUPPORTED_MEDIA_TYPE, handle_unsupported_media_type)"
]