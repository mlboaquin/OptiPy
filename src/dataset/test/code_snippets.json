{
  "1": "# Define here the models for your spider middleware\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass SlidesgoSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(self, response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(self, response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, or item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(self, response, exception, spider):\n        # Called when a spider or process_spider_input() method",
  "2": "def generate_class_docstring(class_code: str, config: Config) -> str:\n    prompt_formatted_str: str = get_class_prompt_template(\n        class_code=class_code, config=config\n    )\n    class_and_docstring = llm.invoke(prompt_formatted_str)\n    return class_and_docstring\n\n\ndef get_class_docstring(class_and_docstring: str) -> str:\n    \"\"\"Get the class docstring.\"\"\"\n    class_tree = ast.parse(class_and_docstring)\n    for node in class_tree.body:\n        if isinstance(node, ClassDef):\n            cls_docstring: str = ast.get_docstring(node)\n            return cls_docstring",
  "3": "from ...agent import State\nfrom ..get_apartment_listings import GetApartmentListings\n\n\nclass GetApartmentDescription(State):\n    def execute(self) -> None:\n        self.agent.ui.get_apartment_description()\n        self.agent.transition_to(GetApartmentListings())\n",
  "4": "from collections import defaultdict\nfrom typing import Any\n\nfrom googleapiclient.http import MediaFileUpload\n\nfrom ...models import (\n    BaseContentDetails,\n    BaseSnippet,\n    Language,\n    LanguageSnippet,\n    Region,\n    RegionSnippet,\n    Video,\n    VideoAbuseReportReason,\n    VideoAbuseReportReasonSnippet,\n    VideoCategory,\n    VideoCategorySnippet,\n)\nfrom ...schemas import (\n    UploadVideo,\n    VideoFilter,\n    VideoOptionalParameters,\n    VideoPart,\n    VideoReportReasonSchema,\n    YouTubeListResponse,\n    YouTubeRatingResponse,\n    YouTubeRequest,\n)\nfrom ..resource import YouTubeResource\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n\n    def parse_snippet(self, snippet_data: dict[str, Any]) -> dict[str, Any]:\n        base_snippet: BaseSnippet = self.parse_base_snippet(snippet_data)\n        parsed_snippet: dict[str, Any] = base_snippet.model_dump()\n        parsed_snippet['channel_id'] = snippet_data['channelId']\n        parsed_snippet['channel_title'] = snippet_data['channelTitle']",
  "5": "from youtube import YouTube\nfrom youtube.models import Search\nfrom youtube.schemas import (\n        YouTubeRequest, YouTubeListResponse, YouTubeResponse,\n        SearchFilter, SearchOptionalParameters, SearchPart\n)\nfrom typing import Iterator\n\n\nclient_secrets_file = \"/home/lyle/oryks/backend/api/libraries/youtube.json\"\ndef get_youtube_client(client_secrets_file: str = client_secrets_file) -> YouTube:\n    youtube: YouTube = YouTube(client_secret_file=client_secrets_file)\n    client = youtube.authenticate()\n    youtube.youtube_client = client\n    return youtube\n\nyoutube: YouTube = get_youtube_client(client_secrets_file=\"/home/lyle/Downloads/test.json\")\n\n\n# query: str = ''\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q=query,\n#     type=['video'],\n#     channelId=\"UCtAcpQcYerN8xxZJYTfWBMw\"\n# )\n# search_request: YouTubeRequest = YouTubeRequest(\n#     part=part, \n#     optional_parameters=optional_parameters\n# )\n# search_results: YouTubeResponse = youtube.search(search_request)\n# search_iterator: Iterator = youtube.get_search_iterator(search_request)\n# # res: YouTubeResponse = youtube.find_channel_by_name(display_name=\"Umar Jamil\")\n# # print(res.items[0])\n# res = next(search_iterator)\n# final = []\n# for x in search_iterator:\n#         for search in x:\n#                 final.append(\n#                         dict(",
  "6": "from .set_config import set_configuration",
  "7": "",
  "8": "from .youtube import YouTube",
  "9": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library for working with Google Drive.'\n\nkey_words = [\n    'drive', 'google-drive', 'google-drive-api', 'upload files to Google Drive',\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-google-drive',\n    packages=find_packages(\n        include=[\n            'google_drive',\n            'google_drive.exceptions',\n            'google_drive.models',\n            'google_drive.schemas',\n            'google_drive.resources'\n        ]\n    ),",
  "10": "# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n\n\n# useful for handling different item types with a single interface\nfrom itemadapter import ItemAdapter\n\n\nclass SlidesgoPipeline:\n    def process_item(self, item, spider):\n        return item\n",
  "11": "from .video import YouTubeVideo",
  "12": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library for working with Google Drive.'\n\nkey_words = [\n    'drive', 'google-drive', 'google-drive-api', 'upload files to Google Drive',\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-google-drive',\n    packages=find_packages(\n        include=[\n            'google_drive',\n            'google_drive.exceptions',\n            'google_drive.models',\n            'google_drive.schemas',\n            'google_drive.resources'\n        ]\n    ),",
  "13": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "14": "# Streamlit application for New York Housing Market Explorer\n\n# Required imports\nimport streamlit as st\nimport pandas as pd\nfrom llama_index import SimpleDirectoryReader, ServiceContext, StorageContext, VectorStoreIndex\nfrom llama_index.llms import OpenAI\nfrom llama_index.embeddings import FastEmbedEmbedding\nfrom qdrant_client import QdrantClient\nimport json\nimport os\nfrom sqlalchemy import create_engine\nfrom llama_index import SQLDatabase, ServiceContext\nfrom llama_index.indices.struct_store import NLSQLTableQueryEngine\nfrom pathlib import Path\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\nfrom llama_index.query_engine import (\n    SQLAutoVectorQueryEngine,\n    RetrieverQueryEngine,\n)\nfrom llama_index.tools.query_engine import QueryEngineTool\nfrom llama_index.indices.vector_store import VectorIndexAutoRetriever\n\nfrom llama_index.indices.vector_store.retrievers import (\n    VectorIndexAutoRetriever,\n)\nfrom llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\nfrom llama_index.query_engine.retriever_query_engine import (\n    RetrieverQueryEngine,\n)\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nst.set_page_config(layout=\"wide\")\nwrite_dir = Path(\"textdata\")\n\n# Initialize Qdrant client\nclient = QdrantClient(\n    url=os.environ['QDRANT_URL'], ",
  "15": "from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service as ChromeService\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.chrome.options import Options\ni\n\noptions = Options()\noptions.add_argument(\"--headless=new\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\ndriver.get(\"https://leetcode.com/problems/remove-linked-list-elements\")\nparagraphs = driver.find_elements(By.TAG_NAME, \"p\")\nprint(paragraphs)\ndriver.quit()",
  "16": "from .view import auth, google_blueprint",
  "17": "from flask import Blueprint, render_template\nfrom http import HTTPStatus\n\nhome = Blueprint(\"home\", __name__)\n\n\n@home.route(\"/\")\n@home.route(\"/home\")\n@home.route(\"/index\")\ndef home_page():\n    \"\"\"Render the home page.\"\"\"\n    return render_template(\"home/index.html\"), HTTPStatus.OK",
  "18": "\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "19": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "20": "from flask.cli import FlaskGroup\nfrom api.helpers.data import create_data\nfrom api import create_app, db\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n@cli.command(\"create_db\")\ndef create_db():\n    \"\"\"Create the database and all the tables.\"\"\"\n    db.drop_all()\n    db.create_all()\n    db.session.commit()\n    \n@cli.command(\"seed_db\")\ndef seed_db():\n    \"\"\"Create the initial data.\"\"\"\n    create_data()\n\n\nif __name__ == \"__main__\":\n    cli()\n",
  "21": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "22": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "23": "from pydantic_settings import BaseSettings\nfrom dotenv import load_dotenv\n\n\nload_dotenv()\n\n\nclass Config(BaseSettings):\n    secret_file: str",
  "24": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library for working with Google Drive.'\n\nkey_words = [\n    'drive', 'google-drive', 'google-drive-api', 'upload files to Google Drive',\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-google-drive',\n    packages=find_packages(\n        include=[\n            'google_drive',\n            'google_drive.exceptions',\n            'google_drive.models',\n            'google_drive.schemas',\n            'google_drive.resources'\n        ]\n    ),",
  "25": "from elasticsearch import Elasticsearch\nfrom elastic_transport import ApiError\nfrom .....config.logger_config import app_logger\n\ndef create_channel_index(es_client: Elasticsearch, channels_index: str = 'channels') -> None:\n    body = {\n        'mappings': {\n            'properties': {\n                'channel_id': {'type': 'keyword'},\n                'channel_title': {\n                    'type': 'text',\n                    'fields': {\n                        'raw': {\n                            'type': 'keyword'\n                        }\n                    }\n                },\n                'published_at': {'type': 'date'},\n                'custom_url': {'type': 'keyword'},\n                'channel_description': {'type': 'text'},\n                'channel_thumbnail': {'type': 'keyword'},\n                'views_count': {'type': 'long'},\n                'videos_count': {'type': 'long'},\n                'subscribers_count': {'type': 'long'}\n            }\n        }\n    }\n    try:\n        es_client.indices.delete(index=channels_index, ignore=[400, 404])\n        es_client.indices.create(index=channels_index, body=body)\n    except ApiError:\n        app_logger.error(f\"Unable to create index '{channels_index}'.\")\n    else:\n        app_logger.info(f\"Index '{channels_index}' created succsefully.\")\n    ",
  "26": "\n\n\n\n\n\n\n\n\n\n\n",
  "27": "from pymongo import MongoClient\n\ndef test_mongo_connection():\n    try:\n        # Create a MongoDB client\n        client = MongoClient(\"mongodb://root:yourpassword@localhost:27017/\")\n        \n        # Get the database instance\n        db = client.yourdbname\n\n        # Create a new collection or get the existing collection\n        collection = db.test_collection\n\n        # Insert a new document\n        result = collection.insert_one({\"message\": \"Hello, MongoDB!\"})\n        \n        # Retrieve the inserted document\n        retrieved_document = collection.find_one({\"_id\": result.inserted_id})\n        \n        print(\"Document inserted successfully:\")\n        print(retrieved_document)\n        \n        # Close the connection\n        client.close()\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\nif __name__ == \"__main__\":\n    test_mongo_connection()\n\n",
  "28": "from .libraries.youtube import YouTube\nimport os\n\n\nclient_secret_file: str = os.environ['CLIENT_SECRET']\nclient_secret_file: str = '/home/lyle/Downloads/client_secret.json'\ncredentials_file: str = os.environ['CREDENTIALS_FILE']\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()\n# youtube.authenticate_from_credentaisl(credentials_file)\n",
  "29": "",
  "30": "from dotenv import load_dotenv\nload_dotenv()\nfrom assistant.agents import default_agent\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set('agent', default_agent)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    agent = cl.user_session.get('agent')\n    msg = cl.Message(content='')\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({'input': message.content})['output']\n    await msg.update()\n",
  "31": "",
  "32": "from contextlib import contextmanager\n\nfrom flask import current_app\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, MappedAsDataclass, sessionmaker\n\nfrom ...config.config import BaseConfig\n\n\nclass Base(MappedAsDataclass, DeclarativeBase):\n    pass\n\n\nSQLALCHEMY_DATABASE_URI = BaseConfig().db_conn_string\nengine = create_engine(SQLALCHEMY_DATABASE_URI)\nSession = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n\n\ndef create_all():\n    Base.metadata.create_all(bind=engine)\n\n\ndef drop_all():\n    Base.metadata.drop_all(bind=engine)\n\n\n@contextmanager\ndef get_db():\n    try:\n        db = Session()\n        yield db\n    finally:\n        db.close()\n",
  "33": "",
  "34": "from typing import Any\n\nfrom ...models import (\n    Channel,\n    ChannelContentDetails,\n    ChannelSnippet,\n    ChannelStatistics,\n    ChannelStatus,\n)\nfrom ...schemas import (\n    ChannelFilter,\n    ChannelOptionalParameters,\n    ChannelPart,\n    YouTubeListResponse,\n    YouTubeRequest,\n)\nfrom ..resource import YouTubeResource\n\n\nclass YouTubeChannel(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n\n    def parse_snippet(self, snippet_data: dict[str, Any]) -> ChannelSnippet:\n        snippet: dict = dict(**self.parse_base_snippet(snippet_data).model_dump())\n        snippet['custom_url'] = snippet_data['customUrl']\n        snippet['country'] = snippet_data.get('country', '')\n        snippet['localized'] = self.parse_localizations(snippet_data['localized'])\n        return ChannelSnippet(**snippet)\n\n    def parse_content_details(\n        self, content_details_data: dict\n    ) -> ChannelContentDetails:\n        content_details: dict = dict(\n            **self.parse_base_content_details(content_details_data).model_dump()\n        )\n        content_details['related_playlists'] = content_details_data['relatedPlaylists']\n        return ChannelContentDetails(**content_details)\n\n    def parse_statistics(self, statistics_data: dict) -> ChannelStatistics:",
  "35": "\"\"\"The Apple Framework builds require their own customization.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport struct\nimport subprocess\nfrom abc import ABCMeta, abstractmethod\nfrom pathlib import Path\nfrom textwrap import dedent\n\nfrom virtualenv.create.via_global_ref.builtin.ref import (\n    ExePathRefToDest,\n    PathRefToDest,\n    RefMust,\n)\n\nfrom .common import CPython, CPythonPosix, is_mac_os_framework\nfrom .cpython3 import CPython3\n\n\nclass CPythonmacOsFramework(CPython, metaclass=ABCMeta):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return is_mac_os_framework(interpreter) and super().can_describe(interpreter)\n\n    def create(self):\n        super().create()\n\n        # change the install_name of the copied python executables\n        target = self.desired_mach_o_image_path()\n        current = self.current_mach_o_image_path()\n        for src in self._sources:\n            if isinstance(src, ExePathRefToDest) and (src.must == RefMust.COPY or not self.symlinks):\n                exes = [self.bin_dir / src.base]\n                if not self.symlinks:\n                    exes.extend(self.bin_dir / a for a in src.aliases)\n                for exe in exes:\n                    fix_mach_o(str(exe), current, target, self.interpreter.max_size)\n",
  "36": "",
  "37": "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "38": "\"\"\"This module contains routes for the app.\"\"\"\nfrom flask import Blueprint, render_template, jsonify, url_for, request\nfrom flask_login import current_user, login_required\nfrom ..post.models.post_model import Post\nfrom datetime import datetime\nfrom .controller.home import handle_befriend\n\nfrom ..utils.http_status_codes import HTTP_200_OK\nfrom .controller.home import handle_load_posts\n\nhome = Blueprint(\"home\", __name__)\n\n\n@home.route(\"/\")\n@home.route(\"/home\")\n@home.route(\"/index\")\n@login_required\ndef home_page():\n    \"\"\"Render the home page.\"\"\"\n    return handle_load_posts()\n\n@home.route(\"/befriend\")\ndef befriend():\n    \"\"\"Render the home page.\"\"\"\n    return handle_befriend(request.args)\n\n@home.route(\"/unfriend\")\ndef unfriend():\n    \"\"\"Render the home page.\"\"\"\n    return jsonify({'success': 'unfriend'}), HTTP_200_OK",
  "39": "# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom oauthlib.common import extract_params\nfrom oauthlib.oauth1 import Client, SIGNATURE_HMAC, SIGNATURE_TYPE_AUTH_HEADER\nfrom oauthlib.oauth1 import SIGNATURE_TYPE_BODY\nfrom requests.compat import is_py3\nfrom requests.utils import to_native_string\nfrom requests.auth import AuthBase\n\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\n\nif is_py3:\n    unicode = str\n\nlog = logging.getLogger(__name__)\n\n# OBS!: Correct signing of requests are conditional on invoking OAuth1\n# as the last step of preparing a request, or at least having the\n# content-type set properly.\nclass OAuth1(AuthBase):\n    \"\"\"Signs the request using OAuth 1 (RFC5849)\"\"\"\n\n    client_class = Client\n\n    def __init__(\n        self,\n        client_key,\n        client_secret=None,\n        resource_owner_key=None,\n        resource_owner_secret=None,\n        callback_uri=None,\n        signature_method=SIGNATURE_HMAC,\n        signature_type=SIGNATURE_TYPE_AUTH_HEADER,\n        rsa_key=None,\n        verifier=None,\n        decoding=\"utf-8\",",
  "40": "from api import create_app\nfrom api.extensions.extensions import celery\n\napp = create_app()",
  "41": "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "42": "from flask import Blueprint\n\n\nhome = Blueprint(\"home\", __name__)\n\n\n@home.route(\"/\")\n@home.route(\"/home\")\n@home.route(\"/index\")\ndef home_page():\n    \"\"\"Render the home page.\"\"\"\n    return 'Home page'",
  "43": "from typing import Any\nfrom ..resource import YouTubeResource\nfrom ..schemas import (\n    YouTubeRequest, YouTubeResponse, CommentThreadFilter, CommentThreadOptionalParameters,\n    CommentThreadPart\n)\nfrom ...models import CommentThread, Comment\nfrom datetime import datetime\n\n\nclass YouTubeCommentThread(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n        \n    def generate_optional_parameters(self, optional_params: CommentThreadOptionalParameters) -> dict:\n        optional: dict = dict()\n        for key, value in optional_params.model_dump().items():\n            if value:\n                optional[key] = value\n        return optional\n    \n    def generate_filter(self, f: CommentThreadFilter) -> dict:\n        comment_filter: dict = dict()\n        for key, value in f.model_dump().items():\n            if value:\n                comment_filter[key] = value\n                break\n        return comment_filter\n    \n    def create_request_dict(self, search_schema: YouTubeRequest) -> dict[str, int|str|datetime]:\n        request_dict: dict[str, int|str|datetime] = dict()\n        request_dict['part'] = self.generate_part(search_schema.part)\n        request_dict.update(self.generate_optional_parameters(search_schema.optional_parameters))\n        request_dict.update(self.generate_filter(search_schema.filter))\n        return request_dict\n        \n    def find_video_comments(self, request: YouTubeRequest) -> YouTubeResponse:\n        \"\"\"Get a particular video's comments.\"\"\"\n        comment_thread_req = self.youtube_client.commentThreads().list(\n            **self.create_request_dict(request)",
  "44": "from ..resource import YouTubeResource\nfrom typing import Any\nfrom ...models import ChannelSection\nfrom ..schemas import (\n    YouTubeListResponse, YouTubeRequest, YouTubeResponse, ChannelSectionFilter,\n    ChannelSectionPart, ChannelSectionOptionalParameters, InsertChannelSection\n)\n\n\nclass YouTubeChannelSection(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n        \n    def list_my_channel_sections(self) -> YouTubeListResponse:\n        part: ChannelSectionPart = ChannelSectionPart()\n        filter: ChannelSectionFilter = ChannelSectionFilter(\n            mine=True\n        )\n        optional: ChannelSectionOptionalParameters = ChannelSectionOptionalParameters()\n        request: YouTubeRequest = YouTubeRequest(\n            part=part,\n            filter=filter,\n            optional_parameters=optional\n        )\n        channel_section_request = self.youtube_client.channelSections().list(\n            **self.create_request_dict(request) \n        )\n        channel_section_response = channel_section_request.execute()\n        return channel_section_response\n    \n    def list_channel_sections(self, channel_id: str) -> YouTubeListResponse:\n        part: ChannelSectionPart = ChannelSectionPart()\n        filter: ChannelSectionFilter = ChannelSectionFilter(\n            channelId=channel_id\n        )\n        optional: ChannelSectionOptionalParameters = ChannelSectionOptionalParameters()\n        request: YouTubeRequest = YouTubeRequest(\n            part=part,\n            filter=filter,\n            optional_parameters=optional",
  "45": "",
  "46": "import os\nfrom dotenv import load_dotenv\nfrom rich.prompt import Prompt\nfrom src.utils.display import (\n    display_intro,\n    select_number_of_posts,\n    select_topic,\n    select_search_queries,\n)\nfrom src.utils.agent import Agent\nfrom src.utils.document_loader import RedditSubLoader, TwitterTweetLoader\n\nload_dotenv()\n\n\ndef main():\n    display_intro()\n    topic = select_topic()\n    platform, keywords, accounts = select_search_queries(topic)\n    number_of_posts = select_number_of_posts()\n\n    if platform == \"reddit\":\n        document_loader = RedditSubLoader(\n            number_submissions=number_of_posts,\n            keywords=keywords,\n            subreddits=accounts,\n        )\n    elif platform == \"twitter\":\n        document_loader = TwitterTweetLoader.from_bearer_token(\n            oauth2_bearer_token=os.environ.get(\"TWITTER_BEARER_TOKEN\"),\n            number_tweets=number_of_posts,\n            twitter_users=accounts,\n            keywords=keywords,\n        )\n    else:\n        raise ValueError(f\"Platform {platform} not supported\")\n\n    agent = Agent(loader=document_loader)\n\n    agent.load_documents()",
  "47": "# Define here the models for your scraped items\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass SlidesgoItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass\n",
  "48": "from pydantic import BaseSettings\n\n\nclass Settings(BaseSettings):\n    mongodb_uri: str\n    mongodb_database: str\n\n\nsettings = Settings()\n",
  "49": "import logging\nimport click\nfrom rich.logging import RichHandler\n\n\nLOGGER_NAME = \"reddit\"\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\",\n    handlers=[RichHandler(rich_tracebacks=True, tracebacks_suppress=[click])],\n)\nlogger = logging.getLogger(LOGGER_NAME)\n\n\nlogging.getLogger(\"clickhouse_connect\").setLevel(logging.ERROR)\nlogging.getLogger(\"clickhouse_connect\").setLevel(logging.ERROR)\nlogging.getLogger(\"numexpr\").setLevel(logging.ERROR)\n",
  "50": "\n",
  "51": "from .google_drive import GoogleDrive\n",
  "52": "",
  "53": "from __future__ import annotations\n\nimport abc\nimport fnmatch\nfrom itertools import chain\nfrom operator import methodcaller as method\nfrom pathlib import Path\nfrom textwrap import dedent\n\nfrom virtualenv.create.describe import Python3Supports\nfrom virtualenv.create.via_global_ref.builtin.ref import PathRefToDest\nfrom virtualenv.create.via_global_ref.store import is_store_python\n\nfrom .common import CPython, CPythonPosix, CPythonWindows, is_mac_os_framework\n\n\nclass CPython3(CPython, Python3Supports, metaclass=abc.ABCMeta):\n    \"\"\"CPython 3 or later.\"\"\"\n\n\nclass CPython3Posix(CPythonPosix, CPython3):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return is_mac_os_framework(interpreter) is False and super().can_describe(interpreter)\n\n    def env_patch_text(self):\n        text = super().env_patch_text()\n        if self.pyvenv_launch_patch_active(self.interpreter):\n            text += dedent(\n                \"\"\"\n                # for https://github.com/python/cpython/pull/9516, see https://github.com/pypa/virtualenv/issues/1704\n                import os\n                if \"__PYVENV_LAUNCHER__\" in os.environ:\n                    del os.environ[\"__PYVENV_LAUNCHER__\"]\n                \"\"\",\n            )\n        return text\n\n    @classmethod\n    def pyvenv_launch_patch_active(cls, interpreter):",
  "54": "#!/bin/python3\n\n# $Id: rst2latex.py 9115 2022-07-28 17:06:24Z milde $\n# Author: David Goodger <goodger@python.org>\n# Copyright: This module has been placed in the public domain.\n\n\"\"\"\nA minimal front end to the Docutils Publisher, producing LaTeX.\n\"\"\"\n\ntry:\n    import locale\n    locale.setlocale(locale.LC_ALL, '')\nexcept Exception:\n    pass\n\nfrom docutils.core import publish_cmdline\n\ndescription = ('Generates LaTeX documents from standalone reStructuredText '\n               'sources. '\n               'Reads from <source> (default is stdin) and writes to '\n               '<destination> (default is stdout).  See '\n               '<https://docutils.sourceforge.io/docs/user/latex.html> for '\n               'the full reference.')\n\npublish_cmdline(writer_name='latex', description=description)\n",
  "55": "from typing import Any, Optional\n\nfrom oryks_google_oauth import GoogleDriveScopes, GoogleOAuth\nfrom pydantic import BaseModel\n\n\nclass GoogleDrive(BaseModel):\n    \"\"\"Provides methods for interacting with the Drive API.\n\n    This class acts as an interface to the Drive API, providing methods for interacting with\n    the Drive API.\n\n    Attributes\n    ----------\n    client_secret_file: str\n        The path to the json file containing your authentication information.\n    \"\"\"\n\n    client_secret_file: Optional[str] = None\n    authenticated: Optional[bool] = False\n    drive_client: Optional[Any] = None\n\n    def authenticate(self, client_secret_file: Optional[str] = None) -> None:\n        \"\"\"Authenticate the requests made to drive.\n\n        Used to generate the credentials that are used when authenticating requests to drive.\n\n        Parameters\n        ----------\n        client_secret_file: str\n            The path to clients secret json file from Google\n\n        Raises\n        ------\n        ValueError:\n            When the client secrets file is not provided\n        FileNotFoundError:\n            When the secrets file path is not found\n        \"\"\"\n        if client_secret_file:",
  "56": "from dotenv import load_dotenv\nload_dotenv()\nfrom assistant.agents import default_agent\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set('agent', default_agent)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    agent = cl.user_session.get('agent')\n    msg = cl.Message(content='')\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({'input': message.content})['output']\n    await msg.update()\n",
  "57": "from ...post.models.post_model import Post\nfrom ...post.models.like_model import Like\nfrom ...post.models.comment_model import Comment\nfrom flask import url_for, render_template, jsonify\nfrom datetime import datetime\nfrom ...utils.http_status_codes import HTTP_200_OK, HTTP_201_CREATED\nimport random\nfrom flask_login import current_user\n# from ..models.friend_model import Friend\nfrom ...extensions.extensions import db\nfrom ...post.models.bookmark_model import Bookmark\n\n\ndef handle_load_posts() -> tuple[str, int]:\n    \"\"\"Load the initial posts.\"\"\"\n    user = {\n        'user_name': current_user.username,\n        'image': url_for('static', filename=f'img/{current_user.image_file}'),\n        'user_id': current_user.id,\n        'email': current_user.email,\n        'handle': f'@{\"\".join(current_user.username.split())}'\n    }\n    posts_raw = Post.query.limit(5)\n    posts = [\n            {\n                'id': post.id,\n                'user_id': post.author_id,\n                'author_image': url_for('static', filename=f'img/{post.author.image_file}'),\n                'author_name': post.author.username,\n                'location': post.location,\n                'publish_time': int((post.date_published - datetime.now()).total_seconds() / 60),\n                'text': post.text,\n                'photo': url_for('static', filename=f'img/{post.image}'),\n                'likes_count': Like.query.filter_by(post_id=post.id).count(),\n                'influencer': random.choice(Like.query.all()).user.username,\n                'liked_by': [\n                    url_for('static', filename=f'img/{like.user.image_file}') for like in Like.query.filter_by(post_id=post.id).limit(3)\n                ],\n                'comments_count': Comment.query.filter_by(post_id=post.id).count(),\n                'comment': {",
  "58": "",
  "59": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "60": "from .comment_thread import YouTubeCommentThread",
  "61": "\n",
  "62": "from ..resource import YouTubeResource\nfrom ...models import Video, Localized, Statistics, Status, VideoCategory\nfrom typing import Any, Callable, Optional\nfrom ..schemas.video import VideoFilter, VideoOptionalParameters, VideoPart\nfrom ..schemas.resource import Filter, RequestSchema, YouTubeResponse\nfrom ..schemas.rating import YouTubeRatingResponse\nfrom datetime import datetime\nfrom googleapiclient.http import MediaFileUpload\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n        \n    def get_video_ratings(self, video_ids: list[str]) -> YouTubeRatingResponse:\n        filters: dict = self.generate_filter(self.generate_video_ids, VideoFilter(id=video_ids))\n        find_video_rating_request: dict = self.youtube_client.videos().getRating(\n            **filters\n        )\n        find_video_rating_result: dict[str, int|str] = find_video_rating_request.execute()\n        return self.parse_user_video_rating(find_video_rating_result)\n    \n    def generate_video_ids(self, video_filter: VideoFilter) -> dict[str, str]:\n        video_ids: str = ','.join(video_filter.id)\n        return dict(id=video_ids)\n\n    def find_video_by_id(self, video_id: str) -> Video:\n        return self.find_videos_by_ids(video_id)[0]\n\n    def find_videos_by_ids(self, video_ids: list[str]) -> list[Video]:\n        filters: dict = self.generate_filter(self.generate_video_ids, VideoFilter(id=[video_ids]))\n        part: VideoPart = VideoPart()\n        optional_params: VideoOptionalParameters = VideoOptionalParameters()\n        request_schema: RequestSchema = RequestSchema(part=part, filter=filters, optional_parameters=optional_params)\n        request_dict = self.create_request_dict(request_schema)\n        request_dict.update(filters)\n        find_video_request: dict = self.youtube_client.videos().list(\n            **request_dict\n        )\n        find_video_result: dict[str, int|str] = find_video_request.execute()",
  "63": "",
  "64": "from .set_config import set_configuration",
  "65": "\n\n",
  "66": "",
  "67": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "68": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "69": "\n\n\n\n\n\n\n\n\n",
  "70": "import torch\nimport clip\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\n\nimage = preprocess(Image.open(\"cat.jpeg\")).unsqueeze(0).to(device)\nlabels: list[str] = [\"a diagram\", \"a dog\", \"a cat\"]\ntext = clip.tokenize(labels).to(device)\n\nwith torch.no_grad():\n    image_features = model.encode_image(image)\n    text_features = model.encode_text(text)\n    \n    logits_per_image, logits_per_text = model(image, text)\n    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n\nprint(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\nprint(labels[probs.argmax(-1)[0]])\n",
  "71": "from argparse import Namespace\n\nfrom .config import Config\nfrom .docstring_generator import generate_project_docstrings\nfrom .extensions import function_code_queue, source_code_queue\nfrom .ui import create_application_config, parse_arguments\n\n\ndef main():\n    args: Namespace = parse_arguments()\n    config: Config = create_application_config(args)\n    generate_project_docstrings(\n        config=config,\n        source_code_queue=source_code_queue,\n        function_code_queue=function_code_queue,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "72": "from pymongo import MongoClient\n\ndef test_mongo_connection():\n    try:\n        # Create a MongoDB client\n        client = MongoClient(\"mongodb://root:yourpassword@localhost:27017/\")\n        \n        # Get the database instance\n        db = client.yourdbname\n\n        # Create a new collection or get the existing collection\n        collection = db.test_collection\n\n        # Insert a new document\n        result = collection.insert_one({\"message\": \"Hello, MongoDB!\"})\n        \n        # Retrieve the inserted document\n        retrieved_document = collection.find_one({\"_id\": result.inserted_id})\n        \n        print(\"Document inserted successfully:\")\n        print(retrieved_document)\n        \n        # Close the connection\n        client.close()\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\nif __name__ == \"__main__\":\n    test_mongo_connection()\n\n",
  "73": "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "74": "from typing import List\nimport os\nfrom functools import lru_cache\nimport tweepy\nfrom src import logger\nfrom src.utils.config import BLACKLIST, SEARCH_FILTERS\n\nfrom praw import Reddit\nfrom praw.models import Subreddit\n\n\n@lru_cache(maxsize=None)\ndef get_api():\n    auth = tweepy.OAuth2BearerHandler(os.environ.get(\"TWITTER_BEARER_TOKEN\"))\n    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n    return api\n\n\ndef search_users(q, count):\n    api = get_api()\n    users = api.search_users(q=q, count=count)\n    extracted_users = []\n\n    for user in users:\n        screen_name = user[\"screen_name\"]\n        followers_count = user[\"followers_count\"]\n        statuses_count = user[\"statuses_count\"]\n        description = user[\"description\"]\n        profile_url = f\"https://twitter/{screen_name}\"\n        lang = user[\"lang\"]\n\n        extracted_user = dict(\n            screen_name=screen_name,\n            profile_url=profile_url,\n            description=description,\n            followers_count=followers_count,\n            statuses_count=statuses_count,\n            lang=lang,\n        )\n        extracted_users.append(extracted_user)",
  "75": "\"\"\"Toctree adapter for sphinx.environment.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, TypeVar\n\nfrom docutils import nodes\nfrom docutils.nodes import Element, Node\n\nfrom sphinx import addnodes\nfrom sphinx.locale import __\nfrom sphinx.util import logging, url_re\nfrom sphinx.util.matching import Matcher\nfrom sphinx.util.nodes import _only_node_keep_children, clean_astext\n\nif TYPE_CHECKING:\n    from collections.abc import Iterable, Set\n\n    from sphinx.builders import Builder\n    from sphinx.environment import BuildEnvironment\n    from sphinx.util.tags import Tags\n\n\nlogger = logging.getLogger(__name__)\n\n\ndef note_toctree(env: BuildEnvironment, docname: str, toctreenode: addnodes.toctree) -> None:\n    \"\"\"Note a TOC tree directive in a document and gather information about\n    file relations from it.\n    \"\"\"\n    if toctreenode['glob']:\n        env.glob_toctrees.add(docname)\n    if toctreenode.get('numbered'):\n        env.numbered_toctrees.add(docname)\n    include_files = toctreenode['includefiles']\n    for include_file in include_files:\n        # note that if the included file is rebuilt, this one must be\n        # too (since the TOC of the included file could have changed)\n        env.files_to_rebuild.setdefault(include_file, set()).add(docname)\n    env.toctree_includes.setdefault(docname, []).extend(include_files)",
  "76": "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy import Request\n# from slidesmodel.items import SlidesModelItem\nfrom scrapy.loader import ItemLoader\nfrom scrapy.utils.project import get_project_settings\nimport json\n\n\nclass SlidesGospider(Spider):\n    name: str = \"slides\"\n    \n    def __init__(self, name: str | None = None, **kwargs: Any):\n        super().__init__(name, **kwargs)\n        # self.start_urls: list[str] = self.load_start_urls()\n        self.start_urls: list[str] = [\n            \"https://slidesgo.com/food#rs=home\"\n        ]\n    \n    \n    def parse(self, response: Response, **kwargs: Any) -> Any:\n        self.logger.info(\"This is my first spider.\")\n        slide_links = response.css('div.theme_post a::attr(href)')\n        for slide_link in slide_links:\n            # title = problem_link.css('a::text')[0].get()\n            link = slide_link.get()\n            yield{\n                \"link\": link,\n            }\n            # yield Request(link, callback=self.parse_problem)\n        # for slide in slides:\n        #     loader: ItemLoader = ItemLoader(item=SlidesModelItem(), selector=slide)\n        #     loader.add_css(\"title\", \".item a::text\")\n        #     loader.add_css(\"category\", \".category::text\")\n        #     slide_item = loader.load_item()\n        #     link = slide.css(\".item a::attr(href)\").get()\n        #     self.logger.info(\"Parsing the slide\")\n        #     yield Request(link, callback=self.parse_slide, meta={\"slide_item\": slide_item})\n        ",
  "77": "",
  "78": "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "79": "from dotenv import load_dotenv\nload_dotenv()\nfrom assistant.agents import default_agent\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set('agent', default_agent)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    agent = cl.user_session.get('agent')\n    msg = cl.Message(content='')\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({'input': message.content})['output']\n    await msg.update()\n",
  "80": "from .bookmark import Bookmark\nfrom .comment import Comment\nfrom .like import Like\nfrom .post import Post\nfrom .user import User\nfrom .view import View\n",
  "81": "from .search import SearchSchema\n",
  "82": "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n\n# loads BAAI/bge-small-en\n# embed_model = HuggingFaceEmbedding()\n\n# loads BAAI/bge-small-en-v1.5\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\nembeddings = embed_model.get_text_embedding(\"Hello World!\")\nprint(len(embeddings))\nprint(embeddings[:5])",
  "83": "",
  "84": "from pydantic import BaseModel\nfrom datetime import datetime\nfrom typing import Optional\n\n\nclass AuthorBase(BaseModel):\n    author_profile_image_url: str\n    author_channel_url: str\n    author_channel_id: str\n    author_display_name: str\n    \nclass AuthorCreate(AuthorBase):\n    pass\n\nclass Author(AuthorBase):\n    author_id: int\n    \nclass CommentBase(BaseModel):\n    comment_id: str\n    video_id: str\n    parent_id: Optional[str]\n    comment_text: str\n    like_count: int\n    published_at: datetime\n    updated_at: datetime\n    \nclass CommentCreate(CommentBase):\n    author: AuthorCreate\n    \nclass Comment(CommentBase):\n    author_id: int\n\nclass CommentsCreate(BaseModel):\n    comments: list[CommentCreate]\n\nclass Comments(BaseModel):\n    comments: list[Comment]\n    \nclass GetComment(BaseModel):\n    comment_id: str",
  "85": "from collections import defaultdict\nfrom typing import Any\n\nfrom googleapiclient.http import MediaFileUpload\n\nfrom ...models import (\n    BaseContentDetails,\n    BaseSnippet,\n    Language,\n    LanguageSnippet,\n    Region,\n    RegionSnippet,\n    Video,\n    VideoAbuseReportReason,\n    VideoAbuseReportReasonSnippet,\n    VideoCategory,\n    VideoCategorySnippet,\n)\nfrom ...schemas import (\n    UploadVideo,\n    VideoFilter,\n    VideoOptionalParameters,\n    VideoPart,\n    VideoReportReasonSchema,\n    YouTubeListResponse,\n    YouTubeRatingResponse,\n    YouTubeRequest,\n)\nfrom ..resource import YouTubeResource\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n\n    def parse_snippet(self, snippet_data: dict[str, Any]) -> dict[str, Any]:\n        base_snippet: BaseSnippet = self.parse_base_snippet(snippet_data)\n        parsed_snippet: dict[str, Any] = base_snippet.model_dump()\n        parsed_snippet['channel_id'] = snippet_data['channelId']\n        parsed_snippet['channel_title'] = snippet_data['channelTitle']",
  "86": "",
  "87": "from langchain_community.document_loaders.generic import GenericLoader\nfrom langchain_community.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain_community.document_loaders.blob_loaders.youtube_audio import (\n    YoutubeAudioLoader,\n)\nfrom langchain_core.documents import Document\nfrom os import path\n\n# Two Karpathy lecture videos\nurls = [\"https://www.youtube.com/watch?v=altvPR7x9IA\"]\n\n# Directory to save audio files\ndata_dir = \"data\"\nvideo_data_dir = \"video\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"sample\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\n\nloader = GenericLoader(\n    YoutubeAudioLoader(urls, save_video_dir), OpenAIWhisperParser(api_key=api_key)\n)\ndocs = loader.load()\n\nfull_transcript = \"\"\nfor doc in docs:\n    full_transcript += doc.page_content\n\nwith open(save_transcript_dir, \"w\", encoding=\"utf-8\") as f:\n    f.write(full_transcript)\n\nprint(full_transcript)\n\n\ndef transcribe_video(video_id: str, save_video_dir: str, api_key: str) -> str:\n    url: str = f\"https://www.youtube.com/watch?v={video_id}\"\n    loader: GenericLoader = GenericLoader(\n        YoutubeAudioLoader([url], save_video_dir), OpenAIWhisperParser(api_key=api_key)",
  "88": "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\n\nfrom calendar_assistant.usecases.agent import agent_executor\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent_executor.invoke({\"input\": message.content})['output']\n    await msg.update()",
  "89": "from flask import Blueprint, render_template\nfrom http import HTTPStatus\n\nhome = Blueprint(\"home\", __name__)\n\n\n@home.route(\"/\")\n@home.route(\"/home\")\n@home.route(\"/index\")\ndef home_page():\n    \"\"\"Render the home page.\"\"\"\n    return render_template(\"home/index.html\"), HTTPStatus.OK",
  "90": "from google_drive import GoogleDrive\n\n\nclient_secrets_file = 'drive.json'\ndrive = GoogleDrive(client_secret_file=client_secrets_file)\ndrive.authenticate()\n",
  "91": "from datetime import datetime\n\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom ..database import Base\n\n\nclass Comment(Base):\n    __tablename__ = \"comments\"\n\n    id: Mapped[str] = mapped_column(primary_key=True)\n    author_id: Mapped[str] = mapped_column(ForeignKey(\"users.id\"))\n    post_id: Mapped[str] = mapped_column(ForeignKey(\"posts.id\"))\n    comment_text: Mapped[str]\n    comment_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n\n    author = relationship(\"User\", back_populates=\"comments\")\n    post = relationship(\"Post\", back_populates=\"comments\")\n",
  "92": "\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "93": "import atexit\nimport os\nimport sys\nimport json\nfrom rich.console import Console\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nimport chromadb\nfrom chromadb.config import Settings\nimport tiktoken\nfrom src import logger\nfrom src.utils.chains import (\n    get_retrieval_qa_chain,\n    summarize_tweets,\n)\nfrom src.utils.data_processing import (\n    get_texts_from_documents,\n    get_metadatas_from_documents,\n)\nfrom src.utils.display import display_bot_answer, display_summary_and_questions\nfrom src.utils.document_loader import TwitterTweetLoader\nfrom src.utils.prompts import summarization_question_template, summarization_template\n\n\nclass TwitterAgent(object):\n    def __init__(\n        self,\n        twitter_users,\n        keywords,\n        number_tweets,\n        persist_db=True,\n    ):\n        self.twitter_users = twitter_users\n        self.keywords = keywords\n        self.number_tweets = number_tweets\n        self.loaded_documents = []\n        self.embeddings = OpenAIEmbeddings()\n        self.persist_db = persist_db\n        self.chain = None\n        self.client = None",
  "94": "def add(a, b):\n        \"\"\"\n        Add two numbers together.\n\n        Parameters\n        ----------\n        a : int or float\n            First number to be added.\n        b : int or float\n            Second number to be added.\n\n        Returns\n        -------\n        int or float\n            Sum of a and b.\n\n        Raises\n        ------\n        TypeError\n            If a or b is not an int or float.\n        \"\"\"\n        try:\n            return operator.add(a, b)\n        except TypeError:\n            raise TypeError(\"a and b must be either int or float\")\n\n    # Example 1: Adding two integers\n    result = add(5, 10)\n    print(result)  # Output: 15\n\n    # Example 2: Adding two floats\n    result = add(3.5, 2.5)\n    print(result)  # Output: 6.0\n\n    # Example 3: Adding an integer and a string\n    result = add(5, \"10\")\n    # Output: TypeError: a and b must be either int or float\n    \n    \n    ",
  "95": "from ..libraries.youtube.models import Channel\nfrom datetime import datetime\nfrom uuid import uuid4\n\n\ndef get_channels() -> list[Channel]:\n    \"\"\"Get a list fo channels.\"\"\"\n    channels: list[Channel] = [\n        Channel(\n            id=1,\n            title='Tech Investment',\n            description='This channel helps the user to invest in disruptive technologies.',\n            subscribers=200,\n            date_created=datetime.now()\n        )\n    ]\n    return channels",
  "96": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, \"README.md\"), encoding=\"utf-8\") as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open(\"pyproject.toml\", \"r\") as f:\n    VERSION = tomli.load(f)[\"tool\"][\"commitizen\"][\"version\"]\n\nDESCRIPTION = \"A python library for generating docstrings for functions and classes.\"\n\nkey_words = [\"dosctrings\", \"documentation\"]\n\ninstall_requires = [\n    \"langchain\",\n    \"langchain-openai\",\n    \"black\",\n    \"pydantic\",\n    \"pydantic-settings\",\n]\n\nsetup(\n    name=\"docstring_generator\",\n    packages=find_packages(\n        include=[\n            \"docstring_generator\",\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type=\"text/markdown\",\n    long_description=LONG_DESCRIPTION,",
  "97": "from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass SearchSchema(BaseModel):\n    id: Optional[str] = None\n    type: Optional[str] = None\n    published_at: Optional[datetime] = None\n    channel_id: Optional[str] = None\n    title: Optional[str] = None\n    description: Optional[str] = None\n    channel_title: Optional[str] = None\n    live_broadcast_content: Optional[str] = None\n    publish_time: Optional[str] = None\n",
  "98": "from .set_config import set_configuration",
  "99": "from pydantic_settings import BaseSettings\n\n\nclass BaseConfig(BaseSettings):\n    max_results: int = 10",
  "100": "from google_calendar import GoogleCalendar\nimport os\n\nclient_secret: str = os.environ['CLIENT_SECRET_FILE']\ngoogle_calendar: GoogleCalendar = GoogleCalendar(secret_file=client_secret)\ngoogle_calendar.authenticate()",
  "101": "# $Id: ko.py 9030 2022-03-05 23:28:32Z milde $\n# Author: Thomas SJ Kang <thomas.kangsj@ujuc.kr>\n# Copyright: This module has been placed in the public domain.\n\n# New language mappings are welcome.  Before doing a new translation, please\n# read <https://docutils.sourceforge.io/docs/howto/i18n.html>.\n# Two files must be translated for each language: one in docutils/languages,\n# the other in docutils/parsers/rst/languages.\n\n\"\"\"\nKorean-language mappings for language-dependent features of\nreStructuredText.\n\"\"\"\n\n__docformat__ = 'reStructuredText'\n\n\ndirectives = {\n      # language-dependent: fixed\n      '': 'attention',\n      '': 'caution',\n      '': 'code',\n      '-': 'code',\n      '': 'code',\n      '': 'danger',\n      '': 'error',\n      '': 'hint',\n      '': 'important',\n      '': 'note',\n      '': 'tip',\n      '': 'warning',\n      '': 'admonition',\n      '': 'sidebar',\n      '': 'topic',\n      '-': 'line-block',\n      '-': 'parsed-literal',\n      '': 'rubric',\n      '': 'epigraph',\n      '': 'highlights',\n      '': 'pull-quote',",
  "102": "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "103": "from .get_appointment import GetAppointment\n",
  "104": "from langchain.agents import AgentType, initialize_agent\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.tools import BaseTool, StructuredTool, Tool, tool\nfrom dotenv import load_dotenv\nfrom pydantic.v1 import BaseModel, Field\nfrom typing import Optional, Type\nfrom pydantic_settings import BaseSettings\nfrom langchain.callbacks.manager import (\n    AsyncCallbackManagerForToolRun,\n    CallbackManagerForToolRun,\n)\nfrom app.libraries.tools.youtube import (\n    YouTubeChannelSearchTool\n)\n\n\nload_dotenv()\n\nclass Config(BaseSettings):\n    open_ai_token: str\n\nconfig: Config = Config()\n\n\nllm = ChatOpenAI(temperature=0, openai_api_key=config.open_ai_token)\n\ntools = [YouTubeChannelSearchTool()]\nagent = initialize_agent(\n    tools, \n    llm, \n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, \n    verbose=True\n)\n\nres = agent.run('What is the id of youtube channel \"Ark Invest\"?')\nprint(res)",
  "105": "import whisper\nimport speech_recognition as sr\n\n\n# model = whisper.load_model(\"base\")\nfile_path: str = \"audio.wav\"\n# result = model.transcribe(file_path)\n# print(f' The text in video: \\n {result[\"text\"]}')\ndef audio_to_text(audio_path):\n    \"\"\"\n    Convert an audio file to text.\n\n    Parameters:\n    audio_path (str): The path to the audio file.\n\n    Returns:\n    test (str): The text recognized from the audio.\n\n    \"\"\"\n    recognizer = sr.Recognizer()\n    audio = sr.AudioFile(audio_path)\n\n    with audio as source:\n        # Record the audio data\n        audio_data = recognizer.record(source)\n\n        try:\n            # Recognize the speech\n            text = recognizer.recognize_whisper(audio_data)\n        except sr.UnknownValueError:\n            print(\"Speech recognition could not understand the audio.\")\n        except sr.RequestError as e:\n            print(f\"Could not request results from service; {e}\")\n\n    return text\n\ntext = audio_to_text(file_path)\nprint(text)",
  "106": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "107": "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "108": "from dotenv import load_dotenv\nload_dotenv()\nfrom flask.cli import FlaskGroup\nfrom api import create_app\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\n\nif __name__ == \"__main__\":\n    cli()",
  "109": "import ast\nfrom ast import AST, FunctionDef, NodeTransformer\n\nfrom .config import Config\nfrom .helpers import generate_doc_string, make_docstring_node\nfrom .model_parsers import parse_function_docstr\n\n\nclass FunctionTransformer(NodeTransformer):\n    def __init__(self, config: Config, function_src: str) -> None:\n        super().__init__()\n        self._config: Config = config\n        self._function_src = function_src\n\n    def visit_FunctionDef(self, node: FunctionDef) -> None:\n        ast_tree: AST = ast.parse(self._function_src)\n        function_node: AST = ast_tree.body[0]\n        docstring: str = ast.get_docstring(node=node)\n        if function_node.name == node.name:\n            if not docstring:\n                src_code: str = ast.unparse(node)\n                func_docstr: str = generate_doc_string(\n                    src_code=src_code, config=self._config\n                )\n                doc_str: str = parse_function_docstr(func_docstr.strip())\n                if doc_str:\n                    dcstr_node: AST = make_docstring_node(doc_str)\n                    node.body.insert(0, dcstr_node)\n            elif self._config.overwrite_function_docstring:\n                src_code: str = ast.unparse(node)\n                func_docstr: str = generate_doc_string(\n                    src_code=src_code, config=self._config\n                )\n                doc_str: str = parse_function_docstr(func_docstr.strip())\n                if doc_str:\n                    dcstr_node: AST = make_docstring_node(doc_str)\n                    node.body[0] = dcstr_node\n        return node\n",
  "110": "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy import Request\n# from slidesmodel.items import SlidesModelItem\nfrom scrapy.loader import ItemLoader\nfrom scrapy.utils.project import get_project_settings\nimport json\n\n\nclass SlidesGospider(Spider):\n    name: str = \"slides\"\n    \n    def __init__(self, name: str | None = None, **kwargs: Any):\n        super().__init__(name, **kwargs)\n        # self.start_urls: list[str] = self.load_start_urls()\n        self.start_urls: list[str] = [\n            \"https://slidesgo.com/food#rs=home\"\n        ]\n    \n    \n    def parse(self, response: Response, **kwargs: Any) -> Any:\n        self.logger.info(\"This is my first spider.\")\n        slide_links = response.css('div.theme_post a::attr(href)')\n        for slide_link in slide_links:\n            # title = problem_link.css('a::text')[0].get()\n            link = slide_link.get()\n            yield{\n                \"link\": link,\n            }\n            # yield Request(link, callback=self.parse_problem)\n        # for slide in slides:\n        #     loader: ItemLoader = ItemLoader(item=SlidesModelItem(), selector=slide)\n        #     loader.add_css(\"title\", \".item a::text\")\n        #     loader.add_css(\"category\", \".category::text\")\n        #     slide_item = loader.load_item()\n        #     link = slide.css(\".item a::attr(href)\").get()\n        #     self.logger.info(\"Parsing the slide\")\n        #     yield Request(link, callback=self.parse_slide, meta={\"slide_item\": slide_item})\n        ",
  "111": "from .llms import chat_openai",
  "112": "",
  "113": "import torch\nfrom transformers import (\n    BitsAndBytesConfig, AutoProcessor, AutoModelForCausalLM,\n    TrainingArguments, Trainer\n)\nfrom peft import get_peft_model, LoraConfig\nfrom datasets import load_dataset, DatasetDict, Dataset\nfrom torch.utils.data import Dataset as DataSet, DataLoader\nfrom tqdm import tqdm\nfrom torch.optim import AdamW\nfrom transformers import get_scheduler\nimport os\nfrom random import randint\nfrom PIL import Image\nfrom PIL.PngImagePlugin import PngImageFile\n\nmodel_id = \"microsoft/Florence-2-base-ft\"\n# model_id = \"microsoft/Florence-2-large-ft\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id, \n    trust_remote_code=True, \n    ).to(device)\n\nprocessor = AutoProcessor.from_pretrained(\n    model_id, \n    trust_remote_code=True, \n    )",
  "114": "",
  "115": "",
  "116": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "117": "from dotenv import load_dotenv\nload_dotenv()\nimport os\n\nimport googlemaps\ngmaps = googlemaps.Client(key=os.environ['GOOGLE_MAPS_API_KEY'])\n\nresults = gmaps.places(query='agrovets in nairobi, kenya')\nfor result in results['results']:\n    bussiness: dict = dict()\n    bussiness['business_status'] = result['business_status']\n    bussiness['formatted_address'] = result['formatted_address']\n    bussiness['name'] = result['name']\n    bussiness['opening_hours'] = result.get('opening_hours', 'NaN')\n    print(bussiness)",
  "118": "\"\"\"\nWritten by Joshua Willman\nFeatured in \"Modern Pyqt - Create GUI Applications for Project Management, Computer Vision, and Data Analysis\"\n\"\"\"\n# Style sheet for the Audio Recorder GUI\n\nstyle_sheet = \"\"\"\n    QWidget {\n        background-color: #FFFFFF\n    }\n\n    QPushButton {\n        background-color: #AFAFB0;\n        border: 2px solid #949495;\n        border-radius: 4px;\n        padding: 5px\n    }\n\n    QPushButton:hover {\n        background-color: #C2C2C4;\n    }\n\n    QPushButton:pressed {\n        background-color: #909091;\n    }\n\n    /* Set up the appearance of the start button for normal, hovered\n    and pressed states. */\n    QPushButton#StartButton {\n        background-color: #FFFFFF; \n        image: url(:/resources/images/mic.png);\n        border: none\n    }\n\n    QPushButton#StartButton:hover {\n        image: url(:/resources/images/mic_hover.png);\n    }\n\n    QPushButton#StartButton:pressed {\n        image: url(:/resources/images/mic_pressed.png);",
  "119": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "120": "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\n\nfrom calendar_assistant.usecases.agent import agent_executor\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent_executor.invoke({\"input\": message.content})['output']\n    await msg.update()",
  "121": "#!/bin/python3\n\n# $Id: rst2odt.py 9115 2022-07-28 17:06:24Z milde $\n# Author: Dave Kuhlman <dkuhlman@rexx.com>\n# Copyright: This module has been placed in the public domain.\n\n\"\"\"\nA front end to the Docutils Publisher, producing OpenOffice documents.\n\"\"\"\n\ntry:\n    import locale\n    locale.setlocale(locale.LC_ALL, '')\nexcept Exception:\n    pass\n\nfrom docutils.core import publish_cmdline_to_binary, default_description\nfrom docutils.writers.odf_odt import Writer, Reader\n\n\ndescription = ('Generates OpenDocument/OpenOffice/ODF documents from '\n               'standalone reStructuredText sources.  ' + default_description)\n\n\nwriter = Writer()\nreader = Reader()\noutput = publish_cmdline_to_binary(reader=reader, writer=writer,\n                                   description=description)\n",
  "122": "from flask.cli import FlaskGroup\nfrom app import create_app\n\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\nif __name__ == \"__main__\":\n    cli()",
  "123": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "124": "from youtube import YouTube\nfrom itertools import chain\n\nyoutube = YouTube()\nclient_secrets_file = '/home/lyle/Downloads/python_learning_site.json'\nyoutube.authenticate_from_client_secrets_file(client_secrets_file)\n\n# channel = youtube.find_channel_by_id('UC8butISFwT-Wl7EV0hUK0BQ')\n# video = youtube.find_video_by_id('vEQ8CXFWLZU')\nquery = 'Python programming'\nvideo_iterator = youtube.get_iterator(query)\nv1 = next(video_iterator)\nv2 = next(video_iterator)\nv3 = next(video_iterator)\n\n# video_collection = video_iterator.get_videos()\n# POSTGRES_HOST='localhost' \n# POSTGRES_PORT=5432 \n# POSTGRES_USER='lyle' \n# POSTGRES_PASSWORD='lyle'\n# POSTGRES_DB='python-learning-app'\n# video_collection.save_to_database(POSTGRES_HOST, POSTGRES_PORT, \n#                         POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB)\n# search_client = youtube.get_search_client(query)\n# prev_token, next_token, v1 = search_client.search_videos()\n# prev_token, next_token, v2 = search_client.search_videos(next_page_token=next_token)\n# prev_token, next_token, v3 = search_client.search_videos(next_page_token=next_token)\nvideos = list(chain(v1,v2,v3))\n\nif __name__ == '__main__':\n    print(len(videos))\n    for video in videos:\n        print(video)\n    # video.to_json()\n    # video.to_csv()",
  "125": "from .create_channel_index import create_channel_index\nfrom .create_playlist_index import create_playlist_index\nfrom .create_video_index import create_video_index",
  "126": "import chainlit as cl\nfrom assistant.utils.assistant_utils import welcome_user\nfrom assistant.agent import get_agent_executor\n\n\n@cl.on_chat_start\nasync def start():\n    res = await cl.AskUserMessage(content=\"What is your name?\", timeout=30).send()\n    if res:\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        msg.content = welcome_user(user_name=res['content'])\n        await msg.update()\n        \n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    query: str = message.content\n    agent_executor = get_agent_executor(query)\n    msg.content = agent_executor.invoke({\"input\": query})['output']\n    await msg.update()",
  "127": "\n\n\n\n",
  "128": "import whisper\nimport speech_recognition as sr\n\n\n# model = whisper.load_model(\"base\")\nfile_path: str = \"audio.wav\"\n# result = model.transcribe(file_path)\n# print(f' The text in video: \\n {result[\"text\"]}')\ndef audio_to_text(audio_path):\n    \"\"\"\n    Convert an audio file to text.\n\n    Parameters:\n    audio_path (str): The path to the audio file.\n\n    Returns:\n    test (str): The text recognized from the audio.\n\n    \"\"\"\n    recognizer = sr.Recognizer()\n    audio = sr.AudioFile(audio_path)\n\n    with audio as source:\n        # Record the audio data\n        audio_data = recognizer.record(source)\n\n        try:\n            # Recognize the speech\n            text = recognizer.recognize_whisper(audio_data)\n        except sr.UnknownValueError:\n            print(\"Speech recognition could not understand the audio.\")\n        except sr.RequestError as e:\n            print(f\"Could not request results from service; {e}\")\n\n    return text\n\ntext = audio_to_text(file_path)\nprint(text)",
  "129": "\n\n\n\n\n\n\n\n\n",
  "130": "# Copyright 2016 Google Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Transport adapter for httplib2.\"\"\"\n\nfrom __future__ import absolute_import\n\nimport http.client\nimport logging\n\nfrom google.auth import exceptions\nfrom google.auth import transport\nimport httplib2\n\n\n_LOGGER = logging.getLogger(__name__)\n# Properties present in file-like streams / buffers.\n_STREAM_PROPERTIES = (\"read\", \"seek\", \"tell\")\n\n\nclass _Response(transport.Response):\n    \"\"\"httplib2 transport response adapter.\n\n    Args:\n        response (httplib2.Response): The raw httplib2 response.\n        data (bytes): The response body.\n    \"\"\"\n\n    def __init__(self, response, data):",
  "131": "from .video import YouTubeVideo",
  "132": "",
  "133": "from setuptools import find_packages, setup\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nVERSION = '0.6.0' \nDESCRIPTION = 'A python library that wraps around the YouTube V3 API. You can use it find, manage and analyze YouTube resources including Videos, Playlists, Channels and Comments.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos',\n    'youtube channels', 'youtube comment thread', 'upload youtube video',\n    'create youtube playlist'\n]\n\ninstall_requires = [\n    'google-api-python-client', \n    'google-auth-oauthlib', \n    'pandas', \n    'elasticsearch', \n    'sqlalchemy',\n    'sqlalchemy_utils',\n    'psycopg2-binary'\n]\n\nsetup(\n    name='youtube',\n    packages=find_packages(\n        include=[\n            'youtube', \n            'youtube.resources.channel',\n            'youtube.resources.video',\n            'youtube.resources.utils',",
  "134": "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "135": "# utils.py\n\nfrom playwright.sync_api import sync_playwright\nimport uuid\nfrom PIL import Image\nimport io\nfrom os import path\nimport json\n\n\ndef take_screenshot_from_url(url, session_data):\n    with sync_playwright() as playwright:\n        webkit = playwright.webkit\n        browser = webkit.launch()\n        browser_context = browser.new_context(device_scale_factor=2)\n        browser_context.add_cookies([session_data])\n        page = browser_context.new_page()\n        page.goto(url)\n        screenshot_bytes = page.locator(\".code\").screenshot()\n        browser.close()\n        return screenshot_bytes\n    \n    \ndef save_data(image_bytes: bytes, code: str) -> None:\n    SYSTEM_MESSAGE: str = \"\"\"You are a helpful assistant that knows how to extract python code from images.\"\"\"\n    USER_MESSAGE: str = \"\"\"Extract python code from the given image.\"\"\"\n    file_name: str = str(uuid.uuid4())\n    image: Image = Image.open(io.BytesIO(image_bytes))\n    file_path: str = \"data-v1\"\n    image_path: str = path.join(file_path, f\"{file_name}.png\")\n    image.save(image_path)\n    code_path: str = path.join(file_path, \"metadata.jsonl\")\n    metadata: dict = {\n        \"file_name\": f\"{file_name}.png\",\n        \"messages\": [\n            {\n                \"role\": \"SYSTEM\",\n                \"content\": SYSTEM_MESSAGE\n            },\n            {                \"role\": \"USER\",\n                \"content\": USER_MESSAGE\n            },\n            {\n                \"role\": \"ASSISTANT\",\n                \"content\": code\n            }\n        ]\n    }\n    print(metadata)\n    with open(code_path, \"a+\", encoding=\"utf-8\") as f:\n        f.write(json.dumps(metadata) + \"\\n\")",
  "136": "from sqlalchemy import create_engine\nfrom sqlalchemy.orm import MappedAsDataclass, sessionmaker, DeclarativeBase\nfrom contextlib import contextmanager\n\nclass Base(MappedAsDataclass, DeclarativeBase):\n    pass\n\nSQL_ALCHEMY_DATABASE_URI = 'sqlite:///./example.db'\nengine = create_engine(SQL_ALCHEMY_DATABASE_URI)\n\nSession = sessionmaker(bind=engine)\n\n@contextmanager\ndef get_db():\n    db = Session()\n    try:\n        yield db\n    finally:\n        db.close()\n        \ndef create_all():\n    Base.metadata.create_all(bind=engine)\n",
  "137": "",
  "138": "from langchain.chat_models import (\n    ChatOpenAI, ChatAnthropic, ChatGooglePalm\n)\nimport os\n\n\nchat_openai: ChatOpenAI = ChatOpenAI(\n    temperature=0, \n    openai_api_key=os.environ['OPENAI_API_KEY'],\n    verbose=True,\n    model='gpt-3.5-turbo'\n    )\nchat_googlepalm: ChatGooglePalm = ChatGooglePalm(\n    google_api_key=os.environ['GOOGLE_PALM_API_KEY'],\n    verbose=True,\n    temperature=0\n)",
  "139": "",
  "140": "from .view import auth, google_blueprint",
  "141": "# $Id: af.py 9116 2022-07-28 17:06:51Z milde $\n# Author: Jannie Hofmeyr <jhsh@sun.ac.za>\n# Copyright: This module has been placed in the public domain.\n\n# New language mappings are welcome.  Before doing a new translation, please\n# read <https://docutils.sourceforge.io/docs/howto/i18n.html>.\n# Two files must be translated for each language: one in docutils/languages,\n# the other in docutils/parsers/rst/languages.\n\n\"\"\"\nAfrikaans-language mappings for language-dependent features of\nreStructuredText.\n\"\"\"\n\n__docformat__ = 'reStructuredText'\n\n\ndirectives = {\n      'aandag': 'attention',\n      'versigtig': 'caution',\n      'code (translation required)': 'code',\n      'gevaar': 'danger',\n      'fout': 'error',\n      'wenk': 'hint',\n      'belangrik': 'important',\n      'nota': 'note',\n      'tip': 'tip',  # hint and tip both have the same translation: wenk\n      'waarskuwing': 'warning',\n      'vermaning': 'admonition',  # sic! Not used in this sense in rST.\n      'kantstreep': 'sidebar',\n      'onderwerp': 'topic',\n      'lynblok': 'line-block',\n      'math (translation required)': 'math',\n      'parsed-literal (translation required)': 'parsed-literal',\n      'rubriek': 'rubric',\n      'epigraaf': 'epigraph',\n      'hoogtepunte': 'highlights',\n      'pull-quote (translation required)': 'pull-quote',\n      'compound (translation required)': 'compound',\n      'container (translation required)': 'container',",
  "142": "",
  "143": "\"\"\"Assets adapter for sphinx.environment.\"\"\"\n\nfrom sphinx.environment import BuildEnvironment\n\n\nclass ImageAdapter:\n    def __init__(self, env: BuildEnvironment) -> None:\n        self.env = env\n\n    def get_original_image_uri(self, name: str) -> str:\n        \"\"\"Get the original image URI.\"\"\"\n        while name in self.env.original_image_uri:\n            name = self.env.original_image_uri[name]\n\n        return name\n",
  "144": "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langchain_experimental.tabular_synthetic_data.openai import (\n    OPENAI_TEMPLATE,\n    create_openai_data_generator,\n)\nfrom langchain_experimental.tabular_synthetic_data.prompts import (\n    SYNTHETIC_FEW_SHOT_PREFIX,\n    SYNTHETIC_FEW_SHOT_SUFFIX,\n)\nfrom langchain_openai import ChatOpenAI\n\n\nclass Apartment(BaseModel):\n    apartment_name: str = Field(description=\"The name of the apartment\")\n    description: str = Field(description=\"The detailed apartment description\")\n    location: str = Field(\n        description=\"The town in Kenya where the apartment is located\"\n    )\n    monthly_rent: int = Field(\n        description=\"The monthly rent for the apartment. This is between 5,000 and 50,000 kenyan shillings.\"\n    )\n\nraj: str = \"\"\"A three bedroomed apartment located in Juja town, 1.6 km off Thika super highway at Juja \nfarm. Apartment features include:\n    - Kitchen shelves and kitchen cabinets \n    - electric fence\n    - 24 hours security\n    - landscaped common areas\n    - cabro paved internal roads\n    - borehole water\n    - solar heater panels\n    - bio-digester for waste water treatment\n    - spacious lounge with separate dining\n    - high quality ceramic tiles finishing\n    - recreational & children play area\n    - designated and visitors car park\n    - parking space\n    - Pre-Paid Meter\n    - Wadrobes",
  "145": "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "146": "\"\"\"The main application package.\"\"\"\nimport sys\n\nfrom dotenv import load_dotenv\nfrom flask import Flask\n\nfrom .auth.models.user import User\nfrom .exceptions.exceptions import DatabaseNotConnectedException\nfrom .extensions.extensions import db, login_manager\nfrom .helpers.helpers import (\n    check_configuration,\n    register_blueprints,\n    register_extensions,\n    set_configuration,\n)\nfrom .utils.http_status_codes import HTTP_200_OK\n\nload_dotenv()\n\n\ndef create_app() -> Flask:\n    \"\"\"Create the Flask App instance.\"\"\"\n    app = Flask(__name__)\n\n    set_configuration(app)\n\n    # try:\n    #     check_configuration()\n    # except DatabaseNotConnectedException as e:\n    #     print(str(e))\n    #     sys.exit(1)\n\n    register_extensions(app)\n    register_blueprints(app=app)\n\n    @login_manager.user_loader\n    def load_user(user_id):\n        return User.query.get(int(user_id))\n\n    @app.route(\"/health\")",
  "147": "from .set_config import set_configuration",
  "148": "import torch\nimport os\nfrom torch import nn\nfrom torchvision import transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport random\n\n\nclass MaizeNet(nn.Module):\n  def __init__(self, K) -> None:\n      super(MaizeNet, self).__init__()\n\n      self.conv_layers = nn.Sequential(\n          # convolution 1\n          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.MaxPool2d(2),\n          # Convolution 2\n          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.MaxPool2d(2),\n          # Convolution 3\n          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),",
  "149": "import os\nfrom elasticsearch import Elasticsearch\nfrom datetime import datetime\nimport requests\nimport time\n\n\ndef create_es_client(es_host: str, es_port: int):\n    \"\"\"Create the elasticsearch client.\"\"\"\n    es_client = Elasticsearch(hosts=[f'http://{es_host}:{es_port}'])\n    return es_client\n\n\ndef index_resource(resource: dict[str, str|int|datetime], index: str, es_client: Elasticsearch, id: str):\n    response = es_client.index(index=index, body=resource, id=id)\n    print(response)\n    \ndef get_channel_playlists(channel_id: str) -> None:\n    resp = requests.post(url='http://web:8000/channel/playlists', params={'channel_id': channel_id})\n    print(resp.status_code)\n    print(resp.json())\n    \ndef get_playlist_videos(playlist_id: str) -> None:\n    resp = requests.post(url='http://web:8000/playlist/videos', params={'playlist_id': playlist_id})\n    print(resp.status_code)\n    print(resp.json())\n    \ndef get_video_comments(video_id: str) -> None:\n    resp = requests.post(url='http://web:8000/video/comments', params={'video_id': video_id})\n    print(resp.status_code)\n    print(resp.json())\n    return resp.json()\n\ndef get_video_comments_task_result(task_id: str) -> dict:\n    resp = requests.get(url='http://web:8000/video/task_status', params={'task_id': task_id})\n    count: int = 0\n    while resp.json()['task_status'] != 'SUCCESS' and count < 10:\n        time.sleep(1)\n        resp = requests.get(url='http://web:8000/video/task_status', params={'task_id': task_id})\n        count += 1",
  "150": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A python library for working with Google Drive.'\n\nkey_words = [\n    'drive', 'google-drive', 'google-drive-api', 'upload files to Google Drive',\n]\n\ninstall_requires = [\n    'oryks-google-oauth',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='oryks-google-drive',\n    packages=find_packages(\n        include=[\n            'google_drive',\n            'google_drive.exceptions',\n            'google_drive.models',\n            'google_drive.schemas',\n            'google_drive.resources'\n        ]\n    ),",
  "151": "from .create_data import get_channels",
  "152": "from .....libraries.youtube import YouTube",
  "153": "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n\n# loads BAAI/bge-small-en\n# embed_model = HuggingFaceEmbedding()\n\n# loads BAAI/bge-small-en-v1.5\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\nembeddings = embed_model.get_text_embedding(\"Hello World!\")\nprint(len(embeddings))\nprint(embeddings[:5])",
  "154": "from .comment_thread import YouTubeCommentThread",
  "155": "from dotenv import load_dotenv\nload_dotenv()\nimport os\n\nimport googlemaps\ngmaps = googlemaps.Client(key=os.environ['GOOGLE_MAPS_API_KEY'])\n\n# directions_result = gmaps.directions(\n#             start,\n#             end,\n#             waypoints=waypoints,\n#             mode=transit_type,\n#             units=\"metric\",\n#             optimize_waypoints=True,\n#             traffic_model=\"best_guess\",\n#             departure_time=start_time,\n# )\ndef convert_to_coords(input_address):\n    return gmaps.geocode(input_address)\n\ngmaps = googlemaps.Client(key=os.environ[\"GOOGLE_MAPS_API_KEY\"])\n\nexample_coords = convert_to_coords(\"Rachives, Nairobi Kenya\")\nprint(example_coords)",
  "156": "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")",
  "157": "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "158": "",
  "159": "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "160": "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy.linkextractors import LinkExtractor \n\n\nclass SlidesLinkExtractor(Spider):\n    name: str = \"links-extractor\"\n    \n    start_urls: list[str] = [\n        \"https://slidesgo.com/\"\n    ]\n    \n    def __init__(self, name=None, **kwargs): \n        super().__init__(name, **kwargs) \n  \n        self.link_extractor = LinkExtractor(unique=True) \n  \n    def parse(self, response: Response, **kwargs: Any) -> Any: \n        self.logger.info(\"Links spider\")\n        links = response.css('li.w-1\\/2 a::attr(href)') \n  \n        for link in links: \n            yield {\n                    \"url\": link.get(), \n                }",
  "161": "from setuptools import find_packages, setup\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nVERSION = '0.6.0' \nDESCRIPTION = 'A python library that wraps around the YouTube V3 API. You can use it find, manage and analyze YouTube resources including Videos, Playlists, Channels and Comments.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos',\n    'youtube channels', 'youtube comment thread', 'upload youtube video',\n    'create youtube playlist'\n]\n\ninstall_requires = [\n    'google-api-python-client', \n    'google-auth-oauthlib', \n    'pandas', \n    'elasticsearch', \n    'sqlalchemy',\n    'sqlalchemy_utils',\n    'psycopg2-binary'\n]\n\nsetup(\n    name='youtube',\n    packages=find_packages(\n        include=[\n            'youtube', \n            'youtube.resources.channel',\n            'youtube.resources.video',\n            'youtube.resources.utils',",
  "162": "from .register_blueprints import register_blueprints",
  "163": "from .view import home",
  "164": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "165": "# $Id: uk.py 9114 2022-07-28 17:06:10Z milde $\n# Author: Dmytro Kazanzhy <dkazanzhy@gmail.com>\n# Copyright: This module has been placed in the public domain.\n\n# New language mappings are welcome.  Before doing a new translation, please\n# read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be\n# translated for each language: one in docutils/languages, the other in\n# docutils/parsers/rst/languages.\n\n\"\"\"\nUkrainian-language mappings for language-dependent features of\nreStructuredText.\n\"\"\"\n\n__docformat__ = 'reStructuredText'\n\ndirectives = {\n    '-': 'line-block',\n    '': 'meta',\n    '': 'math',\n    '-': 'parsed-literal',\n    '-': 'pull-quote',\n    '': 'code',\n    ' ': 'compound',\n    '': 'container',\n    '': 'table',\n    '-csv': 'csv-table',\n    '-': 'list-table',\n    '': 'raw',\n    '': 'replace',\n    '--restructuredtext': 'restructuredtext-test-directive',\n    '-': 'target-notes',\n    '': 'unicode',\n    '': 'date',\n    '-': 'sidebar',\n    '': 'important',\n    '': 'include',\n    '': 'attention',\n    '': 'highlights',\n    '': 'admonition',",
  "166": "from pydantic import BaseModel\nfrom typing import Optional, Iterator\nfrom .models import (\n    Channel, Video, Playlist, VideoCategory, Comment, Activity, Caption, ChannelBanner, \n    ChannelSection, Language, Region, WaterMark, VideoAbuseReportReason, Subscription, \n    PlaylistItem\n)\nfrom .config import BaseConfig\nfrom .auth import OAuth\nfrom typing import Any\nfrom .resources.search import SearchYouTube\nfrom .resources.video import YouTubeVideo\nfrom .resources.playlist import YouTubePlaylist\nfrom .resources.schemas import (\n    CreatePlaylistSchema, CreatePlaylistItem, YouTubeResponse, YouTubeRequest,\n)\nfrom .resources.playlist_item import YouTubePlaylistItem\nfrom .resources.comment_thread import YouTubeCommentThread\nfrom .resources.activity import YouTubeActivity\n\nclass YouTube(BaseModel):\n    \"\"\"\n    Provides methods for interacting with the YouTube API.\n    \n    This class acts as an interface to the YouTube API. It provides methods for \n    interacting with the YouTube V3 API.\n    \n    Attributes\n    ----------\n    client_secret_file: str\n        The path to the json file containing authentication information from Google.\n    credentials_folder: str\n        The path to the folder where the generated credentials will be stored.\n    \"\"\"\n    client_secret_file: Optional[str] = ''\n    youtube_client: Optional[Any] = None\n    \n    def authenticate(self):\n        oauth: OAuth = OAuth(secrets_file=self.client_secret_file)\n        self.youtube_client = oauth.authenticate()",
  "167": "from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass SearchSchema(BaseModel):\n    id: Optional[str] = None\n    type: Optional[str] = None\n    published_at: Optional[datetime] = None\n    channel_id: Optional[str] = None\n    title: Optional[str] = None\n    description: Optional[str] = None\n    channel_title: Optional[str] = None\n    live_broadcast_content: Optional[str] = None\n    publish_time: Optional[str] = None\n",
  "168": "# Define here the models for your scraped items\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass SlidesgoItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass\n",
  "169": "from .youtube import YouTube",
  "170": "import json\n\nfrom oauthlib.common import to_unicode\n\n\ndef douban_compliance_fix(session):\n    def fix_token_type(r):\n        token = json.loads(r.text)\n        token.setdefault(\"token_type\", \"Bearer\")\n        fixed_token = json.dumps(token)\n        r._content = to_unicode(fixed_token).encode(\"utf-8\")\n        return r\n\n    session._client_default_token_placement = \"query\"\n    session.register_compliance_hook(\"access_token_response\", fix_token_type)\n\n    return session\n",
  "171": "import torch\nimport open_clip\nimport cv2\nfrom sentence_transformers import util\nfrom PIL import Image\n\n# image processing model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16-plus-240', \n                                                             pretrained=\"laion400m_e32\")\nmodel.to(device)\n\n\ndef imageEncoder(img):\n    img1 = Image.fromarray(img).convert('RGB')\n    img1 = preprocess(img1).unsqueeze(0).to(device)\n    img1 = model.encode_image(img1)\n    return img1\n\n\ndef generateScore(image1, image2):\n    test_img = cv2.imread(image1, cv2.IMREAD_UNCHANGED)\n    data_img = cv2.imread(image2, cv2.IMREAD_UNCHANGED)\n    img1 = imageEncoder(test_img)\n    img2 = imageEncoder(data_img)\n    cos_scores = util.pytorch_cos_sim(img1, img2)\n    score = round(float(cos_scores[0][0])*100, 2)\n    return score\n\n\nimage1: str = \"cat.jpeg\"\nimage2: str = \"cat2.jpeg\"\n\nprint(f\"similarity Score: \", round(generateScore(image1, image2), 2))",
  "172": "from argparse import Namespace\n\nfrom .config import Config\nfrom .docstring_generator import generate_project_docstrings\nfrom .extensions import function_code_queue, source_code_queue\nfrom .ui import create_application_config, parse_arguments\n\n\ndef main():\n    args: Namespace = parse_arguments()\n    config: Config = create_application_config(args)\n    generate_project_docstrings(\n        config=config,\n        source_code_queue=source_code_queue,\n        function_code_queue=function_code_queue,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
  "173": "import logging\nfrom rich.logging import RichHandler\nfrom rich.console import Console\nfrom rich.prompt import Prompt\nfrom rich.prompt import Confirm\n\n\nlogging_format = \"%(asctime)s - %(levelname)s - %(message)s\"\ndate_format = \"[%X]\"\nhandlers = [RichHandler()]\nlogging.basicConfig(\n    format=logging_format, datefmt=date_format, level=logging.INFO, handlers=handlers\n)\nconsole = Console()\n\nintro_path: str = \"intro.txt\"\n\nwith open(intro_path, \"r\", encoding=\"utf-8\") as f:\n    intro_txt: str = f.read()\n    \nname_prompt: str = \"To get started, what is your name?\"\ncontact_prompt: str = \"Well, {name}, what is your phone number and email address?\"\n    \ndef assistant(text: str) -> None:\n    assistant_prompt: str = f\"\\n[green bold] :adult-emoji: Assistant:[/green bold] [purple italic]{text}[/purple italic]\"\n    console.print(assistant_prompt)\n    \ndef assistant_prompt(text: str) -> str:\n    assistant_prompt: str = f\"\\n[green bold] :adult-emoji: Assistant:[/green bold] [purple italic]{text}[/purple italic]\"\n    res: str = Prompt.ask(assistant_prompt)\n    return res\n\ndef user(text: str) -> str:\n    user_prompt: str = f\"\\n[red bold] :angel-emoji: User:[/red bold] [yellow italic]{text}[/yellow italic]\"\n    console.print(user_prompt)\n    \nis_rich_great = Confirm.ask(\"Do you like rich?\")\n",
  "174": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "175": "import os\nfrom .config import Config\nfrom flask import Flask\n\n\ndef set_configuration(app: Flask):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether the config was set up successfully.\n    \"\"\"\n    config_name = os.environ.get(\"FLASK_ENV\")\n    app.config.from_object(Config[config_name])\n\n    return True",
  "176": "from google_drive import GoogleDrive\n\n\nclient_secrets_file = 'drive.json'\ndrive = GoogleDrive(client_secret_file=client_secrets_file)\ndrive.authenticate()\n",
  "177": "from .introduction import Introduction\n",
  "178": "from fastapi import FastAPI\nfrom .routers.register_routers import register_routers\n\ndef create_app():\n    app = FastAPI()\n    register_routers(app)\n    \n    @app.get('/', tags=['Home'])\n    async def get():\n        return {'message': 'hello world!'}\n    \n    return app",
  "179": "SINGLE_CHANNEL_QUERIES: list[str] = [\n    \"How many subscribers does the Ark Invest Channel have?\",\n    \"What is the id of the Ticker symbol: YOU channel?\"\n    \"What is the title of the channel with id 'UC7kCeZ53sli_9XwuQeFxLqw'?\",\n    \"How many videos does the channel Real Engineering have?\",\n    \"Which is the latest video uploaded to the Pro Robots Channel?\",\n    \"What playlists are in the Ark Invest channel\",\n    \"What are the channel sections found in the Pro Robots channel?\",\n]\n\nMUTIPLE_CHANNEL_QUERIES: list[str] = [\n    \"Between Ark Invest and Ticker Symbol: YOU, which channel was created first?\",\n    \"Among Ark Invest, Pro robots and Ticker Symbol: You, which channel(s) talk about robots?\",\n    \"Are there any similar playlists between Ark Invest and Ticker Symbol: You channels?\",\n    \"Between Ark Invest and Pro Robots, which channel has more subscribers?\"\n]",
  "180": "import argparse\nimport logging\nimport sys\n\nfrom bao.components.crawler.youtube_transcript.transcript_service import (\n    TranscriptService,\n)\nfrom bao.di import global_injector\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n# set a root logger\nhandler = logging.StreamHandler(sys.stdout)\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\nparser = argparse.ArgumentParser(description=\"Crawl transcripts from given video\")\n\nparser.add_argument(\"-v\", \"--video_url\", type=str, help=\"Youtube video URL\")\nparser.add_argument(\n    \"--language\",\n    type=str,\n    default=\"en\",\n    help=\"language that the transcripts should match. e.g. en,cn\",\n    required=False,\n)\n\nargs = parser.parse_args()\n\nif __name__ == \"__main__\":\n    transcript_service = global_injector.get(TranscriptService)\n    logger.info(f\"Crawl output: {transcript_service.settings.crawler.output_dir}\")\n\n    transcript_service.extract_from_youtube(\n        video_url=args.video_url,\n        language=args.language,\n    )\n",
  "181": "\"\"\"This module declares methods for the login module.\"\"\"\nimport sys\nimport os\nfrom dotenv import load_dotenv\nfrom flask import Blueprint, redirect, url_for\nfrom flask_dance.consumer import oauth_authorized\nfrom flask_dance.consumer.storage.sqla import SQLAlchemyStorage\nfrom flask_dance.contrib.google import google, make_google_blueprint\nfrom flask_login import current_user, login_required, login_user, logout_user\nfrom sqlalchemy.exc import OperationalError\nfrom sqlalchemy.orm.exc import NoResultFound\n\n\n# from ..extensions.extensions import db\n# from .models.models import OAuth, User\n\n\nauth = Blueprint(\"auth\", __name__)\n\n\ngoogle_blueprint = make_google_blueprint(\n    client_id=os.environ[\"GOOGLE_OAUTH_CLIENT_ID\"],\n    client_secret=os.environ[\"GOOGLE_OAUTH_CLIENT_SECRET\"],\n    scope=[\"profile\", \"email\"]\n)\n",
  "182": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "183": "from typing import Any, Dict\n\nfrom injector import inject, singleton\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables import RunnableSerializable\n\nfrom bao.components.llms import LLMs\nfrom bao.settings.settings import Settings\n\n\n@singleton\nclass Greeting:\n    @inject\n    def __init__(self, settings: Settings, llms: LLMs) -> None:\n        self.settings = settings\n        self.llms = llms\n\n    def chain(self) -> RunnableSerializable[Dict[str, Any], Dict[str, Any]]:\n        llm = self.llms.get_llm(llm_type=self.settings.chain_templates.greeting_model)\n        chat_template = ChatPromptTemplate.from_messages(\n            [\n                (\"system\", self.settings.chain_templates.greeting_template),\n                MessagesPlaceholder(variable_name=\"chat_history\"),\n                (\"human\", \"{question}\"),\n            ]\n        )\n        return chat_template | llm | StrOutputParser()  # type: ignore\n",
  "184": "from dotenv import load_dotenv\nload_dotenv()\nfrom assistant.agents import default_agent\nimport chainlit as cl\n\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set('agent', default_agent)\n\n\n@cl.on_message\nasync def main(message: cl.Message):\n    agent = cl.user_session.get('agent')\n    msg = cl.Message(content='')\n    await msg.send()\n    await cl.sleep(1)\n    msg.content = agent.invoke({'input': message.content})['output']\n    await msg.update()\n",
  "185": "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\" Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\" Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file",
  "186": "\"\"\"This module has the User model that represnts a single user.\n\nThe classes declared:\n\nUser:\n    A class representing a single user.\n\"\"\"\nfrom dataclasses import dataclass\nfrom datetime import datetime\n\nfrom flask import current_app\nfrom flask_login import UserMixin\nfrom itsdangerous import URLSafeTimedSerializer\n\nfrom ...extensions.extensions import db, ma\n\n\n@dataclass\nclass User(db.Model, UserMixin):\n    \"\"\"A class representing a single user.\"\"\"\n\n    __tablename__ = \"users\"\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(20), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n    image_file = db.Column(db.String(20), nullable=False, default=\"default.jpeg\")\n    password = db.Column(db.String(60), nullable=False)\n    account_activated = db.Column(db.Boolean, default=False)\n\n    @staticmethod\n    def user_with_name_exists(user_name: str) -> bool:\n        \"\"\"Check if user with the name exists.\n\n        Parameters\n        ----------\n        user_name: str\n            The username to check for existance.\n\n        Returns\n        -------",
  "187": "from __future__ import unicode_literals\n\nimport logging\n\nfrom oauthlib.common import generate_token, urldecode\nfrom oauthlib.oauth2 import WebApplicationClient, InsecureTransportError\nfrom oauthlib.oauth2 import LegacyApplicationClient\nfrom oauthlib.oauth2 import TokenExpiredError, is_secure_transport\nimport requests\n\nlog = logging.getLogger(__name__)\n\n\nclass TokenUpdated(Warning):\n    def __init__(self, token):\n        super(TokenUpdated, self).__init__()\n        self.token = token\n\n\nclass OAuth2Session(requests.Session):\n    \"\"\"Versatile OAuth 2 extension to :class:`requests.Session`.\n\n    Supports any grant type adhering to :class:`oauthlib.oauth2.Client` spec\n    including the four core OAuth 2 grants.\n\n    Can be used to create authorization urls, fetch tokens and access protected\n    resources using the :class:`requests.Session` interface you are used to.\n\n    - :class:`oauthlib.oauth2.WebApplicationClient` (default): Authorization Code Grant\n    - :class:`oauthlib.oauth2.MobileApplicationClient`: Implicit Grant\n    - :class:`oauthlib.oauth2.LegacyApplicationClient`: Password Credentials Grant\n    - :class:`oauthlib.oauth2.BackendApplicationClient`: Client Credentials Grant\n\n    Note that the only time you will be using Implicit Grant from python is if\n    you are driving a user agent able to obtain URL fragments.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_id=None,",
  "188": "import logging\nimport click\nfrom rich.logging import RichHandler\n\n\nLOGGER_NAME = \"reddit\"\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\",\n    handlers=[RichHandler(rich_tracebacks=True, tracebacks_suppress=[click])],\n)\nlogger = logging.getLogger(LOGGER_NAME)\n\n\nlogging.getLogger(\"clickhouse_connect\").setLevel(logging.ERROR)\nlogging.getLogger(\"clickhouse_connect\").setLevel(logging.ERROR)\nlogging.getLogger(\"numexpr\").setLevel(logging.ERROR)\n",
  "189": "from pydantic import BaseModel\nfrom typing import Optional\n\n\nclass UserBase(BaseModel):\n  first_name: str\n  last_name: str\n  email_address: str\n\n  \nclass UserCreate(UserBase):\n    password: str\n    role: str = 'user'\n    activated: bool = False\n    \nclass UserCreated(UserBase):\n    id: int\n    activation_token: str\n\nclass User(UserBase):\n    id: int\n    \n    class Config:\n        from_attributes = True\n        \nclass GetUser(BaseModel):\n    user_id: int\n    \nclass GetUsers(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10\n    \nclass ActivateUser(BaseModel):\n    user_id: int\n    activation_token: str\n    \nclass LoginUser(BaseModel):\n    email_address: str\n    password: str\n    ",
  "190": "from __future__ import unicode_literals\n\ntry:\n    from urlparse import urlparse\nexcept ImportError:\n    from urllib.parse import urlparse\n\nimport logging\n\nfrom oauthlib.common import add_params_to_uri\nfrom oauthlib.common import urldecode as _urldecode\nfrom oauthlib.oauth1 import SIGNATURE_HMAC, SIGNATURE_RSA, SIGNATURE_TYPE_AUTH_HEADER\nimport requests\n\nfrom . import OAuth1\n\n\nlog = logging.getLogger(__name__)\n\n\ndef urldecode(body):\n    \"\"\"Parse query or json to python dictionary\"\"\"\n    try:\n        return _urldecode(body)\n    except Exception:\n        import json\n\n        return json.loads(body)\n\n\nclass TokenRequestDenied(ValueError):\n    def __init__(self, message, response):\n        super(TokenRequestDenied, self).__init__(message)\n        self.response = response\n\n    @property\n    def status_code(self):\n        \"\"\"For backwards-compatibility purposes\"\"\"\n        return self.response.status_code\n",
  "191": "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\" Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\" Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file",
  "192": "\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "193": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "194": "\n\n\n\n\n\n\n\n\n",
  "195": "from youtube import YouTube\nfrom itertools import chain\n\nyoutube = YouTube()\nclient_secrets_file = '/home/lyle/Downloads/python_learning_site.json'\nyoutube.authenticate_from_client_secrets_file(client_secrets_file)\n\n# channel = youtube.find_channel_by_id('UC8butISFwT-Wl7EV0hUK0BQ')\n# video = youtube.find_video_by_id('vEQ8CXFWLZU')\nquery = 'Python programming'\nvideo_iterator = youtube.get_iterator(query)\nv1 = next(video_iterator)\nv2 = next(video_iterator)\nv3 = next(video_iterator)\n\n# video_collection = video_iterator.get_videos()\n# POSTGRES_HOST='localhost' \n# POSTGRES_PORT=5432 \n# POSTGRES_USER='lyle' \n# POSTGRES_PASSWORD='lyle'\n# POSTGRES_DB='python-learning-app'\n# video_collection.save_to_database(POSTGRES_HOST, POSTGRES_PORT, \n#                         POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB)\n# search_client = youtube.get_search_client(query)\n# prev_token, next_token, v1 = search_client.search_videos()\n# prev_token, next_token, v2 = search_client.search_videos(next_page_token=next_token)\n# prev_token, next_token, v3 = search_client.search_videos(next_page_token=next_token)\nvideos = list(chain(v1,v2,v3))\n\nif __name__ == '__main__':\n    print(len(videos))\n    for video in videos:\n        print(video)\n    # video.to_json()\n    # video.to_csv()",
  "196": "from .command import Command\n",
  "197": "from flask.cli import FlaskGroup\nfrom app import create_app\n\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\nif __name__ == \"__main__\":\n    cli()",
  "198": "",
  "199": "# -*- coding: utf-8 -*-\n\n# Resource object code\n#\n# Created by: The Resource Compiler for PyQt5 (Qt v5.14.1)\n#\n# WARNING! All changes made in this file will be lost!\n\nfrom PyQt5 import QtCore\n\nqt_resource_data = b\"\\\n\\x00\\x01\\x08\\x57\\\n\\x89\\\n\\x50\\x4e\\x47\\x0d\\x0a\\x1a\\x0a\\x00\\x00\\x00\\x0d\\x49\\x48\\x44\\x52\\x00\\\n\\x00\\x02\\x20\\x00\\x00\\x02\\x20\\x08\\x06\\x00\\x00\\x00\\xbc\\x89\\xd2\\x1c\\\n\\x00\\x00\\x00\\x04\\x73\\x42\\x49\\x54\\x08\\x08\\x08\\x08\\x7c\\x08\\x64\\x88\\\n\\x00\\x00\\x00\\x09\\x70\\x48\\x59\\x73\\x00\\x00\\x0b\\x13\\x00\\x00\\x0b\\x13\\\n\\x01\\x00\\x9a\\x9c\\x18\\x00\\x00\\x00\\x19\\x74\\x45\\x58\\x74\\x53\\x6f\\x66\\\n\\x74\\x77\\x61\\x72\\x65\\x00\\x77\\x77\\x77\\x2e\\x69\\x6e\\x6b\\x73\\x63\\x61\\\n\\x70\\x65\\x2e\\x6f\\x72\\x67\\x9b\\xee\\x3c\\x1a\\x00\\x00\\x20\\x00\\x49\\x44\\\n\\x41\\x54\\x78\\x9c\\xec\\x9d\\x77\\x7c\\x5c\\xc5\\xd5\\xf7\\x7f\\x67\\xee\\xdd\\\n\\x5d\\xed\\xaa\\x77\\xcb\\x92\\x2c\\xd9\\x96\\xdc\\x8d\\xbb\\x8d\\x01\\x1b\\xd3\\\n\\x0c\\x36\\xdd\\x20\\x9b\\x66\\x42\\x49\\x20\\x21\\x0f\\x29\\x6f\\x12\\x02\\xa9\\\n\\x22\\x4f\\xf2\\x90\\x10\\xf2\\x90\\x84\\x34\\x78\\x92\\x50\\x42\\xb5\\x31\\xa1\\\n\\x9a\\x98\\x6a\\xc0\\x06\\xdc\\x7b\\xc1\\x45\\xee\\x96\\xd5\\x7b\\xd9\\xdd\\x7b\\\n\\xe7\\xbc\\x7f\\xec\\x4a\\xc8\\xb2\\xb4\\xda\\x95\\x76\\xb5\\xbb\\xd2\\x7c\\xf9\\\n\\x08\\x4b\\x77\\x67\\xce\\x9c\\x7b\\x75\\xef\\xdc\\x9f\\x66\\xce\\x9c\\x21\\x28\\\n\\x14\\x8a\\x01\\xcd\\x92\\x7f\\x5f\\x38\\x52\\x98\\x34\\x11\\xc0\\x08\\x66\\xca\\\n\\x02\\x21\\x93\\x80\\x54\\x80\\x92\\x40\\x9c\\x00\\x46\\x3c\\x18\\x31\\x20\\x58\\\n\\x00\\xe8\\x0c\\xe8\\x00\\x34\\x02\\x04\\x3c\\x5f\\xe4\\xfd\\xf2\\x40\\x00\\xb8\\\n\\xc3\\xcf\\x9e\\x63\\x0c\\x3e\\xed\\x08\\x7b\\xbf\\x24\\x03\\x12\\x80\\x49\\x80\\\n\\x01\\xc0\\x00\\xc3\\x0d\\x42\\x2b\\x08\\x0d\\x60\\xaa\\x07\\xb8\\x96\\x81\\x2a\\\n\\x30\\xca\\x88\\xb8\\x14\\x40\\x89\\xd4\\x78\\xc7\\x4b\\xd7\\x7e\\x70\\x30\\x64\\\n\\x17\\x45\\xa1\\x50\\x84\\x1d\\xea\\xb9\\x88\\x42\\xa1\\x88\\x20\\xda\\x9f\\xd9\\\n\\x1b\\x5e\\x98\\x97\\xa7\\x59\\xb5\\x59\\x12\\x62\\x12\\xa4\\x1c\\x03\\xd0\\x30\\\n\\x06\\xd2\\x05\\x28\\x9e\\xc1\\x76\\xaf\\xa0\\xd0\\x3a\\x56\\xe4\\x6e\\x0c\\x76\\\n\\x75\\xbc\\x37\\xe5\\xfa\\x62\\xab\\xed\\xc4\\x3a\\x1d\\x37\\xc1\\x70\\x13\\xa8\\\n\\x45\\x82\\x1b\\x08\\xa8\\x00\\xf8\\x28\\x84\\xd8\\x2b\\x20\\xb7\\x99\\x2e\\x73\\\n\\xdd\\x8b\\x37\\xae\\x3e\\xd2\\xa1\\xbc\\x3f\\xcd\\x2b\\x14\\x8a\\x08\\x40\\x09\\\n\\x10\\x85\\x22\\xb2\\xa0\\xb6\\x57\\xe8\\xbc\\xd5\\xf3\\x6c\\x99\\x95\\x62\\x2e\\",
  "200": "from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service as ChromeService\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.chrome.options import Options\ni\n\noptions = Options()\noptions.add_argument(\"--headless=new\")\ndriver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\ndriver.get(\"https://leetcode.com/problems/remove-linked-list-elements\")\nparagraphs = driver.find_elements(By.TAG_NAME, \"p\")\nprint(paragraphs)\ndriver.quit()",
  "201": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A chatbot that enables the user interact with youtube over chat.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos', 'chat with youtube',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'oryks-youtube',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='youtube-assistant',\n    packages=find_packages(\n        include=[\n            'assistant',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',",
  "202": "# $Id: fi.py 9030 2022-03-05 23:28:32Z milde $\n# Author: Asko Soukka <asko.soukka@iki.fi>\n# Copyright: This module has been placed in the public domain.\n\n# New language mappings are welcome.  Before doing a new translation, please\n# read <https://docutils.sourceforge.io/docs/howto/i18n.html>.\n# Two files must be translated for each language: one in docutils/languages,\n# the other in docutils/parsers/rst/languages.\n\n\"\"\"\nFinnish-language mappings for language-dependent features of\nreStructuredText.\n\"\"\"\n\n__docformat__ = 'reStructuredText'\n\n\ndirectives = {\n      # language-dependent: fixed\n      'huomio': 'attention',\n      'varo': 'caution',\n      'code (translation required)': 'code',\n      'vaara': 'danger',\n      'virhe': 'error',\n      'vihje': 'hint',\n      't\\u00e4rke\\u00e4\\u00e4': 'important',\n      'huomautus': 'note',\n      'neuvo': 'tip',\n      'varoitus': 'warning',\n      'kehotus': 'admonition',\n      'sivupalkki': 'sidebar',\n      'aihe': 'topic',\n      'rivi': 'line-block',\n      'tasalevyinen': 'parsed-literal',\n      'ohje': 'rubric',\n      'epigraafi': 'epigraph',\n      'kohokohdat': 'highlights',\n      'lainaus': 'pull-quote',\n      'taulukko': 'table',\n      'csv-taulukko': 'csv-table',",
  "203": "from .set_config import set_configuration",
  "204": "from pydantic import BaseModel\nfrom datetime import datetime\nfrom typing import Optional\n\n\nclass Channel(BaseModel):\n    channel_id: str\n    channel_title: str\n    published_at: datetime\n    custom_url: str\n    channel_description: str\n    channel_thumbnail: str\n    views_count: int\n    videos_count: int\n    subscribers_count: int\n    \nclass Channels(BaseModel):\n    channels: list[Channel]\n    \nclass GetChannel(BaseModel):\n    channel_id: str\n    \nclass GetChannels(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10",
  "205": "from youtube import YouTube\nfrom youtube.models import Search\nfrom youtube.schemas import (\n        YouTubeRequest, YouTubeListResponse, YouTubeResponse,\n        SearchFilter, SearchOptionalParameters, SearchPart\n)\nfrom typing import Iterator\n\n\nclient_secrets_file = \"/home/lyle/oryks/backend/api/libraries/youtube.json\"\ndef get_youtube_client(client_secrets_file: str = client_secrets_file) -> YouTube:\n    youtube: YouTube = YouTube(client_secret_file=client_secrets_file)\n    client = youtube.authenticate()\n    youtube.youtube_client = client\n    return youtube\n\nyoutube: YouTube = get_youtube_client(client_secrets_file=\"/home/lyle/Downloads/test.json\")\n\n\n# query: str = ''\n# part: SearchPart = SearchPart()\n# optional_parameters: SearchOptionalParameters = SearchOptionalParameters(\n#     q=query,\n#     type=['video'],\n#     channelId=\"UCtAcpQcYerN8xxZJYTfWBMw\"\n# )\n# search_request: YouTubeRequest = YouTubeRequest(\n#     part=part, \n#     optional_parameters=optional_parameters\n# )\n# search_results: YouTubeResponse = youtube.search(search_request)\n# search_iterator: Iterator = youtube.get_search_iterator(search_request)\n# # res: YouTubeResponse = youtube.find_channel_by_name(display_name=\"Umar Jamil\")\n# # print(res.items[0])\n# res = next(search_iterator)\n# final = []\n# for x in search_iterator:\n#         for search in x:\n#                 final.append(\n#                         dict(",
  "206": "",
  "207": "\"\"\"\nThe Fitbit API breaks from the OAuth2 RFC standard by returning an \"errors\"\nobject list, rather than a single \"error\" string. This puts hooks in place so\nthat oauthlib can process an error in the results from access token and refresh\ntoken responses. This is necessary to prevent getting the generic red herring\nMissingTokenError.\n\"\"\"\n\nfrom json import loads, dumps\n\nfrom oauthlib.common import to_unicode\n\n\ndef fitbit_compliance_fix(session):\n    def _missing_error(r):\n        token = loads(r.text)\n        if \"errors\" in token:\n            # Set the error to the first one we have\n            token[\"error\"] = token[\"errors\"][0][\"errorType\"]\n        r._content = to_unicode(dumps(token)).encode(\"UTF-8\")\n        return r\n\n    session.register_compliance_hook(\"access_token_response\", _missing_error)\n    session.register_compliance_hook(\"refresh_token_response\", _missing_error)\n    return session\n",
  "208": "from .video import YouTubeVideo",
  "209": "import operator\n\n\ndef add(a: int | float, b: int | float) -> int | float:\n    \"\"\"Subtracts two numbers\n\n    Parameters\n    ----------\n    a : int or float\n        The first number to subtract.\n    b : int or float\n        The second number to subtract.\n\n    Returns\n    -------\n    int or float\n        The result of subtracting b from a.\"\"\"\n    return operator.add(a, b)\n\n\ndef subtract(a: int | float, b: int | float) -> int | float:\n    \"\"\"Subtracts two numbers\n\n    Parameters\n    ----------\n    a : int or float\n        The first number to subtract.\n    b : int or float\n        The second number to subtract.\n\n    Returns\n    -------\n    int or float\n        The result of subtracting b from a.\"\"\"\n    return operator.sub(a, b)\n\n\ndef divide(a: int | float, b: int | float) -> float:\n    \"\"\"Subtracts two numbers\n",
  "210": "import os\nfrom dotenv import load_dotenv\nfrom rich.prompt import Prompt\nfrom src.utils.display import (\n    display_intro,\n    select_number_of_posts,\n    select_topic,\n    select_search_queries,\n)\nfrom src.utils.agent import Agent\nfrom src.utils.document_loader import RedditSubLoader, TwitterTweetLoader\n\nload_dotenv()\n\n\ndef main():\n    display_intro()\n    topic = select_topic()\n    platform, keywords, accounts = select_search_queries(topic)\n    number_of_posts = select_number_of_posts()\n\n    if platform == \"reddit\":\n        document_loader = RedditSubLoader(\n            number_submissions=number_of_posts,\n            keywords=keywords,\n            subreddits=accounts,\n        )\n    elif platform == \"twitter\":\n        document_loader = TwitterTweetLoader.from_bearer_token(\n            oauth2_bearer_token=os.environ.get(\"TWITTER_BEARER_TOKEN\"),\n            number_tweets=number_of_posts,\n            twitter_users=accounts,\n            keywords=keywords,\n        )\n    else:\n        raise ValueError(f\"Platform {platform} not supported\")\n\n    agent = Agent(loader=document_loader)\n\n    agent.load_documents()",
  "211": "from ..resource import YouTubeResource\nfrom ...models import (\n    Video, VideoCategory\n)\nfrom typing import Any, Optional\nfrom ..schemas import (\n    VideoFilter, VideoOptionalParameters, VideoPart, YouTubeResponse, YouTubeRequest, \n    YouTubeRatingResponse, ThumbnailSetResponse, VideoReportReasonResponse, LanguageResponse, \n    RegionResponse, VideoReportAbuse, UploadVideo\n)\nfrom datetime import datetime\nfrom googleapiclient.http import MediaFileUpload\nfrom collections import defaultdict\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n        \n    def get_video_ratings(self, video_ids: list[str]) -> YouTubeRatingResponse:\n        filters: dict = self.generate_filter(self.generate_video_ids, VideoFilter(id=video_ids))\n        find_video_rating_request: dict = self.youtube_client.videos().getRating(\n            **filters\n        )\n        find_video_rating_result: dict[str, int|str] = find_video_rating_request.execute()\n        return self.parse_user_video_rating(find_video_rating_result)\n    \n    def generate_video_ids(self, video_filter: VideoFilter) -> dict[str, str]:\n        video_ids: str = ','.join(video_filter.id)\n        return dict(id=video_ids)\n\n    def find_video_by_id(self, video_id: str) -> Video:\n        filter: VideoFilter = VideoFilter(id=[video_id])\n        part: VideoPart = VideoPart()\n        optional_params: VideoOptionalParameters = VideoOptionalParameters()\n        request_schema: YouTubeRequest = YouTubeRequest(\n            part=part, \n            filter=filter, \n            optional_parameters=optional_params\n        )",
  "212": "from typing import Any\n\nfrom ...models import (\n    Channel,\n    ChannelContentDetails,\n    ChannelSnippet,\n    ChannelStatistics,\n    ChannelStatus,\n)\nfrom ...schemas import (\n    ChannelFilter,\n    ChannelOptionalParameters,\n    ChannelPart,\n    YouTubeListResponse,\n    YouTubeRequest,\n)\nfrom ..resource import YouTubeResource\n\n\nclass YouTubeChannel(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n\n    def parse_snippet(self, snippet_data: dict[str, Any]) -> ChannelSnippet:\n        snippet: dict = dict(**self.parse_base_snippet(snippet_data).model_dump())\n        snippet['custom_url'] = snippet_data['customUrl']\n        snippet['country'] = snippet_data.get('country', '')\n        snippet['localized'] = self.parse_localizations(snippet_data['localized'])\n        return ChannelSnippet(**snippet)\n\n    def parse_content_details(\n        self, content_details_data: dict\n    ) -> ChannelContentDetails:\n        content_details: dict = dict(\n            **self.parse_base_content_details(content_details_data).model_dump()\n        )\n        content_details['related_playlists'] = content_details_data['relatedPlaylists']\n        return ChannelContentDetails(**content_details)\n\n    def parse_statistics(self, statistics_data: dict) -> ChannelStatistics:",
  "213": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "214": "from json import loads, dumps\n\nfrom oauthlib.common import to_unicode\n\n\ndef weibo_compliance_fix(session):\n    def _missing_token_type(r):\n        token = loads(r.text)\n        token[\"token_type\"] = \"Bearer\"\n        r._content = to_unicode(dumps(token)).encode(\"UTF-8\")\n        return r\n\n    session._client.default_token_placement = \"query\"\n    session.register_compliance_hook(\"access_token_response\", _missing_token_type)\n    return session\n",
  "215": "\"\"\"This module declares the application auth models.\"\"\"\nfrom flask_dance.consumer.storage.sqla import OAuthConsumerMixin\nfrom flask_login import UserMixin\n\nfrom ...extensions.extensions import db\n\n\nclass User(UserMixin, db.Model):\n    \"\"\"This class represents a user.\"\"\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(250), unique=True)\n    email = db.Column(db.String(250), unique=True)\n    picture = db.Column(db.String(250), unique=True)\n\n\nclass OAuth(OAuthConsumerMixin, db.Model):\n    \"\"\"This class enables atomatic login.\"\"\"\n\n    user_id = db.Column(db.Integer, db.ForeignKey(User.id))\n    user = db.relationship(User)\n",
  "216": "\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "217": "from database.crud import add_channel\nfrom redis import Redis\nfrom json import loads\nfrom database.database import get_db, create_all\nfrom database.models.channel import Channel\nfrom datetime import datetime\nimport requests\nimport sys\nimport os\nfrom dotenv import load_dotenv\nfrom helpers import (\n    create_es_client, index_resource, get_channel_playlists, get_playlist_videos,\n    get_video_comments, get_video_comments_task_result, create_comments_data\n)\nfrom elasticsearch import Elasticsearch\n\nload_dotenv()\n\nurl_base = os.environ.get('URL_BASE', 'http://localhost:5000/api/v1/')\nredis_host = os.environ.get('REDIS_HOST', 'localhost')\nredis = Redis(host=redis_host)\n\nes_host = os.environ['ES_HOST']\nes_port = os.environ['ES_PORT']\n\nes_client: Elasticsearch = create_es_client(es_host, es_port)\nchannels_index = os.environ['CHANNELS_INDEX']\nplaylists_index = os.environ['PLAYLISTS_INDEX']\nvideos_index = os.environ['VIDEOS_INDEX']\n\ndef add_channel_to_db():\n    sub = redis.pubsub()\n    sub.subscribe('channels')\n    for data in sub.listen():\n        if isinstance(data['data'], bytes):\n            channel_data = loads(data['data'])\n            channel_data['published_at'] = datetime.utcnow()\n            channel = Channel(**channel_data)\n            print(channel)\n            channel = add_channel(session=get_db, channel=channel)",
  "218": "from __future__ import annotations\n\nfrom abc import ABCMeta\nfrom collections import OrderedDict\nfrom pathlib import Path\n\nfrom virtualenv.create.describe import PosixSupports, WindowsSupports\nfrom virtualenv.create.via_global_ref.builtin.ref import RefMust, RefWhen\nfrom virtualenv.create.via_global_ref.builtin.via_global_self_do import ViaGlobalRefVirtualenvBuiltin\n\n\nclass CPython(ViaGlobalRefVirtualenvBuiltin, metaclass=ABCMeta):\n    @classmethod\n    def can_describe(cls, interpreter):\n        return interpreter.implementation == \"CPython\" and super().can_describe(interpreter)\n\n    @classmethod\n    def exe_stem(cls):\n        return \"python\"\n\n\nclass CPythonPosix(CPython, PosixSupports, metaclass=ABCMeta):\n    \"\"\"Create a CPython virtual environment on POSIX platforms.\"\"\"\n\n    @classmethod\n    def _executables(cls, interpreter):\n        host_exe = Path(interpreter.system_executable)\n        major, minor = interpreter.version_info.major, interpreter.version_info.minor\n        targets = OrderedDict((i, None) for i in [\"python\", f\"python{major}\", f\"python{major}.{minor}\", host_exe.name])\n        yield host_exe, list(targets.keys()), RefMust.NA, RefWhen.ANY\n\n\nclass CPythonWindows(CPython, WindowsSupports, metaclass=ABCMeta):\n    @classmethod\n    def _executables(cls, interpreter):\n        # symlink of the python executables does not work reliably, copy always instead\n        # - https://bugs.python.org/issue42013\n        # - venv\n        host = cls.host_python(interpreter)\n        for path in (host.parent / n for n in {\"python.exe\", host.name}):  # noqa: PLC0208",
  "219": "\n\nclass ProductionConfig(BaseConfig):\n    \"\"\"Production configuration.\"\"\"\n\n    TESTING = False\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")\n\n\nConfig = {\n    \"development\": DevelopmentConfig,\n    \"test\": TestingConfig,\n    \"production\": ProductionConfig,\n    \"staging\": ProductionConfig,\n}\n",
  "220": "from abc import ABC\nfrom ..models import Person\nfrom ..nodes import Node\n\n\nclass Command(ABC):\n    def __init__(self, person: Person, node: Node) -> None:\n        super().__init__()\n        self._person: Person = person\n        self._node: Node = node\n\n    def execute(self, user_input: str) -> bool:\n        return self._node.execute(user_input=user_input)\n",
  "221": "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")",
  "222": "\"\"\"Extract the subtitle given youtube URL\"\"\"\n\nimport io\nimport logging\nfrom pathlib import Path\nfrom typing import Any, Dict, List\nfrom injector import singleton, inject\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom bao.settings.settings import Settings\n\nfrom bao.utils.strings import format_seconds, seconds_to_hh_mm_ss\n\nimport yaml\n\nlogger = logging.getLogger()\n\n\n@singleton\nclass TranscriptService:\n\n    @inject\n    def __init__(self, settings: Settings) -> None:\n        self.settings = settings\n\n    def get_title_pubdate(self, video_url: str) -> tuple:\n        r = requests.get(video_url)\n        soup = BeautifulSoup(r.text, features=\"lxml\")\n        link = soup.find_all(name=\"title\")[0]\n        title = link.text.strip()\n        pub_date = soup.find_all(name=\"meta\")[-3][\"content\"][:10]\n        return title, pub_date.replace(\"-\", \"\")\n\n    def get_transcripts(self, video_url: str, language: str = \"en\"):\n        try:\n            from youtube_transcript_api import YouTubeTranscriptApi\n        except:\n            logger.exception(\n                \"cannot import youtube_transcript_api. try 'pip install -U youtube_transcript_api' \"",
  "223": "\"\"\"This module hadles user registration, authentication and authorization.\n\nHas the following methods:\nhandle_create_user:\ncreate_user:\n\"\"\"\nfrom flask import flash, redirect, render_template, request, url_for, session\nfrom flask_login import login_user\n\nfrom ...extensions.extensions import bcrypt, db\nfrom ..models.user import User\nfrom .exceptions import (\n    EmailAddressExistsException,\n    EmailDoesNotExistsException,\n    InvalidEmailAddressFormatException,\n    InvalidPasswordFormatException,\n    InvalidToken,\n    NameExistsException,\n    NameTooLongException,\n    NameTooShortException,\n    PasswordMissmatchException,\n    PasswordTooShortException,\n)\nfrom .helpers import (\n    is_email_address_format_valid,\n    is_password_valid,\n    send_confirm_account_email,\n    send_reset_password_email,\n)\nfrom werkzeug.datastructures import FileStorage\nfrom flask import current_app, jsonify\nimport os\nimport secrets\nfrom ...utils.http_status_codes import HTTP_200_OK\n\n\nALLOWED_EXTENSIONS = {'txt', 'pdf', 'png', 'jpg', 'jpeg', 'gif'}\n\ndef allowed_file(filename: str) -> bool:\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS",
  "224": "\"\"\"Index entries adapters for sphinx.environment.\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nimport unicodedata\nfrom itertools import groupby\nfrom typing import TYPE_CHECKING, Any, Literal\n\nfrom sphinx.errors import NoUri\nfrom sphinx.locale import _, __\nfrom sphinx.util import logging\nfrom sphinx.util.index_entries import _split_into\n\nif TYPE_CHECKING:\n    from sphinx.builders import Builder\n    from sphinx.environment import BuildEnvironment\n\nlogger = logging.getLogger(__name__)\n\n\nclass IndexEntries:\n    def __init__(self, env: BuildEnvironment) -> None:\n        self.env = env\n        self.builder: Builder\n\n    def create_index(self, builder: Builder, group_entries: bool = True,\n                     _fixre: re.Pattern = re.compile(r'(.*) ([(][^()]*[)])'),\n                     ) -> list[tuple[str, list[tuple[str, Any]]]]:\n        \"\"\"Create the real index from the collected index entries.\"\"\"\n        new: dict[str, list] = {}\n\n        rel_uri: str | Literal[False]\n        index_domain = self.env.domains['index']\n        for docname, entries in index_domain.entries.items():\n            try:\n                rel_uri = builder.get_relative_uri('genindex', docname)\n            except NoUri:\n                rel_uri = False\n",
  "225": "from flask.cli import FlaskGroup\nfrom app import create_app\n\n\napp = create_app()\ncli = FlaskGroup(create_app=create_app)\n\n\nif __name__ == \"__main__\":\n    cli()",
  "226": "from .video import YouTubeVideo\n",
  "227": "from typing import Any, Dict\n\nfrom injector import inject, singleton\nfrom langchain_core.output_parsers.json import JsonOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnableSerializable\n\nfrom bao.components.llms import LLMs\nfrom bao.settings.settings import Settings\n\n\n@singleton\nclass IntentClassification:\n    @inject\n    def __init__(self, settings: Settings, llms: LLMs) -> None:\n        self.settings = settings\n        self.llms = llms\n\n    def chain(self) -> RunnableSerializable[Dict[str, Any], Dict[str, Any]]:\n        llm = self.llms.get_llm(\n            llm_type=self.settings.chain_templates.intent_classify_model\n        )\n        chat_template = ChatPromptTemplate.from_messages(\n            [\n                (\"system\", self.settings.chain_templates.intent_classify_template),\n                (\"human\", \"{question}\"),\n            ]\n        )\n        return chat_template | llm | JsonOutputParser()\n",
  "228": "",
  "229": "from .libraries.youtube import YouTube\nfrom .config.config import Config\n\n\nclient_secret_file: str = 'client_secret.json'\nyoutube: YouTube = YouTube(client_secret_file=client_secret_file)\nyoutube.authenticate()",
  "230": "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "231": "",
  "232": "from ...agent import State\nfrom ..summary import Summary\n\n\nclass GetAppointment(State):\n    def execute(self) -> None:\n        self.agent.ui.get_appointment()\n        self.agent.transition_to(Summary())\n",
  "233": "from dotenv import load_dotenv\nload_dotenv()\nimport os\n\nimport googlemaps\ngmaps = googlemaps.Client(key=os.environ['GOOGLE_MAPS_API_KEY'])\n\n# directions_result = gmaps.directions(\n#             start,\n#             end,\n#             waypoints=waypoints,\n#             mode=transit_type,\n#             units=\"metric\",\n#             optimize_waypoints=True,\n#             traffic_model=\"best_guess\",\n#             departure_time=start_time,\n# )\ndef convert_to_coords(input_address):\n    return gmaps.geocode(input_address)\n\ngmaps = googlemaps.Client(key=os.environ[\"GOOGLE_MAPS_API_KEY\"])\n\nexample_coords = convert_to_coords(\"Rachives, Nairobi Kenya\")\nprint(example_coords)",
  "234": "from .search import SearchSchema\n",
  "235": "\"\"\"This module declares methods for the login module.\"\"\"\nimport sys\nimport os\nfrom dotenv import load_dotenv\nfrom flask import Blueprint, redirect, url_for\nfrom flask_dance.consumer import oauth_authorized\nfrom flask_dance.consumer.storage.sqla import SQLAlchemyStorage\nfrom flask_dance.contrib.google import google, make_google_blueprint\nfrom flask_login import current_user, login_required, login_user, logout_user\nfrom sqlalchemy.exc import OperationalError\nfrom sqlalchemy.orm.exc import NoResultFound\n\n\n# from ..extensions.extensions import db\n# from .models.models import OAuth, User\n\n\nauth = Blueprint(\"auth\", __name__)\n\n\ngoogle_blueprint = make_google_blueprint(\n    client_id=os.environ[\"GOOGLE_OAUTH_CLIENT_ID\"],\n    client_secret=os.environ[\"GOOGLE_OAUTH_CLIENT_SECRET\"],\n    scope=[\"profile\", \"email\"]\n)\n",
  "236": "",
  "237": "",
  "238": "\"\"\"\nWritten by Joshua Willman\nFeatured in \"Modern Pyqt - Create GUI Applications for Project Management, Computer Vision, and Data Analysis\"\n\"\"\"\n# Import necessary modules\nimport sys, os\nfrom PyQt5.QtWidgets import (QApplication, QWidget, QLabel, QPushButton, QMessageBox, QMenu, \n    QFileDialog, QVBoxLayout, QSystemTrayIcon)\nfrom PyQt5.QtMultimedia import QAudioRecorder, QAudioEncoderSettings, QMultimedia\nfrom PyQt5.QtCore import Qt, QUrl\nfrom PyQt5.QtGui import QIcon, QFont\nfrom AudioRecorderStyleSheet import style_sheet\nimport resources\n\nclass AudioRecorder(QWidget):    \n\n    def __init__(self):\n        super().__init__()\n        self.initializeUI()\n\n    def initializeUI(self):\n        \"\"\"Initializethewindowanddisplayitscontentstothescreen.\"\"\"\n        self.setFixedSize(360, 540)\n        self.setWindowTitle('9.1 - Audio Recorder')\n\n        self.audio_path = \"\" # Empty variable for path to audio file\n                \n        self.setupWindow()\n        self.setupSystemTrayIcon()\n        self.show()\n\n    def setupWindow(self):\n        \"\"\"Set up widgets in the main window and the QAudioRecorder instance.\"\"\"\n        # Set up two push buttons (the app's first \"screen\")\n        self.select_path_button = QPushButton(\"Select Audio Path\")\n        self.select_path_button.setObjectName(\"SelectFile\")\n        self.select_path_button.setFixedWidth(140)\n        self.select_path_button.clicked.connect(self.selectAudioPath)\n\n        self.start_button = QPushButton()",
  "239": "",
  "240": "from typing import Any, Optional\n\nfrom oryks_google_oauth import GoogleDriveScopes, GoogleOAuth\nfrom pydantic import BaseModel\n\n\nclass GoogleDrive(BaseModel):\n    \"\"\"Provides methods for interacting with the Drive API.\n\n    This class acts as an interface to the Drive API, providing methods for interacting with\n    the Drive API.\n\n    Attributes\n    ----------\n    client_secret_file: str\n        The path to the json file containing your authentication information.\n    \"\"\"\n\n    client_secret_file: Optional[str] = None\n    authenticated: Optional[bool] = False\n    drive_client: Optional[Any] = None\n\n    def authenticate(self, client_secret_file: Optional[str] = None) -> None:\n        \"\"\"Authenticate the requests made to drive.\n\n        Used to generate the credentials that are used when authenticating requests to drive.\n\n        Parameters\n        ----------\n        client_secret_file: str\n            The path to clients secret json file from Google\n\n        Raises\n        ------\n        ValueError:\n            When the client secrets file is not provided\n        FileNotFoundError:\n            When the secrets file path is not found\n        \"\"\"\n        if client_secret_file:",
  "241": "from langchain_community.document_loaders.generic import GenericLoader\nfrom langchain_community.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain_community.document_loaders.blob_loaders.youtube_audio import (\n    YoutubeAudioLoader,\n)\nfrom langchain_core.documents import Document\nfrom os import path\n\n# Two Karpathy lecture videos\nurls = [\"https://www.youtube.com/watch?v=altvPR7x9IA\"]\n\n# Directory to save audio files\ndata_dir = \"data\"\nvideo_data_dir = \"video\"\ntranscribed_data = \"transcriptions\"\nvideo_title = \"sample\"\nsave_video_dir = path.join(data_dir, video_data_dir, video_title)\nsave_transcript_dir = path.join(data_dir, transcribed_data, video_title + \".txt\")\n\napi_key: str = \"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\"\n\nloader = GenericLoader(\n    YoutubeAudioLoader(urls, save_video_dir), OpenAIWhisperParser(api_key=api_key)\n)\ndocs = loader.load()\n\nfull_transcript = \"\"\nfor doc in docs:\n    full_transcript += doc.page_content\n\nwith open(save_transcript_dir, \"w\", encoding=\"utf-8\") as f:\n    f.write(full_transcript)\n\nprint(full_transcript)\n\n\ndef transcribe_video(video_id: str, save_video_dir: str, api_key: str) -> str:\n    url: str = f\"https://www.youtube.com/watch?v={video_id}\"\n    loader: GenericLoader = GenericLoader(\n        YoutubeAudioLoader([url], save_video_dir), OpenAIWhisperParser(api_key=api_key)",
  "242": "#!/bin/python3\n\n# $Id: rst2xetex.py 9115 2022-07-28 17:06:24Z milde $\n# Author: Guenter Milde\n# Copyright: This module has been placed in the public domain.\n\n\"\"\"\nA minimal front end to the Docutils Publisher, producing Lua/XeLaTeX code.\n\"\"\"\n\ntry:\n    import locale\n    locale.setlocale(locale.LC_ALL, '')\nexcept Exception:\n    pass\n\nfrom docutils.core import publish_cmdline\n\ndescription = ('Generates LaTeX documents from standalone reStructuredText '\n               'sources for compilation with the Unicode-aware TeX variants '\n               'XeLaTeX or LuaLaTeX. '\n               'Reads from <source> (default is stdin) and writes to '\n               '<destination> (default is stdout).  See '\n               '<https://docutils.sourceforge.io/docs/user/latex.html> for '\n               'the full reference.')\n\npublish_cmdline(writer_name='xetex', description=description)\n",
  "243": "from typing import Any\nfrom ..resource import YouTubeResource\nfrom ..schemas import (\n    YouTubeRequest, YouTubeResponse, CommentThreadFilter, CommentThreadOptionalParameters,\n    CommentThreadPart\n)\nfrom ...models import CommentThread, Comment\nfrom datetime import datetime\n\n\nclass YouTubeCommentThread(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n        \n    def generate_optional_parameters(self, optional_params: CommentThreadOptionalParameters) -> dict:\n        optional: dict = dict()\n        for key, value in optional_params.model_dump().items():\n            if value:\n                optional[key] = value\n        return optional\n    \n    def generate_filter(self, f: CommentThreadFilter) -> dict:\n        comment_filter: dict = dict()\n        for key, value in f.model_dump().items():\n            if value:\n                comment_filter[key] = value\n                break\n        return comment_filter\n    \n    def create_request_dict(self, search_schema: YouTubeRequest) -> dict[str, int|str|datetime]:\n        request_dict: dict[str, int|str|datetime] = dict()\n        request_dict['part'] = self.generate_part(search_schema.part)\n        request_dict.update(self.generate_optional_parameters(search_schema.optional_parameters))\n        request_dict.update(self.generate_filter(search_schema.filter))\n        return request_dict\n        \n    def find_video_comments(self, request: YouTubeRequest) -> YouTubeResponse:\n        \"\"\"Get a particular video's comments.\"\"\"\n        comment_thread_req = self.youtube_client.commentThreads().list(\n            **self.create_request_dict(request)",
  "244": "#!/bin/python3\n\n# $Id: rst2s5.py 9115 2022-07-28 17:06:24Z milde $\n# Author: Chris Liechti <cliechti@gmx.net>\n# Copyright: This module has been placed in the public domain.\n\n\"\"\"\nA minimal front end to the Docutils Publisher, producing HTML slides using\nthe S5 template system.\n\"\"\"\n\ntry:\n    import locale\n    locale.setlocale(locale.LC_ALL, '')\nexcept Exception:\n    pass\n\nfrom docutils.core import publish_cmdline, default_description\n\n\ndescription = ('Generates S5 (X)HTML slideshow documents from standalone '\n               'reStructuredText sources.  ' + default_description)\n\npublish_cmdline(writer_name='s5', description=description)\n",
  "245": "from ..resource import YouTubeResource\nfrom ...models import Video, Localized, Statistics, Status, VideoCategory\nfrom typing import Any, Callable, Optional\nfrom ..schemas.video import VideoFilter, VideoOptionalParameters, VideoPart\nfrom ..schemas.resource import Filter, RequestSchema, YouTubeResponse\nfrom ..schemas.rating import YouTubeRatingResponse\nfrom datetime import datetime\nfrom googleapiclient.http import MediaFileUpload\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n        \n    def get_video_ratings(self, video_ids: list[str]) -> YouTubeRatingResponse:\n        filters: dict = self.generate_filter(self.generate_video_ids, VideoFilter(id=video_ids))\n        find_video_rating_request: dict = self.youtube_client.videos().getRating(\n            **filters\n        )\n        find_video_rating_result: dict[str, int|str] = find_video_rating_request.execute()\n        return self.parse_user_video_rating(find_video_rating_result)\n    \n    def generate_video_ids(self, video_filter: VideoFilter) -> dict[str, str]:\n        video_ids: str = ','.join(video_filter.id)\n        return dict(id=video_ids)\n\n    def find_video_by_id(self, video_id: str) -> Video:\n        return self.find_videos_by_ids(video_id)[0]\n\n    def find_videos_by_ids(self, video_ids: list[str]) -> list[Video]:\n        filters: dict = self.generate_filter(self.generate_video_ids, VideoFilter(id=[video_ids]))\n        part: VideoPart = VideoPart()\n        optional_params: VideoOptionalParameters = VideoOptionalParameters()\n        request_schema: RequestSchema = RequestSchema(part=part, filter=filters, optional_parameters=optional_params)\n        request_dict = self.create_request_dict(request_schema)\n        request_dict.update(filters)\n        find_video_request: dict = self.youtube_client.videos().list(\n            **request_dict\n        )\n        find_video_result: dict[str, int|str] = find_video_request.execute()",
  "246": "",
  "247": "import torch\nimport open_clip\nimport cv2\nfrom sentence_transformers import util\nfrom PIL import Image\n\n# image processing model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16-plus-240', \n                                                             pretrained=\"laion400m_e32\")\nmodel.to(device)\n\n\ndef imageEncoder(img):\n    img1 = Image.fromarray(img).convert('RGB')\n    img1 = preprocess(img1).unsqueeze(0).to(device)\n    img1 = model.encode_image(img1)\n    return img1\n\n\ndef generateScore(image1, image2):\n    test_img = cv2.imread(image1, cv2.IMREAD_UNCHANGED)\n    data_img = cv2.imread(image2, cv2.IMREAD_UNCHANGED)\n    img1 = imageEncoder(test_img)\n    img2 = imageEncoder(data_img)\n    cos_scores = util.pytorch_cos_sim(img1, img2)\n    score = round(float(cos_scores[0][0])*100, 2)\n    return score\n\n\nimage1: str = \"cat.jpeg\"\nimage2: str = \"cat2.jpeg\"\n\nprint(f\"similarity Score: \", round(generateScore(image1, image2), 2))",
  "248": "from datetime import datetime\n\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom ..database import Base\n\n\nclass Post(Base):\n    __tablename__ = \"posts\"\n\n    id: Mapped[str] = mapped_column(primary_key=True)\n    author_id: Mapped[str] = mapped_column(ForeignKey(\"users.id\"))\n    location: Mapped[str]\n    text: Mapped[str]\n    image_url: Mapped[str]\n    date_published: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n    date_updated: Mapped[datetime] = mapped_column(\n        onupdate=datetime.utcnow, default_factory=datetime.utcnow\n    )\n\n    author = relationship(\"User\", back_populates=\"posts\")\n    bookmarks = relationship(\"Bookmark\", back_populates=\"post\")\n    likes = relationship(\"Like\", back_populates=\"post\")\n    comments = relationship(\"Comment\", back_populates=\"post\")\n    views = relationship(\"View\", back_populates=\"post\")\n",
  "249": "from collections import defaultdict\nfrom typing import Any\n\nfrom googleapiclient.http import MediaFileUpload\n\nfrom ...models import (\n    BaseContentDetails,\n    BaseSnippet,\n    Language,\n    LanguageSnippet,\n    Region,\n    RegionSnippet,\n    Video,\n    VideoAbuseReportReason,\n    VideoAbuseReportReasonSnippet,\n    VideoCategory,\n    VideoCategorySnippet,\n)\nfrom ...schemas import (\n    UploadVideo,\n    VideoFilter,\n    VideoOptionalParameters,\n    VideoPart,\n    VideoReportReasonSchema,\n    YouTubeListResponse,\n    YouTubeRatingResponse,\n    YouTubeRequest,\n)\nfrom ..resource import YouTubeResource\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n\n    def parse_snippet(self, snippet_data: dict[str, Any]) -> dict[str, Any]:\n        base_snippet: BaseSnippet = self.parse_base_snippet(snippet_data)\n        parsed_snippet: dict[str, Any] = base_snippet.model_dump()\n        parsed_snippet['channel_id'] = snippet_data['channelId']\n        parsed_snippet['channel_title'] = snippet_data['channelTitle']",
  "250": "import chainlit as cl\nfrom assistant.utils.assistant_utils import welcome_user\nfrom assistant.agent import get_agent_executor\n\n\n@cl.on_chat_start\nasync def start():\n    res = await cl.AskUserMessage(content=\"What is your name?\", timeout=30).send()\n    if res:\n        msg = cl.Message(content=\"\")\n        await msg.send()\n        msg.content = welcome_user(user_name=res['content'])\n        await msg.update()\n        \n\n@cl.on_message\nasync def main(message: cl.Message):\n    msg = cl.Message(content=\"\")\n    await msg.send()\n    query: str = message.content\n    agent_executor = get_agent_executor(query)\n    msg.content = agent_executor.invoke({\"input\": query})['output']\n    await msg.update()",
  "251": "import cv2\nfrom ultralytics import YOLO\n\n\n# model = YOLO(\"yolov9c.pt\")\n# model = YOLO(\"yolov8x.pt\")\nmodel = YOLO('yolov9c-seg.pt')\nres = model.predict(\"soccer.jpeg\", save=True)\nprint(res)",
  "252": "try:\n    from urlparse import urlparse, parse_qs\nexcept ImportError:\n    from urllib.parse import urlparse, parse_qs\n\nfrom oauthlib.common import add_params_to_uri\n\n\ndef instagram_compliance_fix(session):\n    def _non_compliant_param_name(url, headers, data):\n        # If the user has already specified the token in the URL\n        # then there's nothing to do.\n        # If the specified token is different from ``session.access_token``,\n        # we assume the user intends to override the access token.\n        url_query = dict(parse_qs(urlparse(url).query))\n        token = url_query.get(\"access_token\")\n        if token:\n            # Nothing to do, just return.\n            return url, headers, data\n\n        token = [(\"access_token\", session.access_token)]\n        url = add_params_to_uri(url, token)\n        return url, headers, data\n\n    session.register_compliance_hook(\"protected_request\", _non_compliant_param_name)\n    return session\n",
  "253": "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")",
  "254": "",
  "255": "\"\"\"This module declares the extensions used by the application.\"\"\"\nfrom flask_bcrypt import Bcrypt\nfrom flask_cors import CORS\nfrom flask_login import LoginManager\nfrom flask_mail import Mail\nfrom flask_marshmallow import Marshmallow\nfrom flask_migrate import Migrate\nfrom flask_sqlalchemy import SQLAlchemy\n\ncors = CORS()\ndb = SQLAlchemy()\nmigrate = Migrate()\nma = Marshmallow()\nbcrypt = Bcrypt()\nlogin_manager = LoginManager()\nmail = Mail()\n",
  "256": "from dataclasses import dataclass\nfrom ...extensions.extensions import db\nfrom datetime import datetime\n\n\n# @dataclass\n# class Friend(db.Model):\n#     __tablename__ = 'friends'\n#     id: int = db.Column(db.Integer, primary_key=True)\n#     user_id: int = db.Column(db.Integer, db.ForeignKey(\"users.id\"))\n#     friend_id: int = db.Column(db.Integer, db.ForeignKey(\"users.id\"))\n#     date: datetime = db.Column(db.DateTime, default=datetime.utcnow)\n\n#     user = db.relationship(\"User\", backref=\"friends\")\n#     friend = db.relationship(\"User\", backref=\"friends\")",
  "257": "from flask import Flask\nfrom .home import code\n\n\ndef register_blueprints(app: Flask) -> bool:\n    \"\"\"Register the application blueprints.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------\n    bool:\n        Whether all the blueprints were registered.\n    \"\"\"\n    app.register_blueprint(code)\n    return True",
  "258": "from typing import List\nimport os\nfrom functools import lru_cache\nimport tweepy\nfrom src import logger\nfrom src.utils.config import BLACKLIST, SEARCH_FILTERS\n\nfrom praw import Reddit\nfrom praw.models import Subreddit\n\n\n@lru_cache(maxsize=None)\ndef get_api():\n    auth = tweepy.OAuth2BearerHandler(os.environ.get(\"TWITTER_BEARER_TOKEN\"))\n    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n    return api\n\n\ndef search_users(q, count):\n    api = get_api()\n    users = api.search_users(q=q, count=count)\n    extracted_users = []\n\n    for user in users:\n        screen_name = user[\"screen_name\"]\n        followers_count = user[\"followers_count\"]\n        statuses_count = user[\"statuses_count\"]\n        description = user[\"description\"]\n        profile_url = f\"https://twitter/{screen_name}\"\n        lang = user[\"lang\"]\n\n        extracted_user = dict(\n            screen_name=screen_name,\n            profile_url=profile_url,\n            description=description,\n            followers_count=followers_count,\n            statuses_count=statuses_count,\n            lang=lang,\n        )\n        extracted_users.append(extracted_user)",
  "259": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "260": "import operator\n\n\ndef add(a: int | float, b: int | float) -> int | float:\n    \"\"\"Subtracts two numbers\n\n    Parameters\n    ----------\n    a : int or float\n        The first number to subtract.\n    b : int or float\n        The second number to subtract.\n\n    Returns\n    -------\n    int or float\n        The result of subtracting b from a.\"\"\"\n    return operator.add(a, b)\n\n\ndef subtract(a: int | float, b: int | float) -> int | float:\n    \"\"\"Subtracts two numbers\n\n    Parameters\n    ----------\n    a : int or float\n        The first number to subtract.\n    b : int or float\n        The second number to subtract.\n\n    Returns\n    -------\n    int or float\n        The result of subtracting b from a.\"\"\"\n    return operator.sub(a, b)\n\n\ndef divide(a: int | float, b: int | float) -> float:\n    \"\"\"Subtracts two numbers\n",
  "261": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "262": "# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n",
  "263": "from .view import home",
  "264": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "265": "from datetime import datetime\n\nfrom sqlalchemy import ForeignKey\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom ..database import Base\n\n\nclass View(Base):\n    __tablename__ = \"views\"\n\n    id: Mapped[str] = mapped_column(primary_key=True)\n    author_id: Mapped[str] = mapped_column(ForeignKey(\"users.id\"))\n    post_id: Mapped[str] = mapped_column(ForeignKey(\"posts.id\"))\n    view_date: Mapped[datetime] = mapped_column(default_factory=datetime.utcnow)\n\n    author = relationship(\"User\", back_populates=\"views\")\n    post = relationship(\"Post\", back_populates=\"views\")\n",
  "266": "from typing import Any, Dict\n\nfrom injector import inject, singleton\nfrom langchain.chains.question_answering import load_qa_chain\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables import RunnableSerializable\n\nfrom bao.components.llms import LLMs\nfrom bao.settings.settings import Settings\n\n\n@singleton\nclass Answering:\n    @inject\n    def __init__(self, settings: Settings, llms: LLMs) -> None:\n        self.settings = settings\n        self.llms = llms\n\n    def chain(self) -> RunnableSerializable[Dict[str, Any], Dict[str, Any]]:\n        llm = self.llms.get_llm(llm_type=self.settings.chain_templates.answer_model)\n        chat_template = ChatPromptTemplate.from_messages(\n            [\n                (\"system\", self.settings.chain_templates.answer_template),\n                MessagesPlaceholder(variable_name=\"chat_history\"),\n                (\"human\", \"{question}\"),\n            ]\n        )\n        return load_qa_chain(\n            llm=llm, chain_type=\"stuff\", verbose=True, prompt=chat_template\n        )\n",
  "267": "",
  "268": "import ast\nfrom ast import ClassDef, FunctionDef, NodeTransformer\n\nfrom pydantic import BaseModel, Field\n\nfrom .helpers import (\n    generate_class_docstring,\n    generate_function_docstring,\n    get_class_docstring,\n    get_class_methods_docstrings,\n    get_function_docstring,\n    make_docstring_node,\n)\n\n\nclass DocstringWriter(NodeTransformer, BaseModel):\n    module_code: str = Field(description=\"The modules source code\")\n\n    @property\n    def module_tree(self):\n        return ast.parse(self.module_code)\n\n    def visit_ClassDef(self, node):\n        doc_str: str = ast.get_docstring(node)\n        for tree_node in self.module_tree.body:\n            if isinstance(tree_node, ClassDef) and node.name == tree_node.name:\n                class_code: str = ast.get_source_segment(self.module_code, node)\n                print(class_code)\n                class_code_docstring: str = generate_class_docstring(class_code)\n                class_dcstr = get_class_docstring(class_code_docstring)\n                new_docstring_node = make_docstring_node(class_dcstr)\n                if not doc_str:\n                    node.body.insert(0, new_docstring_node)\n                class_mathods_dcst: dict[str, str] = get_class_methods_docstrings(\n                    class_code_docstring\n                )\n                for class_node in node.body:\n                    if isinstance(class_node, FunctionDef):\n                        method_docs: str = class_mathods_dcst[class_node.name]\n                        new_docstring_node = make_docstring_node(method_docs)",
  "269": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A chatbot that enables the user interact with youtube over chat.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos', 'chat with youtube',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'oryks-youtube',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='youtube-assistant',\n    packages=find_packages(\n        include=[\n            'assistant',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',",
  "270": "\"\"\"This module delares helper methods for the whole app.\n\nDeclares the following config:\n\nset_configuration:\n    For setting the apps configuration.\nregister_blueprints:\n    For registering the application blueprints.\nregister_extensions:\n    For registering the application extensions.\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\nfrom flask import Flask\n\nfrom ..auth.views import auth\nfrom ..config.config import Config\nfrom ..exceptions.exceptions import DatabaseNotConnectedException\nfrom ..extensions.extensions import bcrypt, cors, db, login_manager, ma, mail, migrate\nfrom ..home.views import home\nfrom ..post.views import post\nfrom ..utils.utils import check_if_database_exists, create_db_conn_string\n\nload_dotenv()\n\n\ndef set_configuration(app):\n    \"\"\"Set the application configuration.\n\n    The application configuration will depend on the\n    environment i.e Test, Development, Staging or Production.\n\n    Parameters\n    ----------\n    app: flask.Flask\n        A flask app instance\n\n    Returns\n    -------",
  "271": "# Streamlit application for New York Housing Market Explorer\n\n# Required imports\nimport streamlit as st\nimport pandas as pd\nfrom llama_index import SimpleDirectoryReader, ServiceContext, StorageContext, VectorStoreIndex\nfrom llama_index.llms import OpenAI\nfrom llama_index.embeddings import FastEmbedEmbedding\nfrom qdrant_client import QdrantClient\nimport json\nimport os\nfrom sqlalchemy import create_engine\nfrom llama_index import SQLDatabase, ServiceContext\nfrom llama_index.indices.struct_store import NLSQLTableQueryEngine\nfrom pathlib import Path\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\nfrom llama_index.query_engine import (\n    SQLAutoVectorQueryEngine,\n    RetrieverQueryEngine,\n)\nfrom llama_index.tools.query_engine import QueryEngineTool\nfrom llama_index.indices.vector_store import VectorIndexAutoRetriever\n\nfrom llama_index.indices.vector_store.retrievers import (\n    VectorIndexAutoRetriever,\n)\nfrom llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\nfrom llama_index.query_engine.retriever_query_engine import (\n    RetrieverQueryEngine,\n)\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nst.set_page_config(layout=\"wide\")\nwrite_dir = Path(\"textdata\")\n\n# Initialize Qdrant client\nclient = QdrantClient(\n    url=os.environ['QDRANT_URL'], ",
  "272": "from google_drive import GoogleDrive\n\n\nclient_secrets_file = 'drive.json'\ndrive = GoogleDrive(client_secret_file=client_secrets_file)\ndrive.authenticate()\n",
  "273": "from pydantic_settings import BaseSettings\n\n\nclass BaseConfig(BaseSettings):\n    max_results: int = 10",
  "274": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "275": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "276": "from .video import YouTubeVideo\n",
  "277": "import torch\nimport os\nfrom torch import nn\nfrom torchvision import transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport random\n\n\nclass MaizeNet(nn.Module):\n  def __init__(self, K) -> None:\n      super(MaizeNet, self).__init__()\n\n      self.conv_layers = nn.Sequential(\n          # convolution 1\n          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.MaxPool2d(2),\n          # Convolution 2\n          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.MaxPool2d(2),\n          # Convolution 3\n          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),",
  "278": "from typing import Any\nfrom scrapy import Spider\nfrom scrapy.http import Response\nfrom scrapy.linkextractors import LinkExtractor \n\n\nclass SlidesLinkExtractor(Spider):\n    name: str = \"links-extractor\"\n    \n    start_urls: list[str] = [\n        \"https://slidesgo.com/\"\n    ]\n    \n    def __init__(self, name=None, **kwargs): \n        super().__init__(name, **kwargs) \n  \n        self.link_extractor = LinkExtractor(unique=True) \n  \n    def parse(self, response: Response, **kwargs: Any) -> Any: \n        self.logger.info(\"Links spider\")\n        links = response.css('li.w-1\\/2 a::attr(href)') \n  \n        for link in links: \n            yield {\n                    \"url\": link.get(), \n                }",
  "279": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "280": "import atexit\nimport os\nimport sys\nimport json\nfrom rich.console import Console\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nimport chromadb\nfrom chromadb.config import Settings\nimport tiktoken\nfrom src import logger\nfrom src.utils.chains import (\n    get_retrieval_qa_chain,\n    summarize_tweets,\n)\nfrom src.utils.data_processing import (\n    get_texts_from_documents,\n    get_metadatas_from_documents,\n)\nfrom src.utils.display import display_bot_answer, display_summary_and_questions\nfrom src.utils.document_loader import TwitterTweetLoader\nfrom src.utils.prompts import summarization_question_template, summarization_template\n\n\nclass TwitterAgent(object):\n    def __init__(\n        self,\n        twitter_users,\n        keywords,\n        number_tweets,\n        persist_db=True,\n    ):\n        self.twitter_users = twitter_users\n        self.keywords = keywords\n        self.number_tweets = number_tweets\n        self.loaded_documents = []\n        self.embeddings = OpenAIEmbeddings()\n        self.persist_db = persist_db\n        self.chain = None\n        self.client = None",
  "281": "from .view import code",
  "282": "# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n\n\n# useful for handling different item types with a single interface\nfrom itemadapter import ItemAdapter\n\n\nclass SlidesgoPipeline:\n    def process_item(self, item, spider):\n        return item\n",
  "283": "\"\"\"Sphinx environment adapters\"\"\"\n",
  "284": "from .....libraries.youtube import YouTube",
  "285": "import logging\n\nfrom .oauth1_auth import OAuth1\nfrom .oauth1_session import OAuth1Session\nfrom .oauth2_auth import OAuth2\nfrom .oauth2_session import OAuth2Session, TokenUpdated\n\n__version__ = \"1.3.1\"\n\nimport requests\n\nif requests.__version__ < \"2.0.0\":\n    msg = (\n        \"You are using requests version %s, which is older than \"\n        \"requests-oauthlib expects, please upgrade to 2.0.0 or later.\"\n    )\n    raise Warning(msg % requests.__version__)\n\nlogging.getLogger(\"requests_oauthlib\").addHandler(logging.NullHandler())\n",
  "286": "import cv2\nfrom ultralytics import YOLO\n\n\n# model = YOLO(\"yolov9c.pt\")\n# model = YOLO(\"yolov8x.pt\")\nmodel = YOLO('yolov9c-seg.pt')\nres = model.predict(\"soccer.jpeg\", save=True)\nprint(res)",
  "287": "SIMPLE_QUERY: list[str] = [\n    \"\"\"In Jonh Coogans video about 'Being a billionare' find the comment by 'author' and reply to it by disagreeing\"\"\",\n    \n]\n\nsamples: str = \"\"\"\nI do not agree with the comment by Lyle on John Coogans video on 'Billionares'. Craft a reply that \nclearly states this, maake it professional.\nI want to subscribe/unsubscribe to this channel\n\"\"\"",
  "288": "from .resource import Resource\nfrom pydantic import Field\nfrom datetime import datetime\n\n\nclass Channel(Resource):\n    \"\"\"This class represnets a youtube channel.\"\"\"\n    subscribers: int = Field(description='The number of subscribers for this channel.')\n    date_created: datetime = Field(description='The date and time this channel was created.')",
  "289": "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\" Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\" Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file",
  "290": "from dotenv import load_dotenv\nload_dotenv()\nimport chainlit as cl\nfrom farm_agent.agents import agent\nfrom farm_agent.utils import load_model, evaluate_image\nfrom PIL import Image\nimport io\n\n\nuser_location: str = None\nuser_name: str = None\nwelcome_text: str = \"\"\"\nHello there. This is an application that helps farmers monitor the health level of their crops. \nStart by giving me your name and location, then upload an image of your crops. I will analyze it to \ndetermine the diasease or pest that affects it and then tell you how to deal with the pest or \ndisease and where to purchase pesticides or fungicides.\n\"\"\"\n\n@cl.on_chat_start\nasync def start():\n    cl.user_session.set(\"agent\", agent)\n    await cl.Message(content=welcome_text).send()\n    user_name = await cl.AskUserMessage(content=\"What is your name?\", timeout=120).send()\n    user_location = await cl.AskUserMessage(content=\"Where are you from?\", timeout=120).send()\n    res = await cl.AskActionMessage(\n        content=\"Would you like to determine if your crops are infected by a disease or by pests?\",\n        actions=[\n            cl.Action(name=\"Check for diseases\", value=\"diseases\", label=\" Check for diseases\"),\n            cl.Action(name=\"Check for Pests\", value=\"pests\", label=\" Check for Pests\")\n        ]\n    ).send()\n    if res and res.get(\"value\") == \"diseases\":\n        files = None\n        # Wait for the user to upload a file\n        while files == None:\n            files = await cl.AskFileMessage(\n                content=f\"{user_name['content']}, start by uploading an image of your crop.\", \n                accept=[\"image/jpeg\", \"image/png\", \"image/jpg\"]\n            ).send()\n        # Decode the file",
  "291": "\"\"\"Twitter document loader.\"\"\"\nfrom __future__ import annotations\nimport os\nfrom abc import ABC, abstractmethod\nfrom typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Sequence, Union\n\nfrom praw import Reddit\nfrom praw.models import Submission, MoreComments\nfrom rich.console import Console\nfrom contextlib import nullcontext\n\nfrom langchain.docstore.document import Document\n\nfrom src.utils.search import (\n    search_tweets_by_keywords,\n    search_tweets_by_usernames,\n)\n\nif TYPE_CHECKING:\n    import tweepy\n    from tweepy import OAuth2BearerHandler, OAuthHandler\n\n\ndef _dependable_tweepy_import() -> tweepy:\n    try:\n        import tweepy\n    except ImportError:\n        raise ValueError(\n            \"tweepy package not found, please install it with `pip install tweepy`\"\n        )\n    return tweepy\n\n\nclass DocumentLoader(ABC):\n    @property\n    @abstractmethod\n    def source(self) -> str:\n        pass\n\n    @abstractmethod",
  "292": "",
  "293": "from pydantic import BaseModel\nfrom datetime import datetime\nfrom typing import Optional\n\n\nclass Video(BaseModel):\n    video_id: str\n    video_title: str\n    channel_id: str\n    published_at: datetime\n    video_description: str\n    video_thumbnail: str\n    views_count: int\n    likes_count: int\n    comments_count: int\n    video_duration: str\n    \nclass Videos(BaseModel):\n    videos: list[Video]\n    \nclass GetVideo(BaseModel):\n    video_id: str\n    \nclass GetVideos(BaseModel):\n    offset: Optional[int] = 0\n    limit: Optional[int] = 10",
  "294": "from .channel_section import YouTubeChannelSection",
  "295": "",
  "296": "from .get_apartment_description import GetApartmentDescription\n",
  "297": "import torch\nimport clip\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\n\nimage = preprocess(Image.open(\"cat.jpeg\")).unsqueeze(0).to(device)\nlabels: list[str] = [\"a diagram\", \"a dog\", \"a cat\"]\ntext = clip.tokenize(labels).to(device)\n\nwith torch.no_grad():\n    image_features = model.encode_image(image)\n    text_features = model.encode_text(text)\n    \n    logits_per_image, logits_per_text = model(image, text)\n    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n\nprint(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\nprint(labels[probs.argmax(-1)[0]])\n",
  "298": "import abc\nimport collections\nimport collections.abc\nimport functools\nimport inspect\nimport operator\nimport sys\nimport types as _types\nimport typing\nimport warnings\n\n__all__ = [\n    # Super-special typing primitives.\n    'Any',\n    'ClassVar',\n    'Concatenate',\n    'Final',\n    'LiteralString',\n    'ParamSpec',\n    'ParamSpecArgs',\n    'ParamSpecKwargs',\n    'Self',\n    'Type',\n    'TypeVar',\n    'TypeVarTuple',\n    'Unpack',\n\n    # ABCs (from collections.abc).\n    'Awaitable',\n    'AsyncIterator',\n    'AsyncIterable',\n    'Coroutine',\n    'AsyncGenerator',\n    'AsyncContextManager',\n    'Buffer',\n    'ChainMap',\n\n    # Concrete collection types.\n    'ContextManager',\n    'Counter',",
  "299": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright (c) 2005-2010 ActiveState Software Inc.\n# Copyright (c) 2013 Eddy Petrior\n\n\"\"\"Utilities for determining application-specific dirs.\n\nSee <http://github.com/ActiveState/appdirs> for details and usage.\n\"\"\"\n# Dev Notes:\n# - MSDN on where to store app data files:\n#   http://support.microsoft.com/default.aspx?scid=kb;en-us;310294#XSLTH3194121123120121120120\n# - Mac OS X: http://developer.apple.com/documentation/MacOSX/Conceptual/BPFileSystem/index.html\n# - XDG spec for Un*x: http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html\n\n__version__ = \"1.4.4\"\n__version_info__ = tuple(int(segment) for segment in __version__.split(\".\"))\n\n\nimport sys\nimport os\n\nPY3 = sys.version_info[0] == 3\n\nif PY3:\n    unicode = str\n\nif sys.platform.startswith('java'):\n    import platform\n    os_name = platform.java_ver()[3][0]\n    if os_name.startswith('Windows'): # \"Windows XP\", \"Windows 7\", etc.\n        system = 'win32'\n    elif os_name.startswith('Mac'): # \"Mac OS X\", etc.\n        system = 'darwin'\n    else: # \"Linux\", \"SunOS\", \"FreeBSD\", etc.\n        # Setting this to \"linux2\" is not ideal, but only Windows or Mac\n        # are actually checked for and the rest of the module expects\n        # *sys.platform* style strings.\n        system = 'linux2'\nelse:",
  "300": "from .channel import Channel",
  "301": "# Define here the models for your spider middleware\n#\n# See documentation in:\n# https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n# useful for handling different item types with a single interface\nfrom itemadapter import is_item, ItemAdapter\n\n\nclass SlidesgoSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(self, response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(self, response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, or item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(self, response, exception, spider):\n        # Called when a spider or process_spider_input() method",
  "302": "from google_drive import GoogleDrive\n\n\nclient_secrets_file = 'drive.json'\ndrive = GoogleDrive(client_secret_file=client_secrets_file)\ndrive.authenticate()\n",
  "303": "import torch\nimport os\nfrom torch import nn\nfrom torchvision import transforms\nimport numpy as np\nimport os\nfrom PIL import Image\nimport torch\nimport os\nfrom torch import nn\nimport torch.nn.functional as F\nimport random\n\n\nclass MaizeNet(nn.Module):\n  def __init__(self, K) -> None:\n      super(MaizeNet, self).__init__()\n\n      self.conv_layers = nn.Sequential(\n          # convolution 1\n          nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(32),\n          nn.MaxPool2d(2),\n          # Convolution 2\n          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(64),\n          nn.MaxPool2d(2),\n          # Convolution 3\n          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n          nn.ReLU(),\n          nn.BatchNorm2d(128),\n          nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),",
  "304": "",
  "305": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A chatbot that enables the user interact with youtube over chat.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos', 'chat with youtube',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'oryks-youtube',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='youtube-assistant',\n    packages=find_packages(\n        include=[\n            'assistant',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',",
  "306": "from collections import defaultdict\nfrom typing import Any\n\nfrom googleapiclient.http import MediaFileUpload\n\nfrom ...models import (\n    BaseContentDetails,\n    BaseSnippet,\n    Language,\n    LanguageSnippet,\n    Region,\n    RegionSnippet,\n    Video,\n    VideoAbuseReportReason,\n    VideoAbuseReportReasonSnippet,\n    VideoCategory,\n    VideoCategorySnippet,\n)\nfrom ...schemas import (\n    UploadVideo,\n    VideoFilter,\n    VideoOptionalParameters,\n    VideoPart,\n    VideoReportReasonSchema,\n    YouTubeListResponse,\n    YouTubeRatingResponse,\n    YouTubeRequest,\n)\nfrom ..resource import YouTubeResource\n\n\nclass YouTubeVideo(YouTubeResource):\n    def __init__(self, youtube_client: Any) -> None:\n        super().__init__(youtube_client)\n\n    def parse_snippet(self, snippet_data: dict[str, Any]) -> dict[str, Any]:\n        base_snippet: BaseSnippet = self.parse_base_snippet(snippet_data)\n        parsed_snippet: dict[str, Any] = base_snippet.model_dump()\n        parsed_snippet['channel_id'] = snippet_data['channelId']\n        parsed_snippet['channel_title'] = snippet_data['channelTitle']",
  "307": "#!/usr/bin/env python\nfrom __future__ import with_statement\n\nimport logging\nimport optparse\nimport os\nimport os.path\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport itertools\n\n__version__ = '0.5.7'\n\n\nlogger = logging.getLogger()\n\n\nenv_bin_dir = 'bin'\nif sys.platform == 'win32':\n    env_bin_dir = 'Scripts'\n\n\nclass UserError(Exception):\n    pass\n\n\ndef _dirmatch(path, matchwith):\n    \"\"\"Check if path is within matchwith's tree.\n\n    >>> _dirmatch('/home/foo/bar', '/home/foo/bar')\n    True\n    >>> _dirmatch('/home/foo/bar/', '/home/foo/bar')\n    True\n    >>> _dirmatch('/home/foo/bar/etc', '/home/foo/bar')\n    True\n    >>> _dirmatch('/home/foo/bar2', '/home/foo/bar')\n    False\n    >>> _dirmatch('/home/foo/bar2/etc', '/home/foo/bar')",
  "308": "from argparse import ArgumentParser\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\nimport os\nfrom os import path\n\nfrom .config import Config\nfrom .docstring_generator import generate_docstrings\nfrom .extensions import failed_modules_queue, modules_queue, processed_modules_queue\n\nparser: ArgumentParser = ArgumentParser()\nparser.add_argument(\"--path\", nargs=\"?\", default=\".\", type=str)\nparser.add_argument(\"--OPENAI_API_KEY\", nargs=\"?\", default=\"\", type=str)\nargs = parser.parse_args()\nsource_code_dir: str = args.path\n\nif not path.exists(source_code_dir):\n    print(f\"The target directory '{source_code_dir}' doesn't exist\")\n    raise SystemExit(1)\n\nif not args.OPENAI_API_KEY and not os.environ.get(\"OPENAI_API_KEY\", None):\n    print(\"You have not provided the open ai api key.\")\n    raise SystemExit(1)\n\nconfig: Config = Config(path=source_code_dir)\ngenerate_docstrings(\n    config=config,\n    modules_queue=modules_queue,\n    processed_modules_queue=processed_modules_queue,\n    failed_modules_queue=failed_modules_queue,\n)\n",
  "309": "from pydantic import BaseSettings\n\n\nclass Settings(BaseSettings):\n    mongodb_uri: str\n    mongodb_database: str\n\n\nsettings = Settings()\n",
  "310": "from .google_drive import GoogleDrive\n",
  "311": "import ast\nfrom ast import AST, FunctionDef, NodeTransformer\n\nfrom .config import Config\nfrom .helpers import generate_doc_string, make_docstring_node\nfrom .model_parsers import parse_function_docstr\n\n\nclass FunctionTransformer(NodeTransformer):\n    def __init__(self, config: Config, function_src: str) -> None:\n        super().__init__()\n        self._config: Config = config\n        self._function_src = function_src\n\n    def visit_FunctionDef(self, node: FunctionDef) -> None:\n        ast_tree: AST = ast.parse(self._function_src)\n        function_node: AST = ast_tree.body[0]\n        docstring: str = ast.get_docstring(node=node)\n        if function_node.name == node.name:\n            if not docstring:\n                src_code: str = ast.unparse(node)\n                func_docstr: str = generate_doc_string(\n                    src_code=src_code, config=self._config\n                )\n                doc_str: str = parse_function_docstr(func_docstr.strip())\n                if doc_str:\n                    dcstr_node: AST = make_docstring_node(doc_str)\n                    node.body.insert(0, dcstr_node)\n            elif self._config.overwrite_function_docstring:\n                src_code: str = ast.unparse(node)\n                func_docstr: str = generate_doc_string(\n                    src_code=src_code, config=self._config\n                )\n                doc_str: str = parse_function_docstr(func_docstr.strip())\n                if doc_str:\n                    dcstr_node: AST = make_docstring_node(doc_str)\n                    node.body[0] = dcstr_node\n        return node\n",
  "312": "from setuptools import find_packages, setup\nfrom pip._vendor import tomli\n\n# For consistent encoding\nfrom codecs import open\nfrom os import path\n\n# The directory containing this file\nHERE = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(HERE, 'README.md'), encoding='utf-8') as f:\n    LONG_DESCRIPTION = f.read()\n\nwith open('pyproject.toml', 'r') as f:\n    VERSION = tomli.load(f)['tool']['commitizen']['version']\n\nDESCRIPTION = 'A chatbot that enables the user interact with youtube over chat.'\n\nkey_words = [\n    'youtube', 'youtube-api', 'youtube comments', 'youtube videos', 'chat with youtube',\n    'youtube channels', 'youtube comment thread', 'create youtube playlist'\n]\n\ninstall_requires = [\n    'oryks-youtube',\n    'pydantic',\n    'pydantic-settings'\n]\n\nsetup(\n    name='youtube-assistant',\n    packages=find_packages(\n        include=[\n            'assistant',\n        ]\n    ),\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description_content_type='text/markdown',",
  "313": "\"\"\"This module declares the app configuration.\n\nThe classes include:\n\nBaseConfig:\n    Has all the configurations shared by all the environments.\n\n\"\"\"\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nclass BaseConfig:\n    \"\"\"Base configuration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass DevelopmentConfig(BaseConfig):\n    \"\"\"Development confuguration.\"\"\"\n\n    DEBUG = True\n    TESTING = False\n    SECRET_KEY = os.environ.get(\n        \"SECRET_KEY\", \"df0331cefc6c2b9a5d0208a726a5d1c0fd37324feba25506\"\n    )\n\n\nclass TestingConfig(BaseConfig):\n    \"\"\"Testing configuration.\"\"\"\n\n    TESTING = True\n    SECRET_KEY = os.environ.get(\"SECRET_KEY\", \"secret-key\")",
  "314": "from ..auth.models.user import User\nfrom ..post.models.post_model import Post\nfrom ..post.models.like_model import Like\nfrom ..post.models.comment_model import Comment\nfrom faker import Faker\nfrom datetime import datetime, timedelta\nfake = Faker()\nimport random\nfrom ..extensions.extensions import db, bcrypt\n\ndef generate_users(count: int = 10) -> list[User]:\n    \"\"\"Generate ten random users.\"\"\"\n    profile_pictures = (f'profile-{i}.jpg' for i in range(count))\n    names = (fake.name() for _ in range(count))\n    emails = (fake.email() for i in range(count))\n    password = hashed_password = bcrypt.generate_password_hash(\"password\").decode(\n        \"utf-8\"\n    )\n    return [\n        User(\n            username=name,\n            email=email,\n            image_file=profile_pic,\n            password=password,\n            account_activated=True\n        ) \n        for profile_pic, name, email in zip(profile_pictures, names, emails)\n    ]\n\ndef generate_posts(authors: list[User], count: int = 100) -> list[Post]:\n    \"\"\"Generate posts.\"\"\"\n    cities = [fake.city() for _ in range(10)]\n    posts_text = [fake.text() for _ in range(count)]\n    post_images = [f'feed-{i}.jpg' for i in range(8)]\n    dates_published = (datetime.now() + timedelta(minutes=random.randint(1,60)) for _ in range(count))\n    return [\n        Post(\n            author=random.choice(authors),\n            location=random.choice(cities),\n            text=text,",
  "315": "from sqlalchemy.orm import Session\nfrom .models.channel import Channel\nfrom sqlalchemy.exc import IntegrityError\n\ndef add_channel(session: Session, channel: Channel):\n    with session() as db:\n        try:\n            db.add(channel)\n            db.commit()\n            db.refresh(channel)\n        except IntegrityError:\n            return None\n        else:\n            return channel"
}